<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.14" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="MLOps_Model_Server_Application_Performance_Analyser" onTaskError="continueJobExecution" priority="normal" projectName="3. MLOps Model Server Workflows" tags="Model Inference,MLOps,Triton" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd">
  <variables>
    <variable advanced="false" description="GRPC inference url of the model server (e.g. localhost:8001)." group="Model Server" hidden="false" name="GRPC_INFERENCE_URL" value=""/>
    <variable advanced="false" description="Name of the model to be tested." group="Model Server" hidden="false" model="PA:LIST(simple,simple_identity,simple_int8,simple_sequence,simple_string,densenet_onnx,inception_graphdef)" name="MODEL_NAME" value="simple"/>
    <variable advanced="true" description="Container platform used for executing the workflow tasks." group="Container Parameters" hidden="false" model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker"/>
    <variable advanced="true" description="Name of the container image being used to run the workflow tasks." group="Container Parameters" hidden="false" model="PA:LIST(,nvcr.io/nvidia/tritonserver:22.10-py3-sdk)" name="CONTAINER_IMAGE" value="nvcr.io/nvidia/tritonserver:22.10-py3-sdk"/>
    <variable advanced="false" description="The option concurrency-range &lt;start&gt;:&lt;end&gt;:&lt;step&gt; enables data collection for a range of request concurrency levels." group="Model Server" hidden="false" model="PA:REGEXP(^(\d+):(\d+):(\d+)$)?" name="CONCURRENCY_RANGE" value="1:4:1"/>
  </variables>
  <description>
    <![CDATA[ Analyze the performance of a deployed model by sending multiple inferences concurrently ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="ai-mlops-dashboard"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/model_server.png"/>
<info name="Documentation" value="PAIO/PAIOUserGuide.html"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Model_Performance_Analyser" preciousResult="true" runAsMe="true">
      <description>
        <![CDATA[ Analyze the performance of a deployed model by sending multiple inferences concurrently ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/model_server.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html"/>
      </genericInformation>
      <selection>
        <script type="static">
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/check_node_source_name/raw"/>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.io.FileType

String GRPC_INFERENCE_URL = variables.get("GRPC_INFERENCE_URL")
String MODEL_NAME = variables.get("MODEL_NAME")
String CONCURRENCY_RANGE = variables.get("CONCURRENCY_RANGE")

// -------------------------------------------------------------
// Execute the performance analyzer on the selected model
try {
    def command = "perf_analyzer -i grpc -u $GRPC_INFERENCE_URL -m $MODEL_NAME --concurrency-range $CONCURRENCY_RANGE -f perf.csv"
    println "Running " + command
    def output = command.execute().text
    println(output)
} catch(java.io.IOException e) {
    println("This model can not be tested using the performance analyzer!")
}
// -------------------------------------------------------------

// Read the CSV output file
def inputFile = new File('perf.csv')
if (inputFile.exists()) {
    println "Parsing the results from the perf.csv file"
    def lines = inputFile.readLines()
    def headers = lines[0].split(',')
    // Generate the HTML output
    def html = new StringBuilder()
    html << """
    <!DOCTYPE html>
    <html>
    <head>
    <style>
      table {
        width: 100%;
        border-collapse: collapse;
      }
      th, td {
        padding: 8px;
        text-align: left;
        border-bottom: 1px solid #ddd;
      }
      th {
        background-color: rgb(51, 122, 183);
        color: white; /* Optional - this will set the text color to white */
        font-weight: bold;
      }
      tr:nth-child(even) {
        background-color: #f2f2f2;
      }
    </style>
    </head>
    <body>
    <table>
    """
    // Add table headers
    html << '<tr>'
    headers.each { header ->
        html << "<th>${header}</th>"
    }
    html << '</tr>'
    // Add table data
    lines.drop(1).each { line ->
        def values = line.split(',')
        html << '<tr>'
        values.each { value ->
            html << "<td>${value}</td>"
        }
        html << '</tr>'
    }
    byte[] htmlBytes = html.toString().getBytes("UTF-8")
    result = htmlBytes
    println "Done"
} else {
  println "File perf.csv not found"
  result = ""
}
resultMetadata.put("file.extension", ".html")
resultMetadata.put("file.name", "output.html")
resultMetadata.put("content.type", "text/html")

]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            151.48333740234375
        </positionTop>
        <positionLeft>
            347.91668701171875
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:3178px;
            height:4892px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-146.48333740234375px;left:-342.91668701171875px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" style="top: 151.483px; left: 347.917px;" id="jsPlumb_1_22"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Analyze the performance of a deployed model by sending multiple inferences concurrently"><img src="/automation-dashboard/styles/patterns/img/wf-icons/model_server.png" width="20px">&nbsp;<span class="name">Model_Performance_Analyser</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div style="position: absolute; height: 20px; width: 20px; left: 425.5px; top: 181px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: #a8a095; --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
