<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.14" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Train_Deploy_Drift_Model_For_Iris_Flowers_Classification" onTaskError="continueJobExecution" priority="normal" projectName="5. MLOps Workflows Example" tags="Samples,Big Data,Machine Learning,Analytics" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd">
  <variables>
    <variable advanced="true" description="Working directory for the data space used to transfer files automatically between the workflow tasks." hidden="false" model="PA:LIST(.,$HOME/,$WORK/,$SCRATCH/)" name="WORK_DIR" value="."/>
    <variable advanced="true" description="Container platform used for executing the workflow tasks." group="Container Parameters" hidden="false" model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker"/>
    <variable advanced="true" description="If True, it will activate the use of GPU for the workflow tasks on the selected container platform." group="Container Parameters" hidden="false" model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="false"/>
    <variable advanced="true" description="Name of the container image being used." group="Container Parameters" hidden="false" model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/rapidsai,docker://activeeon/nvidia:rapidsai)" name="CONTAINER_IMAGE" value=""/>
    <variable advanced="false" description="Name of the model to be deployed" hidden="false" name="MODEL_NAME" value="iris-classification-model-${PA_JOB_ID}"/>
    <variable advanced="false" description="Version of the model to be deployed." hidden="false" model="PA:Integer" name="MODEL_VERSION" value="1"/>
    <variable advanced="false" description="ID of the model server used to deploy the trained model" hidden="false" model="PA:Integer?" name="MODEL_SERVER_ID" value=""/>
    <variable advanced="false" hidden="true" name="MODEL_NAME_DDD" value="${MODEL_NAME}-ddd"/>
  </variables>
  <description>
    <![CDATA[ Train a drift model for Iris flowers classification using the Spot_The_Diff and deploy it to the MLOps Model Server. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="ai-mlops-dashboard"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/ml_data_drift.png"/>
<info name="Documentation" value="PAIO/PAIOUserGuide.html#_mlops_dashboard"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Load_Iris_Dataset" preciousResult="true">
      <description>
        <![CDATA[ Load and return the iris dataset classification. ]]>
      </description>
      <variables>
        <variable advanced="false" description="If False, the task will be ignored, it will not be executed." inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="True"/>
        <variable advanced="false" description="Method/protocol to import the data source." inherited="false" model="PA:LIST(PA:URL,PA:URI,PA:USER_FILE,PA:GLOBAL_FILE)" name="IMPORT_FROM" value="PA:URL"/>
        <variable advanced="false" description="Path or name of the file that contains the dataset." inherited="false" model="$IMPORT_FROM" name="FILE_PATH" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/iris.csv"/>
        <variable advanced="false" description="Delimiter to use." inherited="false" name="FILE_DELIMITER" value=","/>
        <variable advanced="false" description="Maximum number of rows displayed in the output" inherited="false" model="PA:Integer" name="LIMIT_OUTPUT_VIEW" value="-1"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/load_dataset.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_load_iris_dataset"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-machine-learning/resources/Load_Iris_Dataset_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            71.4453125
        </positionTop>
        <positionLeft>
            452
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Split_Data">
      <description>
        <![CDATA[ Separate data into training and testing sets. ]]>
      </description>
      <variables>
        <variable advanced="false" description="Float number within the range (0.0, 1.0), not including the values 0.0 and 1.0." inherited="false" name="TRAIN_SIZE" value="0.7"/>
        <variable advanced="false" description="If False, the task will be ignored, it will not be executed." inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_split_data"/>
      </genericInformation>
      <depends>
        <task ref="Encode_Data"/>
      </depends>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-machine-learning/resources/Split_Data_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            327.453125
        </positionTop>
        <positionLeft>
            452
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Encode_Data" preciousResult="true">
      <description>
        <![CDATA[ Encode the specified columns from the data. ]]>
      </description>
      <variables>
        <variable advanced="false" description="If False, the task will be ignored, it will not be executed." hidden="false" inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="True"/>
        <variable advanced="false" description="List of columns to restrict to. Columns names should be separated by a comma." hidden="false" inherited="false" name="COLUMNS_NAME" value="species"/>
        <variable advanced="false" description="Number of rows that will be previewed in the browser." hidden="false" inherited="false" model="PA:Integer" name="LIMIT_OUTPUT_VIEW" value="5"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_encode_data"/>
      </genericInformation>
      <depends>
        <task ref="Load_Iris_Dataset"/>
      </depends>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-machine-learning/resources/Encode_Data_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            199.453125
        </positionTop>
        <positionLeft>
            452
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Train_Drift_Model">
      <description>
        <![CDATA[ Train a classification/clustering/anomaly detection model. ]]>
      </description>
      <variables>
        <variable advanced="false" description="If False, the task will be ignored, it will not be executed." hidden="false" inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="True"/>
        <variable advanced="false" description="Label/class column name." hidden="false" inherited="false" name="LABEL_COLUMN" value="species"/>
        <variable advanced="false" description="Number of splits you want to perform on the data." hidden="false" inherited="false" model="PA:Integer" name="N_SPLITS" value="5"/>
        <variable advanced="false" hidden="false" inherited="false" name="CONTAINER_IMAGE" value="activeeon/dlm4"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_train_model"/>
      </genericInformation>
      <depends>
        <task ref="Split_Data"/>
        <task ref="Spot_The_Diff"/>
      </depends>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/ai-auto-ml-optimization/resources/get_automl_token/raw"/>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-machine-learning/resources/Train_Model_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <post>
        <script>
          <code language="bash">
            <![CDATA[
pwd
find .
# sleep infinity
]]>
          </code>
        </script>
      </post>
      <outputFiles>
        <files accessMode="transferToUserSpace" includes="x_ref.npy"/>
        <files accessMode="transferToUserSpace" includes="config.toml"/>
      </outputFiles>
      <metadata>
        <positionTop>
            455.453125
        </positionTop>
        <positionLeft>
            451.9921875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Spot_The_Diff">
      <description>
        <![CDATA[ Kolmogorov-Smirnov (KS) test is a nonparametric statistical test used to compare a sample with a reference probability distribution or to compare two samples. It is particularly useful in the context of drift detection in data streams or datasets over time. ]]>
      </description>
      <variables>
        <variable advanced="false" description="If False, the task will be ignored, it will not be executed." hidden="false" inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="True"/>
        <variable advanced="false" description="Parameters' values of the Isolation Forest algorithm." hidden="false" inherited="false" name="INPUT_VARIABLES" value="{&quot;backend&quot;: &quot;pytorch&quot;,&quot;p_val&quot;: 0.01,&quot;n_diffs&quot;: 1,&quot;l1_reg&quot;: 1e-3, &quot;epochs&quot;: 10, &quot;batch_size&quot;: 32}"/>
        <variable advanced="false" description="Function used to evaluate the quality of a given pipeline for the anomaly detection problem." hidden="false" inherited="false" model="PA:List(accuracy,balanced_accuracy,average_precision,brier_score_loss,f1,f1_micro,f1_macro,f1_weighted,f1_samples,neg_log_loss,precision,recall,roc_auc)" name="SCORING" value="accuracy"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/ml_data_drift.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_isolation_forest"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/ai-auto-ml-optimization/resources/get_automl_params/raw"/>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-machine-learning/resources/Spot_The_Diff_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            327.453125
        </positionTop>
        <positionLeft>
            591.9921875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Drift_Model_Packaging" preciousResult="true">
      <description>
        <![CDATA[ Package the drift model. ]]>
      </description>
      <variables>
        <variable advanced="false" description="If False, the task will be ignored, it will not be executed." inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="True"/>
        <variable advanced="false" hidden="false" inherited="false" name="CONTAINER_IMAGE" value="activeeon/dlm4"/>
        <variable advanced="false" hidden="false" inherited="true" name="MODEL_NAME" value="model-${PA_JOB_ID}"/>
        <variable advanced="false" hidden="false" inherited="true" name="MODEL_NAME_DDD" value="${MODEL_NAME}-ddd"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_download_model"/>
        <info name="PRE_SCRIPT_AS_FILE" value="model.py"/>
      </genericInformation>
      <depends>
        <task ref="Train_Drift_Model"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromUserSpace" includes="x_ref.npy"/>
        <files accessMode="transferFromUserSpace" includes="config.toml"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <code language="cpython">
            <![CDATA[
import json
import os
import numpy as np
from alibi_detect.saving import load_detector

# triton_python_backend_utils is available in every Triton Python model. You
# need to use this module to create inference requests and responses. It also
# contains some utility functions for extracting information from model_config
# and converting Triton input/output types to numpy types.
import triton_python_backend_utils as pb_utils


class TritonPythonModel:
    """Your Python model must use the same class name. Every Python model
    that is created must have "TritonPythonModel" as the class name.
    """

    def initialize(self, args):
        """`initialize` is called only once when the model is being loaded.
        Implementing `initialize` function is optional. This function allows
        the model to initialize any state associated with this model.

        Parameters
        ----------
        args : dict
          Both keys and values are strings. The dictionary keys and values are:
          * model_config: A JSON string containing the model configuration
          * model_instance_kind: A string containing model instance kind
          * model_instance_device_id: A string containing model instance device ID
          * model_repository: Model repository path
          * model_version: Model version
          * model_name: Model name
        """

        # You must parse model_config. JSON string is not parsed here
        self.model_config = model_config = json.loads(args["model_config"])

        # Get OUTPUT0 configuration
        output0_config = pb_utils.get_output_config_by_name(model_config, "OUTPUT0")

        # Convert Triton types to numpy types
        self.output0_dtype = pb_utils.triton_string_to_numpy(
            output0_config["data_type"]
        )

        # Load model
        """
        args:  {'model_config': '{"name":"iris-classification-model-ddd","platform":"","backend":"python","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"INPUT0","data_type":"TYPE_FP32","format":"FORMAT_NONE","dims":[-1,-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false}],"output":[{"name":"OUTPUT0","data_type":"TYPE_FP32","dims":[1],"label_filename":"","is_shape_tensor":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"instance_group":[{"name":"iris-classification-model-ddd_0","kind":"KIND_CPU","count":1,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'iris-classification-model-ddd_0', 'model_instance_device_id': '0', 'model_repository': '/models/iris-classification-model-ddd', 'model_version': '1', 'model_name': 'iris-classification-model-ddd'}
        """
        self.detector_path = os.path.join(args['model_repository'], args['model_version'], 'ddd')
        print("detector_path: ", self.detector_path)
        self.model = load_detector(self.detector_path)

    def execute(self, requests):
        """`execute` MUST be implemented in every Python model. `execute`
        function receives a list of pb_utils.InferenceRequest as the only
        argument. This function is called when an inference request is made
        for this model. Depending on the batching configuration (e.g. Dynamic
        Batching) used, `requests` may contain multiple requests. Every
        Python model, must create one pb_utils.InferenceResponse for every
        pb_utils.InferenceRequest in `requests`. If there is an error, you can
        set the error argument when creating a pb_utils.InferenceResponse

        Parameters
        ----------
        requests : list
          A list of pb_utils.InferenceRequest

        Returns
        -------
        list
          A list of pb_utils.InferenceResponse. The length of this list must
          be the same as `requests`
        """

        output0_dtype = self.output0_dtype
        responses = []

        # Every Python backend must iterate over everyone of the requests
        # and create a pb_utils.InferenceResponse for each of them.
        for request in requests:
            # Get INPUT0
            in_0 = pb_utils.get_input_tensor_by_name(request, "INPUT0")

            # --------------------------------------------------
            try:
              # Predict drift
              preds = self.model.predict(in_0.as_numpy(), return_p_val=True, return_distance=True)
              out_0 = np.array([preds['data']['is_drift']], dtype=float)
            except Exception as e:
              print(f"Error loading model: {str(e)}")
              out_0 = np.array([0], dtype=float)
            # --------------------------------------------------

            # Create output tensors. You need pb_utils.Tensor
            # objects to create pb_utils.InferenceResponse.
            out_tensor_0 = pb_utils.Tensor("OUTPUT0", out_0.astype(output0_dtype))

            # Create InferenceResponse. You can set an error here in case
            # there was a problem with handling this inference request.
            # Below is an example of how you can set errors in inference
            # response:
            #
            # pb_utils.InferenceResponse(
            #    output_tensors=..., TritonError("An error occurred"))
            inference_response = pb_utils.InferenceResponse(output_tensors=[out_tensor_0])
            responses.append(inference_response)

        # You should return a list of pb_utils.InferenceResponse. Length
        # of this list must match the length of `requests` list.
        return responses

    def finalize(self):
        """`finalize` is called only once when the model is being unloaded.
        Implementing `finalize` function is OPTIONAL. This function allows
        the model to perform any necessary clean ups before exit.
        """
        print("Cleaning up...")
]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import os
import subprocess
import shutil
import zipfile
import requests
import json

from urllib.parse import urlparse

def assert_not_none_not_empty(value, message):
    if not value:
        raise ValueError(message)

def zip_directory(directory_path):
    zip_file_path = directory_path + ".zip"
    with zipfile.ZipFile(zip_file_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
        for root, dirs, files in os.walk(directory_path):
            for file in files:
                zip_file.write(os.path.join(root, file),
                               os.path.relpath(os.path.join(root, file),
                               os.path.dirname(directory_path)))
    print(f"The zip file '{zip_file_path}' has been created.")
    return zip_file_path

# Main code execution starts here
__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

# Get schedulerapi access and acquire session id
schedulerapi.connect()
sessionid = schedulerapi.getSession()
connection_info = schedulerapi.getConnectionInfo()
ci_url = connection_info.getUrl()
url = urlparse(ci_url)
proactive_url = url.scheme + "://" + url.hostname + ":" + str(url.port)
print("proactive_url: ", proactive_url)

# Execute `pwd` to get the current working directory
pwd_result = subprocess.run(['pwd'], capture_output=True, text=True)
print("Current directory:", pwd_result.stdout.strip())

# Execute `find .` to list all files and directories starting from the current directory
find_result = subprocess.run(['find', '.'], capture_output=True, text=True)
print("All files and directories:")
print(find_result.stdout.strip())

MODEL_NAME_DDD = variables.get("MODEL_NAME_DDD")
assert_not_none_not_empty(MODEL_NAME_DDD, "MODEL_NAME_DDD should be defined!")

MODEL_VERSION = variables.get("MODEL_VERSION")
assert_not_none_not_empty(MODEL_VERSION, "MODEL_VERSION should be defined!")

MODEL_SERVER_ID = variables.get("MODEL_SERVER_ID")
assert_not_none_not_empty(MODEL_SERVER_ID, "MODEL_SERVER_ID should be defined!")

def get_instance_name_and_model_registry_path(sessionid, proactive_url, instance_id):
    headers = {'sessionid': sessionid}
    url = f"{proactive_url}/cloud-automation-service/serviceInstances/{instance_id}"
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        data = json.loads(response.text)
        instance_name = data.get('variables', {}).get('INSTANCE_NAME')
        model_registry_path = data.get('variables', {}).get('MODEL_REGISTRY_PATH')
        return instance_name, model_registry_path
    else:
        print(f"Failed to get data, status code: {response.status_code}")
        return None, None
instance_name, model_registry_path = get_instance_name_and_model_registry_path(sessionid, proactive_url, MODEL_SERVER_ID)
MODEL_SERVER_TOKEN = "PSA_" + instance_name
print('MODEL_SERVER_TOKEN: ', MODEL_SERVER_TOKEN)
print('MODEL_SERVER_REGISTRY: ', model_registry_path)
variables.put('MODEL_SERVER_TOKEN', MODEL_SERVER_TOKEN)
variables.put('MODEL_SERVER_REGISTRY', model_registry_path)

# Directory setup
LOCALSPACE = MODEL_NAME_DDD
os.makedirs(LOCALSPACE, exist_ok=True)

MODEL_VERSION_DIR = os.path.join(LOCALSPACE, MODEL_VERSION)
os.makedirs(MODEL_VERSION_DIR, exist_ok=True)

DDD_DIR = os.path.join(MODEL_VERSION_DIR, "ddd")
os.makedirs(DDD_DIR, exist_ok=True)

config_path = os.path.join(LOCALSPACE, "config.pbtxt")

# Configuration writing
config_content = f"""name: "{MODEL_NAME_DDD}"
backend: "python"

input [
  {{
    name: "INPUT0"
    data_type: TYPE_FP32
    dims: [ -1, -1 ]
  }}
]
output [
  {{
    name: "OUTPUT0"
    data_type: TYPE_FP32
    dims: [ 1 ]
  }}
]

instance_group [{{ kind: KIND_CPU }}]
"""

with open(config_path, 'w') as config_file:
    config_file.write(config_content)

# File movement
source_files = {
    'x_ref.npy': DDD_DIR,
    'config.toml': DDD_DIR,
    'model.py': MODEL_VERSION_DIR
}

for filename, destination in source_files.items():
    source_path = os.path.join(pwd_result.stdout.strip(), filename)
    destination_path = os.path.join(destination, filename)
    if os.path.exists(source_path):
        shutil.move(source_path, destination_path)
        print(f"Moved {filename} to {destination_path}")
    else:
        print(f"File {filename} does not exist in the current directory.")

# Zipping directory
zip_file_path = zip_directory(LOCALSPACE)

# Read the whole file at once
FILE_BIN = None
with open(zip_file_path, "rb") as binary_file:
    FILE_BIN = binary_file.read()
assert FILE_BIN is not None

result = FILE_BIN
resultMetadata.put("file.extension", ".zip")
resultMetadata.put("file.name", MODEL_NAME_DDD + ".zip")
resultMetadata.put("content.type", "application/octet-stream")

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <post>
        <script>
          <code language="bash">
            <![CDATA[
pwd
find .
]]>
          </code>
        </script>
      </post>
      <outputFiles>
        <files accessMode="transferToUserSpace" includes="${MODEL_NAME_DDD}.zip"/>
      </outputFiles>
      <metadata>
        <positionTop>
            583.453125
        </positionTop>
        <positionLeft>
            452
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Deploy_Model_Drift">
      <description>
        <![CDATA[ The simplest task, ran by a bash engine. ]]>
      </description>
      <genericInformation>
        <info name="NODE_ACCESS_TOKEN" value="${MODEL_SERVER_TOKEN}"/>
      </genericInformation>
      <depends>
        <task ref="Drift_Model_Packaging"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromUserSpace" includes="${MODEL_NAME_DDD}.zip"/>
      </inputFiles>
      <pre>
        <script>
          <code language="bash">
            <![CDATA[
pwd
find .
]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="bash">
            <![CDATA[
# Assign variables
MODEL_NAME=$variables_MODEL_NAME_DDD
MODEL_VERSION=$variables_MODEL_VERSION
MODEL_SERVER_REGISTRY=$variables_MODEL_SERVER_REGISTRY

echo "MODEL_NAME: $MODEL_NAME"
echo "MODEL_VERSION: $MODEL_VERSION"
echo "MODEL_SERVER_REGISTRY: $MODEL_SERVER_REGISTRY"

# Construct the target path
TARGET_PATH="$MODEL_SERVER_REGISTRY/$MODEL_NAME/$MODEL_VERSION"

# Check if the MODEL_NAME directory exists in the MODEL_SERVER_REGISTRY
if [ ! -d "$MODEL_SERVER_REGISTRY/$MODEL_NAME" ]; then
    # If not, unzip the full content
    unzip $MODEL_NAME.zip -d $MODEL_SERVER_REGISTRY
# else
#     # If MODEL_NAME directory exists, check if MODEL_VERSION directory exists
#     if [ ! -d "$TARGET_PATH" ]; then
#         # If MODEL_VERSION directory does not exist, create it
#         mkdir -p $TARGET_PATH
#     fi
#     # Extract the model.onnx file to the target directory, overwrite if exists
#     unzip -o $MODEL_NAME.zip $MODEL_NAME/$MODEL_VERSION/model.onnx -d $MODEL_SERVER_REGISTRY
fi
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            711.453125
        </positionTop>
        <positionLeft>
            452
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Train_Prediction_Model">
      <description>
        <![CDATA[ Train a classification/clustering/anomaly detection model ]]>
      </description>
      <variables>
        <variable advanced="false" description="If False, the task will be ignored, it will not be executed." inherited="false" name="TASK_ENABLED" value="True"/>
        <variable advanced="false" description="Label/class column name." inherited="false" name="LABEL_COLUMN" value="species"/>
        <variable advanced="false" description="Number of splits you want to perform on the data." inherited="false" model="PA:Integer" name="N_SPLITS" value="5"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_train_model"/>
      </genericInformation>
      <depends>
        <task ref="Split_Data"/>
        <task ref="Logistic_Regression"/>
      </depends>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/ai-auto-ml-optimization/resources/get_automl_token/raw"/>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-machine-learning/resources/Train_Model_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            455.4453125
        </positionTop>
        <positionLeft>
            697
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Logistic_Regression">
      <description>
        <![CDATA[ Logistic Regression is a regression model where the Dependent Variable (DV) is categorical. ]]>
      </description>
      <variables>
        <variable advanced="false" description="If False, the task will be ignored, it will not be executed." inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="True"/>
        <variable description="A set of specific variables (usecase-related) that are used in the model training process." inherited="true" name="INPUT_VARIABLES" value="{}"/>
        <variable advanced="false" description="Function used to evaluate the quality of a given pipeline for the clustering problem." inherited="false" model="PA:List(accuracy,balanced_accuracy, average_precision, brier_score_loss, f1, f1_micro, f1_macro, f1_weighted, f1_samples, neg_log_loss, precision, recall, roc_auc)" name="SCORING" value="accuracy"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/ml_classification.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_logistic_regression"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/ai-auto-ml-optimization/resources/get_automl_params/raw"/>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-machine-learning/resources/Logistic_Regression_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            327.4453125
        </positionTop>
        <positionLeft>
            747
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Prediction_Model_Packaging" preciousResult="true">
      <description>
        <![CDATA[ Download a trained model. ]]>
      </description>
      <variables>
        <variable advanced="false" description="If False, the task will be ignored, it will not be executed." inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="True"/>
        <variable advanced="false" hidden="false" inherited="false" name="CONTAINER_IMAGE" value="activeeon/dlm4"/>
        <variable advanced="false" hidden="false" inherited="true" name="MODEL_NAME" value="model-${PA_JOB_ID}"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_download_model"/>
      </genericInformation>
      <depends>
        <task ref="Train_Prediction_Model"/>
      </depends>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import os
import sys
import zipfile
import requests
import json
import ssl
import urllib.request
import joblib
import pickle
import bz2
import onnx
import uuid
import pandas as pd

from os import remove, listdir, makedirs
from os.path import basename, splitext, exists, join, isfile
from urllib.parse import urlparse
from sklearn.model_selection import train_test_split
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType

__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

# -------------------------------------------------------------
# Get schedulerapi access and acquire session id
schedulerapi.connect()
sessionid = schedulerapi.getSession()
connection_info = schedulerapi.getConnectionInfo()
ci_url = connection_info.getUrl()
url = urlparse(ci_url)
proactive_url = url.scheme + "://" + url.hostname + ":" + str(url.port)
print("proactive_url: ", proactive_url)

# -------------------------------------------------------------
# Import an external python script containing a collection of
# common utility Python functions and classes
PA_CATALOG_REST_URL = variables.get("PA_CATALOG_REST_URL")
PA_PYTHON_UTILS_URL = PA_CATALOG_REST_URL + "/buckets/ai-machine-learning/resources/Utils_Script/raw"
req = urllib.request.Request(PA_PYTHON_UTILS_URL)
req.add_header('sessionid', sessionid)
if PA_PYTHON_UTILS_URL.startswith('https'):
    content = urllib.request.urlopen(req, context=ssl._create_unverified_context()).read()
else:
    content = urllib.request.urlopen(req).read()
exec(content, globals())

# -------------------------------------------------------------
# Check if the Python task is enabled or not
check_task_is_enabled()

# -------------------------------------------------------------
# Get data from the propagated variables
#
input_variables = {'task.model_id': None}
get_input_variables(input_variables)

model_id = input_variables['task.model_id']
model = get_and_decompress_model(model_id)

# Load the trained model from disk
#loaded_model = joblib.load('logitic_regression.pkl')
#print(loaded_model)
NVIDIA_RAPIDS_ENABLED = is_nvidia_rapids_enabled()
print('NVIDIA_RAPIDS_ENABLED: ', NVIDIA_RAPIDS_ENABLED)

if NVIDIA_RAPIDS_ENABLED:
    import cudf
    # import cuml
    # import cupy as cp

input_variables = {
    'task.dataframe_id': None,
    'task.dataframe_id_train': None,
    'task.algorithm_json': None,
    'task.label_column': None,
    'task.feature_names': None,
    'task.encode_map_json': None,
    'task.model_id': None
}
get_input_variables(input_variables)

# get algorithm name
algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
alg = dict_to_obj(algorithm)

MODEL_NAME = variables.get("MODEL_NAME")
assert_not_none_not_empty(MODEL_NAME, "MODEL_NAME should be defined!")

MODEL_VERSION = variables.get("MODEL_VERSION")
assert_not_none_not_empty(MODEL_VERSION, "MODEL_VERSION should be defined!")

MODEL_SERVER_ID = variables.get("MODEL_SERVER_ID")
assert_not_none_not_empty(MODEL_VERSION, "MODEL_SERVER_ID should be defined!")

def get_instance_name_and_model_registry_path(sessionid, proactive_url, instance_id):
    headers = {'sessionid': sessionid}
    url = f"{proactive_url}/cloud-automation-service/serviceInstances/{instance_id}"
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        data = json.loads(response.text)
        instance_name = data.get('variables', {}).get('INSTANCE_NAME')
        model_registry_path = data.get('variables', {}).get('MODEL_REGISTRY_PATH')
        return instance_name, model_registry_path
    else:
        print(f"Failed to get data, status code: {response.status_code}")
        return None, None
instance_name, model_registry_path = get_instance_name_and_model_registry_path(sessionid, proactive_url, MODEL_SERVER_ID)
MODEL_SERVER_TOKEN = "PSA_" + instance_name
print('MODEL_SERVER_TOKEN: ', MODEL_SERVER_TOKEN)
print('MODEL_SERVER_REGISTRY: ', model_registry_path)
variables.put('MODEL_SERVER_TOKEN', MODEL_SERVER_TOKEN)
variables.put('MODEL_SERVER_REGISTRY', model_registry_path)

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
    dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_train'] is not None:
    dataframe_id = input_variables['task.dataframe_id_train']
print("dataframe id (in): ", dataframe_id)

dataframe_json = get_and_decompress_json_dataframe(dataframe_id)

if NVIDIA_RAPIDS_ENABLED:
    dataframe = cudf.read_json(dataframe_json, orient='split')
else:
    dataframe = pd.read_json(dataframe_json, orient='split')

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if is_not_none_not_empty(LABEL_COLUMN):
    is_labeled_data = True
else:
    LABEL_COLUMN = input_variables['task.label_column']
    if is_not_none_not_empty(LABEL_COLUMN):
        is_labeled_data = True

dataframe_train = None
dataframe_label = None
model_explainer = None
loss = 0
if model is not None:
    print('-' * 30)
    print(model)
    print('-' * 30)
    if is_labeled_data:
        dataframe_train = dataframe.drop([LABEL_COLUMN], axis=1)
        dataframe_label = dataframe[LABEL_COLUMN]
    else:
        dataframe_train = dataframe
    if NVIDIA_RAPIDS_ENABLED:
        for colname in dataframe_train.columns:
            dataframe_train[colname] = dataframe_train[colname].astype('float32')
        dataframe_label = dataframe_label.astype('float32') if dataframe_label is not None else None

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None
print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

loaded_model = pickle.loads(model_bin)

if loaded_model is not None:
    print('-' * 30)
    print(loaded_model)
    print('-' * 30)

def prepare_onnx_conversion_params(X, target_opset, model):
    if target_opset in {9, 17}:
        tensor = FloatTensorType([None, 4])
    else:
        tensor = FloatTensorType([None, X.shape[1]])
    if target_opset == 9:
        options = {id(model): {'zipmap': False}}
    elif target_opset == 12:
        options = {type(model): {'zipmap': False}}
    else:
        options = None
    return tensor, options

def convert2onnx(model, initial_type, options, target_opset):
    try:
        # Try to convert the trained model to ONNX format
        onnx_model = convert_sklearn(model, initial_types=initial_type, options=options, target_opset=target_opset)
    except Exception as e:
        print("Error occurred while converting model to ONNX format:", e)
    return onnx_model

def create_triton_config(model, config_path, model_name, max_batch_size=0):
    # Define a map from TensorProto.DataType to the corresponding string
    tensor_type_to_string = {
        1: "TYPE_FP32",
        2: "TYPE_UINT8",
        3: "TYPE_INT8",
        4: "TYPE_UINT16",
        5: "TYPE_INT16",
        6: "TYPE_INT32",
        7: "TYPE_INT64",
        8: "TYPE_STRING",
        9: "TYPE_BOOL",
        10: "TYPE_FP16",
        11: "TYPE_FP64",
        12: "TYPE_UINT32",
        13: "TYPE_UINT64",
        14: "TYPE_COMPLEX64",
        15: "TYPE_COMPLEX128",
        16: "TYPE_BFLOAT16"
    }
    # Extract input and output information
    input_tensors = []
    for i in model.graph.input:
        shape = [dim.dim_value if dim.dim_value != 0 else -1 for dim in i.type.tensor_type.shape.dim]
        data_type = tensor_type_to_string.get(i.type.tensor_type.elem_type, "TYPE_UNDEFINED")
        input_tensors.append({"name": i.name, "data_type": data_type, "dims": shape})
    output_tensors = []
    for o in model.graph.output:
        shape = [dim.dim_value if dim.dim_value != 0 else -1 for dim in o.type.tensor_type.shape.dim]
        data_type = tensor_type_to_string.get(o.type.tensor_type.elem_type, "TYPE_UNDEFINED")
        output_tensors.append({"name": o.name, "data_type": data_type, "dims": shape})
    # Create the Triton configuration
    config = {
        "name": model_name,
        "platform": "onnxruntime_onnx",
        "max_batch_size": max_batch_size,
        "input": input_tensors,
        "output": output_tensors,
        "instance_group": [{"count": 1, "kind": "KIND_CPU"}],
    }
    # Save the configuration as a JSON file
    with open(config_path, 'w') as f:
        f.write("name: \"" + config['name'] + "\"\n")
        f.write("platform: \"" + config['platform'] + "\"\n")
        # f.write("max_batch_size: " + str(config['max_batch_size']) + "\n")
        f.write("input [\n")
        for input_tensor in config['input']:
            f.write("  {\n")
            f.write("    name: \"" + input_tensor['name'] + "\"\n")
            f.write("    data_type: " + input_tensor['data_type'] + "\n")
            f.write("    dims: [ " + ", ".join([str(dim) for dim in input_tensor['dims']]) + " ]\n")
            f.write("  }\n")
        f.write("]\n")
        f.write("output [\n")
        for i, output_tensor in enumerate(config['output']):
            f.write("  {\n")
            f.write("    name: \"" + output_tensor['name'] + "\"\n")
            f.write("    data_type: " + output_tensor['data_type'] + "\n")
            f.write("    dims: [ " + ", ".join([str(dim) for dim in output_tensor['dims']]) + " ]\n")
            f.write("  }\n")
            if i != len(config['output']) - 1:  # If not the last output tensor, add a comma
                f.write(",\n")
        f.write("]\n")
        f.write("instance_group [\n")
        for instance_group in config['instance_group']:
            f.write("  {\n")
            f.write("    count: " + str(instance_group['count']) + "\n")
            f.write("    kind: " + instance_group['kind'] + "\n")
            f.write("  }\n")
        f.write("]\n")
    print(f"The configuration file has been saved to '{config_path}'")

# Prepare the ONNX conversion parameters
target_opset = 12  # Update this value based on your model type
tensor, options = prepare_onnx_conversion_params(dataframe_train, target_opset, loaded_model)

input_name = 'float_input'
initial_type = [(input_name, tensor)]

# Convert the model to ONNX format
onnx_model = convert2onnx(loaded_model, initial_type, options, target_opset)

# Get an unique ID
ID = str(uuid.uuid4())

# Define localspace
# LOCALSPACE = os.path.join(alg.name, MODEL_NAME)
LOCALSPACE = MODEL_NAME
os.makedirs(LOCALSPACE, exist_ok=True)

MODEL_VERSION_DIR = os.path.join(LOCALSPACE, MODEL_VERSION)
os.makedirs(MODEL_VERSION_DIR, exist_ok=True)

config_path = os.path.join(LOCALSPACE, "config.pbtxt")
create_triton_config(onnx_model, config_path, MODEL_NAME, max_batch_size=0)

model_path = os.path.join(MODEL_VERSION_DIR, "model.onnx")
with open(model_path, "wb") as f:
    f.write(onnx_model.SerializeToString())

def zip_directory(directory_path):
    # Create a zipfile object and write files to it
    zip_file_path = directory_path + ".zip"
    with zipfile.ZipFile(zip_file_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
        for root, dirs, files in os.walk(directory_path):
            for file in files:
                # Keep the directory_path inside the zip so when unzipped it creates a folder and extracts the files inside it
                zip_file.write(os.path.join(root, file),
                               os.path.relpath(os.path.join(root, file),
                               os.path.dirname(directory_path)))
                # zip_file.write(os.path.join(root, file),
                #                os.path.relpath(os.path.join(root, file),
                #                directory_path))
    print(f"The zip file '{zip_file_path}' has been created.")
    return zip_file_path

# Test the function
zip_file_path = zip_directory(LOCALSPACE) # replace with your directory

# Read the whole file at once
FILE_BIN = None
with open(zip_file_path, "rb") as binary_file:
    FILE_BIN = binary_file.read()
assert FILE_BIN is not None

result = FILE_BIN
resultMetadata.put("file.extension", ".zip")
resultMetadata.put("file.name", MODEL_NAME + ".zip")
resultMetadata.put("content.type", "application/octet-stream")
# -------------------------------------------------------------
print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <outputFiles>
        <files accessMode="transferToUserSpace" includes="${MODEL_NAME}.zip"/>
      </outputFiles>
      <metadata>
        <positionTop>
            583.4453125
        </positionTop>
        <positionLeft>
            697
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Deploy_Model_Prediction">
      <description>
        <![CDATA[ The simplest task, ran by a bash engine. ]]>
      </description>
      <genericInformation>
        <info name="NODE_ACCESS_TOKEN" value="${MODEL_SERVER_TOKEN}"/>
      </genericInformation>
      <depends>
        <task ref="Prediction_Model_Packaging"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromUserSpace" includes="${MODEL_NAME}.zip"/>
      </inputFiles>
      <scriptExecutable>
        <script>
          <code language="bash">
            <![CDATA[
# Assign variables
MODEL_NAME=$variables_MODEL_NAME
MODEL_VERSION=$variables_MODEL_VERSION
MODEL_SERVER_REGISTRY=$variables_MODEL_SERVER_REGISTRY

echo "MODEL_NAME: $MODEL_NAME"
echo "MODEL_VERSION: $MODEL_VERSION"
echo "MODEL_SERVER_REGISTRY: $MODEL_SERVER_REGISTRY"

# Construct the target path
TARGET_PATH="$MODEL_SERVER_REGISTRY/$MODEL_NAME/$MODEL_VERSION"

# Check if the MODEL_NAME directory exists in the MODEL_SERVER_REGISTRY
if [ ! -d "$MODEL_SERVER_REGISTRY/$MODEL_NAME" ]; then
    # If not, unzip the full content
    unzip $MODEL_NAME.zip -d $MODEL_SERVER_REGISTRY
else
    # If MODEL_NAME directory exists, check if MODEL_VERSION directory exists
    if [ ! -d "$TARGET_PATH" ]; then
        # If MODEL_VERSION directory does not exist, create it
        mkdir -p $TARGET_PATH
    fi
    # Extract the model.onnx file to the target directory, overwrite if exists
    unzip -o $MODEL_NAME.zip $MODEL_NAME/$MODEL_VERSION/model.onnx -d $MODEL_SERVER_REGISTRY
fi
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            711.4375
        </positionTop>
        <positionLeft>
            697
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2838px;
            height:3532px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-66.4453125px;left:-446.9921875px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_60" style="top: 71.453px; left: 452px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load and return the iris dataset classification."><img src="/automation-dashboard/styles/patterns/img/wf-icons/load_dataset.png" width="20px">&nbsp;<span class="name">Load_Iris_Dataset</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_63" style="top: 327.461px; left: 452px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Separate data into training and testing sets."><img src="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png" width="20px">&nbsp;<span class="name">Split_Data</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_66" style="top: 199.461px; left: 452px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Encode the specified columns from the data."><img src="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png" width="20px">&nbsp;<span class="name">Encode_Data</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_69" style="top: 455.461px; left: 451.992px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="" data-original-title="Train a classification/clustering/anomaly detection model."><img src="/automation-dashboard/styles/patterns/img/wf-icons/train.png" width="20px">&nbsp;<span class="name">Train_Drift_Model</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_72" style="top: 327.461px; left: 591.992px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Kolmogorov-Smirnov (KS) test is a nonparametric statistical test used to compare a sample with a reference probability distribution or to compare two samples. It is particularly useful in the context of drift detection in data streams or datasets over time."><img src="/automation-dashboard/styles/patterns/img/wf-icons/ml_data_drift.png" width="20px">&nbsp;<span class="name">Spot_The_Diff</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_75" style="top: 583.461px; left: 452px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Package the drift model."><img src="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png" width="20px">&nbsp;<span class="name">Drift_Model_Packaging</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_78" style="top: 711.461px; left: 452px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="The simplest task, ran by a bash engine."><img src="/studio/images/LinuxBash.png" width="20px">&nbsp;<span class="name">Deploy_Model_Drift</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_81" style="top: 455.453px; left: 697px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Train a classification/clustering/anomaly detection model"><img src="/automation-dashboard/styles/patterns/img/wf-icons/train.png" width="20px">&nbsp;<span class="name">Train_Prediction_Model</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_84" style="top: 327.453px; left: 747px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Logistic Regression is a regression model where the Dependent Variable (DV) is categorical."><img src="/automation-dashboard/styles/patterns/img/wf-icons/ml_classification.png" width="20px">&nbsp;<span class="name">Logistic_Regression</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_87" style="top: 583.453px; left: 697px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Download a trained model."><img src="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png" width="20px">&nbsp;<span class="name">Prediction_Model_Packaging</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_90" style="top: 711.445px; left: 697px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="The simplest task, ran by a bash engine."><img src="/studio/images/LinuxBash.png" width="20px">&nbsp;<span class="name">Deploy_Model_Prediction</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon"></i></a></div><svg style="position:absolute;left:491.5px;top:238.5px" width="21.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 10.5 50 0.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.7747343749999995,66.78168750000002 L4.918836648297567,47.038107153227145 L-2.286251050858403,52.790212093809444 L-9.072638757893003,46.54962382908555 L-2.7747343749999995,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.7747343749999995,66.78168750000002 L4.918836648297567,47.038107153227145 L-2.286251050858403,52.790212093809444 L-9.072638757893003,46.54962382908555 L-2.7747343749999995,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:492px;top:110.5px" width="31.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 20.5 50 10.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-1.9357920000000004,66.303232 L8.31507669701995,47.75816012210056 L0.4090324791346134,52.50099311777328 L-5.487162185206769,45.41333564296595 L-1.9357920000000004,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-1.9357920000000004,66.303232 L8.31507669701995,47.75816012210056 L0.4090324791346134,52.50099311777328 L-5.487162185206769,45.41333564296595 L-1.9357920000000004,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:491.5px;top:366.5px" width="30.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 9.5 88 C 19.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M11.521328,66.303232 L15.340231614961638,45.46058401132944 L9.353652074163795,52.472064981973276 L1.5090645969349188,47.628259937165645 L11.521328,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M11.521328,66.303232 L15.340231614961638,45.46058401132944 L9.353652074163795,52.472064981973276 L1.5090645969349188,47.628259937165645 L11.521328,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:501px;top:366.5px" width="153.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 142.5 50 132.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M16.3872,60.999424000000005 L37.4573130285072,58.75212852189062 L29.036190403401555,54.99917052413289 L31.457059552640086,46.10313811848906 L16.3872,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M16.3872,60.999424000000005 L37.4573130285072,58.75212852189062 L29.036190403401555,54.99917052413289 L31.457059552640086,46.10313811848906 L16.3872,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:501px;top:494.5px" width="33.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 12.5 88 C 22.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M14.26472,66.303232 L17.28289408617318,45.32966231848053 L11.569127383829805,52.565190638595936 L3.54485272476912,48.02525493465072 L14.26472,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M14.26472,66.303232 L17.28289408617318,45.32966231848053 L11.569127383829805,52.565190638595936 L3.54485272476912,48.02525493465072 L14.26472,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:505.5px;top:622.5px" width="29" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 18 50 8 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.149632,66.303232 L7.49984351657956,47.438247975227235 L-0.24966605297428535,52.43275510120006 L-6.370633382220376,45.538282028201515 L-2.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.149632,66.303232 L7.49984351657956,47.438247975227235 L-0.24966605297428535,52.43275510120006 L-6.370633382220376,45.538282028201515 L-2.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:491.5px;top:366.5px" width="289" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 268 88 C 278 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M222.658468,58.618708 L204.6517578322571,47.44917851416648 L208.99144631496728,55.583494949678 L201.6165447819351,61.11620019919922 L222.658468,58.618708" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M222.658468,58.618708 L204.6517578322571,47.44917851416648 L208.99144631496728,55.583494949678 L201.6165447819351,61.11620019919922 L222.658468,58.618708" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:759.5px;top:366.5px" width="63" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 52 50 42 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M1.2956579999999975,64.9032055 L17.76044473316764,51.56488484741008 L8.65197172234549,52.99167124036613 L5.848910473533769,44.20857112506459 L1.2956579999999975,64.9032055" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M1.2956579999999975,64.9032055 L17.76044473316764,51.56488484741008 L8.65197172234549,52.99167124036613 L5.848910473533769,44.20857112506459 L1.2956579999999975,64.9032055" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:759.5px;top:494.5px" width="33" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 12 88 C 22 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M13.807488,66.303232 L16.95868678791453,45.34923605175552 L11.199122872356591,52.54836263090405 L3.2038174188185877,47.95760117939893 L13.807488,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M13.807488,66.303232 L16.95868678791453,45.34923605175552 L11.199122872356591,52.54836263090405 L3.2038174188185877,47.95760117939893 L13.807488,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:763.5px;top:622.5px" width="29" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 18 50 8 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.149632,66.303232 L7.49984351657956,47.438247975227235 L-0.24966605297428535,52.43275510120006 L-6.370633382220376,45.538282028201515 L-2.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.149632,66.303232 L7.49984351657956,47.438247975227235 L-0.24966605297428535,52.43275510120006 L-6.370633382220376,45.538282028201515 L-2.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 503px; top: 101px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 492px; top: 357px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 492px; top: 317px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 492.5px; top: 229px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 492.5px; top: 189px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 501.5px; top: 485px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 501.5px; top: 445px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 634px; top: 357px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 514px; top: 613px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 514px; top: 573px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 506px; top: 741px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 506px; top: 701px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 760px; top: 485px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 760px; top: 445px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 802px; top: 357px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 772px; top: 613px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 772px; top: 573px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 764px; top: 741px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 764px; top: 701px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
