<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.14" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Train_Deploy_Image_Classification" onTaskError="continueJobExecution" priority="normal" projectName="5. MLOps Workflows Example" tags="Natural Language Processing,Classification,Text Analysis,Computer Vision,Image Analysis,Machine Learning,Deep Learning" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd">
  <variables>
    <variable advanced="true" description="Container platform used for executing the workflow tasks." group="Container Parameters" model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker"/>
    <variable advanced="true" description="If True, it will activate the use of GPU for the workflow tasks on the selected container platform." group="Container Parameters" model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="true"/>
    <variable advanced="true" description="Name of the container image being used." group="Container Parameters" model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/rapidsai,docker://activeeon/nvidia:rapidsai)" name="CONTAINER_IMAGE" value=""/>
    <variable advanced="false" description="Name of the model to be deployed" group="Model Deployment" hidden="false" name="MODEL_NAME" value="image-classification-model-${PA_JOB_ID}"/>
    <variable description="Version of the model to be deployed." group="Model Deployment" model="PA:Integer" name="MODEL_VERSION" value="1"/>
    <variable advanced="false" description="ID of the model server used to deploy the trained model" group="Model Deployment" hidden="false" model="PA:Integer?" name="MODEL_SERVER_ID" value=""/>
    <variable advanced="false" description="The MLOps Dashboard instance where the mode will be deployed." hidden="false" model="PA:MODEL_FROM_URL(${PA_SCHEDULER_REST_PUBLIC_URL}/rm/model/tokens?name=PSA_mlops-dashboard.*)" name="MLOPS_DASHBOARD_INSTANCE" value="PSA_mlops-dashboard-1"/>
  </variables>
  <description>
    <![CDATA[ Train an image classification model using a ResNet-18 network and deploy it to the MLOps Model Server. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="ai-mlops-dashboard"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
<info name="submission.mode" value="studio"/>
<info name="Documentation" value="PAIO/PAIOUserGuide.html#_mlops_dashboard"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Import_Image_Dataset">
      <description>
        <![CDATA[ Load and return an image dataset. ]]>
      </description>
      <variables>
        <variable advanced="false" description="Method/protocol to import the data source." hidden="false" inherited="false" model="PA:LIST(PA:URL,PA:URI,PA:USER_FILE,PA:GLOBAL_FILE)" name="IMPORT_FROM" value="PA:URL"/>
        <variable advanced="false" description="Path or name of the file that contains the image dataset." hidden="false" inherited="false" model="$IMPORT_FROM" name="DATA_PATH" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/ants_vs_bees.zip"/>
        <variable advanced="false" description="Float between 0.0 and 1.0 representing the ratio of data to be used for the model training." hidden="false" inherited="false" name="TRAIN_SPLIT" value="0.80"/>
        <variable advanced="false" description="Float between 0.0 and 1.0 representing the ratio of data to be used for the model validation." hidden="false" inherited="false" name="VAL_SPLIT" value="0.1"/>
        <variable advanced="false" description="Float between 0.0 and 1.0 representing the ratio of data to be used for the model testing." hidden="false" inherited="false" name="TEST_SPLIT" value="0.1"/>
        <variable advanced="false" description="Dataset type to be imported. Check the documentation for more information about the organization of your dataset folders and files according to each dataset type." hidden="false" inherited="false" model="PA:LIST(Classification, Detection, Segmentation)" name="DATASET_TYPE" value="Classification"/>
        <variable advanced="false" description="Path where the logs are created and stored on the host." hidden="false" inherited="false" name="HOST_LOG_PATH" value=""/>
        <variable advanced="false" description="Path where the logs are created and stored on the specified container." hidden="false" inherited="false" name="CONTAINER_LOG_PATH" value=""/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_image.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_import_image_dataset"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-deep-learning/resources/Import_Image_Dataset_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$DATASET_PATH/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            153
        </positionTop>
        <positionLeft>
            428.5
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Train_Image_Classification_Model">
      <description>
        <![CDATA[ Train a model using an image classification network. ]]>
      </description>
      <variables>
        <variable advanced="false" description="Hyperparameter that defines the number of times that the learning algorithm will work through the entire training dataset to update weights." hidden="false" inherited="false" name="NUM_EPOCHS" value="3"/>
        <variable advanced="false" description="Number of samples that are going to be propagated through the network" hidden="false" inherited="false" name="BATCH_SIZE" value="4"/>
        <variable advanced="false" description="Number of subprocesses to use for data loading. 0 means that the data will be loaded in the main process." hidden="false" inherited="false" name="NUM_WORKERS" value="2"/>
        <variable advanced="false" description="If True, the data will be reshuffled at every epoch." hidden="false" inherited="false" name="SHUFFLE" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_train_image_classification_model"/>
      </genericInformation>
      <depends>
        <task ref="Import_Image_Dataset"/>
        <task ref="ResNet_18"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-deep-learning/resources/Train_Image_Classification_Model_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <post>
        <script>
          <code language="bash">
            <![CDATA[

]]>
          </code>
        </script>
      </post>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            281
        </positionTop>
        <positionLeft>
            508
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="ResNet_18">
      <description>
        <![CDATA[ ResNet-18 is a deep convolutional neural network, trained on 1.28 million ImageNet training images, coming from 1000 classes. ]]>
      </description>
      <variables>
        <variable advanced="false" description="If True, the pre-trained model with the corresponding number of layers is loaded and used for training. Otherwise, the network is trained from scratch." hidden="false" inherited="false" model="PA:Boolean" name="USE_PRETRAINED_MODEL" value="true"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_learning.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_resnet_18"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-deep-learning/resources/ResNet_18_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            153
        </positionTop>
        <positionLeft>
            587.5
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Deploy_Model">
      <description>
        <![CDATA[ The simplest task, ran by a bash engine. ]]>
      </description>
      <genericInformation>
        <info name="NODE_ACCESS_TOKEN" value="${MODEL_SERVER_TOKEN}"/>
      </genericInformation>
      <depends>
        <task ref="Model_Packaging"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromUserSpace" includes="${MODEL_NAME}.zip"/>
      </inputFiles>
      <scriptExecutable>
        <script>
          <code language="bash">
            <![CDATA[
# Assign variables
MODEL_NAME=$variables_MODEL_NAME
MODEL_VERSION=$variables_MODEL_VERSION
MODEL_SERVER_REGISTRY=$variables_MODEL_SERVER_REGISTRY

echo "MODEL_NAME: $MODEL_NAME"
echo "MODEL_VERSION: $MODEL_VERSION"
echo "MODEL_SERVER_REGISTRY: $MODEL_SERVER_REGISTRY"

# Construct the target path
TARGET_PATH="$MODEL_SERVER_REGISTRY/$MODEL_NAME/$MODEL_VERSION"

# Check if the MODEL_NAME directory exists in the MODEL_SERVER_REGISTRY
if [ ! -d "$MODEL_SERVER_REGISTRY/$MODEL_NAME" ]; then
    # If not, unzip the full content
    unzip $MODEL_NAME.zip -d $MODEL_SERVER_REGISTRY
else
    # If MODEL_NAME directory exists, check if MODEL_VERSION directory exists
    if [ ! -d "$TARGET_PATH" ]; then
        # If MODEL_VERSION directory does not exist, create it
        mkdir -p $TARGET_PATH
    fi
    # Extract the model.onnx file to the target directory, overwrite if exists
    unzip -o $MODEL_NAME.zip $MODEL_NAME/$MODEL_VERSION/model.onnx -d $MODEL_SERVER_REGISTRY
fi
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            537
        </positionTop>
        <positionLeft>
            508
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Model_Packaging" preciousResult="true">
      <description>
        <![CDATA[ Download a trained model. ]]>
      </description>
      <variables>
        <variable advanced="false" description="If False, the task will be ignored, it will not be executed." hidden="false" inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="true"/>
        <variable advanced="false" hidden="false" inherited="false" name="CONTAINER_IMAGE" value="activeeon/dlm4"/>
        <variable advanced="false" hidden="false" inherited="true" name="MODEL_NAME" value="model-${PA_JOB_ID}"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_download_model"/>
      </genericInformation>
      <depends>
        <task ref="Train_Image_Classification_Model"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import os
import sys
import zipfile
import requests
import json
import ssl
import urllib.request
import joblib
import pickle
import bz2
import onnx
import uuid
import pandas as pd
from os import remove, listdir, makedirs
from os.path import basename, splitext, exists, join, isfile
from urllib.parse import urlparse
import torch
from pathlib import Path

from os import remove, listdir, makedirs
from os.path import basename, splitext, exists, join, isfile
from urllib.parse import urlparse
from sklearn.model_selection import train_test_split
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType

__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

# -------------------------------------------------------------
# Get schedulerapi access and acquire session id
schedulerapi.connect()
sessionid = schedulerapi.getSession()
connection_info = schedulerapi.getConnectionInfo()
ci_url = connection_info.getUrl()
url = urlparse(ci_url)
proactive_url = url.scheme + "://" + url.hostname + ":" + str(url.port)
print("proactive_url: ", proactive_url)

# -------------------------------------------------------------
# Import an external python script containing a collection of
# common utility Python functions and classes
PA_CATALOG_REST_URL = variables.get("PA_CATALOG_REST_URL")
PA_PYTHON_UTILS_URL = PA_CATALOG_REST_URL + "/buckets/ai-machine-learning/resources/Utils_Script/raw"
req = urllib.request.Request(PA_PYTHON_UTILS_URL)
req.add_header('sessionid', sessionid)
if PA_PYTHON_UTILS_URL.startswith('https'):
    content = urllib.request.urlopen(req, context=ssl._create_unverified_context()).read()
else:
    content = urllib.request.urlopen(req).read()
exec(content, globals())

# -------------------------------------------------------------
# Check if the Python task is enabled or not
check_task_is_enabled()

# -------------------------------------------------------------
# Get data from the propagated variables
#
MODEL_PATH = variables.get("MODEL_PATH")
assert_not_none_not_empty(MODEL_PATH, "MODEL_PATH should be defined!")

MODEL_NAME = variables.get("MODEL_NAME")
assert_not_none_not_empty(MODEL_NAME, "MODEL_NAME should be defined!")

MODEL_VERSION = variables.get("MODEL_VERSION")
assert_not_none_not_empty(MODEL_VERSION, "MODEL_VERSION should be defined!")

MODEL_SERVER_ID = variables.get("MODEL_SERVER_ID")
assert_not_none_not_empty(MODEL_VERSION, "MODEL_SERVER_ID should be defined!")

BATCH_SIZE = int(str(variables.get("BATCH_SIZE")))
assert_not_none_not_empty(BATCH_SIZE, "BATCH_SIZE should be defined!")

def get_instance_name_and_model_registry_path(sessionid, proactive_url, instance_id):
    headers = {'sessionid': sessionid}
    url = f"{proactive_url}/cloud-automation-service/serviceInstances/{instance_id}"
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        data = json.loads(response.text)
        instance_name = data.get('variables', {}).get('INSTANCE_NAME')
        model_registry_path = data.get('variables', {}).get('MODEL_REGISTRY_PATH')
        return instance_name, model_registry_path
    else:
        print(f"Failed to get data, status code: {response.status_code}")
        return None, None
instance_name, model_registry_path = get_instance_name_and_model_registry_path(sessionid, proactive_url, MODEL_SERVER_ID)
MODEL_SERVER_TOKEN = "PSA_" + instance_name
print('MODEL_SERVER_TOKEN: ', MODEL_SERVER_TOKEN)
print('MODEL_SERVER_REGISTRY: ', model_registry_path)
variables.put('MODEL_SERVER_TOKEN', MODEL_SERVER_TOKEN)
variables.put('MODEL_SERVER_REGISTRY', model_registry_path)

# Load trained model
model = torch.load(MODEL_PATH,map_location={'cuda:0': 'cpu'})

# http://pytorch.org/docs/master/cuda.html#torch.cuda.is_available
# Returns a bool indicating if CUDA is currently available.
use_gpu = torch.cuda.is_available()
if use_gpu:
    model = model.cuda()

# Check for GPU availability and use CPU if not available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.eval()

# Dummy input for ONNX export
CHANNEL = 3
dummy_input = torch.randn(BATCH_SIZE, CHANNEL, 224, 224).to(device)

# Export the model to ONNX format
onnx_output = 'model.onnx'
#torch.onnx.export(model, dummy_input, onnx_output, input_names=['input'], output_names=['output'])
torch.onnx.export(model, dummy_input,onnx_output)

# Load the ONNX model from the file
onnx_model = onnx.load(onnx_output)

def create_triton_config(model, config_path, model_name, max_batch_size=0):
    # Extract input information
    input_tensors = []
    for i in model.graph.input:
        shape = [dim.dim_value if dim.dim_value >= 1 else -1 for dim in i.type.tensor_type.shape.dim]
        if i.type.tensor_type.elem_type == onnx.TensorProto.INT64:
            data_type = "TYPE_INT64"
        else:
            data_type = "TYPE_FP32"
        input_tensors.append({"name": i.name, "data_type": data_type, "dims": shape})
    # Extract output information
    output_tensors = []
    for o in model.graph.output:
        shape = [dim.dim_value if dim.dim_value >= 1 else -1 for dim in o.type.tensor_type.shape.dim]
        if o.type.tensor_type.elem_type == onnx.TensorProto.INT64:
            data_type = "TYPE_INT64"
        else:
            data_type = "TYPE_FP32"
        output_tensors.append({"name": o.name, "data_type": data_type, "dims": shape})
    # Create the Triton configuration
    config = {
        "name": model_name,
        "backend": "onnxruntime",
        "max_batch_size": max_batch_size,
        "input": input_tensors,
        "output": output_tensors,
        "instance_group": [{"count": 1, "kind": "KIND_CPU"}],
    }
    # Save the configuration as a JSON file
    with open(config_path, 'w') as f:
        f.write("name: \"" + config['name'] + "\"\n")
        f.write("backend: \"" + config['backend'] + "\"\n")
        # f.write("max_batch_size: " + str(config['max_batch_size']) + "\n")
        for input_tensor in config['input']:
            f.write("input {\n")
            f.write("  name: \"" + input_tensor['name'] + "\"\n")
            f.write("  data_type: " + input_tensor['data_type'] + "\n")
            f.write("  dims: [ " + ", ".join([str(dim) for dim in input_tensor['dims']]) + " ]\n")
            f.write("}\n")
        for output_tensor in config['output']:
            f.write("output {\n")
            f.write("  name: \"" + output_tensor['name'] + "\"\n")
            f.write("  data_type: " + output_tensor['data_type'] + "\n")
            f.write("  dims: [ " + ", ".join([str(dim) for dim in output_tensor['dims']]) + " ]\n")
            f.write("}\n")
        for instance_group in config['instance_group']:
            f.write("instance_group {\n")
            f.write("  count: " + str(instance_group['count']) + "\n")
            f.write("  kind: " + instance_group['kind'] + "\n")
            f.write("}\n")
    print(f"The configuration file has been saved to '{config_path}'")

# Define localspace
os.makedirs(MODEL_NAME, exist_ok=True)

MODEL_VERSION_DIR = os.path.join(MODEL_NAME, MODEL_VERSION)
os.makedirs(MODEL_VERSION_DIR, exist_ok=True)

config_path = os.path.join(MODEL_NAME, "config.pbtxt")
create_triton_config(onnx_model, config_path, MODEL_NAME, max_batch_size=BATCH_SIZE)

with open(config_path , 'r') as file:
    content = file.read()
    print(content)

model_path = os.path.join(MODEL_VERSION_DIR, "model.onnx")
with open(model_path, "wb") as f:
    f.write(onnx_model.SerializeToString())

def zip_directory(directory_path):
    # Create a zipfile object and write files to it
    zip_file_path = directory_path + ".zip"
    with zipfile.ZipFile(zip_file_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
        for root, dirs, files in os.walk(directory_path):
            for file in files:
                # Keep the directory_path inside the zip so when unzipped it creates a folder and extracts the files inside it
                zip_file.write(os.path.join(root, file), 
                               os.path.relpath(os.path.join(root, file), 
                               os.path.dirname(directory_path)))
                # zip_file.write(os.path.join(root, file), 
                #                os.path.relpath(os.path.join(root, file), 
                #                directory_path))
    print(f"The zip file '{zip_file_path}' has been created.")
    return zip_file_path

# Test the function
zip_file_path = zip_directory(MODEL_NAME) # replace with your directory

# -------------------------------------------------------------
print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <outputFiles>
        <files accessMode="transferToUserSpace" includes="${MODEL_NAME}.zip"/>
      </outputFiles>
      <metadata>
        <positionTop>
            409
        </positionTop>
        <positionLeft>
            508
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Update_Deployment_Time">
      <description>
        <![CDATA[ Update the deployment time in the dashboard for the model that was just deployed. ]]>
      </description>
      <depends>
        <task ref="Deploy_Model"/>
      </depends>
      <pre>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.io.FileType
import com.google.common.base.Splitter
import org.ow2.proactive.scheduler.common.job.JobVariable
import groovy.json.JsonSlurper
import java.net.URL

def getMLOpsDashboardEndpointUrl(String sessionid, String proactiveUrl, String mlopsDashboardToken, String instanceId) {
    // Define headers
    def headers = ['sessionid': sessionid]

    // Define base URL
    def baseUrl = "$proactiveUrl/cloud-automation-service/serviceInstances/active"

    // Create URL object
    def url = new URL(baseUrl)

    // Open connection
    def connection = url.openConnection()

    // Set headers
    headers.each { key, value ->
        connection.setRequestProperty(key, value)
    }

    // Get response
    def response
    try {
        response = connection.getInputStream()
    } catch (Exception e) {
        println "Error: Unable to connect to $baseUrl"
        return [null, null]
    }

    // Parse JSON response
    def json = new JsonSlurper().parseText(response.text)
    // println "json: $json"
    
    // Get instance name given its id
    def instance_name = ""
    if (instanceId != "-1") {
        instance_name = json.find{it.instance_id == instanceId.toInteger()}?.variables.INSTANCE_NAME
    }

    // Fetch MLOPS_ENDPOINT_ID
    def mlopsDashboardEndpointID = json.variables.find{ it.PSA_TOKEN == mlopsDashboardToken }?.ENDPOINT_ID
    // println "mlops endpoint id: $mlopsDashboardEndpointID"
    
    // Fetch MLOPS_DASHBOARD_URL
    def mlopsEndpointUrl = json.deployments.endpoint.flatten().find{ it.id.contains(mlopsDashboardEndpointID) }?.url
    println "mlopsEndpointUrl: $mlopsEndpointUrl"
    
    // Remove "dashboard" from the URL if it exists
    if (mlopsEndpointUrl) {
        mlopsEndpointUrl = mlopsEndpointUrl.replace("/dashboard/", "")
    }
    
    return mlopsEndpointUrl
}

// Usage example
schedulerapi.connect()
connectionInfo = schedulerapi.getConnectionInfo()
ciLogin = connectionInfo.getLogin()
ciPasswd = connectionInfo.getPassword()
String ciUrl = connectionInfo.getUrl()
def sessionId = schedulerapi.getSession()

user_credentials = [
    sessionId: sessionId,
    ciLogin: ciLogin,
    ciPasswd: ciPasswd,
    ciUrl: ciUrl
]

def url = new URL(ciUrl)
def proactiveUrl = url.getProtocol() + "://" + url.getHost() + ":" + url.getPort()
def mlopsDashboardToken = variables.get("MLOPS_DASHBOARD_INSTANCE")

println "mlopsDashboardToken: $mlopsDashboardToken"

def instanceId = variables.get("MODEL_SERVER_ID")
println "MODEL_SERVER_ID: $instanceId"

results = getMLOpsDashboardEndpointUrl(sessionId, proactiveUrl, mlopsDashboardToken, instanceId)
println "results: $results"

mlopsEndpointUrl = results
println "mlopsEndpointUrl: $mlopsEndpointUrl"
variables.put("MLOPS_DASHBOARD_ENDPOINT_URL", mlopsEndpointUrl)
]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.json.JsonSlurper
import java.net.URL
import java.net.URLEncoder
import java.net.HttpURLConnection

// Print task beginning
def taskName = variables.get("PA_TASK_NAME")
println("BEGIN " + taskName)

// Get schedulerapi access and acquire session id
schedulerapi.connect()
def sessionid = schedulerapi.getSession()
def connectionInfo = schedulerapi.getConnectionInfo()
def ciUrl = connectionInfo.getUrl()
def url = new URL(ciUrl)
def proactiveUrl = url.protocol + "://" + url.host + ":" + url.port
println("proactive_url: " + proactiveUrl)

// Get variables from workflow
def MODEL_NAME = variables.get("MODEL_NAME")
def MODEL_VERSION = variables.get("MODEL_VERSION")
def MODEL_SERVER_ID = variables.get("MODEL_SERVER_ID")
def MODEL_SERVER_TOKEN = variables.get("MODEL_SERVER_TOKEN")

def MLOPS_DASHBOARD_ENDPOINT_URL = variables.get('MLOPS_DASHBOARD_ENDPOINT_URL')
println("MLOPS_DASHBOARD_ENDPOINT_URL: " + MLOPS_DASHBOARD_ENDPOINT_URL)

// Extract model server name from token
def MODEL_SERVER_NAME = MODEL_SERVER_TOKEN.replace("PSA_", "")
println("MODEL_SERVER_NAME: " + MODEL_SERVER_NAME)

// Determine dashboard API URL
def dashboard_url = variables.get('MLOPS_DASHBOARD_ENDPOINT_URL')

// Call the API to update the deployment time
def api_url = "${dashboard_url}/api/update_model_deployment_time"
def params = [
    model_server_name: MODEL_SERVER_NAME,
    model_name: MODEL_NAME,
    model_version: MODEL_VERSION
]

// Build query string
def queryString = params.collect { k, v -> 
    URLEncoder.encode(k, "UTF-8") + "=" + URLEncoder.encode(v.toString(), "UTF-8")
}.join("&")

def fullUrl = "${api_url}?${queryString}"
println("Making API call to: " + fullUrl)

try {
    // Create connection
    def apiConnection = new URL(fullUrl).openConnection() as HttpURLConnection
    apiConnection.requestMethod = "GET"
    
    // Get response
    def responseCode = apiConnection.responseCode
    def responseText = apiConnection.inputStream.text
    println("Response status code: " + responseCode)
    println("Response body: " + responseText)
    
    if (responseCode == 200) {
        println("Successfully updated deployment time")
    } else {
        println("Failed to update deployment time")
    }
} catch (Exception e) {
    println("Error making API call: " + e.toString())
}

println("END " + taskName)
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            664.9921875
        </positionTop>
        <positionLeft>
            508
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2464px;
            height:3428px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-148px;left:-423.5px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_789" style="top: 153px; left: 428.5px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load and return an image dataset."><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_image.png" width="20px">&nbsp;<span class="name">Import_Image_Dataset</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_792" style="top: 281px; left: 508px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Train a model using an image classification network."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png" width="20px">&nbsp;<span class="name">Train_Image_Classification_Model</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_795" style="top: 153px; left: 587.5px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="ResNet-18 is a deep convolutional neural network, trained on 1.28 million ImageNet training images, coming from 1000 classes."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_learning.png" width="20px">&nbsp;<span class="name">ResNet_18</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_798" style="top: 537px; left: 508px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="The simplest task, ran by a bash engine."><img src="/studio/images/LinuxBash.png" width="20px">&nbsp;<span class="name">Deploy_Model</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_801" style="top: 409px; left: 508px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Download a trained model."><img src="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png" width="20px">&nbsp;<span class="name">Model_Packaging</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_804" style="top: 664.992px; left: 508px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Update the deployment time in the dashboard for the model that was just deployed."><img src="/studio/images/Groovy.png" width="20px">&nbsp;<span class="name">Update_Deployment_Time</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon"></i></a></div><svg style="position:absolute;left:489.5px;top:192.5px" width="125.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 104.5 88 C 114.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style="--darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);" data-darkreader-inline-stroke=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M93.327773,61.830692 L79.92864211743489,45.415354915678826 L81.3891100125129,54.51848808659566 L72.61643820403054,57.35401790316592 L93.327773,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M93.327773,61.830692 L79.92864211743489,45.415354915678826 L81.3891100125129,54.51848808659566 L72.61643820403054,57.35401790316592 L93.327773,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);"></path></svg><svg style="position:absolute;left:594px;top:192.5px" width="54.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 43.5 50 33.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style="--darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);" data-darkreader-inline-stroke=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M0.30595699999999804,65.364084 L15.410522372513896,50.50299033541886 L6.48166106497759,52.79982201205104 L2.846260384564932,44.32728627044126 L0.30595699999999804,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M0.30595699999999804,65.364084 L15.410522372513896,50.50299033541886 L6.48166106497759,52.79982201205104 L2.846260384564932,44.32728627044126 L0.30595699999999804,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);"></path></svg><svg style="position:absolute;left:549.5px;top:448.5px" width="29" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 18 50 8 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style="--darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);" data-darkreader-inline-stroke=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.149632,66.303232 L7.49984351657956,47.438247975227235 L-0.24966605297428535,52.43275510120006 L-6.370633382220376,45.538282028201515 L-2.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.149632,66.303232 L7.49984351657956,47.438247975227235 L-0.24966605297428535,52.43275510120006 L-6.370633382220376,45.538282028201515 L-2.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);"></path></svg><svg style="position:absolute;left:557.5px;top:320.5px" width="57.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 46.5 50 36.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style="--darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);" data-darkreader-inline-stroke=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M0.5897029999999984,65.364084 L16.164455622844606,50.99651354646838 L7.166337365145637,53.004962654726896 L3.8053342775714984,44.41987918132274 L0.5897029999999984,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M0.5897029999999984,65.364084 L16.164455622844606,50.99651354646838 L7.166337365145637,53.004962654726896 L3.8053342775714984,44.41987918132274 L0.5897029999999984,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);"></path></svg><svg style="position:absolute;left:549.5px;top:576.5px" width="48.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 27.5 88 C 37.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style="--darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);" data-darkreader-inline-stroke=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M27.874324375,65.8307285 L26.909461410455734,44.66308717037495 L22.65251929621236,52.841011346838144 L13.919744257293866,49.88489224916259 L27.874324375,65.8307285" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M27.874324375,65.8307285 L26.909461410455734,44.66308717037495 L22.65251929621236,52.841011346838144 L13.919744257293866,49.88489224916259 L27.874324375,65.8307285" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: var(--darkreader-text-666666, #a8a095);"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 490px; top: 183px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 594.5px; top: 311px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 594.5px; top: 271px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 628px; top: 183px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 550px; top: 567px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 550px; top: 527px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 558px; top: 439px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 558px; top: 399px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 577.5px; top: 695px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 577.5px; top: 655px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: var(--darkreader-text-666666, #a8a095); --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
