<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.14" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd"  name="MLOps_Model_Server_Application_Performance_Analyzer" projectName="3. MLOps Model Server Workflows" tags="MLOps,Model Inference,Triton" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="GRPC_INFERENCE_URL" value=""  description="GRPC inference url of the model server (e.g. localhost:8001)." group="Model Server" advanced="false" hidden="false"/>
    <variable name="MODEL_NAME" value="simple" model="PA:LIST(simple,simple_identity,simple_int8,simple_sequence,simple_string,densenet_onnx,inception_graphdef)" description="Name of the model to be tested." group="Model Server" advanced="false" hidden="false"/>
    <variable name="CONTAINER_PLATFORM" value="docker" model="PA:LIST(no-container,docker,podman,singularity)" description="Container platform used for executing the workflow tasks." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="CONTAINER_IMAGE" value="nvcr.io/nvidia/tritonserver:22.10-py3-sdk" model="PA:LIST(,nvcr.io/nvidia/tritonserver:22.10-py3-sdk)" description="Name of the container image being used to run the workflow tasks." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="CONCURRENCY_RANGE" value="1:4:1" model="PA:REGEXP(^(\d+):(\d+):(\d+)$)?" description="The option concurrency-range  should be defined following this template start:end:step  It specifies the range of concurrency levels covered to measure the performance of the deployed model. The performance will be analyzed starting from the concurrency level of &#39;start&#39; and go until &#39;end&#39; with a stride of &#39;step&#39;." group="Model Server" advanced="false" hidden="false"/>
  </variables>
  <description>
    <![CDATA[ This workflow helps to measure the inference performance of the deployed models on the Model Server. It measures the changes in performance by testing different concurrency ranges.

To analyze the performance of your deployed model, you need to specify your MODEL_NAME, the GRPC_INFERENCE_URI of the Model Server where the model is deployed, and the concurrency range.

In concurrency mode, the workflow attempts to send inference requests to the server such that N requests are always outstanding during the test. For example, when using concurrency range = 4, it will attempt to have 4 outgoing inference requests at all times during the test.

The performance report can be accessed at the end of the execution via the job results tab. The model latency is broken down into the following components:

Queue: The average time spent in the inference schedule queue by a request waiting for an instance of the model to become available.
Compute: The average time spent performing the actual inference, including any time needed to copy data to/from the GPU/CPU.
Overhead: The average time spent in the endpoint that cannot be correctly captured in the send/receive time. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="ai-mlops-dashboard"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/model_server.png"/>
    <info name="Documentation" value="PAIO/PAIOUserGuide.html"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Model_Performance_Analyzer" preciousResult="true" fork="true">
      <description>
        <![CDATA[ Analyze the performance of a deployed model by sending multiple inferences concurrently ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/model_server.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html"/>
      </genericInformation>
      <selection>
        <script type="static">
          <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/check_node_source_name/raw" language="groovy"></file>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.io.FileType

String GRPC_INFERENCE_URL = variables.get("GRPC_INFERENCE_URL")
String MODEL_NAME = variables.get("MODEL_NAME")
String CONCURRENCY_RANGE = variables.get("CONCURRENCY_RANGE")

// -------------------------------------------------------------
// Execute the performance analyzer on the selected model
try {
    def command = "perf_analyzer -i grpc -u $GRPC_INFERENCE_URL -m $MODEL_NAME --concurrency-range $CONCURRENCY_RANGE -f perf.csv"
    println "Running " + command
    def output = command.execute().text
    println(output)
} catch(java.io.IOException e) {
    println("This model can not be tested using the performance analyzer!")
}
// -------------------------------------------------------------

// Read the CSV output file
def inputFile = new File('perf.csv')
if (inputFile.exists()) {
    println "Parsing the results from the perf.csv file"
    def lines = inputFile.readLines()
    def headers = lines[0].split(',')
    // Generate the HTML output
    def html = new StringBuilder()
    html << """
    <!DOCTYPE html>
    <html>
    <head>
    <style>
      table {
        width: 100%;
        border-collapse: collapse;
      }
      th, td {
        padding: 8px;
        text-align: left;
        border-bottom: 1px solid #ddd;
      }
      th {
        background-color: rgb(51, 122, 183);
        color: white; /* Optional - this will set the text color to white */
        font-weight: bold;
      }
      tr:nth-child(even) {
        background-color: #f2f2f2;
      }
    </style>
    </head>
    <body>
    <table>
    """
    // Add table headers
    html << '<tr>'
    headers.each { header ->
        html << "<th>${header}</th>"
    }
    html << '</tr>'
    // Add table data
    lines.drop(1).each { line ->
        def values = line.split(',')
        html << '<tr>'
        values.each { value ->
            html << "<td>${value}</td>"
        }
        html << '</tr>'
    }
    byte[] htmlBytes = html.toString().getBytes("UTF-8")
    result = htmlBytes
    println "Done"
} else {
  println "File perf.csv not found"
  result = ""
}
resultMetadata.put("file.extension", ".html")
resultMetadata.put("file.name", "output.html")
resultMetadata.put("content.type", "text/html")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            78.984375
        </positionTop>
        <positionLeft>
            397.5390625
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2091px;
            height:2400px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-73.984375px;left:-392.5390625px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_7" style="top: 78.9846px; left: 397.539px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Analyze the performance of a deployed model by sending multiple inferences concurrently"><img src="/automation-dashboard/styles/patterns/img/wf-icons/model_server.png" width="20px">&nbsp;<span class="name">Model_Performance_Analyzer</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 475.5px; top: 109px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
