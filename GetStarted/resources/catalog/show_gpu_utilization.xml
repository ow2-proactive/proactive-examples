<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.13" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Show_GPU_Utilization" onTaskError="continueJobExecution" priority="normal" projectName="2. Advanced Workflows" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd">
  <description>
    <![CDATA[ A Python module for programmatically getting the GPU utilization from NVIDIA GPUs using nvidia-smi ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="basic-examples"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/nvidia.png"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Show_GPU_Utilization">
      <description>
        <![CDATA[ A Python module for programmatically getting the GPU utilization from NVIDIA GPUs using nvidia-smi. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/nvidia.png"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <code language="python">
            <![CDATA[
# GPUtil - GPU utilization
#
# A Python module for programmatically getting the GPU utilization from NVIDIA GPUs using nvidia-smi
#
# Author: Anders Krogh Mortensen (anderskm)
# Date:   16 January 2017
# Web:    https://github.com/anderskm/gputil
#
# LICENSE
#
# MIT License
#
# Copyright (c) 2017 anderskm
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
from subprocess import Popen, PIPE
from distutils import spawn
import os
import math
import random
import time
import sys
import platform


class GPU:
    def __init__(self, ID, uuid, load, memoryTotal, memoryUsed, memoryFree, driver, gpu_name, serial, display_mode, display_active, temp_gpu):
        self.id = ID
        self.uuid = uuid
        self.load = load
        self.memoryUtil = float(memoryUsed)/float(memoryTotal)
        self.memoryTotal = memoryTotal
        self.memoryUsed = memoryUsed
        self.memoryFree = memoryFree
        self.driver = driver
        self.name = gpu_name
        self.serial = serial
        self.display_mode = display_mode
        self.display_active = display_active
        self.temperature = temp_gpu


def safeFloatCast(strNumber):
    try:
        number = float(strNumber)
    except ValueError:
        number = float('nan')
    return number


def getGPUs():
    if platform.system() == "Windows":
        # If the platform is Windows and nvidia-smi 
        # could not be found from the environment path, 
        # try to find it from system drive with default installation path
        nvidia_smi = spawn.find_executable('nvidia-smi')
        if nvidia_smi is None:
            nvidia_smi = "%s\\Program Files\\NVIDIA Corporation\\NVSMI\\nvidia-smi.exe" % os.environ['systemdrive']
    else:
        nvidia_smi = "nvidia-smi"
    # Get ID, processing and memory utilization for all GPUs
    try:
        p = Popen([nvidia_smi, "--query-gpu=index,uuid,utilization.gpu,memory.total,memory.used,memory.free,driver_version,name,gpu_serial,display_active,display_mode,temperature.gpu", "--format=csv,noheader,nounits"], stdout=PIPE)
        stdout, stderror = p.communicate()
    except:
        return []
    output = stdout.decode('UTF-8')
    # Parse output
    lines = output.split(os.linesep)
    numDevices = len(lines)-1
    GPUs = []
    for g in range(numDevices):
        line = lines[g]
        vals = line.split(', ')
        for i in range(12):
            if i == 0:
                deviceIds = int(vals[i])
            elif i == 1:
                uuid = vals[i]
            elif i == 2:
                gpuUtil = safeFloatCast(vals[i])/100
            elif i == 3:
                memTotal = safeFloatCast(vals[i])
            elif i == 4:
                memUsed = safeFloatCast(vals[i])
            elif i == 5:
                memFree = safeFloatCast(vals[i])
            elif i == 6:
                driver = vals[i]
            elif i == 7:
                gpu_name = vals[i]
            elif i == 8:
                serial = vals[i]
            elif i == 9:
                display_active = vals[i]
            elif i == 10:
                display_mode = vals[i]
            elif i == 11:
                temp_gpu = safeFloatCast(vals[i])
        GPUs.append(GPU(deviceIds, uuid, gpuUtil, memTotal, memUsed, memFree, driver, gpu_name, serial, display_mode, display_active, temp_gpu))
    return GPUs  # (deviceIds, gpuUtil, memUtil)


def getAvailable(order='first', limit=1, maxLoad=0.5, maxMemory=0.5, memoryFree=0, includeNan=False, excludeID=[], excludeUUID=[]):
    # order = first | last | random | load | memory
    #    first --> select the GPU with the lowest ID (DEFAULT)
    #    last --> select the GPU with the highest ID
    #    random --> select a random available GPU
    #    load --> select the GPU with the lowest load
    #    memory --> select the GPU with the most memory available
    # limit = 1 (DEFAULT), 2, ..., Inf
    #     Limit sets the upper limit for the number of GPUs to return. E.g. if limit = 2, but only one is available, only one is returned.
    # Get device IDs, load and memory usage
    GPUs = getGPUs()
    # Determine, which GPUs are available
    GPUavailability = getAvailability(GPUs, maxLoad=maxLoad, maxMemory=maxMemory, memoryFree=memoryFree, includeNan=includeNan, excludeID=excludeID, excludeUUID=excludeUUID)
    availAbleGPUindex = [idx for idx in range(0, len(GPUavailability)) if (GPUavailability[idx] == 1)]
    # Discard unavailable GPUs
    GPUs = [GPUs[g] for g in availAbleGPUindex]
    # Sort available GPUs according to the order argument
    if order == 'first':
        GPUs.sort(key=lambda x: float('inf') if math.isnan(x.id) else x.id, reverse=False)
    elif order == 'last':
        GPUs.sort(key=lambda x: float('-inf') if math.isnan(x.id) else x.id, reverse=True)
    elif order == 'random':
        GPUs = [GPUs[g] for g in random.sample(range(0, len(GPUs)), len(GPUs))]
    elif order == 'load':
        GPUs.sort(key=lambda x: float('inf') if math.isnan(x.load) else x.load, reverse=False)
    elif order == 'memory':
        GPUs.sort(key=lambda x: float('inf') if math.isnan(x.memoryUtil) else x.memoryUtil, reverse=False)
    # Extract the number of desired GPUs, but limited to the total number of available GPUs
    GPUs = GPUs[0:min(limit, len(GPUs))]
    # Extract the device IDs from the GPUs and return them
    deviceIds = [gpu.id for gpu in GPUs]
    return deviceIds


def getAvailability(GPUs, maxLoad=0.5, maxMemory=0.5, memoryFree=0, includeNan=False, excludeID=[], excludeUUID=[]):
    # Determine, which GPUs are available
    GPUavailability = [
        1 if (gpu.memoryFree >= memoryFree)
        and (gpu.load < maxLoad or (includeNan and math.isnan(gpu.load)))
        and (gpu.memoryUtil < maxMemory or (includeNan and math.isnan(gpu.memoryUtil)))
        and ((gpu.id not in excludeID) and (gpu.uuid not in excludeUUID)) else 0 for gpu in GPUs
    ]
    return GPUavailability


def getFirstAvailable(order='first', maxLoad=0.5, maxMemory=0.5, attempts=1, interval=900, verbose=False, includeNan=False, excludeID=[], excludeUUID=[]):
    for i in range(attempts):
        if verbose:
            print('Attempting (' + str(i+1) + '/' + str(attempts) + ') to locate available GPU.')
        # Get first available GPU
        available = getAvailable(order=order, limit=1, maxLoad=maxLoad, maxMemory=maxMemory, includeNan=includeNan, excludeID=excludeID, excludeUUID=excludeUUID)
        # If an available GPU was found, break for loop.
        if available:
            if verbose:
                print('GPU ' + str(available) + ' located!')
            break
        # If this is not the last attempt, sleep for 'interval' seconds
        if i != (attempts-1):
            time.sleep(interval)
    # Check if an GPU was found, or if the attempts simply ran out. Throw error, if no GPU was found
    if not available:
        raise RuntimeError('Could not find an available GPU after ' + str(attempts) + ' attempts with ' + str(interval) + ' seconds interval.')
    # Return found GPU
    return available


def showUtilization(all=False, attrList=None, useOldCode=False):
    GPUs = getGPUs()
    if all:
        if useOldCode:
            print(' ID | Name | Serial | UUID || GPU util. | Memory util. || Memory total | Memory used | Memory free || Display mode | Display active |')
            print('------------------------------------------------------------------------------------------------------------------------------')
            for gpu in GPUs:
                print(' {0:2d} | {1:s}  | {2:s} | {3:s} || {4:3.0f}% | {5:3.0f}% || {6:.0f}MB | {7:.0f}MB | {8:.0f}MB || {9:s} | {10:s}'.format(gpu.id,gpu.name,gpu.serial,gpu.uuid,gpu.load*100,gpu.memoryUtil*100,gpu.memoryTotal,gpu.memoryUsed,gpu.memoryFree,gpu.display_mode,gpu.display_active))
        else:
            attrList = [
                [{'attr': 'id', 'name': 'ID'},
                 {'attr': 'name', 'name': 'Name'},
                 {'attr': 'serial', 'name': 'Serial'},
                 {'attr': 'uuid', 'name': 'UUID'}],
                [{'attr': 'temperature', 'name': 'GPU temp.', 'suffix': 'C', 'transform': lambda x: x, 'precision': 0},
                 {'attr': 'load', 'name': 'GPU util.', 'suffix': '%', 'transform': lambda x: x*100, 'precision': 0},
                 {'attr': 'memoryUtil', 'name': 'Memory util.', 'suffix': '%', 'transform': lambda x: x*100, 'precision': 0}],
                [{'attr': 'memoryTotal', 'name': 'Memory total', 'suffix': 'MB', 'precision': 0},
                 {'attr': 'memoryUsed', 'name': 'Memory used', 'suffix': 'MB', 'precision': 0},
                 {'attr': 'memoryFree', 'name': 'Memory free', 'suffix': 'MB', 'precision': 0}],
                [{'attr': 'display_mode', 'name': 'Display mode'},
                 {'attr': 'display_active', 'name': 'Display active'}]]
    else:
        if useOldCode:
            print(' ID  GPU  MEM')
            print('--------------')
            for gpu in GPUs:
                print(' {0:2d} {1:3.0f}% {2:3.0f}%'.format(gpu.id, gpu.load*100, gpu.memoryUtil*100))
        elif attrList is None:
            # if `attrList` was not specified, use the default one
            attrList = [[
                 {'attr': 'id', 'name': 'ID'},
                 {'attr': 'load', 'name': 'GPU', 'suffix': '%', 'transform': lambda x: x*100, 'precision': 0},
                 {'attr': 'memoryUtil', 'name': 'MEM', 'suffix': '%', 'transform': lambda x: x*100, 'precision': 0}],
                ]
    if not useOldCode:
        if attrList is not None:
            headerString = ''
            GPUstrings = ['']*len(GPUs)
            for attrGroup in attrList:
                for attrDict in attrGroup:
                    headerString = headerString + '| ' + attrDict['name'] + ' '
                    headerWidth = len(attrDict['name'])
                    minWidth = len(attrDict['name'])
                    attrPrecision = '.' + str(attrDict['precision']) if ('precision' in attrDict.keys()) else ''
                    attrSuffix = str(attrDict['suffix']) if ('suffix' in attrDict.keys()) else ''
                    attrTransform = attrDict['transform'] if ('transform' in attrDict.keys()) else lambda x : x
                    for gpu in GPUs:
                        attr = getattr(gpu, attrDict['attr'])
                        attr = attrTransform(attr)
                        if isinstance(attr, float):
                            attrStr = ('{0:' + attrPrecision + 'f}').format(attr)
                        elif isinstance(attr, int):
                            attrStr = '{0:d}'.format(attr)
                        elif isinstance(attr, str):
                            attrStr = attr
                        elif sys.version_info[0] == 2:
                            if isinstance(attr, unicode):
                                attrStr = attr.encode('ascii', 'ignore')
                        else:
                            raise TypeError('Unhandled object type (' + str(type(attr)) + ') for attribute \'' + attrDict['name'] + '\'')
                        attrStr += attrSuffix
                        minWidth = max(minWidth, len(attrStr))
                    headerString += ' '*max(0, minWidth-headerWidth)
                    minWidthStr = str(minWidth - len(attrSuffix))
                    for gpuIdx, gpu in enumerate(GPUs):
                        attr = getattr(gpu, attrDict['attr'])
                        attr = attrTransform(attr)
                        if isinstance(attr, float):
                            attrStr = ('{0:' + minWidthStr + attrPrecision + 'f}').format(attr)
                        elif isinstance(attr, int):
                            attrStr = ('{0:' + minWidthStr + 'd}').format(attr)
                        elif isinstance(attr, str):
                            attrStr = ('{0:' + minWidthStr + 's}').format(attr)
                        elif sys.version_info[0] == 2:
                            if isinstance(attr, unicode):
                                attrStr = ('{0:' + minWidthStr + 's}').format(attr.encode('ascii', 'ignore'))
                        else:
                            raise TypeError('Unhandled object type (' + str(type(attr)) + ') for attribute \'' + attrDict['name'] + '\'')
                        attrStr += attrSuffix
                        GPUstrings[gpuIdx] += '| ' + attrStr + ' '
                headerString = headerString + '|'
                for gpuIdx, gpu in enumerate(GPUs):
                    GPUstrings[gpuIdx] += '|'
            headerSpacingString = '-' * len(headerString)
            print(headerString)
            print(headerSpacingString)
            for GPUstring in GPUstrings:
                print(GPUstring)


# Show the utilization of all GPUs in a nice table
showUtilization()

# Show all stats of all GPUs in a nice table
showUtilization(all=True)

# Get all available GPU(s), ordered by ID in ascending order
print('All available ordered by id: ')
print(getAvailable(order='first', limit=999))

# Get 1 available GPU, ordered by ID in descending order
print('Last available: ')
print(getAvailable(order='last', limit=1))

# Get 1 random available GPU
print('Random available: ')
print(getAvailable(order='random'))

# Get 1 available GPU, ordered by GPU load ascending
print('First available weighted by GPU load ascending: ')
print(getAvailable(order='load', limit=1))

# Get all available GPU with max load of 10%, ordered by memory ascending
print('All available weighted by memory load ascending: ')
print(getAvailable(order='memory', limit=999, maxLoad=0.1))

# Get the first available GPU
firstGPU = getFirstAvailable()
print('First available GPU id:')
print(firstGPU)

# Get the first available GPU, where memory usage is less than 90% and processing is less than 80%
firstGPU = getFirstAvailable(maxMemory=0.9, maxLoad=0.8)
print('First available GPU id (memory < 90%, load < 80%):')
print(firstGPU)

# Get the first available GPU, where processing is less than 1%
firstGPU = getFirstAvailable(attempts=5, interval=5, maxLoad=0.01, verbose=True)
print('First available GPU id (load < 1%):')
print(firstGPU)
# NOTE: If all your GPUs currently have a load larger than 1%, this step will
# fail. It's not a bug! It is intended to do so, if it does not find an available GPU.

# Get the first available GPU, where memory usage is less than 1%
firstGPU = getFirstAvailable(attempts=5, interval=5, maxMemory=0.01, verbose=True)
print('First available GPU id (memory < 1%):')
print(firstGPU)
# NOTE: If all your GPUs currently have a memory consumption larger than 1%,
# this step will fail. It's not a bug! It is intended to do so, if it does not
# find an available GPU.

"""
| ID | GPU | MEM |
------------------
| 0 | 0% | 0% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
| 4 | 0% | 0% |
| 5 | 0% | 0% |
| 6 | 0% | 0% |
| 7 | 0% | 0% |
| ID | Name | Serial | UUID || GPU temp. | GPU util. | Memory util. || Memory total | Memory used | Memory free || Display mode | Display active |
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
| 0 | A100-SXM4-40GB | 1321320064527 | GPU-518b05da-f616-cb99-4027-a993c9b13d58 || 34C | 0% | 0% || 40537MB | 0MB | 40537MB || Enabled | Disabled |
| 1 | A100-SXM4-40GB | 1321520084090 | GPU-2515b8f7-0709-b726-f9b0-136eb581bc14 || 32C | 0% | 0% || 40537MB | 0MB | 40537MB || Enabled | Disabled |
| 2 | A100-SXM4-40GB | 1321420072578 | GPU-403c3c90-0b35-32ab-c1d8-da66c5bd451f || 31C | 0% | 0% || 40537MB | 0MB | 40537MB || Enabled | Disabled |
| 3 | A100-SXM4-40GB | 1321320020898 | GPU-be1fbc3f-9b92-e2e9-526e-0f823c5f4192 || 32C | 0% | 0% || 40537MB | 0MB | 40537MB || Enabled | Disabled |
| 4 | A100-SXM4-40GB | 1321320035971 | GPU-058ca801-a94f-5c3d-55bd-a2bf614b55bf || 35C | 0% | 0% || 40537MB | 0MB | 40537MB || Enabled | Disabled |
| 5 | A100-SXM4-40GB | 1321420030573 | GPU-be0b7ece-6b09-336b-6f78-164dbeb4bb00 || 32C | 0% | 0% || 40537MB | 0MB | 40537MB || Enabled | Disabled |
| 6 | A100-SXM4-40GB | 1321320032812 | GPU-7275e6ce-384b-0446-6b22-63d2e7820129 || 32C | 0% | 0% || 40537MB | 0MB | 40537MB || Enabled | Disabled |
| 7 | A100-SXM4-40GB | 1321320033526 | GPU-ed064eca-05c6-0196-8e05-d9299d4f40ba || 32C | 0% | 0% || 40537MB | 0MB | 40537MB || Enabled | Disabled |
All available ordered by id:
[0, 1, 2, 3, 4, 5, 6, 7]
Last available:
[7]
Random available:
[4]
First available weighted by GPU load ascending:
[0]
All available weighted by memory load ascending:
[0, 1, 2, 3, 4, 5, 6, 7]
First available GPU id:
[0]
First available GPU id (memory < 90%, load < 80%):
[0]
Attempting (1/5) to locate available GPU.
GPU [0] located!
First available GPU id (load < 1%):
[0]
Attempting (1/5) to locate available GPU.
GPU [0] located!
First available GPU id (memory < 1%):
[0]
"""

]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            158.3854217529297
        </positionTop>
        <positionLeft>
            123.1944580078125
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2350px;
            height:3071px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-153.3854217529297px;left:-118.1944580078125px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_1" style="top: 158.403px; left: 123.212px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="A Python module for programmatically getting the GPU utilization from NVIDIA GPUs using nvidia-smi."><img src="/automation-dashboard/styles/patterns/img/wf-icons/nvidia.png" width="20px">&nbsp;<span class="name">Show_GPU_Utilization</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 181px; top: 189px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
