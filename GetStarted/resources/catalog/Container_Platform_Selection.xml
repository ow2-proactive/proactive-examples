<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.12" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd"  name="Container_Platform_Selection" projectName="2. Advanced Workflows" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="CONTAINER_PLATFORM" value="docker" model="PA:LIST(docker,podman,singularity)"/>
    <variable name="CONTAINER_ENABLED" value="True" model="PA:Boolean"/>
    <variable name="CONTAINER_IMAGE" value="python:3.7" />
    <variable name="NODE_ACCESS_TOKEN" value="GPU" />
  </variables>
  <description>
    <![CDATA[ A workflow that executes in multiple container platforms. ]]>
  </description>
  <genericInformation>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/container.jpg"/>
    <info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
  </genericInformation>
  <taskFlow>
    <task name="python_script" fork="true">
      <description>
        <![CDATA[ The simplest task, ran by a bash engine. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/container.jpg"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="groovy">
              <![CDATA[
// This script creates a docker fork environment for various machine learning usages (CUDA, GPU, RAPIDS ...) and uses task or job variables for configuration.
// Variables:
// CONTAINER_ENABLED: true/false, set to false to disable docker completely (default=false)
// CONTAINER_IMAGE: docker image name (default=activeeon/dlm3)
// CONTAINER_GPU_ENABLED: true/false, set to true to enable gpu parameters and use activeeon/cuda image (default=false)
// USE_NVIDIA_RAPIDS: true/false, set to true to use activeeon/rapidsai image (default=false)
// MOUNT_LOG_PATH: optional host path to store logs
// CONTAINER_LOG_PATH: mounting point of optional logs in the docker container

// If used on windows:
//  - currently, only linux containers are supported
//  - make sure the drives containing the scheduler installation and TEMP folders are shared with docker containers
//  - the container used must have java installed by default in the /usr folder. Change the value of the java home parameter to use a different installation path
// On linux, the java installation used by the ProActive Node will be also used inside the container

import org.ow2.proactive.utils.OperatingSystem
import org.ow2.proactive.utils.OperatingSystemFamily

CONTAINER_ENABLED = false
if ("true".equalsIgnoreCase(variables.get("CONTAINER_ENABLED"))) {
    CONTAINER_ENABLED = true
}
if ((new File("/.dockerenv")).exists() && ! (new File("/var/run/docker.sock")).exists()) {
    println ("Already inside docker container, without host docker access")
    CONTAINER_ENABLED = false
}

MOUNT_LOG_PATH = variables.get("MOUNT_LOG_PATH")
CONTAINER_LOG_PATH = variables.get("CONTAINER_LOG_PATH")

CONTAINER_GPU_ENABLED = false
if (variables.get("CONTAINER_GPU_ENABLED") != null && variables.get("CONTAINER_GPU_ENABLED").toLowerCase().equals("true")) {
    CONTAINER_GPU_ENABLED = true
}

CUDA_ENABLED = false
CUDA_HOME = System.getenv('CUDA_HOME')
CUDA_HOME_DEFAULT = "/usr/local/cuda"
if (CUDA_HOME && (new File(CUDA_HOME)).isDirectory()) {
    CUDA_ENABLED = true
} else if ((new File(CUDA_HOME_DEFAULT)).isDirectory()) {
    CUDA_ENABLED = true
}
if (!CUDA_ENABLED) {
    CONTAINER_GPU_ENABLED = false
}

USE_NVIDIA_RAPIDS = false
if (variables.get("USE_NVIDIA_RAPIDS") != null && variables.get("USE_NVIDIA_RAPIDS").toLowerCase().equals("true")) {
    USE_NVIDIA_RAPIDS = true
}

DEFAULT_CONTAINER_IMAGE = "activeeon/dlm3"

// activate CUDA support if CONTAINER_GPU_ENABLED is True
if (CONTAINER_GPU_ENABLED) {
    if (USE_NVIDIA_RAPIDS) {
        DEFAULT_CONTAINER_IMAGE = "activeeon/rapidsai"
    } else {
        DEFAULT_CONTAINER_IMAGE = "activeeon/cuda"
    }
}

if (variables.get("CONTAINER_IMAGE") != null && !variables.get("CONTAINER_IMAGE").isEmpty()) {
    CONTAINER_IMAGE = variables.get("CONTAINER_IMAGE")
} else {
    CONTAINER_IMAGE = DEFAULT_CONTAINER_IMAGE
}

DEFAULT_CONTAINER_PLATFORM = "docker"
if (variables.get("CONTAINER_PLATFORM") != null && !variables.get("CONTAINER_PLATFORM").isEmpty()) {
    CONTAINER_PLATFORM = variables.get("CONTAINER_PLATFORM")
} else {
    CONTAINER_PLATFORM = DEFAULT_CONTAINER_PLATFORM
}

println "Fork environment info..."
println "CONTAINER_PLATFORM:    " + CONTAINER_PLATFORM
println "CONTAINER_ENABLED:     " + CONTAINER_ENABLED
println "CONTAINER_IMAGE:       " + CONTAINER_IMAGE
println "CONTAINER_GPU_ENABLED: " + CONTAINER_GPU_ENABLED
println "CUDA_ENABLED:          " + CUDA_ENABLED
println "USE_NVIDIA_RAPIDS:     " + USE_NVIDIA_RAPIDS

if (CONTAINER_ENABLED) {
    // Prepare Docker parameters
    containerName = CONTAINER_IMAGE
    cmd = []
    cmd.add(CONTAINER_PLATFORM)
    cmd.add("run")
    cmd.add("--rm")
    cmd.add("--env")
    cmd.add("HOME=/tmp")
    if (CUDA_ENABLED && CONTAINER_GPU_ENABLED) {
        cmd.add("--runtime=nvidia")
    }

    String osName = System.getProperty("os.name");
    println "Operating system : " + osName;
    OperatingSystem operatingSystem = OperatingSystem.resolveOrError(osName);
    OperatingSystemFamily family = operatingSystem.getFamily();

    switch (family) {
        case OperatingSystemFamily.WINDOWS:
            isWindows = true;
            break;
        default:
            isWindows = false;
    }
    forkEnvironment.setDockerWindowsToLinux(isWindows)

    // Prepare ProActive home volume
    paHomeHost = variables.get("PA_SCHEDULER_HOME")
    paHomeContainer = (isWindows ? forkEnvironment.convertToLinuxPath(paHomeHost) : paHomeHost)
    cmd.add("-v")
    cmd.add(paHomeHost + ":" + paHomeContainer)
    // Prepare working directory (For Dataspaces and serialized task file)
    workspaceHost = localspace
    workspaceContainer = (isWindows ? forkEnvironment.convertToLinuxPath(workspaceHost) : workspaceHost)
    cmd.add("-v")
    cmd.add(workspaceHost + ":" + workspaceContainer)

    cachespaceHost = cachespace
    cachespaceContainer = (isWindows ? forkEnvironment.convertToLinuxPath(cachespaceHost) : cachespaceHost)
    cachespaceHostFile = new File(cachespaceHost)
    if (cachespaceHostFile.exists() && cachespaceHostFile.canRead()) {
        cmd.add("-v")
        cmd.add(cachespaceHost + ":" + cachespaceContainer)
    } else {
        println cachespaceHost + " does not exist or is not readable, access to cache space will be disabled in the container"
    }

    if (!isWindows) {
        // when not on windows, mount and use the current JRE
        currentJavaHome = System.getProperty("java.home")
        forkEnvironment.setJavaHome(currentJavaHome)
        cmd.add("-v")
        cmd.add(currentJavaHome + ":" + currentJavaHome)
    }

    // Prepare log directory
    logPathVolume = ""
    if (MOUNT_LOG_PATH && CONTAINER_LOG_PATH) {
        mountLogHost = MOUNT_LOG_PATH
        logPathContainer = CONTAINER_LOG_PATH
        cmd.add("-v")
        cmd.add(mountLogHost + ":" + logPathContainer)
    }

    sharedDirectory = new File("/shared")
    if (sharedDirectory.isDirectory() && sharedDirectory.canWrite()) {
        cmd.add("-v")
        cmd.add("/shared:/shared")
    }

    // Prepare container working directory
    cmd.add("-w")
    cmd.add(workspaceContainer)

    sigar = new org.hyperic.sigar.Sigar()
    try {
        pid = sigar.getPid()
        creds = sigar.getProcCred(pid)
        uid = creds.getUid()
        gid = creds.getGid()
        userDefinition = "--user=" + uid + ":" + gid + " "
    } catch (Exception e) {
        println "Cannot retrieve user or group id : " + e.getMessage()
        userDefinition = "";
    } finally {
        sigar.close()
    }

    cmd.add(containerName)

    forkEnvironment.setPreJavaCommand(cmd)

    // Show the generated command
    println "CONTAINER COMMAND : " + forkEnvironment.getPreJavaCommand()
} else {
    println "Fork environment disabled"
}
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <code language="bash">
            <![CDATA[
pip install py4j
]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
#import os
import socket
import platform
print('-------------------------------------------------------------')
print('Interpreter')
print('platform.python_version:    ', platform.python_version())
print('platform.python_compiler:   ', platform.python_compiler())
print('platform.python_build:      ', platform.python_build())
print()
print('Platform')
print('platform.platform(Normal):  ', platform.platform())
print('platform.platform(Aliased): ', platform.platform(aliased=True))
print('platform.platform(Terse):   ', platform.platform(terse=True))
print()
print('Operating System and Hardware Info')
print('platform.uname:             ', platform.uname())
print('platform.system:            ', platform.system())
print('platform.node:              ', platform.node())
print('platform.release:           ', platform.release())
print('platform.version:           ', platform.version())
print('platform.machine:           ', platform.machine())
print('platform.processor:         ', platform.processor())
print()
print('Executable Architecture')
print('platform.architecture:      ', platform.architecture())
#print()
#print('OS')
#print('os.uname:                   ', os.uname())
#print('os.getcwd:                  ', os.getcwd())
print()
print('Network')
print('socket.gethostname:         ', socket.gethostname())
print('socket.gethostbyname        ', socket.gethostbyname(socket.gethostname()))
print('-------------------------------------------------------------')
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            131.9444580078125
        </positionTop>
        <positionLeft>
            206.26739501953125
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2351px;
            height:3072px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-126.9444580078125px;left:-201.26739501953125px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_125" style="top: 131.945px; left: 206.268px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/container.jpg" width="20px">&nbsp;<span class="name">python_script</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 247px; top: 162px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>