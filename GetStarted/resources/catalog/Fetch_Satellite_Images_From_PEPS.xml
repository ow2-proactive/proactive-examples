<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"
    name="Fetch_Satellite_Images_From_PEPS" projectName="2. Advanced Workflows"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
     <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ Load and return a peps dataset.
You can see more details in: https://github.com/olivierhagolle/peps_download ]]>
  </description>
  <genericInformation>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/peps-logo.png"/>
  </genericInformation>
  <taskFlow>
    <task name="Fetch_Satellite_Images_From_PEPS" >
      <description>
        <![CDATA[ Load and return a peps dataset.
You can see more details in: https://github.com/olivierhagolle/peps_download ]]>
      </description>
      <variables>
        <variable name="LOCATION" value="Romania" inherited="true" />
        <variable name="COLLECTION" value="S1" inherited="true" model="PA:LIST(S1, S2, S2ST, S3)"/>
        <variable name="PRODUCT_TYPE" value="GRD" inherited="true" model="PA:LIST(GRD, SLC, OCN)"/>
        <variable name="SENSOR_MODE" value="IW" inherited="true" model="PA:LIST(EW, IW , SM, WV, INS-NOBS, INS-RAW )"/>
        <variable name="START_DATE" value="2018-11-26" inherited="true" />
        <variable name="END_DATE" value="2018-11-27" inherited="true" />
        <variable name="TILE" value="" inherited="true" />
        <variable name="LATITUDE" value="" inherited="true" />
        <variable name="LONGITUDE" value="" inherited="true" />
        <variable name="OUTPUT_PATH" value="" inherited="true" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/peps-logo.png"/>
      </genericInformation>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Import_Peps")

import sys
import uuid
import json
import time
import zipfile
import optparse 
from os.path import join, exists, os, isfile
from datetime import date

if 'variables' in locals():
  LOCATION      = variables.get("LOCATION") 		 # location 
  COLLECTION    = variables.get("COLLECTION")        # Collection within theia collections  ----- choices=['S1', 'S2', 'S2ST', 'S3']  
  PRODUCT_TYPE  = variables.get("PRODUCT_TYPE")      # GRD, SLC, OCN (for S1) | S2MSI1C S2MSI2A S2MSI2Ap (for S2) 
  SENSOR_MODE   = variables.get("SENSOR_MODE")		 # EW, IW , SM, WV (for S1) | INS-NOBS, INS-RAW (for S3)
  START_DATE = variables.get("START_DATE")			 # Start date, fmt('2015-12-22')  
  END_DATE = variables.get("END_DATE")				 # End date, fmt('2015-12-23') 
  TILE = variables.get("TILE")						 # Sentinel-2 tile number type= string 
  LATITUDE = variables.get("LATITUDE")               # Latitude in decimal degrees 
  LONGITUDE = variables.get("LONGITUDE")             # Longitude in decimal degrees 
  EMAIL = credentials.get("USER_EMAIL")              # User email
  PASSWD = credentials.get("USER_PASS")              # User password
  OUTPUT_PATH = variables.get("OUTPUT_PATH")         # Folder output path 
    
COLLECTION =   COLLECTION.upper()
PRODUCT_TYPE = PRODUCT_TYPE.upper()
SENSOR_MODE =  SENSOR_MODE.upper()

if LOCATION == "": LOCATION = None
if TILE == "": TILE = None
LATITUDE = None if LATITUDE == "" else float(LATITUDE)
LONGITUDE = None if LONGITUDE == "" else float(LONGITUDE)  

 
NO_DOWNLOAD = False  # Do not download products, just print curl command
LATMIN = None		 # Min latitude in decimal degrees  
LATMAX = None		 # Max latitude in decimal degreess 
LONMIN = None       # Min longitude in decimal degrees
LONMAX = None       # Max longitude in decimal degrees
ORBIT = None         # Orbit Path number # type int
SEARCH_JSON_FILE = None   
WINDOWS = False

# Get an unique ID
ID = str(uuid.uuid4())

# Define dataset_path
os.getcwd() if OUTPUT_PATH == "" else os.chdir(OUTPUT_PATH)
DATASET_PATH = join(OUTPUT_PATH, ID)
os.makedirs(DATASET_PATH, exist_ok=True)

class OptionParser (optparse.OptionParser):

    def check_required(self, opt):
        option = self.get_option(opt)

        # Assumes the option's 'default' is set to None!
        if getattr(self.values, option.dest) is None:
            self.error("%s option not supplied" % option)


###########################################################################
def check_rename(tmpfile, prodsize):
    print(os.path.getsize(tmpfile), prodsize)
    if os.path.getsize(tmpfile) != prodsize:
        with open(tmpfile) as f_tmp:
            try:
                tmp_data = json.load(f_tmp)
                print("Result is a json file (might come from a wrong password file)")
                print(tmp_data)
                sys.exit(-1)
            except ValueError:
                print("\ndownload was not complete, tmp file removed")
                os.remove(tmpfile)
                pass
    else:
        os.rename("%s" % tmpfile, "%s/%s.zip" % (DATASET_PATH, prod))
        print("product saved as : %s/%s.zip" % (DATASET_PATH, prod))

###########################################################################


def parse_catalog(SEARCH_JSON_FILE):
    # Filter catalog result
    with open(SEARCH_JSON_FILE) as data_file:
        data = json.load(data_file)

    if 'ErrorCode' in data:
        print(data['ErrorMessage'])
        sys.exit(-2)

    # Sort data
    download_dict = {}
    storage_dict = {}
    size_dict = {}
    if len(data["features"])>0:
        for i in range(len(data["features"])):
            prod = data["features"][i]["properties"]["productIdentifier"]
            print(prod, data["features"][i]["properties"]["storage"]["mode"])
            feature_id = data["features"][i]["id"]
            try:
                storage = data["features"][i]["properties"]["storage"]["mode"]
                platform = data["features"][i]["properties"]["platform"]
                resourceSize = int(data["features"][i]["properties"]["resourceSize"])
                # recup du numero d'orbite
                orbitN = data["features"][i]["properties"]["orbitNumber"]
                if platform == 'S1A':
                    # calcul de l'orbite relative pour Sentinel 1A
                    relativeOrbit = ((orbitN - 73) % 175) + 1
                elif platform == 'S1B':
                    # calcul de l'orbite relative pour Sentinel 1B
                    relativeOrbit = ((orbitN - 27) % 175) + 1

            # print data["features"][i]["properties"]["productIdentifier"],data["features"][i]["id"],data["features"][i]["properties"]["startDate"],storage

                if ORBIT is not None:
                    if platform.startswith('S2'):
                        if prod.find("_R%03d" % ORBIT) > 0:
                            download_dict[prod] = feature_id
                            storage_dict[prod] = storage
                            size_dict[prod] = resourceSize
                    elif platform.startswith('S1'):
                        if relativeOrbit == ORBIT:
                            download_dict[prod] = feature_id
                            storage_dict[prod] = storage
                            size_dict[prod] = resourceSize
                else:
                    download_dict[prod] = feature_id
                    storage_dict[prod] = storage
                    size_dict[prod] = resourceSize
            except:
                pass
    else:
        print(">>> no product corresponds to selection criteria")
        sys.exit(-1)

    return(prod, download_dict, storage_dict, size_dict)
  
    
    
if SEARCH_JSON_FILE is None or SEARCH_JSON_FILE == "":
    SEARCH_JSON_FILE = 'search.json'

if TILE is None:
    if LOCATION is None:
        if LATITUDE is None or LONGITUDE is None:
            if (LATMIN is None) or (LONMIN is None) or (LATMAX is None) or (LONMAX is None):
                print("provide at least a point or rectangle or tile number")
                sys.exit(-1)
            else:
                geom = 'rectangle'
        else:
            if (LATMIN is None) and (LONMIN is None) and (LATMAX is None) and (LONMAX is None):
                geom = 'point'
            else:
                print("please choose between point and rectangle, but not both")
                sys.exit(-1)
    else:
        if (LATMIN is None) and (LONMIN is None) and (LATMAX is None) and (LONMAX is None) and (LATITUDE is None) or (LONGITUDE is None):
            geom = 'LOCATION'
        else:
            print("please choose location and coordinates, but not both")
            sys.exit(-1)

# geometric parameters of catalog request

if TILE is not None:
    if TILE.startswith('T') and len(TILE)==6:
        tileid = TILE[1:6]
    elif len(TILE)==5:
        tileid = TILE[0:5]
    else:
        print("tile name is ill-formated : 31TCJ or T31TCJ are allowed")
        sys.exit(-4)
    query_geom="tileid=%s"%(tileid)
elif geom == 'point':
    query_geom = 'LATITUDE=%f\&LONGITUDE=%f' % (LATITUDE, LONGITUDE)
elif geom == 'rectangle':
    query_geom = 'box={LONMIN},{LATMIN},{LONMAX},{LATMAX}'.format(
        LATMIN=LATMIN, LATMAX=LATMAX, LONMIN=LONMIN, LONMAX=LONMAX)
elif geom == 'LOCATION':
    query_geom = "q=%s" % LOCATION
    
# date parameters of catalog request
if START_DATE is not None:
    START_DATE = START_DATE
    if END_DATE is not None:
        END_DATE = END_DATE
    else:
        END_DATE = date.today().isoformat()

# special case for Sentinel-2     

if COLLECTION == 'S2':
    if START_DATE >= '2016-12-05':
        print("**** products after '2016-12-05' are stored in Tiled products collection")
        print("**** please use option -c S2ST")
    elif END_DATE >= '2016-12-05':
        print("**** products after '2016-12-05' are stored in Tiled products collection")
        print("**** please use option -c S2ST to get the products after that date")
        print("**** products before that date will be downloaded")
 
if COLLECTION == 'S2ST':
    if END_DATE < '2016-12-05':
        print("**** products before '2016-12-05' are stored in non-tiled products collection")
        print("**** please use option -c S2")
    elif START_DATE < '2016-12-05':
        print("**** products before '2016-12-05' are stored in non-tiled products collection")
        print("**** please use option -c S2 to get the products before that date")
        print("**** products after that date will be downloaded")
        

# ====================
# search in catalog
# ====================
if (PRODUCT_TYPE == "") and (SENSOR_MODE == ""):
    search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500' % (
        SEARCH_JSON_FILE, COLLECTION, query_geom, START_DATE, END_DATE)
else:
    search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500\&productType=%s\&sensorMode=%s' % (
        SEARCH_JSON_FILE, COLLECTION, query_geom, START_DATE, END_DATE, PRODUCT_TYPE, SENSOR_MODE)

if WINDOWS :
    search_catalog = search_catalog.replace('\&','^&')

print(search_catalog)
os.system(search_catalog)
time.sleep(5)

prod, download_dict, storage_dict, size_dict = parse_catalog(SEARCH_JSON_FILE)


# ====================
# Download
# ====================

if len(download_dict) == 0:
    print("No product matches the criteria")
else:
    # first try for the products on tape
    if DATASET_PATH == None:
        DATASET_PATH = os.getcwd()

    for prod in list(download_dict.keys()):
        file_exists = os.path.exists(("%s/%s.SAFE") % (DATASET_PATH, prod)
                                     ) or os.path.exists(("%s/%s.zip") % (DATASET_PATH, prod))
        if (not(NO_DOWNLOAD) and not(file_exists)):
            if storage_dict[prod] == "tape":
                tmticks = time.time()
                tmpfile = ("%s/tmp_%s.tmp") % (DATASET_PATH, tmticks)
                print("\nStage tape product: %s" % prod)
                get_product = 'curl -o %s -k -u "%s:%s" https://peps.cnes.fr/resto/collections/%s/%s/download/?issuerId=peps &>/dev/null' % (
                    tmpfile, EMAIL, PASSWD, COLLECTION, download_dict[prod])
                os.system(get_product)
                if os.path.exists(tmpfile):
                    os.remove(tmpfile)

    NbProdsToDownload = len(list(download_dict.keys()))
    print("##########################")
    print("%d  products to download" % NbProdsToDownload)
    print("##########################")
    while (NbProdsToDownload > 0):
       # redo catalog search to update disk/tape status
        if (PRODUCT_TYPE == "") and (SENSOR_MODE == ""):
            search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500' % (
                SEARCH_JSON_FILE, COLLECTION, query_geom, START_DATE, END_DATE)
        else:
            search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500\&productType=%s\&sensorMode=%s' % (
                SEARCH_JSON_FILE, COLLECTION, query_geom, START_DATE, END_DATE, PRODUCT_TYPE, SENSOR_MODE)

        if WINDOWS :
            search_catalog = search_catalog.replace('\&','^&')

        os.system(search_catalog)
        time.sleep(2)

        prod, download_dict, storage_dict, size_dict = parse_catalog(SEARCH_JSON_FILE)

        NbProdsToDownload = 0
        # download all products on disk
        for prod in list(download_dict.keys()):
            file_exists = os.path.exists(("%s/%s.SAFE") % (DATASET_PATH, prod)) or os.path.exists(("%s/%s.zip") % (DATASET_PATH, prod))
            if (not(NO_DOWNLOAD) and not(file_exists)):
                if storage_dict[prod] == "disk":
                    tmticks = time.time()
                    tmpfile = ("%s/tmp_%s.tmp") % (DATASET_PATH, tmticks)
                    print("\nDownload of product : %s" % prod)
                    get_product = 'curl -o %s -k -u "%s:%s" https://peps.cnes.fr/resto/collections/%s/%s/download/?issuerId=peps' % (
                        tmpfile, EMAIL, PASSWD, COLLECTION, download_dict[prod])
                    print(get_product)
                    os.system(get_product)
                    # check binary product, rename tmp file
                    if not os.path.exists(("%s/tmp_%s.tmp") % (DATASET_PATH, tmticks)):
                        NbProdsToDownload += 1
                    else:
                         check_rename(tmpfile, size_dict[prod])

            elif file_exists:
                print("%s already exists" % prod)

        # download all products on tape
        for prod in list(download_dict.keys()):
            file_exists = os.path.exists(("%s/%s.SAFE") % (DATASET_PATH, prod)
                                         ) or os.path.exists(("%s/%s.zip") % (DATASET_PATH, prod))
            if (not(NO_DOWNLOAD) and not(file_exists)):
                if storage_dict[prod] == "tape" or storage_dict[prod] == "staging" :
                    NbProdsToDownload += 1

        if NbProdsToDownload > 0:
            print("##############################################################################")
            print("%d remaining products are on tape, lets's wait 1 minute before trying again" % NbProdsToDownload)
            print("##############################################################################")
            time.sleep(60)

if 'variables' in locals():
	variables.put("DATASET_PATH", DATASET_PATH)
  
print("END Import_Peps")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            309.5
        </positionTop>
        <positionLeft>
            988.5
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
</job>