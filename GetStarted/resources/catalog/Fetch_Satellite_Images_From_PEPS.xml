<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.12" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Fetch_Satellite_Images_From_PEPS" onTaskError="continueJobExecution" priority="normal" projectName="5. Satellite Imagery Datasets" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd">
  <description>
    <![CDATA[ Load and return a peps dataset. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="basic-examples"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/peps-logo.png"/>
<info name="Documentation" value="https://github.com/olivierhagolle/peps_download"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Fetch_Satellite_Images_From_PEPS">
      <description>
        <![CDATA[ Load and return a peps dataset.
Warning:
See bellow some prerequisites to have this workflow working:
1: Two third party credentials to connect to PEPS (USER_NAME_PEPS and USER_PASS_PEPS)
2: Support the versions of Python > 3.2
3: Use a PYTHON_COMMAND  in the Generic Information (GI) field to specify the full path of your python3.

Note that the workflow does not work on try, trydev and tryqa servers, only in local.

Parameter description
##################################
LOCATION: town name. Type: String
COLLECTION: collection within theia collections. Options=[S1, S2, S2ST, S3]. Type: String
PRODUCT_TYPE: product type. Options=GRD, SLC, OCN (for S1) or S2MSI1C S2MSI2A S2MSI2Ap (for S2). Type: String
SENSOR_MODE: sensor mode. Options=EW, IW , SM, WV (for S1) or INS-NOBS, INS-RAW (for S3). Type: String
START_DATE: start date. Type: String
END_DATE: end date. Type: String
TILE:  sentinel tile number. Type: String
LATITUDE: latitude in decimal degrees. Type: Float
LONGITUDE: longitude in decimal degrees. Type: Float
OUTPUT_PATH: address path to save downloaded images. ]]>
      </description>
      <variables>
        <variable inherited="true" name="LOCATION" value="Romania"/>
        <variable inherited="true" model="PA:LIST(S1, S2, S2ST, S3)" name="COLLECTION" value="S1"/>
        <variable inherited="true" model="PA:LIST(GRD, SLC, OCN)" name="PRODUCT_TYPE" value="GRD"/>
        <variable inherited="true" model="PA:LIST(EW, IW , SM, WV, INS-NOBS, INS-RAW )" name="SENSOR_MODE" value="IW"/>
        <variable inherited="true" name="START_DATE" value="2018-11-26"/>
        <variable inherited="true" name="END_DATE" value="2018-11-27"/>
        <variable inherited="true" name="TILE" value=""/>
        <variable inherited="true" name="LATITUDE" value=""/>
        <variable inherited="true" name="LONGITUDE" value=""/>
        <variable inherited="true" name="OUTPUT_PATH" value="/tmp/"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/peps-logo.png"/>
        <info name="task.documentation" value="https://github.com/olivierhagolle/peps_download"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

import sys
import uuid
import json
import time
import shutil
import zipfile
import optparse 
from datetime import date
from zipfile import ZipFile 
from os.path import join, exists, os, isfile


if 'variables' in locals():
  LOCATION      = variables.get("LOCATION") 		 # location 
  COLLECTION    = variables.get("COLLECTION")        # Collection within theia collections  ----- choices=['S1', 'S2', 'S2ST', 'S3']  
  PRODUCT_TYPE  = variables.get("PRODUCT_TYPE")      # GRD, SLC, OCN (for S1) | S2MSI1C S2MSI2A S2MSI2Ap (for S2) 
  SENSOR_MODE   = variables.get("SENSOR_MODE")		 # EW, IW , SM, WV (for S1) | INS-NOBS, INS-RAW (for S3)
  START_DATE = variables.get("START_DATE")			 # Start date, fmt('2015-12-22')  
  END_DATE = variables.get("END_DATE")				 # End date, fmt('2015-12-23') 
  TILE = variables.get("TILE")						 # Sentinel-2 tile number type= string 
  LATITUDE = variables.get("LATITUDE")               # Latitude in decimal degrees 
  LONGITUDE = variables.get("LONGITUDE")             # Longitude in decimal degrees 
  EMAIL = credentials.get("USER_NAME_PEPS")              # User email
  PASSWD = credentials.get("USER_PASS_PEPS")              # User password
  OUTPUT_PATH = variables.get("OUTPUT_PATH")         # Folder output path 
    

COLLECTION =   COLLECTION.upper()
PRODUCT_TYPE = PRODUCT_TYPE.upper()
SENSOR_MODE =  SENSOR_MODE.upper()

if LOCATION == "": LOCATION = None
if TILE == "": TILE = None
LATITUDE = None if LATITUDE == "" else float(LATITUDE)
LONGITUDE = None if LONGITUDE == "" else float(LONGITUDE)  

 
NO_DOWNLOAD = False  # Do not download products, just print curl command
LATMIN = None		 # Min latitude in decimal degrees  
LATMAX = None		 # Max latitude in decimal degreess 
LONMIN = None        # Min longitude in decimal degrees
LONMAX = None        # Max longitude in decimal degrees
ORBIT = None         # Orbit Path number # type int
SEARCH_JSON_FILE = None   
WINDOWS = False

# Get an unique ID
ID = str(uuid.uuid4())

# Define the current 'dataset_path'
os.getcwd() if OUTPUT_PATH == "" else os.chdir(OUTPUT_PATH)

dataset_path = join(OUTPUT_PATH, ID, 'dataset')
output_path = join(OUTPUT_PATH, ID, 'peps')
os.makedirs(dataset_path, exist_ok=True)
os.makedirs(output_path, exist_ok=True)

print('The path input PEPS dataset', dataset_path)
print('The path output PEPS dataset', output_path)

class OptionParser (optparse.OptionParser):

    def check_required(self, opt):
        option = self.get_option(opt)

        # Assumes the option's 'default' is set to None!
        if getattr(self.values, option.dest) is None:
            self.error("%s option not supplied" % option)


###########################################################################
def check_rename(tmpfile, prodsize):
    print(os.path.getsize(tmpfile), prodsize)
    if os.path.getsize(tmpfile) != prodsize:
        with open(tmpfile) as f_tmp:
            try:
                tmp_data = json.load(f_tmp)
                print("Result is a json file (might come from a wrong password file)")
                print(tmp_data)
                sys.exit(-1)
            except ValueError:
                print("\ndownload was not complete, tmp file removed")
                os.remove(tmpfile)
                pass
    else:
        os.rename("%s" % tmpfile, "%s/%s.zip" % (dataset_path, prod))
        print("product saved as : %s/%s.zip" % (dataset_path, prod))

###########################################################################

def parse_catalog(SEARCH_JSON_FILE):
    # Filter catalog result
    with open(SEARCH_JSON_FILE) as data_file:
        data = json.load(data_file)

    if 'ErrorCode' in data:
        print(data['ErrorMessage'])
        sys.exit(-2)

    # Sort data
    download_dict = {}
    storage_dict = {}
    size_dict = {}
    if len(data["features"])>0:
        for i in range(len(data["features"])):
            prod = data["features"][i]["properties"]["productIdentifier"]
            print(prod, data["features"][i]["properties"]["storage"]["mode"])
            feature_id = data["features"][i]["id"]
            try:
                storage = data["features"][i]["properties"]["storage"]["mode"]
                platform = data["features"][i]["properties"]["platform"]
                resourceSize = int(data["features"][i]["properties"]["resourceSize"])
                # recup du numero d'orbite
                orbitN = data["features"][i]["properties"]["orbitNumber"]
                if platform == 'S1A':
                    # calcul de l'orbite relative pour Sentinel 1A
                    relativeOrbit = ((orbitN - 73) % 175) + 1
                elif platform == 'S1B':
                    # calcul de l'orbite relative pour Sentinel 1B
                    relativeOrbit = ((orbitN - 27) % 175) + 1

            # print data["features"][i]["properties"]["productIdentifier"],data["features"][i]["id"],data["features"][i]["properties"]["startDate"],storage

                if ORBIT is not None:
                    if platform.startswith('S2'):
                        if prod.find("_R%03d" % ORBIT) > 0:
                            download_dict[prod] = feature_id
                            storage_dict[prod] = storage
                            size_dict[prod] = resourceSize
                    elif platform.startswith('S1'):
                        if relativeOrbit == ORBIT:
                            download_dict[prod] = feature_id
                            storage_dict[prod] = storage
                            size_dict[prod] = resourceSize
                else:
                    download_dict[prod] = feature_id
                    storage_dict[prod] = storage
                    size_dict[prod] = resourceSize
            except:
                pass
    else:
        print(">>> no product corresponds to selection criteria")
        sys.exit(-1)

    return(prod, download_dict, storage_dict, size_dict)
  
    
    
if SEARCH_JSON_FILE is None or SEARCH_JSON_FILE == "":
    SEARCH_JSON_FILE = 'search.json'

if TILE is None:
    if LOCATION is None:
        if LATITUDE is None or LONGITUDE is None:
            if (LATMIN is None) or (LONMIN is None) or (LATMAX is None) or (LONMAX is None):
                print("provide at least a point or rectangle or tile number")
                sys.exit(-1)
            else:
                geom = 'rectangle'
        else:
            if (LATMIN is None) and (LONMIN is None) and (LATMAX is None) and (LONMAX is None):
                geom = 'point'
            else:
                print("please choose between point and rectangle, but not both")
                sys.exit(-1)
    else:
        if (LATMIN is None) and (LONMIN is None) and (LATMAX is None) and (LONMAX is None) and (LATITUDE is None) or (LONGITUDE is None):
            geom = 'LOCATION'
        else:
            print("please choose location and coordinates, but not both")
            sys.exit(-1)

# geometric parameters of catalog request

if TILE is not None:
    if TILE.startswith('T') and len(TILE)==6:
        tileid = TILE[1:6]
    elif len(TILE)==5:
        tileid = TILE[0:5]
    else:
        print("tile name is ill-formated : 31TCJ or T31TCJ are allowed")
        sys.exit(-4)
    query_geom="tileid=%s"%(tileid)
elif geom == 'point':
    query_geom = 'LATITUDE=%f\&LONGITUDE=%f' % (LATITUDE, LONGITUDE)
elif geom == 'rectangle':
    query_geom = 'box={LONMIN},{LATMIN},{LONMAX},{LATMAX}'.format(
        LATMIN=LATMIN, LATMAX=LATMAX, LONMIN=LONMIN, LONMAX=LONMAX)
elif geom == 'LOCATION':
    query_geom = "q=%s" % LOCATION
    
# date parameters of catalog request
if START_DATE is not None:
    START_DATE = START_DATE
    if END_DATE is not None:
        END_DATE = END_DATE
    else:
        END_DATE = date.today().isoformat()

# special case for Sentinel-2     

if COLLECTION == 'S2':
    if START_DATE >= '2016-12-05':
        print("**** products after '2016-12-05' are stored in Tiled products collection")
        print("**** please use option -c S2ST")
    elif END_DATE >= '2016-12-05':
        print("**** products after '2016-12-05' are stored in Tiled products collection")
        print("**** please use option -c S2ST to get the products after that date")
        print("**** products before that date will be downloaded")
 
if COLLECTION == 'S2ST':
    if END_DATE < '2016-12-05':
        print("**** products before '2016-12-05' are stored in non-tiled products collection")
        print("**** please use option -c S2")
    elif START_DATE < '2016-12-05':
        print("**** products before '2016-12-05' are stored in non-tiled products collection")
        print("**** please use option -c S2 to get the products before that date")
        print("**** products after that date will be downloaded")
        

# ====================
# search in catalog
# ====================
if (PRODUCT_TYPE == "") and (SENSOR_MODE == ""):
    search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500' % (
        SEARCH_JSON_FILE, COLLECTION, query_geom, START_DATE, END_DATE)
else:
    search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500\&productType=%s\&sensorMode=%s' % (
        SEARCH_JSON_FILE, COLLECTION, query_geom, START_DATE, END_DATE, PRODUCT_TYPE, SENSOR_MODE)

if WINDOWS :
    search_catalog = search_catalog.replace('\&','^&')

print(search_catalog)
os.system(search_catalog)
time.sleep(5)

prod, download_dict, storage_dict, size_dict = parse_catalog(SEARCH_JSON_FILE)


# ====================
# Download
# ====================

if len(download_dict) == 0:
    print("No product matches the criteria")
else:
    # first try for the products on tape
    if dataset_path == None:
        dataset_path = os.getcwd()

    for prod in list(download_dict.keys()):
        file_exists = os.path.exists(("%s/%s.SAFE") % (dataset_path, prod)
                                     ) or os.path.exists(("%s/%s.zip") % (dataset_path, prod))
        if (not(NO_DOWNLOAD) and not(file_exists)):
            if storage_dict[prod] == "tape":
                tmticks = time.time()
                tmpfile = ("%s/tmp_%s.tmp") % (dataset_path, tmticks)
                print("\nStage tape product: %s" % prod)
                get_product = 'curl -o %s -k -u "%s:%s" https://peps.cnes.fr/resto/collections/%s/%s/download/?issuerId=peps &>/dev/null' % (
                    tmpfile, EMAIL, PASSWD, COLLECTION, download_dict[prod])
                os.system(get_product)
                if os.path.exists(tmpfile):
                    os.remove(tmpfile)

    NbProdsToDownload = len(list(download_dict.keys()))
    print("##########################")
    print("%d  products to download" % NbProdsToDownload)
    print("##########################")
    while (NbProdsToDownload > 0):
       # redo catalog search to update disk/tape status
        if (PRODUCT_TYPE == "") and (SENSOR_MODE == ""):
            search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500' % (
                SEARCH_JSON_FILE, COLLECTION, query_geom, START_DATE, END_DATE)
        else:
            search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500\&productType=%s\&sensorMode=%s' % (
                SEARCH_JSON_FILE, COLLECTION, query_geom, START_DATE, END_DATE, PRODUCT_TYPE, SENSOR_MODE)

        if WINDOWS :
            search_catalog = search_catalog.replace('\&','^&')

        os.system(search_catalog)
        time.sleep(2)

        prod, download_dict, storage_dict, size_dict = parse_catalog(SEARCH_JSON_FILE)

        NbProdsToDownload = 0
        # download all products on disk
        for prod in list(download_dict.keys()):
            file_exists = os.path.exists(("%s/%s.SAFE") % (dataset_path, prod)) or os.path.exists(("%s/%s.zip") % (dataset_path, prod))
            if (not(NO_DOWNLOAD) and not(file_exists)):
                if storage_dict[prod] == "disk":
                    tmticks = time.time()
                    tmpfile = ("%s/tmp_%s.tmp") % (dataset_path, tmticks)
                    print("\nDownload of product : %s" % prod)
                    get_product = 'curl -o %s -k -u "%s:%s" https://peps.cnes.fr/resto/collections/%s/%s/download/?issuerId=peps' % (
                        tmpfile, EMAIL, PASSWD, COLLECTION, download_dict[prod])
                    print(get_product)
                    os.system(get_product)
                    # check binary product, rename tmp file
                    if not os.path.exists(("%s/tmp_%s.tmp") % (dataset_path, tmticks)):
                        NbProdsToDownload += 1
                    else:
                         check_rename(tmpfile, size_dict[prod])

            elif file_exists:
                print("%s already exists" % prod)

        # download all products on tape
        for prod in list(download_dict.keys()):
            file_exists = os.path.exists(("%s/%s.SAFE") % (dataset_path, prod)
                                         ) or os.path.exists(("%s/%s.zip") % (dataset_path, prod))
            if (not(NO_DOWNLOAD) and not(file_exists)):
                if storage_dict[prod] == "tape" or storage_dict[prod] == "staging" :
                    NbProdsToDownload += 1

        if NbProdsToDownload > 0:
            print("##############################################################################")
            print("%d remaining products are on tape, lets's wait 1 minute before trying again" % NbProdsToDownload)
            print("##############################################################################")
            time.sleep(60)
            
            
# List all .zip folders
folder_zip = [i for i in [os.path.relpath(os.path.join(dataset_path, p)) for p in os.listdir(dataset_path)] if i.endswith('.zip')]

# Unzip folders 
print('Extracting all the files...')
for file_name in folder_zip: 
    with ZipFile(file_name, 'r') as zip: 
        zip.printdir() 
        # extracting all the files 
        print('File name:', file_name) 
        zip.extractall(dataset_path) 
print('Finished!')            
            
# List all .safe folders
folder_safe = [i for i in [os.path.relpath(os.path.join(dataset_path, p)) for p in os.listdir(dataset_path)] if i.endswith('.SAFE')]

# Copy and organize files
def folder_copy(image_path):
    for root, dirs, files in os.walk(image_path): 
        os.makedirs(os.path.join(output_path, 'measurement') , exist_ok=True)
        for file in files:   
            fullpath = join(root, file)
            print('File name:', fullpath) 
            shutil.copy(fullpath, os.path.join(output_path, 'measurement'))
    
# Looking for the "measurement" directory 
def folder_search():
    print('Copying the images to the peps directory...')
    for foldername in folder_safe:
        for path, dirs, filename in os.walk(foldername): #omit files, loop through later
            for dirname in dirs:
                fullpath = os.path.join(path, dirname)
                if "measurement" in dirname:
                    folder_copy(fullpath)
    print('Finished!')
                    
# Call folder_search function
folder_search()

# Remove the "dataset_path" directory
shutil.rmtree(dataset_path)
while os.path.exists(dataset_path):
  pass
print('Remove all directory in the', dataset_path)
print('Finished!')  


if 'variables' in locals():
	variables.put("DATASET_PATH", output_path)
  
print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            371.953125
        </positionTop>
        <positionLeft>
            367.484375
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2864px;
            height:3432px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-366.953125px;left:-362.484375px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable active-task" id="jsPlumb_1_181" style="top: 371.953px; left: 367.484px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load and return a peps dataset.
Warning:
See bellow some prerequisites to have this workflow working:
1: Two third party credentials to connect to PEPS (USER_NAME_PEPS and USER_PASS_PEPS)
2: Support the versions of Python > 3.2
3: Use a PYTHON_COMMAND  in the Generic Information (GI) field to specify the full path of your python3.

Note that the workflow does not work on try, trydev and tryqa servers, only in local.

Parameter description
##################################
LOCATION: town name. Type: String
COLLECTION: collection within theia collections. Options=[S1, S2, S2ST, S3]. Type: String
PRODUCT_TYPE: product type. Options=GRD, SLC, OCN (for S1) or S2MSI1C S2MSI2A S2MSI2Ap (for S2). Type: String
SENSOR_MODE: sensor mode. Options=EW, IW , SM, WV (for S1) or INS-NOBS, INS-RAW (for S3). Type: String
START_DATE: start date. Type: String
END_DATE: end date. Type: String
TILE:  sentinel tile number. Type: String
LATITUDE: latitude in decimal degrees. Type: Float
LONGITUDE: longitude in decimal degrees. Type: Float
OUTPUT_PATH: address path to save downloaded images."><img src="/automation-dashboard/styles/patterns/img/wf-icons/peps-logo.png" width="20px">&nbsp;<span class="name">Fetch_Satellite_Images_From_PEPS</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 457.5px; top: 402px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>
