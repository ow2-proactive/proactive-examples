<?xml version="1.0" encoding="UTF-8"?>
<job
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xmlns="urn:proactive:jobdescriptor:3.14" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd"  name="Connect_To_Hive_Cluster_With_Beeline" tags="Orchestration,Hive,Big Data,Building blocks,Analytics,Beeline" projectName="03. Hadoop Hive (SQL DW)"  priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="username" value="" description="HIVE cluster username."  advanced="false" hidden="false"/>
    <variable name="password" value="" model="PA:HIDDEN" description="HIVE cluster password." group="" advanced="false" hidden="false"/>
    <variable name="cluster_ip" value="xxx"  model="PA:NOT_EMPTY_STRING" description="HIVE cluster address."  advanced="false" hidden="false"/>
    <variable name="cluster_port" value="xxx"  model="PA:NOT_EMPTY_STRING" description="HIVE cluster port."  advanced="false" hidden="false"/>
  </variables>
  <description>
    <![CDATA[ A workflow that allows you to connect to an external Hive cluster with IP address or domain name, a username and password using Beeline to execute SQL commands.
You can modify the SQL commands from the prescript file of the workflow task. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="data-big-data"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/hive.png"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Execute_querries"



          preciousResult="true"
          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/hive.png"/>
        <info name="PRE_SCRIPT_AS_FILE" value="commands.sql"/>
      </genericInformation>
      <pre>
        <script>
          <code language="python">
            <![CDATA[
create table employee
(ID INT, Name STRING, Dept STRING, Yoj INT, Salary INT)
row format delimited fields terminated by ','
tblproperties("skip.header.line.count"="1");

describe employee;

LOAD DATA LOCAL INPATH
'/usr/local/hive/employee.csv'
OVERWRITE INTO TABLE employee;


show tables;

SELECT * FROM employee;
]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def cluster_name = variables.get("username").trim()
def cluster_password = variables.get("password").trim()
def cluster_ip = variables.get("cluster_ip").trim()
def cluster_port = variables.get("cluster_port").trim()
def commands_init = variables.get("commands_init")
def container_name = "hive_beeline_connector"

println "\n =================================== \n \n"
println """ cluster name = $cluster_name
			cluster password = $cluster_password
            cluster_ip = $cluster_ip
            cluster_port = $cluster_port
"""
println "\n =================================== \n \n"

def hiveLocalFile = genericInformation.get("PRE_SCRIPT_AS_FILE")
def pre_script_path = new File(localspace, hiveLocalFile )

println " Prescript generic information : "
println hiveLocalFile +  " #### " + pre_script_path





// Submit the hive job
def hive_beeline_command = "beeline -n " +  cluster_name + " -p " + cluster_password + " -u jdbc:hive2://" + cluster_ip + ":"  + cluster_port + " -f " +  pre_script_path + " --nullemptystring=true --silent=true"
println hive_beeline_command
cmd = ["docker","run", "--rm", "-v", localspace + ":" + localspace,  "activeeon/hive:2",  "/bin/sh", "-c", hive_beeline_command]
println cmd
result = cmd.execute().text
result = result.replace("null", "")
println result
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
          382.83333587646484
        </positionTop>
        <positionLeft>
          559.7638854980469
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2509px;
            height:2764px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-377.83333587646484px;left:-554.7638854980469px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_307" style="top: 382.847px; left: 559.764px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task has no description"><img src="/automation-dashboard/styles/patterns/img/wf-icons/hive.png" width="20px">&nbsp;<span class="name">Execute_querries</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 606.5px; top: 413px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
