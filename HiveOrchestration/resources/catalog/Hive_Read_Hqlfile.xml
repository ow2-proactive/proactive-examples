<?xml version="1.0" encoding="UTF-8"?>
<job
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xmlns="urn:proactive:jobdescriptor:3.13" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd"  name="Hive_Read_Hqlfile" projectName="13. Hive_connectors" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
    <variables>
        <variable model="PA:GLOBAL_FILE" name="hql_file_dataspace_relative_path" value="" description="The hql or sql script relative file path from the global space." />
        <variable name="hive_service_instance_id" value="xx"  model="PA:NOT_EMPTY_STRING" description="The service instance id of the targeted Hive."/>
    </variables>
    <description>
        <![CDATA[ A workflow to submit a hive job from a hive docker container with beeline). ]]>
    </description>
    <genericInformation>
        <info name="bucketName" value="big-data"/>
        <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/hive.png"/>
        <info name="group" value="public-objects"/>
    </genericInformation>
    <taskFlow>
        <task name="retrieve_service_variables"
              fork="true">
            <scriptExecutable>
                <script>
                    <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Retrieve_variables_from_service_instance_id/raw" language="groovy">
                        <arguments>
                            <argument value="$hive_service_instance_id"/>
                            <argument value="targeted_network_name"/>
                            <argument value="targeted_network_name"/>
                            <argument value="hive_container_ip"/>
                            <argument value="hive_container_ip"/>
                            <argument value="yarn_token_name"/>
                            <argument value="yarn_token_name"/>
                        </arguments>
                    </file>
                </script>
            </scriptExecutable>
        </task>
        <task name="Hive_read_hql"
              fork="true">
            <genericInformation>
                <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/hive.png"/>
                <info name="NODE_ACCESS_TOKEN" value="$yarn_token_name"/>
            </genericInformation>
            <depends>
                <task ref="retrieve_service_variables"/>
            </depends>
            <inputFiles>
                <files  includes="$hql_file_dataspace_relative_path" accessMode="transferFromGlobalSpace"/>
            </inputFiles>
            <scriptExecutable>
                <script>
                    <code language="groovy">
                        <![CDATA[
// Retrieve variables
def targeted_network_name = variables.get("targeted_network_name")
def hive_container_ip = variables.get("hive_container_ip").trim()

// hql file upload
def hql_file_dataspace_relative_path = variables.get("hql_file_dataspace_relative_path")
def hql_file_path = new File(localspace, hql_file_dataspace_relative_path )

// Submit the hive job
def hive_beeline_command = "beeline -n root -p 123456 -u jdbc:hive2://" + hive_container_ip + ":"  + 10000 + " -f " + hql_file_path
println hive_beeline_command
cmd = ["docker", "run", "--rm", "--net", targeted_network_name, "-v", localspace + ":" + localspace, "activeeon/hive:latest", "bash", "-c", hive_beeline_command]
println cmd
cmd.execute().waitForProcessOutput(System.out, System.err)
]]>
                    </code>
                </script>
            </scriptExecutable>
            <metadata>
                <positionTop>
                    308.125
                </positionTop>
                <positionLeft>
                    514
                </positionLeft>
            </metadata>
        </task>
    </taskFlow>
    <metadata>
        <visualization>
            <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2830px;
            height:3392px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-303.125px;left:-509px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable active-task" id="jsPlumb_1_49" style="top: 308.133px; left: 514px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="A workflow to submit a Spark job from a docker container, to estimate Pi. This workflow requires a Spark platform."><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">Spark_Pi</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 554px; top: 338px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
        </visualization>
    </metadata>
</job>
