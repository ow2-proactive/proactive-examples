<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.13" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="PyTorch_Federated_Learning_Example" onTaskError="continueJobExecution" priority="normal" projectName="3. Federated Learning Workflows" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd">
  <variables>
    <variable advanced="false" description="Name of the host used to run the Federated Learning server." hidden="false" model="PA:MODEL_FROM_URL(${PA_SCHEDULER_REST_PUBLIC_URL}/rm/model/hosts)" name="FEDERATED_LEARNING_SERVER_HOST" value=""/>
    <variable advanced="false" description="Network port number used to run the Federated Learning server." hidden="false" model="PA:INTEGER" name="FEDERATED_LEARNING_SERVER_PORT" value="8080"/>
    <variable advanced="true" description="Name of the Native Scheduler node source to use when the workflow tasks must be deployed inside a cluster such as SLURM, LSF, etc." group="Resource Management" hidden="false" name="NATIVE_SCHEDULER" value=""/>
    <variable advanced="true" description="Parameters given to the native scheduler (SLURM, LSF, etc) while requesting a ProActive node used to deploy the workflow tasks." group="Resource Management" hidden="false" name="NATIVE_SCHEDULER_PARAMS" value=""/>
    <variable advanced="true" description="Container platform used for executing the workflow tasks." group="Container Parameters" hidden="false" model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker"/>
    <variable advanced="true" description="If True, it will activate the use of GPU for the workflow tasks on the selected container platform." group="Container Parameters" hidden="false" model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="False"/>
    <variable advanced="true" description="Name of the container image being used." group="Container Parameters" hidden="false" model="PA:LIST(docker://activeeon/flower:cpu)" name="CONTAINER_IMAGE" value="docker://activeeon/flower:cpu"/>
  </variables>
  <description>
    <![CDATA[ Simple Federated Learning Workflow using PyTorch. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="federated-learning"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytoch.jpg"/>
<info name="PYTHON_COMMAND" value="python3"/>
<info name="NS" value="$NATIVE_SCHEDULER"/>
<info name="Documentation" value="PML/PMLUserGuide.html#_FL"/>
<info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="PyTorch_FL_Server_Task">
      <description>
        <![CDATA[ Simple Federated Learning Server task template using PyTorch. ]]>
      </description>
      <variables>
        <variable advanced="false" hidden="false" inherited="false" model="PA:MODEL_FROM_URL(${PA_SCHEDULER_REST_PUBLIC_URL}/rm/model/nodesources)" name="TASK_NODE_SOURCE_NAME" value=""/>
        <variable advanced="false" hidden="false" inherited="false" model="PA:MODEL_FROM_URL(${PA_SCHEDULER_REST_PUBLIC_URL}/rm/model/tokens)" name="TASK_NODE_ACCESS_TOKEN" value=""/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytoch.jpg"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_FL"/>
        <info name="NODE_ACCESS_TOKEN" value="$TASK_NODE_ACCESS_TOKEN"/>
      </genericInformation>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
selected = false
TASK_NAME = variables.get("PA_TASK_NAME")
TASK_NODE_SOURCE_NAME = variables.get("TASK_NODE_SOURCE_NAME")
println "TASK_NAME: " + TASK_NAME
println "TASK_NODE_SOURCE_NAME: " + TASK_NODE_SOURCE_NAME
println "proactive.node.nodesource: " + System.getProperty("proactive.node.nodesource")
if (TASK_NODE_SOURCE_NAME?.trim()) {
    selected = TASK_NODE_SOURCE_NAME.equals(System.getProperty("proactive.node.nodesource"))
} else {
    selected = true
}
println "selected: " + selected
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

import flwr as fl

FEDERATED_LEARNING_SERVER_PORT = variables.get("FEDERATED_LEARNING_SERVER_PORT")
if FEDERATED_LEARNING_SERVER_PORT is None or FEDERATED_LEARNING_SERVER_PORT.strip() == '':
    FEDERATED_LEARNING_SERVER_PORT = "8080"

FEDERATED_LEARNING_SERVER_ADDR = "[::]:" + FEDERATED_LEARNING_SERVER_PORT
print("FEDERATED_LEARNING_SERVER_ADDR: ", FEDERATED_LEARNING_SERVER_ADDR)

# Define strategy
strategy = fl.server.strategy.FedAvg(
    fraction_fit=0.5,
    fraction_eval=0.5,
)

# Start server
fl.server.start_server(
    server_address=FEDERATED_LEARNING_SERVER_ADDR,
    config={"num_rounds": 3},
    strategy=strategy,
)

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            132
        </positionTop>
        <positionLeft>
            86.515625
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="PyTorch_FL_Client_Task1">
      <description>
        <![CDATA[ Simple Federated Learning Client task template using PyTorch. ]]>
      </description>
      <variables>
        <variable advanced="false" hidden="false" inherited="false" model="PA:MODEL_FROM_URL(${PA_SCHEDULER_REST_PUBLIC_URL}/rm/model/nodesources)" name="TASK_NODE_SOURCE_NAME" value=""/>
        <variable advanced="false" hidden="false" inherited="false" model="PA:MODEL_FROM_URL(${PA_SCHEDULER_REST_PUBLIC_URL}/rm/model/tokens)" name="TASK_NODE_ACCESS_TOKEN" value=""/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytoch.jpg"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_FL"/>
        <info name="NODE_ACCESS_TOKEN" value="$TASK_NODE_ACCESS_TOKEN"/>
      </genericInformation>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
selected = false
TASK_NAME = variables.get("PA_TASK_NAME")
TASK_NODE_SOURCE_NAME = variables.get("TASK_NODE_SOURCE_NAME")
println "TASK_NAME: " + TASK_NAME
println "TASK_NODE_SOURCE_NAME: " + TASK_NODE_SOURCE_NAME
println "proactive.node.nodesource: " + System.getProperty("proactive.node.nodesource")
if (TASK_NODE_SOURCE_NAME?.trim()) {
    selected = TASK_NODE_SOURCE_NAME.equals(System.getProperty("proactive.node.nodesource"))
} else {
    selected = true
}
println "selected: " + selected
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

from collections import OrderedDict
import warnings

import flwr as fl
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torchvision.datasets import CIFAR10

FEDERATED_LEARNING_SERVER_HOST = variables.get("FEDERATED_LEARNING_SERVER_HOST")
FEDERATED_LEARNING_SERVER_PORT = variables.get("FEDERATED_LEARNING_SERVER_PORT")

if FEDERATED_LEARNING_SERVER_HOST is None or FEDERATED_LEARNING_SERVER_HOST.strip() == '':
    FEDERATED_LEARNING_SERVER_HOST = "[::]"

if FEDERATED_LEARNING_SERVER_PORT is None or FEDERATED_LEARNING_SERVER_PORT.strip() == '':
    FEDERATED_LEARNING_SERVER_PORT = "8080"

FEDERATED_LEARNING_SERVER_ADDR = FEDERATED_LEARNING_SERVER_HOST + ":" + FEDERATED_LEARNING_SERVER_PORT
print("FEDERATED_LEARNING_SERVER_ADDR: ", FEDERATED_LEARNING_SERVER_ADDR)

warnings.filterwarnings("ignore", category=UserWarning)
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


# #############################################################################
# 1. PyTorch pipeline: model/train/test/dataloader
# #############################################################################

# Model (simple CNN adapted from 'PyTorch: A 60 Minute Blitz')
class Net(nn.Module):
    def __init__(self) -> None:
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


def train(net, trainloader, epochs):
    """Train the network on the training set."""
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
    net.train()
    for _ in range(epochs):
        for images, labels in trainloader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            loss = criterion(net(images), labels)
            loss.backward()
            optimizer.step()


def test(net, testloader):
    """Validate the network on the entire test set."""
    criterion = torch.nn.CrossEntropyLoss()
    correct, total, loss = 0, 0, 0.0
    net.eval()
    with torch.no_grad():
        for images, labels in testloader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = net(images)
            loss += criterion(outputs, labels).item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    loss /= len(testloader.dataset)
    accuracy = correct / total
    return loss, accuracy


def load_data():
    """Load CIFAR-10 (training and test set)."""
    transform = transforms.Compose(
        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
    )
    trainset = CIFAR10("/tmp/dataset", train=True, download=True, transform=transform)
    testset = CIFAR10("/tmp/dataset", train=False, download=True, transform=transform)
    trainloader = DataLoader(trainset, batch_size=32, shuffle=True)
    testloader = DataLoader(testset, batch_size=32)
    num_examples = {"trainset": len(trainset), "testset": len(testset)}
    return trainloader, testloader, num_examples


# #############################################################################
# 2. Federation of the pipeline with Flower
# #############################################################################
def main():
    """Create model, load data, define Flower client, start Flower client."""

    # Load model
    net = Net().to(DEVICE)

    # Load data (CIFAR-10)
    trainloader, testloader, num_examples = load_data()

    # Flower client
    class CifarClient(fl.client.NumPyClient):
        def get_parameters(self):
            return [val.cpu().numpy() for _, val in net.state_dict().items()]

        def set_parameters(self, parameters):
            params_dict = zip(net.state_dict().keys(), parameters)
            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})
            net.load_state_dict(state_dict, strict=True)

        def fit(self, parameters, config):
            self.set_parameters(parameters)
            train(net, trainloader, epochs=1)
            return self.get_parameters(), num_examples["trainset"], {}

        def evaluate(self, parameters, config):
            self.set_parameters(parameters)
            loss, accuracy = test(net, testloader)
            return float(loss), num_examples["testset"], {"accuracy": float(accuracy)}

    # Start client
    fl.client.start_numpy_client(FEDERATED_LEARNING_SERVER_ADDR, client=CifarClient())


if __name__ == "__main__":
    main()

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            132
        </positionTop>
        <positionLeft>
            214.515625
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="PyTorch_FL_Client_Task2">
      <description>
        <![CDATA[ Simple Federated Learning Client task template using PyTorch. ]]>
      </description>
      <variables>
        <variable advanced="false" hidden="false" inherited="false" model="PA:MODEL_FROM_URL(${PA_SCHEDULER_REST_PUBLIC_URL}/rm/model/nodesources)" name="TASK_NODE_SOURCE_NAME" value=""/>
        <variable advanced="false" hidden="false" inherited="false" model="PA:MODEL_FROM_URL(${PA_SCHEDULER_REST_PUBLIC_URL}/rm/model/tokens)" name="TASK_NODE_ACCESS_TOKEN" value=""/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytoch.jpg"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_FL"/>
        <info name="NODE_ACCESS_TOKEN" value="$TASK_NODE_ACCESS_TOKEN"/>
      </genericInformation>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
selected = false
TASK_NAME = variables.get("PA_TASK_NAME")
TASK_NODE_SOURCE_NAME = variables.get("TASK_NODE_SOURCE_NAME")
println "TASK_NAME: " + TASK_NAME
println "TASK_NODE_SOURCE_NAME: " + TASK_NODE_SOURCE_NAME
println "proactive.node.nodesource: " + System.getProperty("proactive.node.nodesource")
if (TASK_NODE_SOURCE_NAME?.trim()) {
    selected = TASK_NODE_SOURCE_NAME.equals(System.getProperty("proactive.node.nodesource"))
} else {
    selected = true
}
println "selected: " + selected
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

from collections import OrderedDict
import warnings

import flwr as fl
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torchvision.datasets import CIFAR10

FEDERATED_LEARNING_SERVER_HOST = variables.get("FEDERATED_LEARNING_SERVER_HOST")
FEDERATED_LEARNING_SERVER_PORT = variables.get("FEDERATED_LEARNING_SERVER_PORT")

if FEDERATED_LEARNING_SERVER_HOST is None or FEDERATED_LEARNING_SERVER_HOST.strip() == '':
    FEDERATED_LEARNING_SERVER_HOST = "[::]"

if FEDERATED_LEARNING_SERVER_PORT is None or FEDERATED_LEARNING_SERVER_PORT.strip() == '':
    FEDERATED_LEARNING_SERVER_PORT = "8080"

FEDERATED_LEARNING_SERVER_ADDR = FEDERATED_LEARNING_SERVER_HOST + ":" + FEDERATED_LEARNING_SERVER_PORT
print("FEDERATED_LEARNING_SERVER_ADDR: ", FEDERATED_LEARNING_SERVER_ADDR)

warnings.filterwarnings("ignore", category=UserWarning)
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


# #############################################################################
# 1. PyTorch pipeline: model/train/test/dataloader
# #############################################################################

# Model (simple CNN adapted from 'PyTorch: A 60 Minute Blitz')
class Net(nn.Module):
    def __init__(self) -> None:
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


def train(net, trainloader, epochs):
    """Train the network on the training set."""
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
    net.train()
    for _ in range(epochs):
        for images, labels in trainloader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            loss = criterion(net(images), labels)
            loss.backward()
            optimizer.step()


def test(net, testloader):
    """Validate the network on the entire test set."""
    criterion = torch.nn.CrossEntropyLoss()
    correct, total, loss = 0, 0, 0.0
    net.eval()
    with torch.no_grad():
        for images, labels in testloader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = net(images)
            loss += criterion(outputs, labels).item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    loss /= len(testloader.dataset)
    accuracy = correct / total
    return loss, accuracy


def load_data():
    """Load CIFAR-10 (training and test set)."""
    transform = transforms.Compose(
        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
    )
    trainset = CIFAR10("/tmp/dataset", train=True, download=True, transform=transform)
    testset = CIFAR10("/tmp/dataset", train=False, download=True, transform=transform)
    trainloader = DataLoader(trainset, batch_size=32, shuffle=True)
    testloader = DataLoader(testset, batch_size=32)
    num_examples = {"trainset": len(trainset), "testset": len(testset)}
    return trainloader, testloader, num_examples


# #############################################################################
# 2. Federation of the pipeline with Flower
# #############################################################################
def main():
    """Create model, load data, define Flower client, start Flower client."""

    # Load model
    net = Net().to(DEVICE)

    # Load data (CIFAR-10)
    trainloader, testloader, num_examples = load_data()

    # Flower client
    class CifarClient(fl.client.NumPyClient):
        def get_parameters(self):
            return [val.cpu().numpy() for _, val in net.state_dict().items()]

        def set_parameters(self, parameters):
            params_dict = zip(net.state_dict().keys(), parameters)
            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})
            net.load_state_dict(state_dict, strict=True)

        def fit(self, parameters, config):
            self.set_parameters(parameters)
            train(net, trainloader, epochs=1)
            return self.get_parameters(), num_examples["trainset"], {}

        def evaluate(self, parameters, config):
            self.set_parameters(parameters)
            loss, accuracy = test(net, testloader)
            return float(loss), num_examples["testset"], {"accuracy": float(accuracy)}

    # Start client
    fl.client.start_numpy_client(FEDERATED_LEARNING_SERVER_ADDR, client=CifarClient())


if __name__ == "__main__":
    main()

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            132
        </positionTop>
        <positionLeft>
            342.515625
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2836px;
            height:3928px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-127px;left:-81.515625px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_434" style="top: 132px; left: 86.5156px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Simple Federated Learning Server task template using PyTorch."><img src="/automation-dashboard/styles/patterns/img/wf-icons/pytoch.jpg" width="20px">&nbsp;<span class="name">PyTorch_FL_Server_Task</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_437" style="top: 132px; left: 214.516px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Simple Federated Learning Client task template using PyTorch."><img src="/automation-dashboard/styles/patterns/img/wf-icons/pytoch.jpg" width="20px">&nbsp;<span class="name">PyTorch_FL_Client_Task1</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_440" style="top: 132px; left: 342.516px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Simple Federated Learning Client task template using PyTorch."><img src="/automation-dashboard/styles/patterns/img/wf-icons/pytoch.jpg" width="20px">&nbsp;<span class="name">PyTorch_FL_Client_Task2</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 151.5px; top: 162px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 280px; top: 162px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 408px; top: 162px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
