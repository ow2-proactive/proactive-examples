<?xml version="1.0" encoding="UTF-8"?>
<job
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xmlns="urn:proactive:jobdescriptor:3.11" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"  name="Anomaly_Detection_In_Apache_Logs" projectName="2. Log Analysis" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2" >
  <variables>
    <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ Detect anomalies in Apache logs using
Support Vector Machines (SVM) ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="machine-learning-workflows"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/log_analysis.png"/>
    <info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_log_analysis"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Export_Results" >
      <description>
        <![CDATA[ Export the results. ]]>
      </description>
      <variables>
        <variable name="OUTPUT_FILE" value="HTML" inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png"/>
      </genericInformation>
      <depends>
        <task ref="Predict_Model"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters
  containerName = 'activeeon/dlm3'
  dockerRunCommand =  'docker run '
  dockerParameters = '--rm '
  # Prepare ProActive home volume
  paHomeHost = variables.get("PA_SCHEDULER_HOME")
  paHomeContainer = variables.get("PA_SCHEDULER_HOME")
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' '
  # Prepare working directory (For Dataspaces and serialized task file)
  workspaceHost = localspace
  workspaceContainer = localspace
  workspaceVolume = '-v '+localspace +':'+localspace+' '
  # Prepare container working directory
  containerWorkingDirectory = '-w '+workspaceContainer+' '
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Export_Results")

import pandas as pd
import numpy as np

OUTPUT_FILE = variables.get("OUTPUT_FILE")
DATA_TEST_DF_JSON = variables.get("DATA_TEST_DF_JSON")
PREDICT_DATA = variables.get("PREDICT_DATA_JSON")

if DATA_TEST_DF_JSON != None and PREDICT_DATA != None:
  data_test_df  = pd.read_json(DATA_TEST_DF_JSON, orient='split')
  predict_data  = pd.read_json(PREDICT_DATA, orient='split')
  frame_prediction = pd.DataFrame(predict_data)
  prediction_result = data_test_df.assign(predictions=frame_prediction.values)
  prediction_result = prediction_result.sort_index(ascending=True)

  if OUTPUT_FILE == 'CSV':
    result = prediction_result.to_csv()
    resultMetadata.put("file.extension", ".csv")
    resultMetadata.put("file.name", "result.csv")
    resultMetadata.put("content.type", "text/csv")
  elif OUTPUT_FILE == 'HTML':
    result = prediction_result.to_html()
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "result.html")
    resultMetadata.put("content.type", "text/html")
  print("END Export_Results")
else:
  print('It is not possible to export the data')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
    </task>
    <task name="Predict_Model" >
      <description>
        <![CDATA[ Generate predictions using a trained model. ]]>
      </description>
      <variables>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/predict.png"/>
      </genericInformation>
      <depends>
        <task ref="Train_Model"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters
  containerName = 'activeeon/dlm3'
  dockerRunCommand =  'docker run '
  dockerParameters = '--rm '
  # Prepare ProActive home volume
  paHomeHost = variables.get("PA_SCHEDULER_HOME")
  paHomeContainer = variables.get("PA_SCHEDULER_HOME")
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' '
  # Prepare working directory (For Dataspaces and serialized task file)
  workspaceHost = localspace
  workspaceContainer = localspace
  workspaceVolume = '-v '+localspace +':'+localspace+' '
  # Prepare container working directory
  containerWorkingDirectory = '-w '+workspaceContainer+' '
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Predict_Model")

import os
import pickle
import pandas as pd

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score

MODEL_BIN = variables.get("MODEL")
DATA_TEST_DF_JSON = variables.get("DATA_TEST_DF_JSON")

if MODEL_BIN != None and DATA_TEST_DF_JSON != None:
  LABEL_TEST_DF_JSON = variables.get("LABEL_TEST_DF_JSON")

  data_test_df = pd.read_json(DATA_TEST_DF_JSON, orient='split')
  label_test_df = pd.read_json(LABEL_TEST_DF_JSON, orient='split')
  loaded_model = pickle.loads(MODEL_BIN)
  score = loaded_model.score(data_test_df.values, label_test_df.values.ravel())
  predict_data = list(loaded_model.predict(data_test_df.values))
  predict_data_df = pd.DataFrame(predict_data)

  # CLASSIFICATION MEASURES
  try:
    is_classification_algorithm = variables.get("CLASSIFICATION_MEASURE")
    if is_classification_algorithm == 'True':
      print("**********************CLASSIFICATION MEASURES**********************")
      accuracy_score_result = accuracy_score(label_test_df.values.ravel(), predict_data)
      precision_score_result = precision_score(label_test_df.values.ravel(), predict_data, average='micro')
      confusion_matrix_result = confusion_matrix(label_test_df.values.ravel(), predict_data)
      print("ACCURACY SCORE: %.2f" % accuracy_score_result)
      print("PRECISION SCORE: %.2f" % precision_score_result)
      print("CONFUSION MATRIX:\n%s" % confusion_matrix_result)
      print("*********************************************************************************")

  except NameError:
    classification_algorithm = None
    print("SCORE: %.2f" % score)

  # REGRESSION MEASURES
  try:
    is_regression_algorithm = variables.get("REGRESSION_MEASURE")
    if is_regression_algorithm == 'True':
      mean_squared_error_result = mean_squared_error(label_test_df.values.ravel(), predict_data)
      mean_absolute_error_result = mean_absolute_error(label_test_df.values.ravel(), predict_data)
      mean_absolute_error_result = mean_absolute_error(label_test_df.values.ravel(), predict_data)
      r2_score_result = r2_score(label_test_df.values.ravel(), predict_data)
      print("**********************REGRESSION MEASURES**********************")
      print("MEAN SQUARED ERROR: %.2f" % mean_squared_error_result)
      print("MEAN ABSOLUTE ERROR: %.2f" % mean_absolute_error_result)
      print("R2 SCORE: %.2f" % r2_score_result)
      print("*****************************************************************************")
  except NameError:
    is_regression_algorithm = None
    print("SCORE: %.2f" % score)

  variables.put("PREDICT_DATA_JSON", predict_data_df.to_json(orient='split'))
  print("END Predict_Model")

else:
  print('Please check your ML pipeline')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
    </task>
    <task name="Train_Model" >
      <description>
        <![CDATA[ Train a model using a classification or regression algorithm. ]]>
      </description>
      <variables>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
      </genericInformation>
      <depends>
        <task ref="Support_Vector_Machines"/>
        <task ref="Split_Data"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters
  containerName = 'activeeon/dlm3'
  dockerRunCommand =  'docker run '
  dockerParameters = '--rm '
  # Prepare ProActive home volume
  paHomeHost = variables.get("PA_SCHEDULER_HOME")
  paHomeContainer = variables.get("PA_SCHEDULER_HOME")
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' '
  # Prepare working directory (For Dataspaces and serialized task file)
  workspaceHost = localspace
  workspaceContainer = localspace
  workspaceVolume = '-v '+localspace +':'+localspace+' '
  # Prepare container working directory
  containerWorkingDirectory = '-w '+workspaceContainer+' '
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Train_Model")

import pandas as pd
import random
import pickle

IS_SUPERVIDED_ALGORITHM = variables.get("SUPERVISED_ALGORITHM")
LABEL_TRAIN_DF_JSON = variables.get("LABEL_TRAIN_DF_JSON")
DATA_TRAIN_DF_JSON  = variables.get("DATA_TRAIN_DF_JSON")

if IS_SUPERVIDED_ALGORITHM == 'True' and LABEL_TRAIN_DF_JSON != None and DATA_TRAIN_DF_JSON != None:
  ALGORITHM_NAME = variables.get("ALGORITHM_NAME")
  data_train_df = pd.read_json(DATA_TRAIN_DF_JSON, orient='split')
  label_train_df = pd.read_json(LABEL_TRAIN_DF_JSON, orient='split')
  model = None

  # CLASSIFICATION LEARNING
  if ALGORITHM_NAME == 'SupportVectorMachines':
    from sklearn.svm import SVC
    c_para = variables.get("C_PARA")
    kernel_para = variables.get("KERNEL_PARA")
    model = SVC(C=c_para, kernel=kernel_para)

  if ALGORITHM_NAME == 'GaussianNaiveBayes':
    from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()

  if ALGORITHM_NAME == 'LogisticRegression':
    from sklearn.linear_model import LogisticRegression
    penalty_para = variables.get("PENALTY_PARA")
    solver_para = variables.get("SOLVER_PARA")
    max_iter_para = variables.get("MAX_ITERATIONS_PARA")
    n_jobs_para = variables.get("N_JOBS_PARA")
    model = LogisticRegression(penalty=penalty_para, solver=solver_para, max_iter = int(max_iter_para), n_jobs = int(n_jobs_para))

  # REGRESSION LEARNING
  if ALGORITHM_NAME == 'LinearRegression':
    from sklearn.linear_model import LinearRegression
    n_jobs_para = variables.get("N_JOBS_PARA")
    model = LinearRegression(n_jobs = int(n_jobs_para))

  if ALGORITHM_NAME == 'SupportVectorRegression':
    from sklearn.svm import SVR
    c_para = variables.get("C_PARA")
    kernel_para = variables.get("KERNEL_PARA")
    epsilon_para = variables.get("EPSILON_PARA")
    model = SVR(C=c_para, kernel=kernel_para, epsilon=epsilon_para)

  if ALGORITHM_NAME == 'BayesianRidgeRegression':
    from sklearn import linear_model
    n_iter_para = variables.get("N_ITERATIONS_PARA")
    alpha1_para = variables.get("ALPHA1_PARA")
    alpha2_para = variables.get("ALPHA2_PARA")
    lambda1_para = variables.get("LAMBDA1_PARA")
    lambda2_para = variables.get("LAMBDA2_PARA")
    model = linear_model.BayesianRidge(alpha_1=alpha1_para, alpha_2=alpha2_para, lambda_1=lambda1_para, lambda_2=lambda2_para, n_iter= int(n_iter_para))

  model.fit(data_train_df.values, label_train_df.values.ravel())
  model_bin = pickle.dumps(model)
  variables.put("MODEL", model_bin)

  print("END Train_Model")

else:
  print('Please check your ML pipeline')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
    </task>
    <task name="Support_Vector_Machines" >
      <description>
        <![CDATA[ Support vector machines are supervised learning models with associated learning algorithms that analyze data used for classification. ]]>
      </description>
      <variables>
        <variable name="C" value="1.0" inherited="false" />
        <variable name="KERNEL" value="rbf" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/ml_classification.png"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
C = float(variables.get("C"))
KERNEL = variables.get("KERNEL")

variables.put("C_PARA", C)
variables.put("KERNEL_PARA", KERNEL)
variables.put("ALGORITHM_NAME", "SupportVectorMachines")
variables.put("SUPERVISED_ALGORITHM", "True")
variables.put("CLASSIFICATION_MEASURE", "True")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
    </task>
    <task name="Import_Data" >
      <description>
        <![CDATA[ Load data from external sources. ]]>
      </description>
      <variables>
        <variable name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/log_Apache.csv" inherited="false" />
        <variable name="FILE_DELIMITER" value=";" inherited="false" />
        <variable name="IS_LABELED_DATA" value="True" inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters
  containerName = 'activeeon/dlm3'
  dockerRunCommand =  'docker run '
  dockerParameters = '--rm '
  # Prepare ProActive home volume
  paHomeHost = variables.get("PA_SCHEDULER_HOME")
  paHomeContainer = variables.get("PA_SCHEDULER_HOME")
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' '
  # Prepare working directory (For Dataspaces and serialized task file)
  workspaceHost = localspace
  workspaceContainer = localspace
  workspaceVolume = '-v '+localspace +':'+localspace+' '
  # Prepare container working directory
  containerWorkingDirectory = '-w '+workspaceContainer+' '
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Import_Data")

import pandas as pd
import numpy as np

URL_GET = "https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/pima-indians-diabetes.csv"
FILE_SEP = ";"
IS_LABELED_DATA = 'True'
try:
  URL_GET = str(variables.get("FILE_URL"))
  FILE_SEP = str(variables.get("FILE_DELIMITER"))
  IS_LABELED_DATA = variables.get("IS_LABELED_DATA")
except NameError:
  pass

dataframe = pd.read_csv(URL_GET,FILE_SEP)
columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
  data  = dataframe.values[:,0:columns_number-1]
  label = dataframe.values[:,columns_number-1]

  data_df = pd.DataFrame(data=data,columns=columns_name[0:columns_number-1])
  label_df = pd.DataFrame(data=label,columns=[columns_name[columns_number-1]])

  DATAFRAME_JSON = dataframe.to_json(orient='split')
  COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
  DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
  DATA_TEST_DF_JSON = data_df.to_json(orient='split')
  LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
  LABEL_TEST_DF_JSON = label_df.to_json(orient='split')

  try:
    variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
    variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
    variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
    variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
    variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
    variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)
    variables.put("IS_LABELED_DATA", IS_LABELED_DATA)

    #**************Preview Data*********************
    result = dataframe.to_html()
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")
    #***********************************************
  except NameError:
    pass

  print("END Import_Data")

elif IS_LABELED_DATA == 'False':
  data = dataframe.values
  data_df = pd.DataFrame(data=data,columns=columns_name)

  DATAFRAME_JSON = dataframe.to_json(orient='split')
  COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
  DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
  DATA_TEST_DF_JSON = data_df.to_json(orient='split')

  try:
    variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
    variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
    variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
    variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
    variables.put("IS_LABELED_DATA", IS_LABELED_DATA)

    #**************Preview Data*********************
    result = dataframe.to_html()
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")
    #***********************************************
  except NameError:
    pass

  print("END Import_Data")
else:
  print('The import data is failure')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
variables.put("PREVIOUS_PA_TASK_NAME", variables.get("PA_TASK_NAME"))
]]>
          </code>
        </script>
      </post>
    </task>
    <task name="Split_Data" >
      <description>
        <![CDATA[ Divide the data into two sets. ]]>
      </description>
      <variables>
        <variable name="TRAIN_SIZE" value="0.7" inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/split_data.png"/>
      </genericInformation>
      <depends>
        <task ref="Import_Data"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters
  containerName = 'activeeon/dlm3'
  dockerRunCommand =  'docker run '
  dockerParameters = '--rm '
  # Prepare ProActive home volume
  paHomeHost = variables.get("PA_SCHEDULER_HOME")
  paHomeContainer = variables.get("PA_SCHEDULER_HOME")
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' '
  # Prepare working directory (For Dataspaces and serialized task file)
  workspaceHost = localspace
  workspaceContainer = localspace
  workspaceVolume = '-v '+localspace +':'+localspace+' '
  # Prepare container working directory
  containerWorkingDirectory = '-w '+workspaceContainer+' '
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Split_Data")

from sklearn import model_selection
import pandas as pd

TRAIN_SIZE = 0.7
try:
  IS_LABELED_DATA = variables.get("IS_LABELED_DATA")
  TRAIN_SIZE = float(variables.get("TRAIN_SIZE"))
except NameError:
  pass
test_size = 1 - TRAIN_SIZE

if IS_LABELED_DATA == 'True':
  try:
    DATAFRAME_JSON = variables.get("DATAFRAME_JSON")
    COLUMNS_NAME_JSON = variables.get("COLUMNS_NAME_JSON")
  except NameError:
    pass

  dataframe = pd.read_json(DATAFRAME_JSON, orient='split')
  columns_name_df = pd.read_json(COLUMNS_NAME_JSON,typ='series')
  columns_name = columns_name_df.values
  columns_number = len(columns_name)

  data = dataframe.values[:,0:columns_number-1]
  label = dataframe.values[:,columns_number-1]
  indice = dataframe.index.values

  data_train, data_test, label_train, label_test, idx_train, idx_test = model_selection.train_test_split(data, label, indice, test_size=test_size)
  data_train_df = pd.DataFrame(data=data_train,columns=columns_name[0:columns_number-1],index=idx_train)
  label_train_df = pd.DataFrame(data=label_train,columns=[columns_name[columns_number-1]])
  data_test_df = pd.DataFrame(data=data_test,columns=columns_name[0:columns_number-1],index=idx_test)
  label_test_df = pd.DataFrame(data=label_test,columns=[columns_name[columns_number-1]])

  DATA_TRAIN_DF_JSON = data_train_df.to_json(orient='split')
  DATA_TEST_DF_JSON = data_test_df.to_json(orient='split')
  LABEL_TRAIN_DF_JSON = label_train_df.to_json(orient='split')
  LABEL_TEST_DF_JSON = label_test_df.to_json(orient='split')

  try:
    variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
    variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
    variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
    variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)
  except NameError:
    pass

  print("END Split_Data")

elif IS_LABELED_DATA == 'False' or IS_LABELED_DATA == None:
  try:
    DATAFRAME_JSON = variables.get("DATAFRAME_JSON")
    COLUMNS_NAME_JSON = variables.get("COLUMNS_NAME_JSON")
  except NameError:
    pass

  dataframe = pd.read_json(DATAFRAME_JSON, orient='split')
  columns_name_df = pd.read_json(COLUMNS_NAME_JSON,typ='series')
  columns_name = columns_name_df.values
  columns_number = len(columns_name)
  indice = dataframe.index.values
  data = dataframe.values

  data_train, data_test, idx_train, idx_test = model_selection.train_test_split(data,indice, test_size=test_size)
  data_train_df = pd.DataFrame(data=data_train,columns=columns_name,index=idx_train)
  data_test_df = pd.DataFrame(data=data_test,columns=columns_name,index=idx_test)

  DATA_TRAIN_DF_JSON = data_train_df.to_json(orient='split')
  DATA_TEST_DF_JSON = data_test_df.to_json(orient='split')

  try:
    variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
    variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
  except NameError:
    pass

  print("END Split_Data")
else:
  print('The data could not be split, please check ypur ML pipeline')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
    <task name="Visdom_Visualize_Results" >
      <description>
        <![CDATA[ Plot the different results obtained by a predictive model using Visdom ]]>
      </description>
      <variables>
        <variable name="TARGETED_CLASS" value="1" inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_visdom_visualize_results"/>
      </genericInformation>
      <depends>
        <task ref="Start_Visdom_Service"/>
        <task ref="Predict_Model"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters
  containerName = 'activeeon/dlm3'
  dockerRunCommand =  'docker run '
  dockerParameters = '--rm '
  # Prepare ProActive home volume
  paHomeHost = variables.get("PA_SCHEDULER_HOME")
  paHomeContainer = variables.get("PA_SCHEDULER_HOME")
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' '
  # Prepare working directory (For Dataspaces and serialized task file)
  workspaceHost = localspace
  workspaceContainer = localspace
  workspaceVolume = '-v '+localspace +':'+localspace+' '
  # Prepare container working directory
  containerWorkingDirectory = '-w '+workspaceContainer+' '
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("--- BEGIN Visdom_Visualize_Results ---")

import pandas as pd
import numpy as np
from visdom import Visdom
from sklearn.metrics import confusion_matrix
from sklearn import metrics
from sklearn.metrics import *

DATA_TEST_DF_JSON = variables.get("DATA_TEST_DF_JSON")
PREDICT_DATA = variables.get("PREDICT_DATA_JSON")
IS_LABELED_DATA = variables.get("IS_LABELED_DATA")
TARGETED_CLASS = str(variables.get("TARGETED_CLASS"))

visdom_endpoint = variables.get("VISDOM_ENDPOINT") if variables.get("VISDOM_ENDPOINT") else results[0].__str__()
print("VISDOM_ENDPOINT = ",visdom_endpoint)
if visdom_endpoint is not None:
  visdom_endpoint = visdom_endpoint.replace("http://", "")
(VISDOM_HOST, VISDOM_PORT) = visdom_endpoint.split(":")
print("Connecting to %s:%s" % (VISDOM_HOST, VISDOM_PORT))
vis = Visdom(server="http://"+VISDOM_HOST,port=int(VISDOM_PORT))
assert vis.check_connection()

data_test  = pd.read_json(DATA_TEST_DF_JSON, orient='split')
predict_data_df  = pd.read_json(PREDICT_DATA, orient='split')
idx_test_df = data_test.index.values
data_test_df_columns = list(data_test.columns.values)
data_test_df = data_test.values
nb_columns = data_test_df.shape[1]
PREDICTION_LIMIT = data_test_df.shape[0]
predict_df = predict_data_df.iloc[:,-1]
predict_data = [str(predict_df[x]) for x in range(PREDICTION_LIMIT)]

try:
  is_classification_algorithm = variables.get("CLASSIFICATION_MEASURE")
except NameError:
  is_classification_algorithm = 'False'

if is_classification_algorithm == 'True':
  LABEL_TEST_DF_JSON = variables.get("LABEL_TEST_DF_JSON")
  label_test_df = pd.read_json(LABEL_TEST_DF_JSON, orient='split')
  df_classes = label_test_df.iloc[:,-1].unique()
else:
  df_classes = predict_data_df.iloc[:,-1].unique()

classes = [str(df_classes[x]) for x in range(0,len(df_classes))]
classes.sort()
classes_stats = [0]*len(classes)

# REGRESSION PLOTS
try:
  is_regression_algorithm = variables.get("REGRESSION_MEASURE")
except NameError:
  is_regression_algorithm = 'False'

if is_regression_algorithm == 'True':
  list_detected_simples_text = vis.text("List of detected samples in class "+TARGETED_CLASS+" :\n", opts = dict(title = 'List of indexes'))
  targeted_class_line = vis.line(Y = np.array([0]), X = np.array([0]), opts = dict(xlabel = 'Index', ylabel = 'Targeted Class', title = "Detected samples in class "+TARGETED_CLASS+" \n"))
  features_line = vis.line(X=np.column_stack(([0]*nb_columns)), Y=np.column_stack(np.asarray(data_test_df[0][:])), opts=dict(legend=data_test_df_columns,xlabel = 'Index', ylabel = 'Feature Value', title = 'Values of extracted features for each sample'))
  count = 0
  for x in range(PREDICTION_LIMIT):
    if int(float(predict_data[x]))==int(float(TARGETED_CLASS)):
      message = "%s\n"%(idx_test_df[x])
      vis.text(message, win=list_detected_simples_text, append=True)
      vis.line(Y = np.array([1]), X = np.array([count]), win = targeted_class_line, update = 'append')
    else:
      vis.line(Y = np.array([0]), X = np.array([count]), win = targeted_class_line, update = 'append')
      count += 1
    vis.line(X=np.column_stack(([count]*nb_columns)), Y=np.column_stack((np.asarray(data_test_df[x][:]))), win=features_line, update='append')
else:
  list_detected_simples_text = vis.text("List of detected samples in class "+TARGETED_CLASS+" :\n", opts = dict(title = 'List of indexes'))
  targeted_class_line = vis.line(Y = np.array([0]), X = np.array([0]), opts = dict(xlabel = 'Index', ylabel = 'Targeted Class', title = "Detected samples in class "+TARGETED_CLASS+" \n"))
  statistic_pie = vis.pie(X=classes_stats, opts=dict(legend=classes,  title = 'Detected classes',))
  features_line = vis.line(X=np.column_stack(([0]*nb_columns)), Y=np.column_stack(np.asarray(data_test_df[0][:])), opts=dict(legend=data_test_df_columns,xlabel = 'Index', ylabel = 'Feature Value', title = 'Values of extracted features for each sample'))
  count = 0
  for x in range(PREDICTION_LIMIT):
    i=0
    while i<len(classes):
      if predict_data[x] == classes[i]:
        classes_stats[i] += 1
        if classes[i]== TARGETED_CLASS:
          message = "%s\n"%(idx_test_df[x])
          vis.text(message, win=list_detected_simples_text, append=True)
          vis.line(Y = np.array([1]), X = np.array([count]), win = targeted_class_line, update = 'append')
        else:
          vis.line(Y = np.array([0]), X = np.array([count]), win = targeted_class_line, update = 'append')
        count += 1
        vis.pie(X = classes_stats, win = statistic_pie, opts=dict(legend=classes,  title = 'Classification results'))
        i = len(classes)
      i+= 1
    vis.line(X=np.column_stack(([count]*nb_columns)), Y=np.column_stack((np.asarray(data_test_df[x][:]))), win=features_line, update='append')

try:
  is_clustering_algorithm = variables.get("CLUSTERING_MEASURE")
except NameError:
  is_clustering_algorithm = 'False'

if IS_LABELED_DATA == 'True' and not(is_clustering_algorithm == 'True'):
  LABEL_TEST_DF_JSON = variables.get("LABEL_TEST_DF_JSON")
  label_test_df = pd.read_json(LABEL_TEST_DF_JSON, orient='split')
  score_text = vis.text("Model scoring:\n")
  if len(classes)==2:
    fpr, tpr, thresholds = metrics.roc_curve(np.asarray(label_test_df), np.asarray(predict_data_df))
    vis.line(X=fpr, Y=tpr, opts=dict(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate', title = 'ROC Curve'))
  # CLASSIFICATION MEASURES
  try:
    is_classification_algorithm = variables.get("CLASSIFICATION_MEASURE")
    if is_classification_algorithm == 'True':
      X_matrix = confusion_matrix(label_test_df, predict_data_df)
      confusion_bar = vis.bar(X = X_matrix, opts=dict(stacked=True, legend=classes, rownames=classes, title = 'Predictive model performance'))
      vis.text("CLASSIFICATION MEASURES", win=score_text, append=True)
      vis.text("ACCURACY SCORE:", win=score_text, append=True)
      vis.text(str(accuracy_score(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
      vis.text("PRECISION SCORE:", win=score_text, append=True)
      vis.text(str(precision_score(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
      vis.text("CONFUSION MATRIX:", win=score_text, append=True)
      vis.text(str(confusion_matrix(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
  except NameError:
    classification_algorithm = None

  # REGRESSION MEASURES
  try:
    is_regression_algorithm = variables.get("REGRESSION_MEASURE")
    if is_regression_algorithm == 'True':
      vis.text("REGRESSION MEASURES", win=score_text, append=True)
      vis.text("MEAN SQUARED ERROR:", win=score_text, append=True)
      vis.text(str(mean_squared_error(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
      vis.text("MEAN ABSOLUTE ERROR:", win=score_text, append=True)
      vis.text(str(mean_absolute_error(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
      vis.text("COEFFICIENT DE DETERMINATION:", win=score_text, append=True)
      vis.text(str(r2_score(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
  except NameError:
    is_regression_algorithm = None

print("--- END Visdom_Visualize_Results ---")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
    <task name="Wait_For_Web_Validation"

          onTaskError="pauseJob" >
      <description>
        <![CDATA[ Task to pause the job and send a validation message to the notification service ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png"/>
      </genericInformation>
      <depends>
        <task ref="Visdom_Visualize_Results"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/notifications-tools/resources/Web_Validation_Script/raw" language="groovy">
            <arguments>
              <argument value="Please, validate to stop the Visdom service"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
    </task>
    <task name="Start_Visdom_Service"

          onTaskError="cancelJob" >
      <description>
        <![CDATA[ Start the Visdom server as a service. ]]>
      </description>
      <variables>
        <variable name="SERVICE_ID" value="Visdom" inherited="false" />
        <variable name="INSTANCE_NAME" value="visdom-server" inherited="true" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/cloud-automation-scripts/resources/Service_Start/raw" language="groovy"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
    <task name="Visdom_Service_Actions"

          onTaskError="cancelJob" >
      <description>
        <![CDATA[ This task manages the life-cycle of Visdom PCA service. It allows to trigger three possible actions: Pause_Visdom, Resume_Visdom and Finish_Visdom.
It requires the following variables:
INSTANCE_ID: if used alone or;
INSTANCE_NAME: if used within the same workflow as a Visdom_Service_Start task. In this case there is no need for an INSTANCE_ID.
ACTION: the action to execute on the Visdom service among the aforementioned actions. ]]>
      </description>
      <variables>
        <variable name="INSTANCE_NAME" value="visdom-server" inherited="false" />
        <variable name="ACTION" value="Finish_Visdom" inherited="false" model="PA:LIST(Pause_Visdom, Resume_Visdom, Finish_Visdom)"/>
        <variable name="INSTANCE_ID" value="" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html"/>
      </genericInformation>
      <depends>
        <task ref="Wait_For_Web_Validation"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/cloud-automation-scripts/resources/Service_Action/raw" language="groovy"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2854px;
            height:3692px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-128.5px;left:-499.75px"><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 645.5px; left: 578.75px;" id="jsPlumb_1_3455"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png" width="20px">&nbsp;<span class="name">Export_Results</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 517.5px; left: 583.75px;" id="jsPlumb_1_3458"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/predict.png" width="20px">&nbsp;<span class="name">Predict_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 389.5px; left: 583.75px;" id="jsPlumb_1_3461"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/train.png" width="20px">&nbsp;<span class="name">Train_Model</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" style="top: 261.5px; left: 504.75px;" id="jsPlumb_1_3464"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/ml_classification.png" width="20px">&nbsp;<span class="name">Support_Vector_Machines</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" style="top: 133.5px; left: 662.75px;" id="jsPlumb_1_3467"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_Data</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 261.5px; left: 662.75px;" id="jsPlumb_1_3470"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/split_data.png" width="20px">&nbsp;<span class="name">Split_Data</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 645.5px; left: 737.25px;" id="jsPlumb_1_3473"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png" width="20px">&nbsp;<span class="name">Visdom_Visualize_Results</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 773.5px; left: 737.25px;" id="jsPlumb_1_3476"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png" width="20px">&nbsp;<span class="name">Wait_For_Web_Validation</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable active-task" style="top: 517.5px; left: 742.25px;" id="jsPlumb_1_3479"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png" width="20px">&nbsp;<span class="name">Start_Visdom_Service</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 901.5px; left: 737.25px;" id="jsPlumb_1_3482"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png" width="20px">&nbsp;<span class="name">Visdom_Service_Actions</span></a></div><svg style="position:absolute;left:618.5px;top:557.5px" width="26" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 15 50 5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.40953125,66.78168750000002 L6.418448823809465,47.518594087559144 L-1.1087489198275184,52.84224829573104 L-7.5209903804595175,46.21781175738666 L-2.40953125,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.40953125,66.78168750000002 L6.418448823809465,47.518594087559144 L-1.1087489198275184,52.84224829573104 L-7.5209903804595175,46.21781175738666 L-2.40953125,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:618.9817132113825px;top:429.5px" width="15.518286788617468" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 -10 50 0 0 " transform="translate(15.018286788617468,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path></svg><svg style="position:absolute;left:564.5px;top:301.5px" width="80" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 59 88 C 69 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M55.46281725,63.998374500000004 L47.515142617302224,44.355704927541886 L46.21931944319316,53.483730031661715 L37.000498148963935,53.59920273434873 L55.46281725,63.998374500000004" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M55.46281725,63.998374500000004 L47.515142617302224,44.355704927541886 L46.21931944319316,53.483730031661715 L37.000498148963935,53.59920273434873 L55.46281725,63.998374500000004" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:623.5px;top:301.5px" width="100" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 89 50 79 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M6.499009249999998,63.115491500000005 L26.334186455443895,55.661248062290255 L17.24140069906177,54.13768408643156 L17.356379041875453,44.918856613228485 L6.499009249999998,63.115491500000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M6.499009249999998,63.115491500000005 L26.334186455443895,55.661248062290255 L17.24140069906177,54.13768408643156 L17.356379041875453,44.918856613228485 L6.499009249999998,63.115491500000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:697.9817132113825px;top:173.5px" width="15.518286788617468" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 -10 50 0 0 " transform="translate(15.018286788617468,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path></svg><svg style="position:absolute;left:792.5px;top:557.5px" width="25" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 4 88 C 14 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M6.4906875,66.78168750000002 L11.866605249283186,46.28535835664018 L5.369566595211643,52.82664941632405 L-2.088432834392777,47.40647926142854 L6.4906875,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M6.4906875,66.78168750000002 L11.866605249283186,46.28535835664018 L5.369566595211643,52.82664941632405 L-2.088432834392777,47.40647926142854 L6.4906875,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:623.5px;top:557.5px" width="194" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 173 88 C 183 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M147.78181325,59.788559500000005 L131.24905661183325,46.534580552410205 L134.57900301492097,55.13175781896481 L126.59225493079806,59.73739078748925 L147.78181325,59.788559500000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M147.78181325,59.788559500000005 L131.24905661183325,46.534580552410205 L134.57900301492097,55.13175781896481 L126.59225493079806,59.73739078748925 L147.78181325,59.788559500000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:795.5px;top:685.5px" width="22" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 11 50 1 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.73415625,66.78168750000002 L5.087187797721125,47.08837449057529 L-2.1550211532554755,52.793671109542124 L-8.900828592736769,46.50923939383077 L-2.73415625,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.73415625,66.78168750000002 L5.087187797721125,47.08837449057529 L-2.1550211532554755,52.793671109542124 L-8.900828592736769,46.50923939383077 L-2.73415625,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:793px;top:813.5px" width="23.5" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 12.5 50 2.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.612421875,66.78168750000002 L5.589799912231152,47.243940502122534 L-1.7618140918536094,52.80755187738454 L-8.384335710384322,46.39333271897615 L-2.612421875,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.612421875,66.78168750000002 L5.589799912231152,47.243940502122534 L-1.7618140918536094,52.80755187738454 L-8.384335710384322,46.39333271897615 L-2.612421875,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div style="position: absolute; height: 20px; width: 20px; left: 619px; top: 676px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 619px; top: 636px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 624px; top: 548px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 624px; top: 508px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 624px; top: 420px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 624px; top: 380px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 565px; top: 292px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 703px; top: 164px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 703px; top: 292px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 703px; top: 252px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 797px; top: 676px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 797px; top: 636px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 796px; top: 804px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 796px; top: 764px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 793px; top: 548px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 793.5px; top: 932px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 793.5px; top: 892px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>