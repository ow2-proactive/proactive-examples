<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.9"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.9 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.9/schedulerjob.xsd"
    name="Anomaly_Detection_in_Apache_Logs" projectName="Log Analysis"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2"
>
  <variables>
    <variable name="instance_name" value="visdom-server-1" />
  </variables>
  <description>
    <![CDATA[ Detect anomalies in Apache logs using 
Support Vector Machines (SVM) ]]>
  </description>
    <genericInformation>
    <info name="bucketName" value="machine-learning-workflows"/>
    <info name="pca.action.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/log_analysis.png"/>
    <info name="Documentation" value="https://www.activeeon.com/public_content/documentation/latest/MLOS/MLOSUserGuide.html#_log_analysis"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Export_Results">
      <description>
        <![CDATA[ Export the results. ]]>
      </description>
      <variables>
        <variable name="OUTPUT_FILE" value="HTML" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/export_data.png"/>
      </genericInformation>
      <depends>
        <task ref="Predict_Model"/>
      </depends>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Export_Results")

import pandas as pd
import numpy as np

OUTPUT_FILE = variables.get("OUTPUT_FILE")
DATA_TEST_DF_JSON = variables.get("DATA_TEST_DF_JSON")
PREDICT_DATA = variables.get("PREDICT_DATA_JSON")

if DATA_TEST_DF_JSON != None and PREDICT_DATA != None: 
  data_test_df  = pd.read_json(DATA_TEST_DF_JSON, orient='split')   
  predict_data  = pd.read_json(PREDICT_DATA, orient='split')    
  frame_prediction = pd.DataFrame(predict_data)    
  prediction_result = data_test_df.assign(predictions=frame_prediction.values)
  prediction_result = prediction_result.sort_index(ascending=True) 
  
  if OUTPUT_FILE == 'CSV':
    result = prediction_result.to_csv()
    resultMetadata.put("file.extension", ".csv")
    resultMetadata.put("file.name", "result.csv")
    resultMetadata.put("content.type", "text/csv")
  elif OUTPUT_FILE == 'HTML':
    result = prediction_result.to_html()
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "result.html")
    resultMetadata.put("content.type", "text/html")          
  print("END Export_Results")  
else:
  print('It is not possible to export the data')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
    <task name="Bind_or_Start_Visdom_Service"
    
    
    onTaskError="cancelJob" >
      <description>
        <![CDATA[ The simplest task, ran by a groovy engine. ]]>
      </description>
      <variables>
        <variable name="service_model" value="http://models.activeeon.com/pca/visdom" inherited="false" />
        <variable name="instance_name" value="visdom-server-1" inherited="true" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/visdom.png"/>
      </genericInformation>
      <inputFiles>
        <files  includes="cloud-automation-service-client-1.0.0-all.jar" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment >
        <additionalClasspath>
          <pathElement path="cloud-automation-service-client-1.0.0-all.jar"/>
        </additionalClasspath>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import org.ow2.proactive.pca.client.api.CloudAutomationApi;

schedulerapi.connect()

pcaUrl = variables.get("PA_SCHEDULER_REST_URL").replaceAll("/rest\\z", "/cloud-automation-service");
sessionId = schedulerapi.getSession();

api = new CloudAutomationApi(pcaUrl, sessionId);

endpoint = api.getServiceEndpointOrCreate(variables.get("service_model"), variables.get("instance_name"));
endpoint = endpoint.replaceAll("\n",'');

println "Service " + variables.get("service_model") + " is available on " + endpoint

variables.put("endpoint", endpoint)
result = '<meta http-equiv="refresh" content="1; url=http://' + endpoint + '/" />'
result+= '<h2><span style="color:black">Please wait while redirecting...</span></h2>'
resultMetadata.put("content.type", "text/html")
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
    <task name="Visdom_Visualize_Results">
      <description>
        <![CDATA[ Plot the different results obtained by a predictive model using Visdom ]]>
      </description>
      <variables>
        <variable name="TARGETED_CLASS" value="1" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/visdom.png"/>
      </genericInformation>
      <depends>
        <task ref="Predict_Model"/>
        <task ref="Bind_or_Start_Visdom_Service"/>
      </depends>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre/" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN DATA VISUALIZATION")

import pandas as pd
import numpy as np
from visdom import Visdom
from sklearn.metrics import confusion_matrix
from sklearn import metrics
from sklearn.metrics import *

DATA_TEST_DF_JSON = variables.get("DATA_TEST_DF_JSON")
PREDICT_DATA = variables.get("PREDICT_DATA_JSON")
IS_LABELED_DATA = variables.get("IS_LABELED_DATA")
TARGETED_CLASS = str(variables.get("TARGETED_CLASS"))
VISDOM_HOST,VISDOM_PORT = variables.get("endpoint").split(":")
print("Connecting to %s" % VISDOM_PORT)
vis = Visdom(server="http://"+VISDOM_HOST,port=int(VISDOM_PORT))
assert vis.check_connection()
data_test  = pd.read_json(DATA_TEST_DF_JSON, orient='split')   
predict_data_df  = pd.read_json(PREDICT_DATA, orient='split')  
idx_test_df = data_test.index.values
data_test_df_columns = list(data_test.columns.values)
data_test_df = data_test.values
nb_columns = data_test_df.shape[1]
PREDICTION_LIMIT = data_test_df.shape[0]
predict_df = predict_data_df.iloc[:,-1]
predict_data = [str(predict_df[x]) for x in range(PREDICTION_LIMIT)]

try:
  is_classification_algorithm = variables.get("CLASSIFICATION_MEASURE")
except NameError:
    is_classification_algorithm = 'False'

if is_classification_algorithm == 'True':
  LABEL_TEST_DF_JSON = variables.get("LABEL_TEST_DF_JSON")
  label_test_df = pd.read_json(LABEL_TEST_DF_JSON, orient='split')
  df_classes = label_test_df.iloc[:,-1].unique()
else:
  df_classes = predict_data_df.iloc[:,-1].unique()

classes = [str(df_classes[x]) for x in range(0,len(df_classes))]
classes.sort()
classes_stats = [0]*len(classes)

  
# REGRESSION PLOTS
try:
  is_regression_algorithm = variables.get("REGRESSION_MEASURE")
except NameError:
    is_regression_algorithm = 'False'

if is_regression_algorithm == 'True':
  list_detected_simples_text = vis.text("List of detected samples in class "+TARGETED_CLASS+" :\n", opts = dict(title = 'List of indexes'))
  targeted_class_line = vis.line(Y = np.array([0]), X = np.array([0]), opts = dict(xlabel = 'Index', ylabel = 'Targeted Class', title = "Detected samples in class "+TARGETED_CLASS+" \n"))
  features_line = vis.line(X=np.column_stack(([0]*nb_columns)), Y=np.column_stack(np.asarray(data_test_df[0][:])), opts=dict(legend=data_test_df_columns,xlabel = 'Index', ylabel = 'Feature Value', title = 'Values of extracted features for each sample'))
  count = 0 
  for x in range(PREDICTION_LIMIT):
    if int(float(predict_data[x]))==int(float(TARGETED_CLASS)):
      message = "%s\n"%(idx_test_df[x])
      vis.text(message, win=list_detected_simples_text, append=True)
      vis.line(Y = np.array([1]), X = np.array([count]), win = targeted_class_line, update = 'append')
    else:
      vis.line(Y = np.array([0]), X = np.array([count]), win = targeted_class_line, update = 'append')
      count += 1
    vis.line(X=np.column_stack(([count]*nb_columns)), Y=np.column_stack((np.asarray(data_test_df[x][:]))), win=features_line, update='append')
else:
  list_detected_simples_text = vis.text("List of detected samples in class "+TARGETED_CLASS+" :\n", opts = dict(title = 'List of indexes'))
  targeted_class_line = vis.line(Y = np.array([0]), X = np.array([0]), opts = dict(xlabel = 'Index', ylabel = 'Targeted Class', title = "Detected samples in class "+TARGETED_CLASS+" \n"))
  statistic_pie = vis.pie(X=classes_stats, opts=dict(legend=classes,  title = 'Detected classes',))
  features_line = vis.line(X=np.column_stack(([0]*nb_columns)), Y=np.column_stack(np.asarray(data_test_df[0][:])), opts=dict(legend=data_test_df_columns,xlabel = 'Index', ylabel = 'Feature Value', title = 'Values of extracted features for each sample'))
  count = 0
  for x in range(PREDICTION_LIMIT):
    i=0
    while i<len(classes):
      if predict_data[x] == classes[i]:
        classes_stats[i] += 1
        if classes[i]== TARGETED_CLASS:
          message = "%s\n"%(idx_test_df[x])
          vis.text(message, win=list_detected_simples_text, append=True)
          vis.line(Y = np.array([1]), X = np.array([count]), win = targeted_class_line, update = 'append')
        else:
          vis.line(Y = np.array([0]), X = np.array([count]), win = targeted_class_line, update = 'append')
        count += 1
        vis.pie(X = classes_stats, win = statistic_pie, opts=dict(legend=classes,  title = 'Classification results'))
        i = len(classes)
      i+= 1
    vis.line(X=np.column_stack(([count]*nb_columns)), Y=np.column_stack((np.asarray(data_test_df[x][:]))), win=features_line, update='append')

try:
  is_clustering_algorithm = variables.get("CLUSTERING_MEASURE")
except NameError:
    is_clustering_algorithm = 'False' 
  
if IS_LABELED_DATA == 'True' and not(is_clustering_algorithm == 'True'):
  LABEL_TEST_DF_JSON = variables.get("LABEL_TEST_DF_JSON")
  label_test_df = pd.read_json(LABEL_TEST_DF_JSON, orient='split') 
  score_text = vis.text("Model scoring:\n")
  if len(classes)==2:
    fpr, tpr, thresholds = metrics.roc_curve(np.asarray(label_test_df), np.asarray(predict_data_df))
    vis.line(X=fpr, Y=tpr, opts=dict(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate', title = 'ROC Curve'))
  # CLASSIFICATION MEASURES
  try:
    is_classification_algorithm = variables.get("CLASSIFICATION_MEASURE")
    if is_classification_algorithm == 'True':
      X_matrix = confusion_matrix(label_test_df, predict_data_df)
      confusion_bar = vis.bar(X = X_matrix, opts=dict(stacked=True, legend=classes, rownames=classes, title = 'Predictive model performance'))
      vis.text("CLASSIFICATION MEASURES", win=score_text, append=True)
      vis.text("ACCURACY SCORE:", win=score_text, append=True)
      vis.text(str(accuracy_score(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
      vis.text("PRECISION SCORE:", win=score_text, append=True)
      vis.text(str(precision_score(label_test_df.values.ravel(), predict_data_df,average='micro')), win=score_text, append=True)
      vis.text("CONFUSION MATRIX:", win=score_text, append=True)
      vis.text(str(confusion_matrix(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
  except NameError:
    classification_algorithm = None

  # REGRESSION MEASURES
  try:
    is_regression_algorithm = variables.get("REGRESSION_MEASURE")
    if is_regression_algorithm == 'True':
      vis.text("REGRESSION MEASURES", win=score_text, append=True)
      vis.text("MEAN SQUARED ERROR:", win=score_text, append=True)
      vis.text(str(mean_squared_error(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
      vis.text("MEAN ABSOLUTE ERROR:", win=score_text, append=True)
      vis.text(str(mean_absolute_error(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
      vis.text("R2 SCORE:", win=score_text, append=True)
      vis.text(str(r2_score(label_test_df.values.ravel(), predict_data_df)), win=score_text, append=True)
  except NameError:        
    is_regression_algorithm = None
   
print("END DATA VISUALIZATION")
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
    <task name="Wait_Until_Validation"
    
    
    onTaskError="pauseJob" >
      <description>
        <![CDATA[ Task to pause the job and send a validation message to the notification service ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/visdom.png"/>
      </genericInformation>
      <depends>
        <task ref="Visdom_Visualize_Results"/>
      </depends>
      <scriptExecutable>
        <script>
          <code language="python">
            <![CDATA[
# Please fill variables
notification_message = 'Please validate to terminate the Visdom service'

# Don't change code below unless you know what you are doing
from org.ow2.proactive.addons.webhook import Webhook

jobid = variables.get("PA_JOB_ID")
schedulerURL =  variables.get("PA_SCHEDULER_REST_URL")

print schedulerURL
# get sessionid
schedulerapi.connect()

# pause job
schedulerapi.pauseJob(jobid)


# send web validation
print "Sending web validation..."
url = schedulerURL.replace("/rest", "") +'/notification-service/notifications'
headers = '{\"Content-Type\" : \"application/json\" }'
notification_content = '{\"description\": \"'+notification_message+'\", \"jobId\": \"'+jobid+'\" , \"validation\": \"true\"}'
Webhook.execute ( 'POST', url, headers, notification_content);
print "Web Validation sent"
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
    <task name="Terminate_Visdom_Service"
    
    
    onTaskError="cancelJob" >
      <description>
        <![CDATA[ The simplest task, ran by a groovy engine. ]]>
      </description>
      <variables>
        <variable name="service_model" value="http://models.activeeon.com/pca/visdom" inherited="false" />
        <variable name="instance_name" value="visdom-server-1" inherited="true" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/visdom.png"/>
      </genericInformation>
      <depends>
        <task ref="Wait_Until_Validation"/>
      </depends>
      <inputFiles>
        <files  includes="cloud-automation-service-client-1.0.0-all.jar" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment >
        <additionalClasspath>
          <pathElement path="cloud-automation-service-client-1.0.0-all.jar"/>
        </additionalClasspath>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import org.ow2.proactive.pca.client.api.CloudAutomationApi;

schedulerapi.connect()
pcaUrl = variables.get("PA_SCHEDULER_REST_URL").replaceAll("/rest\\z", "/cloud-automation-service");
sessionId = schedulerapi.getSession();

api = new CloudAutomationApi(pcaUrl, sessionId);

println "Terminating " + variables.get("service_model") + " / " + variables.get("instance_name");
try{
  api.terminateServiceFromInstanceName(variables.get("service_model"), variables.get("instance_name"));
}catch(Exception ex){
  println "Service was already terminated"
}
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
    <task name="Predict_Model">
      <description>
        <![CDATA[ Generate predictions using a trained model. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/predict.png"/>
      </genericInformation>
      <depends>
        <task ref="Train_Model"/>
      </depends>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Predict_Model")

import os
import pickle
import pandas as pd

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score

MODEL_BIN = variables.get("MODEL")
DATA_TEST_DF_JSON = variables.get("DATA_TEST_DF_JSON")

if MODEL_BIN != None and DATA_TEST_DF_JSON != None:
  LABEL_TEST_DF_JSON = variables.get("LABEL_TEST_DF_JSON")

  data_test_df = pd.read_json(DATA_TEST_DF_JSON, orient='split')
  label_test_df = pd.read_json(LABEL_TEST_DF_JSON, orient='split')
  loaded_model = pickle.loads(MODEL_BIN)
  score = loaded_model.score(data_test_df.values, label_test_df.values.ravel())
  predict_data = list(loaded_model.predict(data_test_df.values))
  predict_data_df = pd.DataFrame(predict_data)

  # CLASSIFICATION MEASURES
  try: 
    is_classification_algorithm = variables.get("CLASSIFICATION_MEASURE")
    if is_classification_algorithm == 'True':
      print("**********************CLASSIFICATION MEASURES**********************")
      accuracy_score_result = accuracy_score(label_test_df.values.ravel(), predict_data)
      precision_score_result = precision_score(label_test_df.values.ravel(), predict_data, average='micro')
      confusion_matrix_result = confusion_matrix(label_test_df.values.ravel(), predict_data)
      print("ACCURACY SCORE: %.2f" % accuracy_score_result)
      print("PRECISION SCORE: %.2f" % precision_score_result)
      print("CONFUSION MATRIX:\n%s" % confusion_matrix_result)
      print("*********************************************************************************")
      
  except NameError:
    classification_algorithm = None
    print("SCORE: %.2f" % score)

  # REGRESSION MEASURES
  try:
    is_regression_algorithm = variables.get("REGRESSION_MEASURE")
    if is_regression_algorithm == 'True':
      mean_squared_error_result = mean_squared_error(label_test_df.values.ravel(), predict_data)
      mean_absolute_error_result = mean_absolute_error(label_test_df.values.ravel(), predict_data)
      mean_absolute_error_result = mean_absolute_error(label_test_df.values.ravel(), predict_data)
      r2_score_result = r2_score(label_test_df.values.ravel(), predict_data) 
      print("**********************REGRESSION MEASURES**********************")
      print("MEAN SQUARED ERROR: %.2f" % mean_squared_error_result)
      print("MEAN ABSOLUTE ERROR: %.2f" % mean_absolute_error_result)
      print("R2 SCORE: %.2f" % r2_score_result)
      print("*****************************************************************************")
  except NameError:
    is_regression_algorithm = None
    print("SCORE: %.2f" % score)
        
  variables.put("PREDICT_DATA_JSON", predict_data_df.to_json(orient='split'))
  print("END Predict_Model")
  
else:
  print('Please check your ML pipeline')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
    <task name="Train_Model">
      <description>
        <![CDATA[ Train a model using a classification or regression algorithm. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/train.png"/>
      </genericInformation>
      <depends>
        <task ref="Support_Vector_Machines"/>
        <task ref="Split_Data"/>
      </depends>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Train_Model")

import pandas as pd
import random
import pickle

IS_SUPERVIDED_ALGORITHM = variables.get("SUPERVISED_ALGORITHM")
LABEL_TRAIN_DF_JSON = variables.get("LABEL_TRAIN_DF_JSON")
DATA_TRAIN_DF_JSON  = variables.get("DATA_TRAIN_DF_JSON")

if IS_SUPERVIDED_ALGORITHM == 'True' and LABEL_TRAIN_DF_JSON != None and DATA_TRAIN_DF_JSON != None:
  ALGORITHM_NAME = variables.get("ALGORITHM_NAME")
  data_train_df = pd.read_json(DATA_TRAIN_DF_JSON, orient='split')
  label_train_df = pd.read_json(LABEL_TRAIN_DF_JSON, orient='split')
  model = None
  
  # CLASSIFICATION LEARNING
  if ALGORITHM_NAME == 'SupportVectorMachines':
    from sklearn.svm import SVC
    c_para = variables.get("C_PARA")
    kernel_para = variables.get("KERNEL_PARA")
    model = SVC(C=c_para, kernel=kernel_para)
   
  if ALGORITHM_NAME == 'GaussianNaiveBayes':
    from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()
  
  if ALGORITHM_NAME == 'LogisticRegression':
    from sklearn.linear_model import LogisticRegression
    penalty_para = variables.get("PENALTY_PARA")
    solver_para = variables.get("SOLVER_PARA") 
    max_iter_para = variables.get("MAX_ITERATIONS_PARA")
    n_jobs_para = variables.get("N_JOBS_PARA")
    model = LogisticRegression(penalty=penalty_para, solver=solver_para, max_iter = int(max_iter_para), n_jobs = int(n_jobs_para))
  
  # REGRESSION LEARNING
  if ALGORITHM_NAME == 'LinearRegression':
    from sklearn.linear_model import LinearRegression
    n_jobs_para = variables.get("N_JOBS_PARA")
    model = LinearRegression(n_jobs = int(n_jobs_para))

  if ALGORITHM_NAME == 'SupportVectorRegression':
    from sklearn.svm import SVR
    c_para = variables.get("C_PARA")
    kernel_para = variables.get("KERNEL_PARA")
    epsilon_para = variables.get("EPSILON_PARA")
    model = SVR(C=c_para, kernel=kernel_para, epsilon=epsilon_para) 
  
  if ALGORITHM_NAME == 'BayesianRidgeRegression':
    from sklearn import linear_model
    n_iter_para = variables.get("N_ITERATIONS_PARA")
    alpha1_para = variables.get("ALPHA1_PARA")
    alpha2_para = variables.get("ALPHA2_PARA")
    lambda1_para = variables.get("LAMBDA1_PARA")
    lambda2_para = variables.get("LAMBDA2_PARA")
    model = linear_model.BayesianRidge(alpha_1=alpha1_para, alpha_2=alpha2_para, lambda_1=lambda1_para, lambda_2=lambda2_para, n_iter= int(n_iter_para))
  
  model.fit(data_train_df.values, label_train_df.values.ravel())
  model_bin = pickle.dumps(model)
  variables.put("MODEL", model_bin)
  
  print("END Train_Model")

else:
  print('Please check your ML pipeline')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
    <task name="Support_Vector_Machines">
      <description>
        <![CDATA[ Support vector machines are supervised learning models with associated learning algorithms that analyze data used for classification. ]]>
      </description>
      <variables>
        <variable name="C" value="1.0" inherited="false" />
        <variable name="KERNEL" value="rbf" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/ml_classification.png"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
C = float(variables.get("C"))
KERNEL = variables.get("KERNEL")

variables.put("C_PARA", C)
variables.put("KERNEL_PARA", KERNEL)
variables.put("ALGORITHM_NAME", "SupportVectorMachines")
variables.put("SUPERVISED_ALGORITHM", "True")
variables.put("CLASSIFICATION_MEASURE", "True")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
    <task name="Import_Data">
      <description>
        <![CDATA[ Load data from external sources. ]]>
      </description>
      <variables>
        <variable name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/log_Apache.csv" inherited="false" />
        <variable name="FILE_DELIMITER" value=";" inherited="false" />
        <variable name="IS_LABELED_DATA" value="True" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/import_data.png"/>
      </genericInformation>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Import_Data")

import pandas as pd
import numpy as np

URL_GET = "https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/pima-indians-diabetes.csv"
FILE_SEP = ";"
IS_LABELED_DATA = 'True'
try:
  URL_GET = str(variables.get("FILE_URL"))
  FILE_SEP = str(variables.get("FILE_DELIMITER"))
  IS_LABELED_DATA = variables.get("IS_LABELED_DATA")
except NameError:
  pass

dataframe = pd.read_csv(URL_GET,FILE_SEP)
columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
  data  = dataframe.values[:,0:columns_number-1]
  label = dataframe.values[:,columns_number-1]
  
  data_df = pd.DataFrame(data=data,columns=columns_name[0:columns_number-1])
  label_df = pd.DataFrame(data=label,columns=[columns_name[columns_number-1]])
  
  DATAFRAME_JSON = dataframe.to_json(orient='split')
  COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
  DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
  DATA_TEST_DF_JSON = data_df.to_json(orient='split')
  LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
  LABEL_TEST_DF_JSON = label_df.to_json(orient='split')
  
  try:
    variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
    variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
    variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
    variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
    variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
    variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)
    variables.put("IS_LABELED_DATA", IS_LABELED_DATA)
    
    #**************Preview Data*********************
    result = dataframe.to_html()
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")
    #***********************************************
  except NameError:
    pass
  
  print("END Import_Data")
    
elif IS_LABELED_DATA == 'False':
  data = dataframe.values
  data_df = pd.DataFrame(data=data,columns=columns_name)
  
  DATAFRAME_JSON = dataframe.to_json(orient='split')
  COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
  DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
  DATA_TEST_DF_JSON = data_df.to_json(orient='split')
  
  try:
    variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
    variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
    variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
    variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
    variables.put("IS_LABELED_DATA", IS_LABELED_DATA)
    
    #**************Preview Data*********************
    result = dataframe.to_html()
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")
    #***********************************************
  except NameError:
    pass
  
  print("END Import_Data")
else:
  print('The import data is failure')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
variables.put("PREVIOUS_PA_TASK_NAME", variables.get("PA_TASK_NAME"))
]]>
          </code>
        </script>
      </post>
    </task>
    <task name="Split_Data">
      <description>
        <![CDATA[ Divide the data into two sets. ]]>
      </description>
      <variables>
        <variable name="TRAIN_SIZE" value="0.7" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/split_data.png"/>
      </genericInformation>
      <depends>
        <task ref="Import_Data"/>
      </depends>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Split_Data")

from sklearn import model_selection
import pandas as pd

TRAIN_SIZE = 0.7
try:
  IS_LABELED_DATA = variables.get("IS_LABELED_DATA")
  TRAIN_SIZE = float(variables.get("TRAIN_SIZE"))
except NameError:
  pass
test_size = 1 - TRAIN_SIZE

if IS_LABELED_DATA == 'True':
  try:
    DATAFRAME_JSON = variables.get("DATAFRAME_JSON")
    COLUMNS_NAME_JSON = variables.get("COLUMNS_NAME_JSON")
  except NameError:
    pass
  
  dataframe = pd.read_json(DATAFRAME_JSON, orient='split')
  columns_name_df = pd.read_json(COLUMNS_NAME_JSON,typ='series')
  columns_name = columns_name_df.values
  columns_number = len(columns_name)
    
  data = dataframe.values[:,0:columns_number-1]
  label = dataframe.values[:,columns_number-1]
  indice = dataframe.index.values
  
  data_train, data_test, label_train, label_test, idx_train, idx_test = model_selection.train_test_split(data, label, indice, test_size=test_size)
  data_train_df = pd.DataFrame(data=data_train,columns=columns_name[0:columns_number-1],index=idx_train)
  label_train_df = pd.DataFrame(data=label_train,columns=[columns_name[columns_number-1]])
  data_test_df = pd.DataFrame(data=data_test,columns=columns_name[0:columns_number-1],index=idx_test)
  label_test_df = pd.DataFrame(data=label_test,columns=[columns_name[columns_number-1]])
  
  DATA_TRAIN_DF_JSON = data_train_df.to_json(orient='split')
  DATA_TEST_DF_JSON = data_test_df.to_json(orient='split')
  LABEL_TRAIN_DF_JSON = label_train_df.to_json(orient='split')
  LABEL_TEST_DF_JSON = label_test_df.to_json(orient='split')
  
  try:
    variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
    variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
    variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
    variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)
  except NameError:
    pass
  
  print("END Split_Data")
  
elif IS_LABELED_DATA == 'False' or IS_LABELED_DATA == None:
  try:
    DATAFRAME_JSON = variables.get("DATAFRAME_JSON")
    COLUMNS_NAME_JSON = variables.get("COLUMNS_NAME_JSON")
  except NameError:
    pass
  
  dataframe = pd.read_json(DATAFRAME_JSON, orient='split')
  columns_name_df = pd.read_json(COLUMNS_NAME_JSON,typ='series')
  columns_name = columns_name_df.values
  columns_number = len(columns_name)
  indice = dataframe.index.values
  data = dataframe.values
  
  data_train, data_test, idx_train, idx_test = model_selection.train_test_split(data,indice, test_size=test_size)
  data_train_df = pd.DataFrame(data=data_train,columns=columns_name,index=idx_train)
  data_test_df = pd.DataFrame(data=data_test,columns=columns_name,index=idx_test)
  
  DATA_TRAIN_DF_JSON = data_train_df.to_json(orient='split')
  DATA_TEST_DF_JSON = data_test_df.to_json(orient='split')
  
  try:
    variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
    variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
  except NameError:
    pass
  
  print("END Split_Data")
else:
  print('The data could not be split, please check ypur ML pipeline')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
  </taskFlow>
</job>