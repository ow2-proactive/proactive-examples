<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.14" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd"  name="Parse_Update_Json_From_Catalog" tags="Azure,Big Data,Data Streaming,Spark,HDInsight" projectName="07. Azure HDInsight Spark ARM" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="CLUSTER_NAME" value="activeeon-spark-cluster-${PA_JOB_ID}" model="PA:NOT_EMPTY_STRING" description="Name of the Spark cluster to be created." group="Spark Cluster Parameters" advanced="false" hidden="false"/>
    <variable name="CLUSTER_USER" value="act-usr" model="PA:NOT_EMPTY_STRING" description="User login needed to access the Web dashboard of the Spark cluster." group="Spark Cluster Parameters" advanced="true" hidden="false"/>
    <variable name="CLUSTER_PASSWORD" value="ENC(7ZqKwLLZE5B3S4BZoPq1wg==)" model="PA:HIDDEN" description="User password needeed to access the Web dashboard of the Spark cluster." group="Spark Cluster Parameters" advanced="true" hidden="false"/>
    <variable name="CLUSTER_SSH_USER" value="act-usr" model="PA:NOT_EMPTY_STRING" description="User login needed to access the head node of the Spark cluster, remotely via SSH." group="Spark Cluster Parameters" advanced="true" hidden="false"/>
    <variable name="CLUSTER_SSH_PASSWORD" value="ENC(vIn1k0HbSAYteZas59YECw==)" model="PA:HIDDEN" description="User password needed to access the head node of the Spark cluster, remotely via SSH." group="Spark Cluster Parameters" advanced="true" hidden="false"/>
  </variables>
  <genericInformation>
    <info name="bucketName" value="data-big-data"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/json.png"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="update_spark_json_template"




    fork="true">
      <genericInformation>
        <info name="PRE_SCRIPT_AS_FILE" value="Azure_HDInsight_Spark_ARM_Template.json"/>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/json.png"/>
      </genericInformation>
      <pre>
        <script>
          <code language="bash">
            <![CDATA[
{
  "properties": {
    "mode": "Incremental",
    "template": {
      "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
      "contentVersion": "1.0.0.0",
      "parameters": {
        "clusterName": {
          "defaultValue": "activeeon-spark-cluster-1",
          "type": "string",
          "metadata": {
            "description": "The name of the HDInsight cluster to create."
          }
        },
        "clusterLoginUserName": {
          "defaultValue": "act-user",
          "type": "string",
          "metadata": {
            "description": "These credentials can be used to submit jobs to the cluster and to log into cluster dashboards."
          }
        },
        "clusterLoginPassword": {
          "defaultValue": "activeeon2021",
          "type": "securestring",
          "minLength": 10,
          "metadata": {
            "description": "The password must be at least 10 characters in length and must contain at least one digit, one upper case letter, one lower case letter, and one non-alphanumeric character except (single-quote, double-quote, backslash, right-bracket, full-stop). Also, the password must not contain 3 consecutive characters from the cluster username or SSH username."
          }
        },
        "sshUserName": {
          "defaultValue": "act-user",
          "type": "string",
          "metadata": {
            "description": "These credentials can be used to remotely access the cluster."
          }
        },
        "sshPassword": {
          "defaultValue": "activeeon2021",
          "type": "securestring",
          "minLength": 6,
          "maxLength": 72,
          "metadata": {
            "description": "SSH password must be 6-72 characters long and must contain at least one digit, one upper case letter, and one lower case letter.  It must not contain any 3 consecutive characters from the cluster login name"
          }
        },
        "location": {
          "type": "string",
          "defaultValue": "[resourceGroup().location]",
          "metadata": {
            "description": "Location for all resources."
          }
        },
        "HeadNodeVirtualMachineSize": {
          "type": "string",
          "defaultValue": "Standard_E4_v3",
          "allowedValues": [
            "Standard_A4_v2",
            "Standard_A8_v2",
            "Standard_E2_v3",
            "Standard_E4_v3",
            "Standard_E8_v3",
            "Standard_E16_v3",
            "Standard_E20_v3",
            "Standard_E32_v3",
            "Standard_E48_v3"
          ],
          "metadata": {
            "description": "This is the headnode Azure Virtual Machine size, and will affect the cost. If you don't know, just leave the default value."
          }
        },
        "WorkerNodeVirtualMachineSize": {
          "type": "string",
          "defaultValue": "Standard_E4_v3",
          "allowedValues": [
            "Standard_A4_v2",
            "Standard_A8_v2",
            "Standard_E2_v3",
            "Standard_E4_v3",
            "Standard_E8_v3",
            "Standard_E16_v3",
            "Standard_E20_v3",
            "Standard_E32_v3",
            "Standard_E48_v3"
          ],
          "metadata": {
            "description": "This is the worerdnode Azure Virtual Machine size, and will affect the cost. If you don't know, just leave the default value."
          }
        }
      },
      "variables": {
        "defaultStorageAccount": {
          "name": "[concat('storage', uniqueString(resourceGroup().id))]",
          "type": "Standard_LRS"
        }
      },
      "resources": [
        {
          "type": "Microsoft.Storage/storageAccounts",
          "apiVersion": "2019-06-01",
          "name": "[variables('defaultStorageAccount').name]",
          "location": "[parameters('location')]",
          "sku": {
            "name": "[variables('defaultStorageAccount').type]"
          },
          "kind": "Storage",
          "properties": {}
        },
        {
          "type": "Microsoft.HDInsight/clusters",
          "apiVersion": "2018-06-01-preview",
          "name": "[parameters('clusterName')]",
          "location": "[parameters('location')]",
          "dependsOn": [
            "[resourceId('Microsoft.Storage/storageAccounts',variables('defaultStorageAccount').name)]"
          ],
          "properties": {
            "clusterVersion": "4.0",
            "osType": "Linux",
            "tier": "Standard",
            "clusterDefinition": {
              "kind": "spark",
              "configurations": {
                "gateway": {
                  "restAuthCredential.isEnabled": true,
                  "restAuthCredential.username": "[parameters('clusterLoginUserName')]",
                  "restAuthCredential.password": "[parameters('clusterLoginPassword')]"
                }
              }
            },
            "storageProfile": {
              "storageaccounts": [
                {
                  "name": "[replace(replace(reference(resourceId('Microsoft.Storage/storageAccounts', variables('defaultStorageAccount').name)).primaryEndpoints.blob,'https://',''),'/','')]",
                  "isDefault": true,
                  "container": "[parameters('clusterName')]",
                  "key": "[listKeys(resourceId('Microsoft.Storage/storageAccounts', variables('defaultStorageAccount').name), '2019-06-01').keys[0].value]"
                }
              ]
            },
            "computeProfile": {
              "roles": [
                {
                  "name": "headnode",
                  "targetInstanceCount": 2,
                  "hardwareProfile": {
                    "vmSize": "[parameters('HeadNodeVirtualMachineSize')]"
                  },
                  "osProfile": {
                    "linuxOperatingSystemProfile": {
                      "username": "[parameters('sshUserName')]",
                      "password": "[parameters('sshPassword')]"
                    }
                  }
                },
                {
                  "name": "workernode",
                  "targetInstanceCount": 1,
                  "autoscale": {
                    "capacity": {
                      "minInstanceCount": 1,
                      "maxInstanceCount": 2
                    }
                  },
                  "hardwareProfile": {
                    "vmSize": "[parameters('WorkerNodeVirtualMachineSize')]"
                  },
                  "osProfile": {
                    "linuxOperatingSystemProfile": {
                      "username": "[parameters('sshUserName')]",
                      "password": "[parameters('sshPassword')]"
                    }
                  }
                }
              ]
            }
          }
        }
      ],
      "outputs": {
        "storage": {
          "type": "object",
          "value": "[reference(resourceId('Microsoft.Storage/storageAccounts', variables('defaultStorageAccount').name))]"
        },
        "cluster": {
          "type": "object",
          "value": "[reference(resourceId('Microsoft.HDInsight/clusters', parameters('clusterName')))]"
        }
      }
    },
    "parameters": {
      "location": {
        "value": "eastus2"
      }
    }
  }
}
]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="python">
            <![CDATA[
import json

a_file = open("Azure_HDInsight_Spark_ARM_Template.json", "r")
json_object = json.load(a_file)
a_file.close()

json_object['properties']['template']['parameters']['clusterName']['defaultValue']  = variables["CLUSTER_NAME"]
json_object['properties']['template']['parameters']['clusterLoginUserName']['defaultValue']  = variables["CLUSTER_USER"]
json_object['properties']['template']['parameters']['clusterLoginPassword']['defaultValue']  = variables["CLUSTER_PASSWORD"]
json_object['properties']['template']['parameters']['sshUserName']['defaultValue']  = variables["CLUSTER_SSH_USER"]
json_object['properties']['template']['parameters']['sshPassword']['defaultValue']  = variables["CLUSTER_SSH_PASSWORD"]

print(json_object['properties']['template']['parameters']['clusterName']['defaultValue'])
print(json_object['properties']['template']['parameters']['clusterLoginUserName']['defaultValue'])
print(json_object['properties']['template']['parameters']['clusterLoginPassword']['defaultValue'])
print(json_object['properties']['template']['parameters']['sshUserName']['defaultValue'])
print(json_object['properties']['template']['parameters']['sshPassword']['defaultValue'])

a_file = open("Azure_HDInsight_Spark_ARM_Template.json", "w")
json.dump(json_object, a_file)
a_file.close()
]]>
          </code>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <code language="bash">
            <![CDATA[
cat Azure_HDInsight_Spark_ARM_Template.json
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
            425.515625
        </positionTop>
        <positionLeft>
            575.515625
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2732px;
            height:3128px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-420.515625px;left:-570.515625px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_16" style="top: 425.516px; left: 575.516px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task has no description"><img src="/automation-dashboard/styles/patterns/img/wf-icons/json.png" width="20px">&nbsp;<span class="name">update_spark_json_template</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 647.5px; top: 456px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
