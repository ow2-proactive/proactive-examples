<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.14" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd"  name="Azure_HDInsight_Spark_Submit_Application" projectName="07. Azure HDInsight Spark" tags="Azure,Big Data,Spark,HDInsight" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="SPARK_APPLICATION_URL" value="https://activeeon-spark-utils.s3.eu-west-3.amazonaws.com/spark-examples_2.11-2.4.6.4.1.4.8.jar" model="PA:NOT_EMPTY_STRING" description="URL used to download the archive of the Spark application" group="Spark Application Submission" advanced="false" hidden="false"/>
    <variable name="SUBMISSION_PARAMETERS" value="--class org.apache.spark.examples.SparkPi --master yarn " model="PA:NOT_EMPTY_STRING" description="Parameters to be passed to the spark-submit command" group="Spark Application Submission" advanced="false" hidden="false"/>
    <variable name="APPLICATION_ARGUMENTS" value="" model="" description="Arguments to be passed to the Spark application" group="Spark Application Submission" advanced="false" hidden="false"/>
    <variable name="SPARK_HEAD_NODE_ACCESS_TOKEN" value="activeeon-spark-cluster-1-hn" model="PA:NOT_EMPTY_STRING" description="Token used to access the head node of the Spark cluster" group="Spark Application Submission" advanced="false" hidden="false"/>
  </variables>
  <description>
    <![CDATA[ A workflow that executes a shell script in the head node of a HDInsight Spark Cluster. The shell script is implemented in the task "submit_spark_app".
The provided shell script downloads the executable jar of a Spark application, then submits the application to the cluster.
The workflow requires as input: (i) the URL of the Spark application archive, (ii) the submission parameters (to be passed to the spark-submit command), (iii) the application arguments and (iv) the access token of the head node of a HDInsight Spark cluster. The latter input can be obtained, for example, from the workflow "Azure_HDInsight_Create_Spark_Cluster" (available in the big-data bucket), which deploys a HDInsight Spark cluster. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="data-big-data"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
    <info name="group" value="public-objects"/>
    <info name="NODE_ACCESS_TOKEN" value="${SPARK_HEAD_NODE_ACCESS_TOKEN}"/>
  </genericInformation>
  <taskFlow>
    <task name="submit_spark_app" fork="true">
      <description>
        <![CDATA[ A task that downloads the executable jar of Spark application examples (from a Amazon S3 public repository), then submits the application "SparkPi" to Spark platform available in the underlying machine. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <code language="bash">
            <![CDATA[
jobId=$variables_PA_JOB_ID
appURL=$variables_SPARK_APPLICATION_URL
submissionParameters=$variables_SUBMISSION_PARAMETERS
appArguments=$variables_APPLICATION_ARGUMENTS

mkdir -p /tmp/${jobId}/spark-application
cd /tmp/${jobId}/spark-application
wget -O spark-application-${jobId}.jar -nc ${appURL}
spark-submit ${submissionParameters} spark-application-${jobId}.jar ${appArguments}
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            441.203125
        </positionTop>
        <positionLeft>
            578.75
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2736px;
            height:3504px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-436.203125px;left:-573.75px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_4" style="top: 441.219px; left: 578.75px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="A task that downloads the executable jar of Spark application examples (from a Amazon S3 public repository), then submits the application &quot;SparkPi&quot; to Spark platform available in the underlying machine."><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">submit_spark_app</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 627px; top: 471px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
