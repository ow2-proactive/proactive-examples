<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.14" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd"  name="Docker_Swarm_HDFS_Spark_Service" tags="Swarm,Docker,Big Data,Artificial Intelligence,HDFS,Spark,Service Automation,Analytics" projectName="01. Spark" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="1"  >
  <variables>
    <variable name="node_source_name" value="" model="PA:MODEL_FROM_URL(${PA_SCHEDULER_REST_PUBLIC_URL}/rm/model/nodesources)" description="If not empty, the workflow tasks will be run only on nodes belonging to the specified node source."   />
    <variable name="nb_spark_hdfs_workers" value="3" model="PA:INTEGER" description="Number of HDFS/Spark nodes."   />
    <variable name="INSTANCE_NAME" value="docker-swarm-spark-$PA_JOB_ID" model="PA:NOT_EMPTY_STRING" description="Service instance name."   />
  </variables>
  <description>
    <![CDATA[ Deploy a Docker Swarm-HDFS-Spark platform of nb_spark_hdfs_workers datanodes-spark workers. node_source_name refers to the targeted node source of the Spark deployment. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="service-automation"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Error_if_empty_node_source_name"

    onTaskError="cancelJob"


    fork="true">
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
def node_source_name = variables.get("node_source_name")
if (node_source_name.isEmpty()){
  println("A node source name must be selected.")
  throw new IllegalStateException("A node source name must be selected.")
}
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
          439.01248931884766
        </positionTop>
        <positionLeft>
          530.3500061035156
        </positionLeft>
      </metadata>
    </task>
    <task name="Start_Docker_Swarm_Service"

    onTaskError="cancelJob"


    fork="true">
      <description>
        <![CDATA[ Start the Docker_Swarm service. ]]>
      </description>
      <variables>
        <variable inherited="false" name="SERVICE_ACTIVATION_WORKFLOW" value="service-automation/Docker_Swarm" model="PA:CATALOG_OBJECT(Workflow/psa,,,Docker_Swarm%)" description="The service activation workflow. Please keep the default value for this variable." advanced="false" hidden="false"/>
        <variable name="INSTANCE_NAME" value="swarm-$PA_JOB_ID" inherited="false" description="The name of the service to be deployed"/>
        <variable name="TARGETED_PA_NODE_SOURCE_NAME" value="$node_source_name" inherited="false" />
        <variable name="TARGETED_NB_PA_NODES" value="$nb_spark_hdfs_workers" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/swarm.png"/>
      </genericInformation>
      <depends>
        <task ref="Error_if_empty_node_source_name"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Service_Start/raw" language="groovy">
            <arguments>
              <argument value="false"/>
              <argument value="false"/>
              <argument value="INSTANCE_NAME"/>
              <argument value="TARGETED_PA_NODE_SOURCE_NAME"/>
              <argument value="TARGETED_NB_PA_NODES"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
// Propagate the swarm service instance id for spark
def instance_name = variables.get("INSTANCE_NAME")
def instance_id = variables.get("INSTANCE_ID_" + instance_name)
variables.put("propagated_swarm_service_instance_id", instance_id)
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
          567.4124946594238
        </positionTop>
        <positionLeft>
          530.3500061035156
        </positionLeft>
      </metadata>
    </task>
    <task name="Start_HDFS_Service"

    onTaskError="cancelJob"


    fork="true">
      <description>
        <![CDATA[ Start the HDFS service. ]]>
      </description>
      <variables>
        <variable inherited="false" name="SERVICE_ACTIVATION_WORKFLOW" value="service-automation/HDFS" model="PA:CATALOG_OBJECT(Workflow/psa,,,HDFS%)" description="The service activation workflow. Please keep the default value for this variable." advanced="false" hidden="false"/>
        <variable name="INSTANCE_NAME" value="hdfs-$PA_JOB_ID" inherited="false" description="The name of the service to be deployed"/>
        <variable name="swarm_service_instance_id" value="$propagated_swarm_service_instance_id" inherited="false" />
        <variable name="nb_hdfs_datanodes" value="$nb_spark_hdfs_workers" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/hdfs.png"/>
      </genericInformation>
      <depends>
        <task ref="Start_Docker_Swarm_Service"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Service_Start/raw" language="groovy">
            <arguments>
              <argument value="true"/>
              <argument value="false"/>
              <argument value="INSTANCE_NAME"/>
              <argument value="swarm_service_instance_id"/>
              <argument value="nb_hdfs_datanodes"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
// Propagate the hdfs service instance id for spark
def instance_name = variables.get("INSTANCE_NAME")
def instance_id = variables.get("INSTANCE_ID_" + instance_name)
variables.put("propagated_hdfs_service_instance_id", instance_id)
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
          695.8125
        </positionTop>
        <positionLeft>
          530.3500061035156
        </positionLeft>
      </metadata>
    </task>
    <task name="Start_Spark_Service"

    onTaskError="cancelJob"


    fork="true">
      <description>
        <![CDATA[ Start the Spark service. ]]>
      </description>
      <variables>
        <variable inherited="false" name="SERVICE_ACTIVATION_WORKFLOW" value="service-automation/Spark" model="PA:CATALOG_OBJECT(Workflow/psa,,,Spark%)" description="The service activation workflow. Please keep the default value for this variable." advanced="false" hidden="false"/>
        <variable name="INSTANCE_NAME" value="spark-$PA_JOB_ID" inherited="false" description="The name of the service to be deployed"/>
        <variable name="swarm_service_instance_id" value="$propagated_swarm_service_instance_id" inherited="false" />
        <variable name="hdfs_service_instance_id" value="$propagated_hdfs_service_instance_id" inherited="false" />
        <variable name="nb_spark_workers" value="$nb_spark_hdfs_workers" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
      </genericInformation>
      <depends>
        <task ref="Start_HDFS_Service"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Service_Start/raw" language="groovy">
            <arguments>
              <argument value="true"/>
              <argument value="false"/>
              <argument value="INSTANCE_NAME"/>
              <argument value="swarm_service_instance_id"/>
              <argument value="hdfs_service_instance_id"/>
              <argument value="nb_spark_workers"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def spark_service_instance_name = variables.get("INSTANCE_NAME")
def spark_service_instance_id = variables.get("INSTANCE_ID_" + spark_service_instance_name)

// To results
resultMap.put("spark_service_instance_id", spark_service_instance_id)
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
          824.2124938964844
        </positionTop>
        <positionLeft>
          530.3500061035156
        </positionLeft>
      </metadata>
    </task>
    <task name="wait_user_action"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_loop.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_loop"/>
      </genericInformation>
      <depends>
        <task ref="Start_Spark_Service"/>
      </depends>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import org.ow2.proactive.scheduler.common.job.JobVariable

def signals = ['Undeploy_Platform','Submit_Python_Spark_Pi','Submit_Scala_Spark_Pi','Submit_Scala_Spark_Write_Read_HDFS']

// Manage the signal 'Undeploy_Platform'
signalapi.readyForSignal("Undeploy_Platform")

// Manage the signal 'Submit_Python_Spark_Pi'
List <JobVariable> submitPythonSparkPiJobVariables = new java.util.ArrayList<JobVariable>()
submitPythonSparkPiJobVariables.add(new JobVariable("nb_random_points", "10000", "PA:INTEGER", "Number of random points.", "", false, false))
signalapi.readyForSignal("Submit_Python_Spark_Pi", submitPythonSparkPiJobVariables)

// Manage the signal 'Submit_Scala_Spark_Pi'
List <JobVariable> submitScalaSparkPiJobVariables = new java.util.ArrayList<JobVariable>()
submitScalaSparkPiJobVariables.add(new JobVariable("nb_random_points", "10000", "PA:INTEGER", "Number of random points.", "", false, false))
signalapi.readyForSignal("Submit_Scala_Spark_Pi", submitScalaSparkPiJobVariables)

// Manage the signal 'Submit_Scala_Spark_Write_Read_HDFS'
List <JobVariable> submitSubmitScalaSparkWriteReadHDFSJobVariables = new java.util.ArrayList<JobVariable>()
submitSubmitScalaSparkWriteReadHDFSJobVariables.add(new JobVariable("parquet_file_path", "/user/hdfs/wiki/testwiki", "PA:NOT_EMPTY_STRING", "Parquet file path in the HDFS.", "", false, false))
submitSubmitScalaSparkWriteReadHDFSJobVariables.add(new JobVariable("csv_file_path", "/user/hdfs/wiki/testwiki.csv", "PA:NOT_EMPTY_STRING", "CSV file path.", "", false, false))
signalapi.readyForSignal("Submit_Scala_Spark_Write_Read_HDFS", submitSubmitScalaSparkWriteReadHDFSJobVariables)

// Receive the signal
receivedSignal = signalapi.waitForAny(signals.toSet())
println(receivedSignal)

signals.each {  signalapi.removeSignal("ready_"+it) }

if (receivedSignal.getName() == "Undeploy_Platform") {
    variables.put("SIGNAL_ACTION","UNDEPLOY_PLATFORM")
    println("Undeploying platform ...")

} else if (receivedSignal.getName() == "Submit_Python_Spark_Pi"){
    variables.put("SIGNAL_ACTION","SUBMIT_PYTHON_SPARK_PI_SIGNAL")
    variables.put("nb_random_points",receivedSignal.getUpdatedVariables().get("nb_random_points"))
    println("Submitting Spark application to the cluster ...")

} else if (receivedSignal.getName() == "Submit_Scala_Spark_Pi"){
    variables.put("SIGNAL_ACTION","SUBMIT_SCALA_SPARK_PI_SIGNAL")
    variables.put("nb_random_points",receivedSignal.getUpdatedVariables().get("nb_random_points"))
    println("Submitting Spark application to the cluster ...")

} else if (receivedSignal.getName() == "Submit_Scala_Spark_Write_Read_HDFS"){
    variables.put("SIGNAL_ACTION","SUBMIT_SCALA_SPARK_WRITE_READ_HDFS_SIGNAL")
    variables.put("parquet_file_path",receivedSignal.getUpdatedVariables().get("parquet_file_path"))
    variables.put("csv_file_path",receivedSignal.getUpdatedVariables().get("csv_file_path"))
    println("Submitting Spark application to the cluster ...")
}
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="start"></controlFlow>
      <metadata>
        <positionTop>
          950.6124877929688
        </positionTop>
        <positionLeft>
          530.3500061035156
        </positionLeft>
      </metadata>
    </task>
    <task name="handle_user_actions"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_loop.png"/>
      </genericInformation>
      <depends>
        <task ref="wait_user_action"/>
      </depends>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.json.JsonSlurper

if(variables.get("SIGNAL_ACTION")=="UNDEPLOY_PLATFORM"){

    variables.put("jobSubmitted", false)
    variables.put("isFinished", false)


    schedulerapi.connect()
    def jobid
    def called_workflow = null
    def workflow_variables = new HashMap<>()

    if( !variables.get("jobSubmitted") ){

    	workflow_variables.put("node_source_name", variables.get("node_source_name"))
    	workflow_variables.put("nb_spark_hdfs_workers", variables.get("nb_spark_hdfs_workers"))

    	def spark_instance_name = "spark-" + variables.get("PA_JOB_ID")
    	def hdfs_instance_name = "hdfs-" + variables.get("PA_JOB_ID")
    	def swarm_instance_name = "swarm-" + variables.get("PA_JOB_ID")

        def spark_service_instance_id = variables.get("INSTANCE_ID_" + spark_instance_name)
        def hdfs_service_instance_id = variables.get("INSTANCE_ID_" + hdfs_instance_name)
        def swarm_service_instance_id = variables.get("INSTANCE_ID_" + swarm_instance_name)

    	workflow_variables.put("SPARK_INSTANCE_NAME", spark_instance_name)
    	workflow_variables.put("HDFS_INSTANCE_NAME", hdfs_instance_name)
    	workflow_variables.put("SWARM_INSTANCE_NAME", swarm_instance_name)

    	workflow_variables.put("INSTANCE_ID_" + spark_instance_name, spark_service_instance_id)
    	workflow_variables.put("INSTANCE_ID_" + hdfs_instance_name, hdfs_service_instance_id)
    	workflow_variables.put("INSTANCE_ID_" + swarm_instance_name, swarm_service_instance_id)

        called_workflow = "data-big-data/Docker_Swarm_HDFS_Spark_Terminate_Service"

        // submitting the job
        def generic_infos_map = ["PARENT_JOB_ID" : variables.get("PA_JOB_ID")]
        jobid = schedulerapi.submitFromCatalog(variables.get("PA_CATALOG_REST_URL"), called_workflow, workflow_variables, generic_infos_map)
        variables.put("jobSubmitted", true)

        println "Job submitted with job id " + jobid
        variables.put("jobID", jobid)
    }

    if( jobid == null ){
        jobid = variables.get("jobID")
    }
    isFinished = schedulerapi.isJobFinished(jobid)

    variables.put("isFinished", isFinished)

    result = jobid


} else if(variables.get("SIGNAL_ACTION")=="SUBMIT_PYTHON_SPARK_PI_SIGNAL"){

    // connect to the scheduler
    schedulerapi.connect()

    def workflow_variables = new HashMap<>()
    workflow_variables.put("nb_random_points", variables.get("nb_random_points"))
   	def spark_instance_name = "spark-" + variables.get("PA_JOB_ID")
    def spark_service_instance_id = variables.get("INSTANCE_ID_" + spark_instance_name)
    workflow_variables.put("spark_service_instance_id", spark_service_instance_id)

    called_workflow = "data-big-data/Python_Spark_Pi"

    // submitting the job
    def generic_infos_map = ["PARENT_JOB_ID" : variables.get("PA_JOB_ID")]
    jobid = schedulerapi.submitFromCatalog(variables.get("PA_CATALOG_REST_URL"), called_workflow, workflow_variables, generic_infos_map)

    println "Job submitted with job id " + jobid
    result = jobid


} else if(variables.get("SIGNAL_ACTION")=="SUBMIT_SCALA_SPARK_PI_SIGNAL"){

    // connect to the scheduler
    schedulerapi.connect()

    def workflow_variables = new HashMap<>()
    workflow_variables.put("nb_random_points", variables.get("nb_random_points"))
   	def spark_instance_name = "spark-" + variables.get("PA_JOB_ID")
    def spark_service_instance_id = variables.get("INSTANCE_ID_" + spark_instance_name)
    workflow_variables.put("spark_service_instance_id", spark_service_instance_id)

    called_workflow = "data-big-data/Scala_Spark_Pi"

    // submitting the job
    def generic_infos_map = ["PARENT_JOB_ID" : variables.get("PA_JOB_ID")]
    jobid = schedulerapi.submitFromCatalog(variables.get("PA_CATALOG_REST_URL"), called_workflow, workflow_variables, generic_infos_map)

    println "Job submitted with job id " + jobid
    result = jobid


} else if(variables.get("SIGNAL_ACTION")=="SUBMIT_SCALA_SPARK_WRITE_READ_HDFS_SIGNAL"){

    // connect to the scheduler
    schedulerapi.connect()

    def workflow_variables = new HashMap<>()
    workflow_variables.put("parquet_file_path", variables.get("parquet_file_path"))
   	workflow_variables.put("csv_file_path", variables.get("csv_file_path"))
   	def spark_instance_name = "spark-" + variables.get("PA_JOB_ID")
    def spark_service_instance_id = variables.get("INSTANCE_ID_" + spark_instance_name)
    workflow_variables.put("spark_service_instance_id", spark_service_instance_id)

    called_workflow = "data-big-data/Scala_Spark_Write_Read_HDFS"

    // submitting the job
    def generic_infos_map = ["PARENT_JOB_ID" : variables.get("PA_JOB_ID")]
    jobid = schedulerapi.submitFromCatalog(variables.get("PA_CATALOG_REST_URL"), called_workflow, workflow_variables, generic_infos_map)

    println "Job submitted with job id " + jobid
    result = jobid
}
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow  block="end">
        <loop target="wait_user_action">
          <script>
            <code language="groovy">
              <![CDATA[
signalAction=variables.get("SIGNAL_ACTION")

loop = signalAction=="UNDEPLOY_PLATFORM" ? false : true

variables.put("SIGNAL_ACTION","")
]]>
            </code>
          </script>
        </loop>
      </controlFlow>
      <metadata>
        <positionTop>
          1075.0124816894531
        </positionTop>
        <positionLeft>
          530.3500061035156
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2257px;
            height:2581px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-434.01248931884766px;left:-525.3500061035156px"><div class="task ui-draggable" id="jsPlumb_1_211" style="top: 439.013px; left: 530.35px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task has no description"><img src="/studio/images/Groovy.png" width="20px">&nbsp;<span class="name">Error_if_empty_node_source_name</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_214" style="top: 567.413px; left: 530.35px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Start the Docker_Swarm service."><img src="/automation-dashboard/styles/patterns/img/wf-icons/swarm.png" width="20px">&nbsp;<span class="name">Start_Docker_Swarm_Service</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon" class="glyphicon glyphicon-arrow-right"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_217" style="top: 695.824px; left: 530.35px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Start the HDFS service."><img src="/automation-dashboard/styles/patterns/img/wf-icons/hdfs.png" width="20px">&nbsp;<span class="name">Start_HDFS_Service</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon" class="glyphicon glyphicon-arrow-right"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable" id="jsPlumb_1_220" style="top: 824.213px; left: 530.35px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Start the Spark service."><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">Start_Spark_Service</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon" class="glyphicon glyphicon-arrow-right"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task block-start ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_226" style="top: 950.613px; left: 530.35px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title=""><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_loop.png" width="20px">&nbsp;<span class="name">wait_user_action</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon"></i></a></div><div class="task block-end ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_229" style="top: 1075.02px; left: 530.35px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title=""><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_loop.png" width="20px">&nbsp;<span class="name">handle_user_actions</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon"></i></a></div><svg style="position:absolute;left:606.5px;top:478.5px" width="33.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 22.5 50 12.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-1.7647200000000005,66.303232 L8.955147275230877,48.02525493465072 L0.9308726161701921,52.565190638595936 L-4.782894086173185,45.32966231848053 L-1.7647200000000005,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-1.7647200000000005,66.303232 L8.955147275230877,48.02525493465072 L0.9308726161701921,52.565190638595936 L-4.782894086173185,45.32966231848053 L-1.7647200000000005,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:586px;top:606.5px" width="41.5" height="90" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 89 C -10 39 30.5 50 20.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-1.0044066250000012,66.74071675 L11.517842394635135,49.647054781590576 L3.073657634674195,53.34783088122744 L-1.875043474137434,45.56899052191638 L-1.0044066250000012,66.74071675" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-1.0044066250000012,66.74071675 L11.517842394635135,49.647054781590576 L3.073657634674195,53.34783088122744 L-1.875043474137434,45.56899052191638 L-1.0044066250000012,66.74071675" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:585.5px;top:735.5px" width="21.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 10.5 50 0.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.7747343749999995,66.78168750000002 L4.918836648297567,47.038107153227145 L-2.286251050858403,52.790212093809444 L-9.072638757893003,46.54962382908555 L-2.7747343749999995,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.7747343749999995,66.78168750000002 L4.918836648297567,47.038107153227145 L-2.286251050858403,52.790212093809444 L-9.072638757893003,46.54962382908555 L-2.7747343749999995,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:569.5px;top:990.5px" width="28.5" height="85" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 84 C -10 34 17.5 50 7.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.217225,63.573684000000014 L7.259194673834721,44.62117835654067 L-0.44428077814096634,49.68639957192781 L-6.6280897542374815,42.84823413468163 L-2.217225,63.573684000000014" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.217225,63.573684000000014 L7.259194673834721,44.62117835654067 L-0.44428077814096634,49.68639957192781 L-6.6280897542374815,42.84823413468163 L-2.217225,63.573684000000014" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:629.5px;top:940.5px" width="66" height="185" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 15 0 C 65 -50 10 134 0 84 " transform="translate(0.5,50.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#316b31" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M34.17988125,-4.451209500000002 L44.107421355074116,14.26893866880852 L36.28486278424837,9.38963775515289 L30.266574099921222,16.373920203056887 L34.17988125,-4.451209500000002" class="" stroke="#316b31" fill="#316b31" transform="translate(0.5,50.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M34.17988125,-4.451209500000002 L44.107421355074116,14.26893866880852 L36.28486278424837,9.38963775515289 L30.266574099921222,16.373920203056887 L34.17988125,-4.451209500000002" class="" stroke="#316b31" fill="#316b31" transform="translate(0.5,50.5)"></path></svg><div class="_jsPlumb_overlay l1 component label" id="jsPlumb_1_258" style="position: absolute; transform: translate(-50%, -50%); left: 659.5px; top: 1032.5px;">loop</div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 619.5px; top: 469px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 607px; top: 597px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 607px; top: 557px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 586.5px; top: 726px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 586.5px; top: 686px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable endpointDrag _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 586px; top: 854px; visibility: visible;" dragid="jsPlumb_1_268" elid="jsPlumb_1_220"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 586px; top: 814px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 577.5px; top: 981px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint loop-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 635px; top: 981px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#316b31" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 570px; top: 1105px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 570px; top: 1065px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint loop-source-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 620px; top: 1065px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#316b31" stroke="none" style=""></circle></svg></div><svg style="position:absolute;left:577px;top:863.5px" width="29.5" height="88" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 87 C -10 37 18.5 50 8.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.125484375,65.86284375000001 L7.590322450053323,47.03193570661965 L-0.17671617285377517,51.99913924888258 L-6.273382051064109,45.08316750447342 L-2.125484375,65.86284375000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected connected" style="position: absolute; height: 20px; width: 20px; left: 577.5px; top: 941px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>