<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"  name="Reserve_Nodes" projectName="Cloud Automation - Deployment" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2" >
  <variables>
    <variable name="node_source_name" value="local" />
    <variable name="nb_nodes" value="2" />
  </variables>
  <description>
    <![CDATA[ Reserve ProActive nodes. ]]>
  </description>
  <genericInformation>
    <info name="pca.service.id" value="HDFS-Spark"/>
    <info name="pca.states" value="(VOID,PA_NODES_RESERVED)"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Reserve_Nodes" >
      <variables>
        <variable name="sleep_duration_in_seconds" value="5" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
      </genericInformation>
      <inputFiles>
        <files  includes="replicated_sleeps.xml" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import org.ow2.proactive.scheduler.common.job.*
import org.ow2.proactive.scheduler.common.task.*
import org.ow2.proactive.scripting.*
import org.ow2.proactive.pca.service.client.ApiClient
import org.ow2.proactive.pca.service.client.api.ServiceInstanceRestApi
import org.ow2.proactive.pca.service.client.model.ServiceInstanceData

// Retrieve variables
def node_source_name = variables.get("node_source_name")
def nb_nodes = variables.get("nb_nodes") as Integer
def sleep_duration_in_seconds = variables.get("sleep_duration_in_seconds")
def scheduler_rest_url = variables.get("PA_SCHEDULER_REST_URL")
def service_instance_id = variables.get("PCA_INSTANCE_ID") as Long

// Define other variables
def pca_url = scheduler_rest_url.replaceAll("/rest\\z", "/cloud-automation-service")

// Get schedulerapi access
schedulerapi.connect()

// Reserve required proactive nodes by submitting replicated_sleeps.xml
def generic_infos_map = ["PARENT_JOB_ID" : variables.get("PA_JOB_ID")]
def parameters = new HashMap()
parameters.put("node_source_name", node_source_name)
parameters.put("nb_nodes", nb_nodes)
parameters.put("sleep_duration_in_seconds", sleep_duration_in_seconds)
parameters.put("service_instance_id", service_instance_id)
def job_id = schedulerapi.submit(new File(localspace, "replicated_sleeps.xml"), parameters, generic_infos_map)

// Ensure resources are blocked (sleeps run fine)
while (true) {
  def running_sleep_tasks = schedulerapi.getJobState(job_id).getTasks().findAll { it.getName().substring(0,5) == "sleep" && it.getStatus() == TaskStatus.RUNNING }
  if (running_sleep_tasks.size() == nb_nodes)
    break
}

// Connect to APIs
def api_client = new ApiClient()
api_client.setBasePath(pca_url)
def service_instance_rest_api = new ServiceInstanceRestApi(api_client)

// Update the related service instance status
def service_instance_data = service_instance_rest_api.getServiceInstanceUsingGET(service_instance_id)
service_instance_data.setInstanceStatus("PA_NODES_RESERVED")
service_instance_rest_api.updateServiceInstanceUsingPUT(service_instance_id, service_instance_data)

// Inform other platforms that the HDFS-Spark service is in the PA_NODES_RESERVED state through Synchronization API
def channel = "Service_Instance_" + service_instance_id
synchronizationapi.createChannelIfAbsent(channel, false)
synchronizationapi.put(channel, "PA_NODES_RESERVED", true)
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:1139px;
            height:566px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-333.9875030517578px;left:-496px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_760" style="top: 339px; left: 501px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">reserve_nodes</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 541.5px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>