<?xml version="1.0" encoding="UTF-8"?>
<job
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xmlns="urn:proactive:jobdescriptor:3.14" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd"  name="Spark" projectName="2. Big Data" tags="Artificial Intelligence,Big Data,Spark,Service Automation,Analytics" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="1"  >
  <variables>
    <variable name="INSTANCE_NAME" value="spark-$PA_JOB_ID" model="PA:NOT_EMPTY_STRING" description="The name of the service to be deployed."  advanced="false" hidden="false"/>
    <variable name="swarm_service_instance_id" value="xx" model="PA:NOT_EMPTY_STRING" description="This variable must be set to the targeted Docker_Swarm service instance id."  advanced="false" hidden="false"/>
    <variable name="hdfs_service_instance_id" value=""  description="This variable must be set to the targeted HDFS service instance id."  advanced="false" hidden="false"/>
    <variable name="nb_spark_workers" value="3" model="PA:NOT_EMPTY_STRING" description="Number of Spark workers"  advanced="false" hidden="false"/>
  </variables>
  <description>
    <![CDATA[ Deploy a Spark platform of `nb_spark_workers` Spark workers.
A Swarm service (Docker\_Swarm) needs to be started first, and the `swarm_service_instance_id` variable must be set to the service instance id of this targeted Docker Swarm.
To connect a HDFS platform (optional), a HDFS service needs to be started after the Swarm service, and the `hdfs_service_instance_id` variable must be set to the service instance id of this targeted HDFS. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="service-automation"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
    <info name="pca.states" value="(VOID,RUNNING)"/>
    <info name="Documentation" value="http://spark.apache.org/docs/latest/spark-standalone.html"/>
    <info name="pca.service.id" value="Spark"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="retrieve_services_variables"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Retrieve_variables_from_service_instance_id/raw" language="groovy">
            <arguments>
              <argument value="$swarm_service_instance_id"/>
              <argument value="swarm_token_name"/>
              <argument value="PSA_%{INSTANCE_NAME}"/>
              <argument value="swarm_manager_and_workers_pa_node_names"/>
              <argument value="swarm_manager_and_workers_pa_node_names"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Retrieve_variables_from_service_instance_id/raw" language="groovy">
            <arguments>
              <argument value="$hdfs_service_instance_id"/>
              <argument value="hdfs_network_name"/>
              <argument value="hdfs_network_name"/>
              <argument value="hdfs_namenode_host_port"/>
              <argument value="hdfs_namenode_host_port"/>
            </arguments>
          </file>
        </script>
      </post>
      <metadata>
        <positionTop>
          -68.85000610351562
        </positionTop>
        <positionLeft>
          473.6000061035156
        </positionLeft>
      </metadata>
    </task>
    <task name="create_overlay_network_or_not_and_start_spark_master"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$swarm_token_name"/>
      </genericInformation>
      <depends>
        <task ref="retrieve_services_variables"/>
      </depends>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
// The overlay network must be created on the swarm manager host
def swarm_manager_pa_node_name = variables.get("swarm_manager_and_workers_pa_node_names").split(",")[0]

selected = (nodename == swarm_manager_pa_node_name)
]]>
          </code>
        </script>
      </selection>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def spark_service_instance_id = variables.get("PCA_INSTANCE_ID")
def instance_name = variables.get("INSTANCE_NAME")
def instance_id = variables.get("PCA_INSTANCE_ID")
def job_id = variables.get("PA_JOB_ID")
def pa_node_name = variables.get("PA_NODE_NAME")
def pa_node_host = variables.get("PA_NODE_HOST")
def hdfs_network_name = variables.get("hdfs_network_name")
def hdfs_namenode_host_port = variables.get("hdfs_namenode_host_port")
def nb_spark_workers = variables.get("nb_spark_workers") as Integer
def pca_public_rest_url = variables.get('PA_CLOUD_AUTOMATION_REST_PUBLIC_URL')

// If hdfs wkw param is not set, create a spark overlay network rather than using the hdfs one
def spark_network_name = hdfs_network_name

if (hdfs_network_name == null) {
  spark_network_name = instance_name + "-spark-network"
  def cmd = ["docker", "network", "create", "-d", "overlay", "--attachable", spark_network_name]
  println cmd
  cmd.execute().waitForProcessOutput(System.out, System.err)
}

// Find a free port for spark_master_gui_port
def spark_master_gui_port = null
try {
  def server = new ServerSocket(0)
  spark_master_gui_port = server.getLocalPort()
  server.close()
} catch (IOException e) {
  throw new RuntimeException( "Failed to find free local port to bind the agent to", e);
}

// Build the proxified url
def endpoint_id = "spark-gui-" + job_id
def spark_master_endpoint_proxyfied_url = pca_public_rest_url + "/services/" + instance_id + "/endpoints/" + endpoint_id + "/"

// Start the spark master docker container
def spark_master_container_name = instance_name + "-spark-master"
cmd = ["docker", "run", "--rm", "-dit", "--publish", spark_master_gui_port + ":" + spark_master_gui_port, "--name", spark_master_container_name, "--net", spark_network_name, "activeeon/hdfs-spark:latest"]
println cmd
def spark_master_container_id = new StringBuilder()
cmd.execute().waitForProcessOutput(spark_master_container_id, System.err)

// Spark master configuration + Start
// core-site.xml
def hdfs_config_command = "sed s/IP:PORT/" + hdfs_namenode_host_port + "/ \$HADOOP_HOME/etc/hadoop/core-site.xml.template > \$HADOOP_HOME/etc/hadoop/core-site.xml"
// spark-env.sh
def create_spark_env_file_command = "touch \$SPARK_HOME/conf/spark-env.sh"
def spark_public_dns_config_command = "echo \"export SPARK_PUBLIC_DNS=" + pa_node_host + "\" >> \$SPARK_HOME/conf/spark-env.sh"
def spark_master_webui_port_config_command = "echo \"export SPARK_MASTER_WEBUI_PORT=" + spark_master_gui_port + "\" >> \$SPARK_HOME/conf/spark-env.sh"
// spark-defaults.conf
def create_spark_defaults_conf_file_command = "touch \$SPARK_HOME/conf/spark-defaults.conf"
def spark_ui_reverse_proxy_command = "echo \"spark.ui.reverseProxy true\" >> \$SPARK_HOME/conf/spark-defaults.conf"
def spark_ui_reverse_proxy_url_command = "echo \"spark.ui.reverseProxyUrl " + spark_master_endpoint_proxyfied_url + "\" >> \$SPARK_HOME/conf/spark-defaults.conf"
// start-master.sh"
def start_master_command = "\$SPARK_HOME/sbin/start-master.sh"
def command_in_container = hdfs_config_command + ";" + create_spark_env_file_command + ";" + spark_public_dns_config_command + ";" + spark_master_webui_port_config_command + ";" + create_spark_defaults_conf_file_command + ";" + spark_ui_reverse_proxy_command + ";" + spark_ui_reverse_proxy_url_command + ";" + start_master_command
cmd = ["docker", "exec", spark_master_container_name, "/bin/sh", "-c", command_in_container]
println cmd
cmd.execute().waitForProcessOutput(System.out, System.err)

// Ensure Master is started
cmd = ["docker", "exec", spark_master_container_name, "jps"]
println cmd
def docker_exec_jps_output = new StringBuilder()
while (!docker_exec_jps_output.toString().contains("Master")){
	cmd.execute().waitForProcessOutput(docker_exec_jps_output, System.err)
	sleep(1000)
}

// Retrieve the spark master url
def spark_master_url = "spark://" + spark_master_container_name + ":7077"

// Propagate variables
variables.put("spark_master_gui_port", spark_master_gui_port)
variables.put("spark_network_name", spark_network_name)
variables.put("spark_master_container_name", spark_master_container_name)
variables.put("spark_master_url", spark_master_url)
variables.put("nb_spark_deployments", (nb_spark_workers + 1))
variables.put("spark_master_and_workers_pa_node_names", pa_node_name)
variables.put("spark_master_endpoint_proxyfied_url", spark_master_endpoint_proxyfied_url)

// To results
resultMap.put("spark_service_instance_id", spark_service_instance_id)
resultMap.put("spark_network_name", spark_network_name)
resultMap.put("spark_master_url", spark_master_url)

// Propagate variables to the current post script
new File(localspace, "spark_master_container_id").text = spark_master_container_id.toString()
new File(localspace, "spark_master_container_name").text = spark_master_container_name
new File(localspace, "endpoint_id").text = endpoint_id
new File(localspace, "spark_master_endpoint_proxyfied_url").text = spark_master_endpoint_proxyfied_url
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow >
        <replicate>
          <script>
            <code language="groovy">
              <![CDATA[
runs = variables.get("nb_spark_workers")
]]>
            </code>
          </script>
        </replicate>
      </controlFlow>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.json.JsonOutput

// Retrieve the script arguments
def spark_master_container_id = new File(localspace, "spark_master_container_id").text
def spark_master_container_name = new File(localspace, "spark_master_container_name").text
def endpoint_id = new File(localspace, "endpoint_id").text
def spark_master_endpoint_proxyfied_url = new File(localspace, "spark_master_endpoint_proxyfied_url").text

// Retrieve variables
def instance_name = variables.get("INSTANCE_NAME")
def pa_node_name = variables.get("PA_NODE_NAME")
def pa_node_host = variables.get("PA_NODE_HOST")
def pa_node_source_name = variables.get("PA_NODE_SOURCE")
def pa_node_url = variables.get("PA_NODE_URL")
def spark_master_gui_port = variables.get("spark_master_gui_port")

// Build the endpoint url
def endpoint_url = "http://" + pa_node_host + ":" + spark_master_gui_port

// Create the deployment map and json
def deployment_map = ["endpoint":["id":endpoint_id,"url":endpoint_url,"proxyfied_url":spark_master_endpoint_proxyfied_url],"node":["name":pa_node_name,"host":pa_node_host,"node_source_name":pa_node_source_name,"url":pa_node_url],"container":["id":spark_master_container_id,"name":spark_master_container_name]]
def deployment_json = JsonOutput.toJson(deployment_map)

// Propagate the deployment map
variables.put("spark_deployment_json_0", deployment_json)
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
          59.55000305175781
        </positionTop>
        <positionLeft>
          473.6000061035156
        </positionLeft>
      </metadata>
    </task>
    <task name="start_spark_worker"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$swarm_token_name"/>
      </genericInformation>
      <depends>
        <task ref="create_overlay_network_or_not_and_start_spark_master"/>
      </depends>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
def task_replication_id = variables.get("PA_TASK_REPLICATION") as Integer
def swarm_manager_and_workers_pa_node_names = variables.get("swarm_manager_and_workers_pa_node_names")

def targeted_pa_node_name = swarm_manager_and_workers_pa_node_names.split(",")[task_replication_id]

selected = (nodename == targeted_pa_node_name)
]]>
          </code>
        </script>
      </selection>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def instance_name = variables.get("INSTANCE_NAME")
def task_replication_id = variables.get("PA_TASK_REPLICATION") as Integer
def spark_network_name = variables.get("spark_network_name")
def spark_master_url = variables.get("spark_master_url")
def pa_node_host = variables.get("PA_NODE_HOST")
def pa_node_name = variables.get("PA_NODE_NAME")
def hdfs_namenode_host_port = variables.get("hdfs_namenode_host_port")
def spark_master_endpoint_proxyfied_url = variables.get("spark_master_endpoint_proxyfied_url")

// Find a free port for spark_master_gui_port
def spark_worker_gui_port = null
try {
  def server = new ServerSocket(0)
  spark_worker_gui_port = server.getLocalPort()
  server.close()
} catch (IOException e) {
  throw new RuntimeException( "Failed to find free local port to bind the agent to", e);
}

// Start the spark worker container
def spark_worker_container_name = instance_name + "-spark-worker-" + task_replication_id
def cmd = ["docker", "run", "--rm", "-dit", "--publish", spark_worker_gui_port + ":" + spark_worker_gui_port, "--name", spark_worker_container_name, "--net", spark_network_name, "activeeon/hdfs-spark:latest"]
println cmd
def spark_worker_container_id = new StringBuilder()
cmd.execute().waitForProcessOutput(spark_worker_container_id, System.err)

// Spark worker configuration + Start
// core-site.xml
def hdfs_config_command = "sed s/IP:PORT/" + hdfs_namenode_host_port + "/ \$HADOOP_HOME/etc/hadoop/core-site.xml.template > \$HADOOP_HOME/etc/hadoop/core-site.xml"
// spark-env.sh
def create_spark_env_file_command = "touch \$SPARK_HOME/conf/spark-env.sh"
def spark_public_dns_config_command = "echo \"export SPARK_PUBLIC_DNS=" + pa_node_host + "\" >> \$SPARK_HOME/conf/spark-env.sh"
def spark_worker_webui_port_config_command = "echo \"export SPARK_WORKER_WEBUI_PORT=" + spark_worker_gui_port + "\" >> \$SPARK_HOME/conf/spark-env.sh"
// spark-defaults.conf
def create_spark_defaults_conf_file_command = "touch \$SPARK_HOME/conf/spark-defaults.conf"
def spark_ui_reverse_proxy_command = "echo \"spark.ui.reverseProxy true\" >> \$SPARK_HOME/conf/spark-defaults.conf"
def spark_ui_reverse_proxy_url_command = "echo \"spark.ui.reverseProxyUrl " + spark_master_endpoint_proxyfied_url + "\" >> \$SPARK_HOME/conf/spark-defaults.conf"
// start-slave.sh
def start_worker_command = "\$SPARK_HOME/sbin/start-slave.sh " + spark_master_url
// docker exec
def command_in_container = hdfs_config_command + ";" + create_spark_env_file_command + ";" + spark_public_dns_config_command + ";" + spark_worker_webui_port_config_command + ";" + create_spark_defaults_conf_file_command + ";" + spark_ui_reverse_proxy_command + ";" + spark_ui_reverse_proxy_url_command + ";" + start_worker_command
cmd = ["docker", "exec", spark_worker_container_name, "/bin/sh", "-c", command_in_container]
println cmd
cmd.execute().waitForProcessOutput(System.out, System.err)

// Propagate variables
variables.put("spark_worker_" + task_replication_id + "_pa_node_name", pa_node_name)

// Propagate variables to the current post script
new File(localspace, "spark_worker_container_id").text = spark_worker_container_id.toString()
new File(localspace, "spark_worker_container_name").text = spark_worker_container_name
]]>
          </code>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.json.JsonOutput

// Retrieve the script arguments
def spark_worker_container_id = new File(localspace, "spark_worker_container_id").text
def spark_worker_container_name = new File(localspace, "spark_worker_container_name").text

// Retrieve variables
def job_id = variables.get("PA_JOB_ID")
def task_replication_id = variables.get("PA_TASK_REPLICATION")
def instance_name = variables.get("INSTANCE_NAME")
def pa_node_name = variables.get("PA_NODE_NAME")
def pa_node_host = variables.get("PA_NODE_HOST")
def pa_node_source_name = variables.get("PA_NODE_SOURCE")
def pa_node_url = variables.get("PA_NODE_URL")

// Create the deployment map and json
def endpoint_id = "spark-" + job_id + "-" + task_replication_id
def deployment_map = ["endpoint":["id":endpoint_id],"node":["name":pa_node_name,"host":pa_node_host,"node_source_name":pa_node_source_name,"url":pa_node_url],"container":["id":spark_worker_container_id,"name":spark_worker_container_name]]
def deployment_json = JsonOutput.toJson(deployment_map)

// Propagate the deployment map (spark_deployment_json_0 is the master deployment)
variables.put("spark_deployment_json_" + ((task_replication_id as Integer) + 1), deployment_json)

// Add token to the current node (RM API)
rmapi.connect()
println "Adding token PSA_" + instance_name + " to node " + pa_node_url
rmapi.addNodeToken(pa_node_url, "PSA_" + instance_name)
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
          187.9499969482422
        </positionTop>
        <positionLeft>
          473.6000061035156
        </positionLeft>
      </metadata>
    </task>
    <task name="merge_json_deployments_and_propagate"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="PSA_$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="start_spark_worker"/>
      </depends>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def nb_spark_workers = variables.get("nb_spark_workers") as Integer
def spark_master_and_workers_pa_node_names = variables.get("spark_master_and_workers_pa_node_names")

for (i = 0; i < nb_spark_workers; i++) {
    spark_master_and_workers_pa_node_names += "," + variables.get("spark_worker_" + i + "_pa_node_name")
}

variables.put("spark_master_and_workers_pa_node_names", spark_master_and_workers_pa_node_names)
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
          316.34999084472656
        </positionTop>
        <positionLeft>
          473.6000061035156
        </positionLeft>
      </metadata>
    </task>
    <task name="propagate_variables_and_update_deployments_with_service"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="PSA_$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="merge_json_deployments_and_propagate"/>
      </depends>
      <pre>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Propagate_variables_to_current_service/raw" language="groovy">
            <arguments>
              <argument value="spark_network_name"/>
              <argument value="VARIABLE_VALUE"/>
              <argument value="spark_master_url"/>
              <argument value="VARIABLE_VALUE"/>
              <argument value="hdfs_namenode_host_port"/>
              <argument value="VARIABLE_VALUE"/>
              <argument value="spark_master_and_workers_pa_node_names"/>
              <argument value="VARIABLE_VALUE"/>
            </arguments>
          </file>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Add_deployments_and_update_service/raw" language="groovy">
            <arguments>
              <argument value="spark_deployment_json_"/>
              <argument value="$nb_spark_deployments"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <cleaning>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Clean_Start_Service/raw" language="groovy"></file>
        </script>
      </cleaning>
      <metadata>
        <positionTop>
          444.75001525878906
        </positionTop>
        <positionLeft>
          473.6000061035156
        </positionLeft>
      </metadata>
    </task>
    <task name="loop_over_spark_master_status"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="PSA_$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="propagate_variables_and_update_deployments_with_service"/>
      </depends>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
def spark_master_and_workers_pa_node_names = variables.get("spark_master_and_workers_pa_node_names")

def spark_master_pa_node_name = spark_master_and_workers_pa_node_names.split(",")[0]

selected = (nodename == spark_master_pa_node_name)
]]>
          </code>
        </script>
      </selection>
      <pre>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def spark_master_container_name = variables.get("spark_master_container_name")
def instance_name = variables.get("INSTANCE_NAME")

// Ensure spark master is running
def cmd = ["docker", "exec", spark_master_container_name, "jps"]
println cmd
def docker_exec_jps_output = new StringBuilder()
cmd.execute().waitForProcessOutput(docker_exec_jps_output, System.err)

def is_spark_master_ok = docker_exec_jps_output.toString().contains("Master")
println "DEBUG is_spark_master_ok " + is_spark_master_ok
def is_docker_based_service = true
def token_to_remove = "PSA_" + instance_name
def main_container_name = spark_master_container_name

// Propagate to the current task script
new File(localspace, "arguments.txt").text = String.valueOf(is_spark_master_ok) + "," + String.valueOf(is_docker_based_service) + "," + token_to_remove + "," + main_container_name
]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Loop_over_service_instance_status/raw" language="groovy"></file>
        </script>
      </scriptExecutable>
      <controlFlow >
        <loop target="loop_over_spark_master_status">
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Fetch_Logs/raw" language="groovy"></file>
          </script>
        </loop>
      </controlFlow>
      <metadata>
        <positionTop>
          573.1499786376953
        </positionTop>
        <positionLeft>
          473.6000061035156
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2248px;
            height:2574px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:73.85000610351562px;left:-468.6000061035156px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_46" style="top: -68.85px; left: 473.6px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task has no description"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">retrieve_services_variables</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_49" style="top: 59.55px; left: 473.6px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task has no description"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">create_overlay_network_or_not_and_start_spark_master</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_52" style="top: 187.95px; left: 473.6px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task has no description"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">start_spark_worker</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_55" style="top: 316.35px; left: 473.6px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task has no description"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">merge_json_deployments_and_propagate</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_58" style="top: 444.75px; left: 473.6px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task has no description"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">propagate_variables_and_update_deployments_with_service</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_61" style="top: 573.15px; left: 473.6px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task has no description"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">loop_over_spark_master_status</span></a>&nbsp;&nbsp;<a id="called-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: 17px; right: 3px;"><i title="Workflows being Called by this Task" id="called-icon"></i></a><a title="Scripts being Called by this Task" id="reference-icon-a" href="javascript:void(0)" class="pointer" style=" position: inherit; top: -7px; right: 3px;"><i id="reference-icon" class="glyphicon glyphicon-list-alt"></i></a></div><svg style="position:absolute;left:544px;top:-29.5px" width="87" height="90" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 66 89 C 76 39 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M61.377312,64.440458 L52.386123662064904,45.25300031869736 L51.58242650470048,54.43744754644299 L42.38311320850788,55.047885813996885 L61.377312,64.440458" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M61.377312,64.440458 L52.386123662064904,45.25300031869736 L51.58242650470048,54.43744754644299 L42.38311320850788,55.047885813996885 L61.377312,64.440458" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:563.5px;top:89.5px" width="155.39999999999998" height="99" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 88 144.39999999999998 -10 134.39999999999998 0 " transform="translate(10.5,10.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#e5db3d" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M18.1875,72.84375 L38.62505803296332,67.24855369877368 L29.71130180781637,64.89378195640585 L30.675089989369162,55.724751890957315 L18.1875,72.84375" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(10.5,10.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M18.1875,72.84375 L38.62505803296332,67.24855369877368 L29.71130180781637,64.89378195640585 L30.675089989369162,55.724751890957315 L18.1875,72.84375" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(10.5,10.5)"></path></svg><div class="_jsPlumb_overlay l1 component label" id="jsPlumb_1_72" style="position: absolute; transform: translate(-50%, -50%); left: 640.7px; top: 139.75px;">replicate</div><svg style="position:absolute;left:526px;top:99.5px" width="105" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 94 50 84 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M7.5250559999999975,62.682047999999995 L27.614426165697402,55.94281908672015 L18.58202529375022,54.09464850789153 L19.027026673588935,44.885849792969935 L7.5250559999999975,62.682047999999995" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M7.5250559999999975,62.682047999999995 L27.614426165697402,55.94281908672015 L18.58202529375022,54.09464850789153 L19.027026673588935,44.885849792969935 L7.5250559999999975,62.682047999999995" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:526px;top:227.5px" width="72" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 51 88 C 61 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M48.576,64.44800000000001 L42.12796115021043,44.26328313323161 L40.14937832765171,53.26801577858403 L30.947976928794457,52.6899048055799 L48.576,64.44800000000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M48.576,64.44800000000001 L42.12796115021043,44.26328313323161 L40.14937832765171,53.26801577858403 L30.947976928794457,52.6899048055799 L48.576,64.44800000000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:577px;top:355.5px" width="63.5" height="90" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 42.5 89 C 52.5 39 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M41.154719375000006,65.80396025 L36.625322877266285,45.104091473451746 L33.8121399552513,53.883954903328274 L24.705317530594552,52.44667089320046 L41.154719375000006,65.80396025" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M41.154719375000006,65.80396025 L36.625322877266285,45.104091473451746 L33.8121399552513,53.883954903328274 L24.705317530594552,52.44667089320046 L41.154719375000006,65.80396025" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:554.5px;top:484.5px" width="86" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 75 50 65 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M4.508909999999998,63.554236 L23.50168446304822,54.158784004710824 L14.302278717405704,53.54974055220558 L13.497189015253797,44.36541528730511 L4.508909999999998,63.554236" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M4.508909999999998,63.554236 L23.50168446304822,54.158784004710824 L14.302278717405704,53.54974055220558 L13.497189015253797,44.36541528730511 L4.508909999999998,63.554236" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:645.5px;top:562.5px" width="61" height="61" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 40 C 50 -10 -10 50 0 0 " transform="translate(10.5,10.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#316b31" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M13.55903999999999,26.37184000000001 L31.950657715430147,15.848133532719785 L22.731266562420885,15.794966176056539 L21.37378389148668,6.67590697029889 L13.55903999999999,26.37184000000001" class="" stroke="#316b31" fill="#316b31" transform="translate(10.5,10.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M13.55903999999999,26.37184000000001 L31.950657715430147,15.848133532719785 L22.731266562420885,15.794966176056539 L21.37378389148668,6.67590697029889 L13.55903999999999,26.37184000000001" class="" stroke="#316b31" fill="#316b31" transform="translate(10.5,10.5)"></path></svg><div class="_jsPlumb_overlay l1 component label" id="jsPlumb_1_90" style="position: absolute; transform: translate(-50%, -50%); left: 670.5px; top: 592.5px;">loop</div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 544.5px; top: -39px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 610.5px; top: 90px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 610.5px; top: 50px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint replicate-source-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 698.4px; top: 90px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 526.5px; top: 218px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint replicate-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 564px; top: 178px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 526.5px; top: 178px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 577.5px; top: 346px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 577.5px; top: 306px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 620px; top: 475px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 620px; top: 435px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 555px; top: 603px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 555px; top: 563px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint loop-source-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 646px; top: 563px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#316b31" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint loop-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 646px; top: 603px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#316b31" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>