<?xml version="1.0" encoding="UTF-8"?>
<job
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xmlns="urn:proactive:jobdescriptor:3.12" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd"  name="Spark" projectName="Service Automation - Deployment" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="1"  >
<variables>
  <variable model="PA:NOT_EMPTY_STRING" name="INSTANCE_NAME" value="spark-$PA_JOB_ID" />
  <variable model="PA:NOT_EMPTY_STRING" name="swarm_service_instance_id" value="xx" />
  <variable name="hdfs_service_instance_id" value="" />
  <variable model="PA:NOT_EMPTY_STRING" name="nb_spark_workers" value="3" />
  </variables>
  <description>
    <![CDATA[ Deploy a Spark platform of nb_spark_workers spark workers. swarm_service_instance_id is the service instance id of the targeted Docker Swarm. hdfs_service_instance_id is the service instance id of the targeted HDFS platform (optional). ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="service-automation"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
    <info name="pca.states" value="(VOID,RUNNING)"/>
    <info name="Documentation" value="http://spark.apache.org/docs/latest/spark-standalone.html"/>
    <info name="pca.service.id" value="Spark"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>

    <task name="retrieve_services_variables"
          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Retrieve_variables_from_service_instance_id/raw" language="groovy">
            <arguments>
              <argument value="$swarm_service_instance_id"/>
              <argument value="swarm_token_name"/>
              <argument value="INSTANCE_NAME"/>
              <argument value="swarm_manager_and_workers_pa_node_names"/>
              <argument value="swarm_manager_and_workers_pa_node_names"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Retrieve_variables_from_service_instance_id/raw" language="groovy">
            <arguments>
              <argument value="$hdfs_service_instance_id"/>
              <argument value="hdfs_network_name"/>
              <argument value="hdfs_network_name"/>
              <argument value="hdfs_namenode_host_port"/>
              <argument value="hdfs_namenode_host_port"/>
            </arguments>
          </file>
        </script>
      </post>
    </task>
    <task name="create_overlay_network_or_not_and_start_spark_master" fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$swarm_token_name"/>
      </genericInformation>
      <depends>
        <task ref="retrieve_services_variables"/>
      </depends>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
// The overlay network must be created on the swarm manager host
def swarm_manager_pa_node_name = variables.get("swarm_manager_and_workers_pa_node_names").split(",")[0]

selected = (nodename == swarm_manager_pa_node_name)
]]>
          </code>
        </script>
      </selection>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def spark_service_instance_id = variables.get("PCA_INSTANCE_ID")
def instance_name = variables.get("INSTANCE_NAME")
def instance_id = variables.get("PCA_INSTANCE_ID")
def job_id = variables.get("PA_JOB_ID")
def pa_node_name = variables.get("PA_NODE_NAME")
def pa_node_host = variables.get("PA_NODE_HOST")
def hdfs_network_name = variables.get("hdfs_network_name")
def hdfs_namenode_host_port = variables.get("hdfs_namenode_host_port")
def nb_spark_workers = variables.get("nb_spark_workers") as Integer
def pca_public_rest_url = variables.get('PA_CLOUD_AUTOMATION_REST_PUBLIC_URL')

// If hdfs wkw param is not set, create a spark overlay network rather than using the hdfs one
def spark_network_name = hdfs_network_name

if (hdfs_network_name == null) {
  spark_network_name = instance_name + "-spark-network"
  def cmd = ["docker", "network", "create", "-d", "overlay", "--attachable", spark_network_name]
  println cmd
  cmd.execute().waitForProcessOutput(System.out, System.err)
}

// Find a free port for spark_master_gui_port
def spark_master_gui_port = null
try {
  def server = new ServerSocket(0)
  spark_master_gui_port = server.getLocalPort()
  server.close()
} catch (IOException e) {
  throw new RuntimeException( "Failed to find free local port to bind the agent to", e);
}

// Build the proxified url
def endpoint_id = "spark-gui-" + job_id
def spark_master_endpoint_proxyfied_url = pca_public_rest_url + "/services/" + instance_id + "/endpoints/" + endpoint_id + "/"

// Start the spark master docker container
def spark_master_container_name = instance_name + "-spark-master"
cmd = ["docker", "run", "--rm", "-dit", "--publish", spark_master_gui_port + ":" + spark_master_gui_port, "--name", spark_master_container_name, "--net", spark_network_name, "activeeon/hdfs-spark:latest"]
println cmd
def spark_master_container_id = new StringBuilder()
cmd.execute().waitForProcessOutput(spark_master_container_id, System.err)

// Spark master configuration + Start
// core-site.xml
def hdfs_config_command = "sed s/IP:PORT/" + hdfs_namenode_host_port + "/ \$HADOOP_HOME/etc/hadoop/core-site.xml.template > \$HADOOP_HOME/etc/hadoop/core-site.xml"
// spark-env.sh
def create_spark_env_file_command = "touch \$SPARK_HOME/conf/spark-env.sh"
def spark_public_dns_config_command = "echo \"export SPARK_PUBLIC_DNS=" + pa_node_host + "\" >> \$SPARK_HOME/conf/spark-env.sh"
def spark_master_webui_port_config_command = "echo \"export SPARK_MASTER_WEBUI_PORT=" + spark_master_gui_port + "\" >> \$SPARK_HOME/conf/spark-env.sh"
// spark-defaults.conf
def create_spark_defaults_conf_file_command = "touch \$SPARK_HOME/conf/spark-defaults.conf"
def spark_ui_reverse_proxy_command = "echo \"spark.ui.reverseProxy true\" >> \$SPARK_HOME/conf/spark-defaults.conf"
def spark_ui_reverse_proxy_url_command = "echo \"spark.ui.reverseProxyUrl " + spark_master_endpoint_proxyfied_url + "\" >> \$SPARK_HOME/conf/spark-defaults.conf"
// start-master.sh"
def start_master_command = "\$SPARK_HOME/sbin/start-master.sh"
def command_in_container = hdfs_config_command + ";" + create_spark_env_file_command + ";" + spark_public_dns_config_command + ";" + spark_master_webui_port_config_command + ";" + create_spark_defaults_conf_file_command + ";" + spark_ui_reverse_proxy_command + ";" + spark_ui_reverse_proxy_url_command + ";" + start_master_command
cmd = ["docker", "exec", spark_master_container_name, "/bin/sh", "-c", command_in_container]
println cmd
cmd.execute().waitForProcessOutput(System.out, System.err)

// Ensure Master is started
cmd = ["docker", "exec", spark_master_container_name, "jps"]
println cmd
def docker_exec_jps_output = new StringBuilder()
while (!docker_exec_jps_output.toString().contains("Master")){
	cmd.execute().waitForProcessOutput(docker_exec_jps_output, System.err)
	sleep(1000)
}

// Retrieve the spark master url
def spark_master_url = "spark://" + spark_master_container_name + ":7077"

// Propagate variables
variables.put("spark_master_gui_port", spark_master_gui_port)
variables.put("spark_network_name", spark_network_name)
variables.put("spark_master_container_name", spark_master_container_name)
variables.put("spark_master_url", spark_master_url)
variables.put("nb_spark_deployments", (nb_spark_workers + 1))
variables.put("spark_master_and_workers_pa_node_names", pa_node_name)
variables.put("spark_master_endpoint_proxyfied_url", spark_master_endpoint_proxyfied_url)

// To results
resultMap.put("spark_service_instance_id", spark_service_instance_id)
resultMap.put("spark_network_name", spark_network_name)
resultMap.put("spark_master_url", spark_master_url)

// Propagate variables to the current post script
new File(localspace, "spark_master_container_id").text = spark_master_container_id.toString()
new File(localspace, "spark_master_container_name").text = spark_master_container_name
new File(localspace, "endpoint_id").text = endpoint_id
new File(localspace, "spark_master_endpoint_proxyfied_url").text = spark_master_endpoint_proxyfied_url
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow >
        <replicate>
          <script>
            <code language="groovy">
              <![CDATA[
runs = variables.get("nb_spark_workers")
]]>
            </code>
          </script>
        </replicate>
      </controlFlow>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.json.JsonOutput

// Retrieve the script arguments
def spark_master_container_id = new File(localspace, "spark_master_container_id").text
def spark_master_container_name = new File(localspace, "spark_master_container_name").text
def endpoint_id = new File(localspace, "endpoint_id").text
def spark_master_endpoint_proxyfied_url = new File(localspace, "spark_master_endpoint_proxyfied_url").text

// Retrieve variables
def instance_name = variables.get("INSTANCE_NAME")
def pa_node_name = variables.get("PA_NODE_NAME")
def pa_node_host = variables.get("PA_NODE_HOST")
def pa_node_source_name = variables.get("PA_NODE_SOURCE")
def pa_node_url = variables.get("PA_NODE_URL")
def spark_master_gui_port = variables.get("spark_master_gui_port")

// Build the endpoint url
def endpoint_url = "http://" + pa_node_host + ":" + spark_master_gui_port

// Create the deployment map and json
def deployment_map = ["endpoint":["id":endpoint_id,"url":endpoint_url,"proxyfied_url":spark_master_endpoint_proxyfied_url],"node":["name":pa_node_name,"host":pa_node_host,"node_source_name":pa_node_source_name,"url":pa_node_url],"container":["id":spark_master_container_id,"name":spark_master_container_name]]
def deployment_json = JsonOutput.toJson(deployment_map)

// Propagate the deployment map
variables.put("spark_deployment_json_0", deployment_json)
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
            418.5
        </positionTop>
        <positionLeft>
            643
        </positionLeft>
      </metadata>
    </task>
    <task name="start_spark_worker" >
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$swarm_token_name"/>
      </genericInformation>
      <depends>
        <task ref="create_overlay_network_or_not_and_start_spark_master"/>
      </depends>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
def task_replication_id = variables.get("PA_TASK_REPLICATION") as Integer
def swarm_manager_and_workers_pa_node_names = variables.get("swarm_manager_and_workers_pa_node_names")

def targeted_pa_node_name = swarm_manager_and_workers_pa_node_names.split(",")[task_replication_id]

selected = (nodename == targeted_pa_node_name)
]]>
          </code>
        </script>
      </selection>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def instance_name = variables.get("INSTANCE_NAME")
def task_replication_id = variables.get("PA_TASK_REPLICATION") as Integer
def spark_network_name = variables.get("spark_network_name")
def spark_master_url = variables.get("spark_master_url")
def pa_node_host = variables.get("PA_NODE_HOST")
def pa_node_name = variables.get("PA_NODE_NAME")
def hdfs_namenode_host_port = variables.get("hdfs_namenode_host_port")
def spark_master_endpoint_proxyfied_url = variables.get("spark_master_endpoint_proxyfied_url")

// Find a free port for spark_master_gui_port
def spark_worker_gui_port = null
try {
  def server = new ServerSocket(0)
  spark_worker_gui_port = server.getLocalPort()
  server.close()
} catch (IOException e) {
  throw new RuntimeException( "Failed to find free local port to bind the agent to", e);
}

// Start the spark worker container
def spark_worker_container_name = instance_name + "-spark-worker-" + task_replication_id
def cmd = ["docker", "run", "--rm", "-dit", "--publish", spark_worker_gui_port + ":" + spark_worker_gui_port, "--name", spark_worker_container_name, "--net", spark_network_name, "activeeon/hdfs-spark:latest"]
println cmd
def spark_worker_container_id = new StringBuilder()
cmd.execute().waitForProcessOutput(spark_worker_container_id, System.err)

// Spark worker configuration + Start
// core-site.xml
def hdfs_config_command = "sed s/IP:PORT/" + hdfs_namenode_host_port + "/ \$HADOOP_HOME/etc/hadoop/core-site.xml.template > \$HADOOP_HOME/etc/hadoop/core-site.xml"
// spark-env.sh
def create_spark_env_file_command = "touch \$SPARK_HOME/conf/spark-env.sh"
def spark_public_dns_config_command = "echo \"export SPARK_PUBLIC_DNS=" + pa_node_host + "\" >> \$SPARK_HOME/conf/spark-env.sh"
def spark_worker_webui_port_config_command = "echo \"export SPARK_WORKER_WEBUI_PORT=" + spark_worker_gui_port + "\" >> \$SPARK_HOME/conf/spark-env.sh"
// spark-defaults.conf
def create_spark_defaults_conf_file_command = "touch \$SPARK_HOME/conf/spark-defaults.conf"
def spark_ui_reverse_proxy_command = "echo \"spark.ui.reverseProxy true\" >> \$SPARK_HOME/conf/spark-defaults.conf"
def spark_ui_reverse_proxy_url_command = "echo \"spark.ui.reverseProxyUrl " + spark_master_endpoint_proxyfied_url + "\" >> \$SPARK_HOME/conf/spark-defaults.conf"
// start-slave.sh
def start_worker_command = "\$SPARK_HOME/sbin/start-slave.sh " + spark_master_url
// docker exec
def command_in_container = hdfs_config_command + ";" + create_spark_env_file_command + ";" + spark_public_dns_config_command + ";" + spark_worker_webui_port_config_command + ";" + create_spark_defaults_conf_file_command + ";" + spark_ui_reverse_proxy_command + ";" + spark_ui_reverse_proxy_url_command + ";" + start_worker_command
cmd = ["docker", "exec", spark_worker_container_name, "/bin/sh", "-c", command_in_container]
println cmd
cmd.execute().waitForProcessOutput(System.out, System.err)

// Propagate variables
variables.put("spark_worker_" + task_replication_id + "_pa_node_name", pa_node_name)

// Propagate variables to the current post script
new File(localspace, "spark_worker_container_id").text = spark_worker_container_id.toString()
new File(localspace, "spark_worker_container_name").text = spark_worker_container_name
]]>
          </code>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.json.JsonOutput

// Retrieve the script arguments
def spark_worker_container_id = new File(localspace, "spark_worker_container_id").text
def spark_worker_container_name = new File(localspace, "spark_worker_container_name").text

// Retrieve variables
def job_id = variables.get("PA_JOB_ID")
def task_replication_id = variables.get("PA_TASK_REPLICATION")
def instance_name = variables.get("INSTANCE_NAME")
def pa_node_name = variables.get("PA_NODE_NAME")
def pa_node_host = variables.get("PA_NODE_HOST")
def pa_node_source_name = variables.get("PA_NODE_SOURCE")
def pa_node_url = variables.get("PA_NODE_URL")

// Create the deployment map and json
def endpoint_id = "spark-" + job_id + "-" + task_replication_id
def deployment_map = ["endpoint":["id":endpoint_id],"node":["name":pa_node_name,"host":pa_node_host,"node_source_name":pa_node_source_name,"url":pa_node_url],"container":["id":spark_worker_container_id,"name":spark_worker_container_name]]
def deployment_json = JsonOutput.toJson(deployment_map)

// Propagate the deployment map (spark_deployment_json_0 is the master deployment)
variables.put("spark_deployment_json_" + ((task_replication_id as Integer) + 1), deployment_json)

// Add token to the current node (RM API)
rmapi.connect()
println "Adding token " + instance_name + " to node " + pa_node_url
rmapi.addNodeToken(pa_node_url, instance_name)
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
            546.5
        </positionTop>
        <positionLeft>
            643
        </positionLeft>
      </metadata>
    </task>

    <task name="merge_json_deployments_and_propagate"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="start_spark_worker"/>
      </depends>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def nb_spark_workers = variables.get("nb_spark_workers") as Integer
def spark_master_and_workers_pa_node_names = variables.get("spark_master_and_workers_pa_node_names")

for (i = 0; i < nb_spark_workers; i++) {
    spark_master_and_workers_pa_node_names += "," + variables.get("spark_worker_" + i + "_pa_node_name")
}

variables.put("spark_master_and_workers_pa_node_names", spark_master_and_workers_pa_node_names)
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
          542.5
        </positionTop>
        <positionLeft>
          668
        </positionLeft>
      </metadata>
    </task>

    <task name="propagate_variables_and_update_deployments_with_service"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="merge_json_deployments_and_propagate"/>
      </depends>
      <pre>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Propagate_variables_to_current_service/raw" language="groovy">
            <arguments>
              <argument value="spark_network_name"/>
              <argument value="VARIABLE_VALUE"/>
              <argument value="spark_master_url"/>
              <argument value="VARIABLE_VALUE"/>
              <argument value="hdfs_namenode_host_port"/>
              <argument value="VARIABLE_VALUE"/>
              <argument value="spark_master_and_workers_pa_node_names"/>
              <argument value="VARIABLE_VALUE"/>
            </arguments>
          </file>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Add_deployments_and_update_service/raw" language="groovy">
            <arguments>
              <argument value="spark_deployment_json_"/>
              <argument value="$nb_spark_deployments"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <cleaning>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Clean_Start_Service/raw" language="groovy"></file>
        </script>
      </cleaning>
    </task>

    <task name="loop_over_spark_master_status"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="propagate_variables_and_update_deployments_with_service"/>
      </depends>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
def spark_master_and_workers_pa_node_names = variables.get("spark_master_and_workers_pa_node_names")

def spark_master_pa_node_name = spark_master_and_workers_pa_node_names.split(",")[0]

selected = (nodename == spark_master_pa_node_name)
]]>
          </code>
        </script>
      </selection>
      <pre>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def spark_master_container_name = variables.get("spark_master_container_name")
def instance_name = variables.get("INSTANCE_NAME")

// Ensure spark master is running
def cmd = ["docker", "exec", spark_master_container_name, "jps"]
println cmd
def docker_exec_jps_output = new StringBuilder()
cmd.execute().waitForProcessOutput(docker_exec_jps_output, System.err)

def is_spark_master_ok = docker_exec_jps_output.toString().contains("Master")
println "DEBUG is_spark_master_ok " + is_spark_master_ok
def is_docker_based_service = true
def token_to_remove = instance_name

// Propagate to the current task script
new File(localspace, "arguments.txt").text = String.valueOf(is_spark_master_ok) + "," + String.valueOf(is_docker_based_service) + "," + token_to_remove
]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Loop_over_service_instance_status/raw" language="groovy"></file>
        </script>
      </scriptExecutable>
      <controlFlow >
        <loop target="loop_over_spark_master_status">
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Fetch_Logs/raw" language="groovy"></file>
          </script>
        </loop>
      </controlFlow>
      <metadata>
        <positionTop>
          798.5
        </positionTop>
        <positionLeft>
          668
        </positionLeft>
      </metadata>
    </task>


  </taskFlow>
</job>