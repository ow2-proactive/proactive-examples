<?xml version="1.0" encoding="UTF-8"?>
<job
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xmlns="urn:proactive:jobdescriptor:3.12" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd"  name="Spark" projectName="Service Automation - Deployment" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="1"  >
<variables>
  <variable name="INSTANCE_NAME" value="spark-$PA_JOB_ID" />
  <variable name="spark_gui_start_port" value="5500" />
  <variable name="swarm_service_instance_id" value="" />
  <variable name="hdfs_service_instance_id" value="" />
  <variable name="nb_spark_worker" value="3" />
  </variables>
  <description>
    <![CDATA[ Deployment of a Spark platform with nb_spark_worker spark workers. spark_gui_start_port is the Spark master web portal port. Other worker web portals ports will increment it. swarm_service_instance_id is the service instance id of the targeted Docker Swarm. hdfs_service_instance_id is the service instance id of the targeted HDFS (optional). ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="service-automation"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
    <info name="pca.states" value="(VOID,RUNNING)"/>
    <info name="Documentation" value="http://spark.apache.org/docs/latest/spark-standalone.html"/>
    <info name="pca.service.id" value="Spark"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>

    <task name="retrieve_services_variables"
          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Retrieve_variables_from_service_instance_id/raw" language="groovy">
            <arguments>
              <argument value="$swarm_service_instance_id"/>
              <argument value="swarm_token_name"/>
              <argument value="INSTANCE_NAME"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Retrieve_variables_from_service_instance_id/raw" language="groovy">
            <arguments>
              <argument value="$hdfs_service_instance_id"/>
              <argument value="hdfs_token_name"/>
              <argument value="INSTANCE_NAME"/>
              <argument value="hdfs_network_name"/>
              <argument value="hdfs_network_name"/>
              <argument value="hdfs_namenode_host_port"/>
              <argument value="hdfs_namenode_host_port"/>
            </arguments>
          </file>
        </script>
      </post>
    </task>

    <task name="propagate_variables"
          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
      </genericInformation>
      <depends>
        <task ref="retrieve_services_variables"/>
      </depends>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// EITHER target the HDFS platform (optional wkw param) by relying on its token and its docker network
// OR spark relies on the swarm token and creates its own docker network
def swarm_service_instance_id = variables.get("swarm_service_instance_id")
def hdfs_service_instance_id = variables.get("hdfs_service_instance_id")
def instance_name = variables.get("INSTANCE_NAME")

def targeted_token_name = null
def targeted_network_name = null

if (!swarm_service_instance_id.isEmpty()) {
    targeted_token_name = variables.get("swarm_token_name")
    targeted_network_name = instance_name + "-spark-network"
} else if (!hdfs_service_instance_id.isEmpty()) {
    targeted_token_name = variables.get("hdfs_token_name")
    targeted_network_name = variables.get("hdfs_network_name")
} else {
    println ("Either specify swarm_service_instance_id or hdfs_service_instance_id")
    System.exit(1)
}

println "targeted_token_name " + targeted_token_name
println "targeted_network_name " + targeted_network_name

// Propagate variables
variables.put("targeted_token_name", targeted_token_name)
variables.put("targeted_network_name", targeted_network_name)
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>




    <task name="create_overlay_network_or_not_and_start_spark_master" >
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$targeted_token_name"/>
      </genericInformation>
      <depends>
        <task ref="propagate_variables"/>
      </depends>
      <selection>
        <script type="static">
          <code language="groovy">
            <![CDATA[
// The overlay network must be created on the swarm manager host
def cmd = ["docker", "node", "ls"]
println cmd
def docker_node_ls_output = new StringBuilder()
cmd.execute().waitForProcessOutput(docker_node_ls_output, System.err)

selected = docker_node_ls_output.toString().contains("HOSTNAME")
]]>
          </code>
        </script>
      </selection>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def instance_name = variables.get("INSTANCE_NAME")
def spark_gui_start_port = variables.get("spark_gui_start_port")
def job_id = variables.get("PA_JOB_ID")
def hdfs_namenode_host_port = variables.get("hdfs_namenode_host_port")
def spark_master_node_name = variables.get("PA_NODE_NAME")
def spark_master_host = variables.get("PA_NODE_HOST")
def targeted_network_name = variables.get("targeted_network_name")

// Create the overlay network if no hdfs. Otherwise use the hdfs docker network
if (targeted_network_name.contains("spark")) {
  def cmd = ["docker", "network", "create", "-d", "overlay", "--attachable", targeted_network_name]
  println cmd
  cmd.execute().waitForProcessOutput(System.out, System.err)
}

// Start the spark master docker container
def spark_master_container_name = instance_name + "-spark-master"
cmd = ["docker", "run", "--rm", "-dit", "--publish", spark_gui_start_port + ":" + spark_gui_start_port, "--name", spark_master_container_name, "--net", targeted_network_name, "activeeon/hdfs-spark:latest"]
println cmd
cmd.execute().waitForProcessOutput(System.out, System.err)

// Spark master configuration + Start
def hdfs_config_command = "sed s/IP:PORT/" + hdfs_namenode_host_port + "/ \$HADOOP_HOME/etc/hadoop/core-site.xml.template > \$HADOOP_HOME/etc/hadoop/core-site.xml"
def spark_create_spark_env_file_config_command = "touch \$SPARK_HOME/conf/spark-env.sh"
def spark_public_dns_config_command = "echo \"export SPARK_PUBLIC_DNS=" + spark_master_host + "\" >> \$SPARK_HOME/conf/spark-env.sh"
def spark_master_webui_port_config_command = "echo \"export SPARK_MASTER_WEBUI_PORT=" + spark_gui_start_port + "\" >> \$SPARK_HOME/conf/spark-env.sh"
def start_master_command = "\$SPARK_HOME/sbin/start-master.sh"
def command_in_container = hdfs_config_command + ";" + spark_create_spark_env_file_config_command + ";" + spark_public_dns_config_command + ";" + spark_master_webui_port_config_command + ";" + start_master_command
cmd = ["docker", "exec", spark_master_container_name, "/bin/sh", "-c", command_in_container]
println cmd
cmd.execute().waitForProcessOutput(System.out, System.err)

// Ensure Master is started
cmd = ["docker", "exec", spark_master_container_name, "jps"]
println cmd
def docker_exec_jps_output = new StringBuilder()
while (!docker_exec_jps_output.toString().contains("Master")){
	cmd.execute().waitForProcessOutput(docker_exec_jps_output, System.err)
	sleep(1000)
}

// Propagate variables
variables.put("spark_master_node_name", spark_master_node_name)
variables.put("spark_master_url", "spark://" + spark_master_container_name + ":7077")

// Propagate variables to the current post script
def spark_master_endpoint_url = "http://" + spark_master_host + ":" + spark_gui_start_port
new File(localspace, "arguments.txt").text = "spark_master_gui," + spark_master_endpoint_url + ", , , , , , "
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow >
        <replicate>
          <script>
            <code language="groovy">
              <![CDATA[
runs = variables.get("nb_spark_worker")
]]>
            </code>
          </script>
        </replicate>
      </controlFlow>
      <post>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Update_service_instance_and_add_token/raw" language="groovy"></file>
        </script>
      </post>
      <metadata>
        <positionTop>
          334.6333312988281
        </positionTop>
        <positionLeft>
          596
        </positionLeft>
      </metadata>
    </task>
    <task name="start_spark_slave" >
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$targeted_token_name"/>
      </genericInformation>
      <depends>
        <task ref="create_overlay_network_or_not_and_start_spark_master"/>
      </depends>
      <selection>
        <script type="static">
          <code language="groovy">
            <![CDATA[
// The 1st replicated task must run on the spark master node
def task_replication_id = variables.get("PA_TASK_REPLICATION") as Integer

selected = (task_replication_id == 0 && nodename.equals(variables.get("spark_master_node_name")) ||  task_replication_id > 0)
]]>
          </code>
        </script>
      </selection>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def instance_name = variables.get("INSTANCE_NAME")
def task_replication_id = variables.get("PA_TASK_REPLICATION") as Integer
def targeted_network_name = variables.get("targeted_network_name")
def hdfs_namenode_host_port = variables.get("hdfs_namenode_host_port")
def spark_master_url = variables.get("spark_master_url")
def spark_gui_start_port = variables.get("spark_gui_start_port") as Integer
def spark_slave_host = variables.get("PA_NODE_HOST")

// Start the spark slave container
def spark_slave_gui_port = spark_gui_start_port + 1 + task_replication_id
def spark_slave_container_name = instance_name + "-spark-slave-" + task_replication_id
def cmd = ["docker", "run", "--rm", "-dit", "--publish", spark_slave_gui_port + ":" + spark_slave_gui_port, "--name", spark_slave_container_name, "--net", targeted_network_name, "activeeon/hdfs-spark:latest"]
println cmd
cmd.execute().waitForProcessOutput(System.out, System.err)

// Spark slave configuration + Start
def hdfs_config_command = "sed s/IP:PORT/" + hdfs_namenode_host_port + "/ \$HADOOP_HOME/etc/hadoop/core-site.xml.template > \$HADOOP_HOME/etc/hadoop/core-site.xml"
def spark_create_spark_env_file_config_command = "touch \$SPARK_HOME/conf/spark-env.sh"
def spark_public_dns_config_command = "echo \"export SPARK_PUBLIC_DNS=" + spark_slave_host + "\" >> \$SPARK_HOME/conf/spark-env.sh"
def worker_webui_port_config_command = "echo \"export SPARK_WORKER_WEBUI_PORT=" + spark_slave_gui_port + "\" >> \$SPARK_HOME/conf/spark-env.sh"
def start_slave_command = "\$SPARK_HOME/sbin/start-slave.sh " + spark_master_url
def command_in_container = hdfs_config_command + ";" + spark_create_spark_env_file_config_command + ";" + spark_public_dns_config_command + ";" + worker_webui_port_config_command + ";" + start_slave_command
cmd = ["docker", "exec", spark_slave_container_name, "/bin/sh", "-c", command_in_container]
println cmd
cmd.execute().waitForProcessOutput(System.out, System.err)

// Propagate variables to the current post script
def spark_slave_endpoint_name = "spark_slave_" + task_replication_id + "_gui_url"
def spark_slave_endpoint_url = "http://" + spark_slave_host + ":" + spark_slave_gui_port
new File(localspace, "arguments.txt").text = spark_slave_endpoint_name + "," + spark_slave_endpoint_url + ", , , , , ," + instance_name
]]>
          </code>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Update_service_instance_and_add_token/raw" language="groovy"></file>
        </script>
      </post>
      <metadata>
        <positionTop>
          462.6333312988281
        </positionTop>
        <positionLeft>
          596
        </positionLeft>
      </metadata>
    </task>
    <task name="end_of_spark_deployment"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$targeted_token_name"/>
      </genericInformation>
      <depends>
        <task ref="start_spark_slave"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Update_service_instance_and_add_token/raw" language="groovy">
            <arguments>
              <argument value=""/>
              <argument value=""/>
              <argument value=""/>
              <argument value=""/>
              <argument value=""/>
              <argument value="RUNNING"/>
              <argument value="true"/>
              <argument value=""/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Propagate_variables_to_current_service/raw" language="groovy">
            <arguments>
              <argument value="targeted_network_name"/>
              <argument value="$targeted_network_name"/>
              <argument value="spark_master_url"/>
              <argument value="$spark_master_url"/>
              <argument value="spark_master_node_name"/>
              <argument value="$spark_master_node_name"/>
              <argument value="hdfs_namenode_host_port"/>
              <argument value="$hdfs_namenode_host_port"/>
            </arguments>
          </file>
        </script>
      </post>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2735px;
            height:2924px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-201.63333129882812px;left:-591px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" style="top: 206.633px; left: 596px;" id="jsPlumb_1_10"><a class="task-name"><img src="/studio/images/Groovy.png" width="20px">&nbsp;<span class="name">get_resources_from_service_instance</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 334.633px; left: 596px;" id="jsPlumb_1_13"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">start_spark_master</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 462.633px; left: 596px;" id="jsPlumb_1_16"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">start_spark_slave</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 590.633px; left: 596px;" id="jsPlumb_1_19"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">update_service_instance</span></a></div><svg style="position:absolute;left:651.5px;top:246.5px" width="67" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 56 50 46 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M1.6926389999999976,64.9032055 L18.66180608105043,52.21276151346453 L9.504895730542636,53.285604853735244 L7.044205434785677,44.400504782921885 L1.6926389999999976,64.9032055" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M1.6926389999999976,64.9032055 L18.66180608105043,52.21276151346453 L9.504895730542636,53.285604853735244 L7.044205434785677,44.400504782921885 L1.6926389999999976,64.9032055" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:683.9px;top:364.5px" width="28.200000000000045" height="99" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 88 17.200000000000045 -10 7.2000000000000455 0 " transform="translate(10.5,10.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#e5db3d" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.1009752999999947,77.41936575 L7.046180412470953,58.30577000320734 L-0.568522702436107,63.50349031809778 L-6.869695019431264,56.77331740564345 L-2.1009752999999947,77.41936575" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(10.5,10.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.1009752999999947,77.41936575 L7.046180412470953,58.30577000320734 L-0.568522702436107,63.50349031809778 L-6.869695019431264,56.77331740564345 L-2.1009752999999947,77.41936575" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(10.5,10.5)"></path></svg><div style="position: absolute; transform: translate(-50%, -50%); left: 697.5px; top: 414.75px;" class="_jsPlumb_overlay l1 component label" id="jsPlumb_1_30">replicate</div><svg style="position:absolute;left:647px;top:374.5px" width="25.5" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 14.5 50 4.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.4501093750000003,66.78168750000002 L6.253690937044999,47.46216731630898 L-1.2390824053543916,52.834163932040326 L-7.69383263091469,46.25114034666338 L-2.4501093750000003,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.4501093750000003,66.78168750000002 L6.253690937044999,47.46216731630898 L-1.2390824053543916,52.834163932040326 L-7.69383263091469,46.25114034666338 L-2.4501093750000003,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:647px;top:502.5px" width="38.5" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 17.5 88 C 27.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M18.83704,66.303232 L20.538982678279996,45.182072204196906 L15.288421492048318,52.76043662072092 L6.996187299000918,48.73069071214858 L18.83704,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M18.83704,66.303232 L20.538982678279996,45.182072204196906 L15.288421492048318,52.76043662072092 L6.996187299000918,48.73069071214858 L18.83704,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div style="position: absolute; height: 20px; width: 20px; left: 698px; top: 237px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 652px; top: 365px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 652px; top: 325px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 691.6px; top: 365px;" class="_jsPlumb_endpoint source-endpoint replicate-source-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 647.5px; top: 493px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 684.4px; top: 453px;" class="_jsPlumb_endpoint target-endpoint replicate-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 647.5px; top: 453px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 665px; top: 621px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 665px; top: 581px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>