<?xml version="1.0" encoding="UTF-8"?>
<job
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xmlns="urn:proactive:jobdescriptor:3.12" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd"  name="Finish_Spark" projectName="Service Automation - Lifecycle" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="1"  >
  <description>
    <![CDATA[ Delete a Spark installation. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="service-automation"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
    <info name="pca.states" value="(RUNNING,FINISHED)(ERROR,FINISHED)"/>
    <info name="Documentation" value="http://spark.apache.org/docs/latest/spark-standalone.html"/>
    <info name="pca.service.id" value="Spark"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
    <taskFlow>
        <task name="retrieve_service_variables"




              fork="true">
            <genericInformation>
                <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
                <info name="NODE_ACCESS_TOKEN" value="$INSTANCE_NAME"/>
            </genericInformation>
            <scriptExecutable>
                <script>
                    <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Retrieve_variables_from_service_instance_id/raw" language="groovy">
                        <arguments>
                            <argument value="$PCA_INSTANCE_ID"/>
                            <argument value="spark_master_node_name"/>
                            <argument value="spark_master_node_name"/>
                            <argument value="targeted_network_name"/>
                            <argument value="targeted_network_name"/>
                        </arguments>
                    </file>
                </script>
            </scriptExecutable>
            <controlFlow >
                <replicate>
                    <script>
                        <code language="groovy">
                            <![CDATA[
runs = variables.get("nb_spark_worker")
]]>
                        </code>
                    </script>
                </replicate>
            </controlFlow>
            <metadata>
                <positionTop>
                    354.5
                </positionTop>
                <positionLeft>
                    605.5
                </positionLeft>
            </metadata>
        </task>
        <task name="docker_rm_spark_containers"




              fork="true">
            <genericInformation>
                <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
                <info name="NODE_ACCESS_TOKEN" value="$INSTANCE_NAME"/>
            </genericInformation>
            <depends>
                <task ref="retrieve_service_variables"/>
            </depends>
            <scriptExecutable>
                <script>
                    <code language="groovy">
                        <![CDATA[
// Retrieve variables
def instance_name = variables.get("INSTANCE_NAME")

// List the spark docker containers to remove
def container_ids = new StringBuilder()
def cmd = ["docker", "ps", "-aqf", "name=^" + instance_name]
println cmd
cmd.execute().waitForProcessOutput(container_ids, System.err)
println "DEBUG container ids to remove " + container_ids

// Remove them
cmd = ["docker", "rm", "-fv"] + container_ids.toString().split("\n").toList()
cmd.execute().waitForProcessOutput(System.out, System.err)
]]>
                    </code>
                </script>
            </scriptExecutable>
            <metadata>
                <positionTop>
                    482.5
                </positionTop>
                <positionLeft>
                    605.5
                </positionLeft>
            </metadata>
        </task>
        <task name="docker_network_rm"




              fork="true">
            <genericInformation>
                <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
                <info name="NODE_ACCESS_TOKEN" value="$INSTANCE_NAME"/>
            </genericInformation>
            <depends>
                <task ref="docker_rm_spark_containers"/>
            </depends>
            <selection>
                <script type="static">
                    <code language="groovy">
                        <![CDATA[
// To select the spark master/docker network pa node
selected = nodename.equals(variables.get("spark_master_node_name"))
]]>
                    </code>
                </script>
            </selection>
            <scriptExecutable>
                <script>
                    <code language="groovy">
                        <![CDATA[
// Retrieve variables
def targeted_network_name = variables.get("targeted_network_name")

// Remove the docker network only if its own network (and not the hdfs one)
if (targeted_network_name.contains("spark")){
    def cmd = ["docker", "network", "rm", targeted_network_name]
    cmd.execute().waitForProcessOutput(System.out, System.err)
}
]]>
                    </code>
                </script>
            </scriptExecutable>
            <post>
                <script>
                    <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Update_service_instance_and_remove_tokens/raw" language="groovy">
                        <arguments>
                            <argument value="FINISHED"/>
                            <argument value="$INSTANCE_NAME"/>
                        </arguments>
                    </file>
                </script>
            </post>
            <metadata>
                <positionTop>
                    610.5
                </positionTop>
                <positionLeft>
                    605.5
                </positionLeft>
            </metadata>
        </task>
    </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:1139px;
            height:566px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-333.9875030517578px;left:-395.5px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_862" style="top: 339px; left: 400.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">delete_spark_and_update_servince_instance</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 509px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>