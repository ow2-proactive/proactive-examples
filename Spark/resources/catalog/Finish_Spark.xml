<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.14" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd"  name="Finish_Spark" tags="Big Data,Artificial Intelligence,Spark,Service Automation,Analytics" projectName="7. Lifecycle workflows" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="1"  >
  <description>
    <![CDATA[ Delete a Spark platform. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="service-automation"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
    <info name="pca.states" value="(RUNNING,FINISHED)(ERROR,FINISHED)"/>
    <info name="Documentation" value="http://spark.apache.org/docs/latest/spark-standalone.html"/>
    <info name="pca.service.id" value="Spark"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="retrieve_service_variables"
    fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="PSA_$INSTANCE_NAME"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Retrieve_variables_from_service_instance_id/raw" language="groovy">
            <arguments>
              <argument value="$PCA_INSTANCE_ID"/>
              <argument value="spark_network_name"/>
              <argument value="spark_network_name"/>
              <argument value="spark_master_and_workers_pa_node_names"/>
              <argument value="spark_master_and_workers_pa_node_names"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            354.5
        </positionTop>
        <positionLeft>
            605.5
        </positionLeft>
      </metadata>
    </task>


    <task name="inform_FINISH_LAUNCHED"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="PSA_$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="retrieve_service_variables"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Pre_Trigger_Action/raw" language="groovy">
            <arguments>
              <argument value="FINISH_LAUNCHED"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <controlFlow >
        <replicate>
          <script>
            <code language="groovy">
              <![CDATA[
runs = variables.get("nb_spark_workers")
]]>
            </code>
          </script>
        </replicate>
      </controlFlow>
      <metadata>
        <positionTop>
          986.5
        </positionTop>
        <positionLeft>
          664.5
        </positionLeft>
      </metadata>
    </task>

    <task name="docker_rm_spark_containers" fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="PSA_$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="inform_FINISH_LAUNCHED"/>
      </depends>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
// Since the master and the 1st worker are running on the same PA node, do not consider the master PA node
def task_replication_id = variables.get("PA_TASK_REPLICATION") as Integer
def targeted_pa_node_name = variables.get("spark_master_and_workers_pa_node_names").split(",")[(task_replication_id + 1)]

selected = (nodename == targeted_pa_node_name)
]]>
          </code>
        </script>
      </selection>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def instance_name = variables.get("INSTANCE_NAME")
def task_replication_id = variables.get('PA_TASK_REPLICATION')

// List the docker containers to remove
def container_ids = new StringBuilder()
def cmd = ["docker", "ps", "-aqf", "name=^" + instance_name]
println cmd
cmd.execute().waitForProcessOutput(container_ids, System.err)
println "DEBUG container ids to remove " + container_ids

// Remove remaining container
def cmd_err = null
if (!container_ids.toString().trim().isEmpty()){
  println "Removing containers from node " + variables.get("PA_NODE_NAME")
  cmd_err = new StringBuilder()
  cmd = ["docker", "rm", "-fv"] + container_ids.toString().split("\n").toList()
  cmd.execute().waitForProcessOutput(System.out, cmd_err)
}

// Propagate the status of the clean
if (cmd_err != null && !cmd_err.toString().isEmpty() && !cmd_err.toString().contains("is already in progress") && !cmd_err.toString().contains("No such container")){
  println "DEBUG adding ko since cmd_err " + cmd_err.toString()
  variables.put("DOCKER_RM_FORCED_EXECUTED_" + task_replication_id, "ko")
}
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            482.5
        </positionTop>
        <positionLeft>
            605.5
        </positionLeft>
      </metadata>
    </task>

    <task name="docker_rm_network"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="PSA_$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="docker_rm_spark_containers"/>
      </depends>
      <selection>
        <script type="dynamic">
          <code language="groovy">
            <![CDATA[
def spark_master_pa_node_name = variables.get("spark_master_and_workers_pa_node_names").split(",")[0]

selected = (nodename == spark_master_pa_node_name)
]]>
          </code>
        </script>
      </selection>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def spark_network_name = variables.get("spark_network_name")

// Remove the docker network only if its own network (and not the hdfs one)
if (spark_network_name.contains("spark")){
    def cmd = ["docker", "network", "rm", spark_network_name]
    cmd.execute().waitForProcessOutput(System.out, System.err)
}
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
          610.5
        </positionTop>
        <positionLeft>
          605.5
        </positionLeft>
      </metadata>
    </task>

    <task name="Set_service_FINISHED_if_all_clean_OK"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
        <info name="NODE_ACCESS_TOKEN" value="PSA_$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="docker_rm_network"/>
      </depends>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
// Retrieve variables
def instance_name = variables.get("INSTANCE_NAME")
def nb_spark_workers = variables.get("nb_spark_workers") as Integer

// Propagate all the err message of the clean commands
def status_file_content = ""
for (i = 0; i < nb_spark_workers; i++) {
    status_file_content += "|" + variables.get("DOCKER_RM_FORCED_EXECUTED_" +  i)
}
new File(localspace, instance_name + "_status").text = status_file_content
]]>
          </code>
        </script>
      </scriptExecutable>
      <post>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Set_service_FINISHED_if_all_clean_OK/raw" language="groovy">
            <arguments>
              <argument value="FINISHED"/>
              <argument value="${INSTANCE_NAME}_status"/>
            </arguments>
          </file>
        </script>
      </post>
      <metadata>
        <positionTop>
          1242.5
        </positionTop>
        <positionLeft>
          664.5
        </positionLeft>
      </metadata>
    </task>
    <task name="remove_tokens_if_failing_platform"




          fork="true">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/spark.png"/>
      </genericInformation>
      <depends>
        <task ref="Set_service_FINISHED_if_all_clean_OK"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Update_service_and_remove_tokens/raw" language="groovy">
            <arguments>
              <argument value="null"/>
              <argument value="PSA_$INSTANCE_NAME"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
          1370.5
        </positionTop>
        <positionLeft>
          664.5
        </positionLeft>
      </metadata>
    </task>

  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:1139px;
            height:566px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-333.9875030517578px;left:-395.5px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_862" style="top: 339px; left: 400.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/spark.png" width="20px">&nbsp;<span class="name">delete_spark_and_update_servince_instance</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 509px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>