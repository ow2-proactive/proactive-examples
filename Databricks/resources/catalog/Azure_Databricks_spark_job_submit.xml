<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"  name="Azure_Databricks_Spark_Job_Submit" projectName="Azure Big Data" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2" >
  <variables>
    <variable name="domain" value="westeurope.azuredatabricks.net" />
    <variable name="token" value="my_databricks_workspace_token" />
    <variable name="existing_cluster_id" value="my_spark_cluster_id" />
    <variable name="jar_path_from_dataspace" value="my_jar_to_put_to_the_dbfs" />
    <variable name="main_class_name" value="my.example.class" />
    <variable name="parameters" value="" />
    <variable name="run_name" value="my_first_spark_job" />
    <variable name="timeout_seconds" value="3600" model="PA:Integer"/>
    <variable name="max_retries" value="1" model="PA:Integer"/>
  </variables>
  <description>
    <![CDATA[ Creates a new Spark job with the provided settings and runs it now. ]]>
  </description>
  <genericInformation>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/databricks.png"/>
    <info name="Documentation" value="https://docs.azuredatabricks.net/api/latest/index.html"/>
  </genericInformation>
  <taskFlow>
    <task name="Azure_Databricks_Spark_Job_Submit" >
      <genericInformation>
        <info name="task.documentation" value="https://docs.azuredatabricks.net/api/latest/index.html"/>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/databricks.png"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.json.JsonBuilder
import org.apache.http.entity.StringEntity
import org.apache.http.client.methods.HttpPost
import org.apache.http.entity.mime.MultipartEntityBuilder
import org.apache.http.impl.client.HttpClientBuilder
import org.apache.http.entity.mime.content.FileBody
import org.apache.http.entity.mime.content.StringBody
import org.apache.http.entity.ContentType


// Retrieve variables
def domain = variables.get("domain")
def token = variables.get("token")
def existing_cluster_id = variables.get("existing_cluster_id")
def jar_path_from_dataspace = variables.get("jar_path_from_dataspace")
def main_class_name = variables.get("main_class_name")
def parameters = variables.get("parameters")
def run_name = variables.get("run_name")
def timeout_seconds = variables.get("timeout_seconds")
def max_retries = variables.get("max_retries")


// Build the command params
def json = new JsonBuilder([run_name: run_name, existing_cluster_id: existing_cluster_id, libraries: ["jar": "dbfs:/" + jar_path_from_dataspace], timeout_seconds: timeout_seconds, max_retries: max_retries, spark_jar_task: ["main_class_name": main_class_name, "parameters": parameters] ])
println json.toString()

// Build the command
def submit_query = "https://" + domain + "/api/2.0/jobs/runs/submit"
def submit_post = new HttpPost(submit_query)
submit_post.addHeader("Content-Type", "application/json")
submit_post.addHeader("Authorization", "Bearer " +  token)
submit_post.setEntity(new StringEntity(json.toString()));
println "RUNS/SUBMIT REQUEST=> " + submit_post.getRequestLine()

// Execute the command
def submit_response = HttpClientBuilder.create().build().execute(submit_post)
println "RUNS/SUBMIT RESPONSE=> " + submit_response
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:1139px;
            height:566px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-333.9875030517578px;left:-424px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_1187" style="top: 339px; left: 429px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/databricks.png" width="20px">&nbsp;<span class="name">Azure_Databricks_spark_job_submit</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 518px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>