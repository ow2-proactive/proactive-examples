<?xml version="1.0" encoding="UTF-8"?>
<job
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xmlns="urn:proactive:jobdescriptor:3.10"
        xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd"
        name="Azure_Databricks_cluster_create" projectName="Azure Big Data"
        priority="normal"
        onTaskError="continueJobExecution"
        maxNumberOfExecution="2"
>
  <variables>
    <variable name="domain" value="westeurope.azuredatabricks.net"/>
    <variable name="token" value="my_databricks_workspace_token"/>
    <variable name="cluster_name" value="my_databricks_spark_cluster" />
    <variable name="spark_version" value="3.4.x-scala2.11" />
    <variable name="node_type_id" value="Standard_D3_v2" />
    <variable name="spark_speculation" value="false" model="PA:Boolean"/>
    <variable name="num_workers" value="2" model="PA:Integer"/>
  </variables>
  <description>
    <![CDATA[ Creates a new Spark cluster. ]]>
  </description>
  <genericInformation>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/databricks.png"/>
    <info name="Documentation" value="https://docs.azuredatabricks.net/api/latest/index.html"/>
  </genericInformation>
  <taskFlow>

    <task name="Azure_Databricks_cluster_create">
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/databricks.png"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import groovy.json.JsonBuilder
import org.apache.http.entity.StringEntity

// Retrieve variables
def domain = variables.get("domain")
def token = variables.get("token")
def cluster_name = variables.get("cluster_name")
def spark_version = variables.get("spark_version")
def node_type_id = variables.get("node_type_id")
def spark_speculation = variables.get("spark_speculation")
def num_workers = variables.get("num_workers")

// Build the command params
def json = new JsonBuilder([cluster_name: cluster_name, spark_version: spark_version, node_type_id: node_type_id, num_workers: num_workers, spark_conf: ["spark.speculation": spark_speculation] ])
println json.toString()

// Build the command
def query = "https://" + domain + "/api/2.0/clusters/create"
def post = new org.apache.http.client.methods.HttpPost(query)
post.addHeader("Content-Type", "application/json")
post.addHeader("Authorization", "Bearer " +  token)
post.setEntity(new StringEntity(json.toString()));

// Execute the command
def response = org.apache.http.impl.client.HttpClientBuilder.create().build().execute(post)
println response
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
  </taskFlow>
</job>