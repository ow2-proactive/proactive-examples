<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.13" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Data_Anomaly_Detection" onTaskError="continueJobExecution" priority="normal" projectName="4. Data Analytics" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd">
  <variables>
    <variable model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker" description="Container platform used for executing the workflow tasks." hidden="false" group="Container Parameters" advanced="true"/>
    <variable model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="False" description="If True, it will activate the use of GPU for the workflow tasks on the selected container platform." hidden="false" group="Container Parameters" advanced="true"/>
    <variable model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/rapidsai,docker://activeeon/nvidia:rapidsai)" name="CONTAINER_IMAGE" value="" description="Name of the container image being used." hidden="false" group="Container Parameters" advanced="true"/>
    <variable name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/fusion_10p.csv" description="URL of a file accessible using HTTP or HTTPS protocols"/>
    <variable model="PA:Integer[1,28]" name="MAX_USERS" value="5" description="Maximum number of customers for which the anomalies on energy consumption will be detected."/>
    <variable name="OUTPUT_FILE" value="HTML" description="Converts the result into the specified file type."/>
    <variable model="PA:LIST(,$HOME/,$WORK/,$SCRATCH/)" name="WORK_DIR" value="" description="Working directory for the data space used to transfer files automatically between the workflow tasks." hidden="true" advanced="false"/>
  </variables>
  <description>
    <![CDATA[ Detect anomalies on energy consumption by customers. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="machine-learning-workflows"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data_analytics.png"/>
<info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
<info name="Documentation" value="PML/PMLUserGuide.html#_data_analytics"/>
<info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Import_Data" preciousResult="true">
      <description>
        <![CDATA[ Load data from external sources and predict its features types if enabled. ]]>
      </description>
      <variables>
        <variable inherited="true" name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/fusion.csv" description="URL of a file accessible using HTTP or HTTPS protocols"/>
        <variable inherited="false" name="FILE_DELIMITER" value="," description="Delimiter to use."/>
        <variable inherited="false" model="PA:Boolean" name="IS_LABELED_DATA" value="False" description="If True, it means the data is labeled."/>
        <variable inherited="false" name="LIMIT_OUTPUT_VIEW" value="5" description="Maximum number of rows displayed in the output"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_import_data"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

import pandas as pd
import numpy as np
import distutils.dir_util

from sklearn.preprocessing import LabelEncoder

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
IS_LABELED_DATA = variables.get("IS_LABELED_DATA")
RENAME_COLUMNS = variables.get("RENAME_COLUMNS")
FILTER_COLUMNS = variables.get("FILTER_COLUMNS")
ENCODE_COLUMNS = variables.get("ENCODE_COLUMNS")
JOB_ID_FOLDER = variables.get("WORK_DIR") + variables.get("PA_JOB_ID") + "/"
distutils.dir_util.mkpath(JOB_ID_FOLDER)

assert FILE_URL is not None
assert FILE_DELIMITER is not None

dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)
#dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER, chunksize=1000)

if RENAME_COLUMNS is not None:
  RENAME_COLUMNS = [x.strip() for x in RENAME_COLUMNS.split(',')]
  dataframe.columns = RENAME_COLUMNS

if FILTER_COLUMNS is not None:
  FILTER_COLUMNS = [x.strip() for x in FILTER_COLUMNS.split(',')]
  dataframe = dataframe.filter(items=FILTER_COLUMNS)

if ENCODE_COLUMNS is not None:
  ENCODE_COLUMNS = [x.strip() for x in ENCODE_COLUMNS.split(',')]
  map_struct = {}
  for col in ENCODE_COLUMNS:
    unique_vector = dataframe[col].unique()
    LE = LabelEncoder()
    LE.fit(unique_vector)
    enc_values = LE.transform(unique_vector)
    enc_map = dict(zip(unique_vector, enc_values))
    dataframe[col] = dataframe[col].map(enc_map)
    map_struct[col] = enc_map
  print(map_struct)

print(dataframe.head(3))
print(dataframe.dtypes)
print(dataframe.shape)

columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
  data  = dataframe.values[:,0:columns_number-1]
  label = dataframe.values[:,columns_number-1]
  data_df = pd.DataFrame(data=data, columns=columns_name[0:columns_number-1])
  label_df = pd.DataFrame(data=label, columns=[columns_name[columns_number-1]])
  LABEL_TRAIN_DF_JSON = label_df.to_json(path_or_buf=JOB_ID_FOLDER + "LABEL_TRAIN_DF_JSON.json", orient='split')
  LABEL_TEST_DF_JSON = label_df.to_json(path_or_buf=JOB_ID_FOLDER + "LABEL_TEST_DF_JSON.json", orient='split')

else:
  data = dataframe.values
  data_df = pd.DataFrame(data=data, columns=columns_name)

DATAFRAME_JSON = dataframe.to_json(path_or_buf=JOB_ID_FOLDER + "DATAFRAME_JSON.json", orient='split')
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json(path_or_buf=JOB_ID_FOLDER + "COLUMNS_NAME_JSON.json")
DATA_TRAIN_DF_JSON = data_df.to_json(path_or_buf=JOB_ID_FOLDER + "DATA_TRAIN_DF_JSON.json", orient='split')
DATA_TEST_DF_JSON = data_df.to_json(path_or_buf=JOB_ID_FOLDER + "DATA_TEST_DF_JSON.json", orient='split')


LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
variables.put("PREVIOUS_PA_TASK_NAME", variables.get("PA_TASK_NAME"))
]]>
          </code>
        </script>
      </post>
      <outputFiles>
        <files accessMode="transferToUserSpace" includes="${WORK_DIR}${PA_JOB_ID}/*.json"/>
      </outputFiles>
      <metadata>
        <positionTop>
            44.484375
        </positionTop>
        <positionLeft>
            457
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Split">
      <description>
        <![CDATA[ Defines some input, here strings to be processed. ]]>
      </description>
      <variables>
        <variable advanced="false" inherited="true" model="PA:Integer" name="MAX_USERS" value="5" description="Maximum number of customers for which the anomalies on energy consumption will be detected."/>
      </variables>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_replicate"/>
      </genericInformation>
      <depends>
        <task ref="Import_Data"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromUserSpace" includes="${WORK_DIR}${PA_JOB_ID}/*.json"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

import pandas as pd
import numpy as np
import distutils.dir_util

MAX_USERS = variables.get("MAX_USERS")
JOB_ID_FOLDER = variables.get("WORK_DIR") + variables.get("PA_JOB_ID") + "/"
INPUTS_FOLDER = JOB_ID_FOLDER + "inputs/"
distutils.dir_util.mkpath(INPUTS_FOLDER)

assert MAX_USERS is not None

MAX_USERS = int(MAX_USERS)
dataframe = pd.read_json(path_or_buf=JOB_ID_FOLDER + "DATAFRAME_JSON.json", orient='split')

dataframe['DateTime'] = dataframe['DateTime'].astype('datetime64[ns]')
dataframe['Date'] = [datetime.date() for datetime in dataframe['DateTime']]

users = dataframe['LCLid'].unique()
dataframe = dataframe.drop(['DateTime'], axis=1)
ts = dataframe.groupby(['LCLid','Date'])['KWH_hh'].mean()

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)
print(ts.head(3))
print(ts.shape)

result = {}
for idx, user in enumerate(users):
    ts_user = ts[user]
    file_name = INPUTS_FOLDER + "result_" + str(idx) + ".json"
    ts_user.to_json(path_or_buf=file_name)
    result[idx] = file_name
    if idx == MAX_USERS:
        break

RUNS = len(result)
variables.put("RUNS", RUNS)

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow>
        <replicate>
          <script>
            <code language="cpython">
              <![CDATA[
__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

runs = variables.get("RUNS")
print("runs: ", runs)

print("END " + __file__)
]]>
            </code>
          </script>
        </replicate>
      </controlFlow>
      <outputFiles>
        <files accessMode="transferToUserSpace" includes="${WORK_DIR}${PA_JOB_ID}/inputs/*.json"/>
      </outputFiles>
      <metadata>
        <positionTop>
            172.484375
        </positionTop>
        <positionLeft>
            457
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Process">
      <description>
        <![CDATA[ This task will be replicated according to the 'runs' value specified in the replication script. The replication index is used in each task's instance to select the input. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_replicate"/>
      </genericInformation>
      <depends>
        <task ref="Split"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromUserSpace" includes="${WORK_DIR}${PA_JOB_ID}/inputs/result_${PA_TASK_REPLICATION}.json"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")
JOB_ID_FOLDER = variables.get("WORK_DIR") + variables.get("PA_JOB_ID") + "/"
print("BEGIN " + __file__)

#from __future__ import division
from itertools import count
import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt
from numpy import linspace, loadtxt, ones, convolve
import numpy as np
import pandas as pd
import collections
from random import randint
from matplotlib import style
import base64
import os.path
from pandas.io.json import json_normalize
from PIL import Image
from io import BytesIO

def get_thumbnail(path):
  i = Image.open(path)
  i.thumbnail((1200, 600), Image.LANCZOS)
  return i

def image_base64(im):
  if isinstance(im, str):
    im = get_thumbnail(im)
  with BytesIO() as buffer:
    im.save(buffer, 'jpeg')
    return base64.b64encode(buffer.getvalue()).decode()

def image_formatter(im):
  return f'<img src="data:image/jpeg;base64,{image_base64(im)}" height="600" width="1200">'

def image_formatter_url(im_url):
  return """<img src="{0}" height="600" width="1200"/>""".format(im_url)

#style.use('fivethirtyeight')
#%matplotlib inline
try:
    # Python 2
    from itertools import izip
except ImportError:
    # Python 3
    #import zip
    izip = zip

def moving_average(data, window_size):
    """ Computes moving average using discrete linear convolution of two one dimensional sequences.
    Args:
    -----
            data (pandas.Series): independent variable
            window_size (int): rolling window size

    Returns:
    --------
            ndarray of linear convolution

    References:
    ------------
    [1] Wikipedia, "Convolution", http://en.wikipedia.org/wiki/Convolution.
    [2] API Reference: https://docs.scipy.org/doc/numpy/reference/generated/numpy.convolve.html

    """
    window = np.ones(int(window_size))/float(window_size)
    return np.convolve(data, window, 'same')


def explain_anomalies(y, window_size, sigma=1.0):
    """ Helps in exploring the anamolies using stationary standard deviation
    Args:
    -----
        y (pandas.Series): independent variable
        window_size (int): rolling window size
        sigma (int): value for standard deviation

    Returns:
    --------
        a dict (dict of 'standard_deviation': int, 'anomalies_dict': (index: value))
        containing information about the points indentified as anomalies

    """
    avg = moving_average(y, window_size).tolist()
    residual = y - avg
    # Calculate the variation in the distribution of the residual
    std = np.std(residual)
    return {'standard_deviation': round(std, 3),
            'anomalies_dict': collections.OrderedDict([(index, y_i) for
                                                       index, y_i, avg_i in izip(count(), y, avg)
              if (y_i > avg_i + (sigma*std)) | (y_i < avg_i - (sigma*std))])}


def explain_anomalies_rolling_std(y, window_size, sigma=1.0):
    """ Helps in exploring the anamolies using rolling standard deviation
    Args:
    -----
        y (pandas.Series): independent variable
        window_size (int): rolling window size
        sigma (int): value for standard deviation

    Returns:
    --------
        a dict (dict of 'standard_deviation': int, 'anomalies_dict': (index: value))
        containing information about the points indentified as anomalies
    """
    avg = moving_average(y, window_size)
    avg_list = avg.tolist()
    residual = y - avg
    # Calculate the variation in the distribution of the residual
    testing_std = pd.rolling_std(residual, window_size)
    testing_std_as_df = pd.DataFrame(testing_std)
    rolling_std = testing_std_as_df.replace(np.nan,
                                  testing_std_as_df.ix[window_size - 1]).round(3).iloc[:,0].tolist()
    std = np.std(residual)
    return {'stationary standard_deviation': round(std, 3),
            'anomalies_dict': collections.OrderedDict([(index, y_i)
                                                       for index, y_i, avg_i, rs_i in izip(count(),
                                                                                           y, avg_list, rolling_std)
              if (y_i > avg_i + (sigma * rs_i)) | (y_i < avg_i - (sigma * rs_i))])}


# This function is repsonsible for displaying how the function performs on the given dataset.
def plot_results(x, y, window_size, sigma_value=1,
                 text_xlabel="X Axis", text_ylabel="Y Axis", applying_rolling_std=False):
    """ Helps in generating the plot and flagging the anamolies.
        Supports both moving and stationary standard deviation. Use the 'applying_rolling_std' to switch
        between the two.
    Args:
    -----
        x (pandas.Series): dependent variable
        y (pandas.Series): independent variable
        window_size (int): rolling window size
        sigma_value (int): value for standard deviation
        text_xlabel (str): label for annotating the X Axis
        text_ylabel (str): label for annotatin the Y Axis
        applying_rolling_std (boolean): True/False for using rolling vs stationary standard deviation
    """
    #fig = plt.figure(figsize=(15, 8))
    fig = plt.figure(figsize=(12, 6))
    plt.plot(x, y, "k-", color='gray')
    y_av = moving_average(y, window_size)
    plt.plot(x, y_av, color='green')
    #plt.xlim(0, 1000)
    plt.xlabel(text_xlabel)
    plt.ylabel(text_ylabel)

    # Query for the anomalies and plot the same
    events = {}
    if applying_rolling_std:
        events = explain_anomalies_rolling_std(y, window_size=window_size, sigma=sigma_value)
    else:
        events = explain_anomalies(y, window_size=window_size, sigma=sigma_value)

    x_anomaly = np.fromiter(events['anomalies_dict'].keys(), dtype=int, count=len(events['anomalies_dict']))
    y_anomaly = np.fromiter(events['anomalies_dict'].values(), dtype=float,
                                            count=len(events['anomalies_dict']))
    plt.plot(x_anomaly, y_anomaly, "r*", markersize=12)
    # add grid and lines and enable the plot
    plt.grid(True)
    #plt.show()
    fig.savefig('output.jpg')


replication = variables.get('PA_TASK_REPLICATION')
print("replication: ", replication)

input = results[0].value()[replication]
ts_user = pd.read_json(path_or_buf=input, typ='series', orient='records')

#fig = plt.figure(figsize=(12, 6))
#ts_user.plot()
#plt.xlabel('Date')
#plt.ylabel('KWH_hh')
#plt.show()
#fig.savefig('output.jpg')

data_as_frame = ts_user.to_frame()
data_as_frame.columns = ['KWH_hh']
#data_as_frame.columns = ['Date', 'KWH_hh']
data_as_frame['Ordinal'] = [x for x in range(0, ts_user.shape[0])]
print(data_as_frame.head(3))
x = data_as_frame['Ordinal'].values
Y = data_as_frame['KWH_hh'].values
plot_results(x, y=Y, window_size=10, text_xlabel="Day", sigma_value=3, text_ylabel="KWH")

result = ''
user = replication
data = {'ID': [user], 'Image': "output.jpg"}
df = pd.DataFrame(data=data)
with pd.option_context('display.max_colwidth', -1):
  result = df.to_html(index=False, escape=False, formatters=dict(Image=image_formatter))

css_style="""
table {
  border: 1px solid #999999;
  text-align: center;
  border-collapse: collapse;
  width: 100%;
}
td {
  border: 1px solid #999999;
  padding: 3px 2px;
  font-size: 13px;
  border-bottom: 1px solid #999999;
  #border-bottom: 1px solid #FF8C00;
  border-bottom: 1px solid #0B6FA4;
}
th {
  font-size: 17px;
  font-weight: bold;
  color: #FFFFFF;
  text-align: center;
  background: #0B6FA4;
  #background: #E7702A;
  #border-left: 2px solid #999999
  border-bottom: 1px solid #FF8C00;
}
"""
result = """
            <!DOCTYPE html>
            <html>
              <head>
                <meta charset="UTF-8">
                  <style>{0}</style>
                </head>
                <body>{1}</body></html>
""".format(css_style, result)


result = result.encode('utf-8')
resultMetadata.put("file.extension", ".html")
resultMetadata.put("file.name", "result.html")
resultMetadata.put("content.type", "text/html")

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            300.484375
        </positionTop>
        <positionLeft>
            457
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Merge" preciousResult="true">
      <description>
        <![CDATA[ As a merge operation, we simply print the results from previous tasks. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_replicate"/>
      </genericInformation>
      <depends>
        <task ref="Process"/>
      </depends>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

from bs4 import BeautifulSoup
import copy


merged_html = BeautifulSoup(str(results[0].value().decode("utf-8")))
print("len(results): ", len(results))
i = 0
for html in results:
    if i == 0:
        i = i + 1
        continue
    i = i + 1
    soup = BeautifulSoup(html.value())
    for element in soup.body:
        merged_html.body.append(copy.copy(element))

result = str(merged_html).encode('utf-8')
resultMetadata.put("file.extension", ".html")
resultMetadata.put("file.name", "result.html")
resultMetadata.put("content.type", "text/html")

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            428.484375
        </positionTop>
        <positionLeft>
            457
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Clean_DataSpace">
      <description>
        <![CDATA[ Clear the DataSpace. ]]>
      </description>
      <depends>
        <task ref="Merge"/>
      </depends>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
userspaceapi.connect()
userspaceapi.deleteFile(variables.get("WORK_DIR")+variables.get("PA_JOB_ID"))
userspaceapi.disconnect()
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            556.484375
        </positionTop>
        <positionLeft>
            457
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2144px;
            height:2420px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-39.484375px;left:-452px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_1075" style="top: 44.4844px; left: 457px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load data from external sources and predict its features types if enabled."><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_Data</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_1078" style="top: 172.484px; left: 457px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Defines some input, here strings to be processed."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Split</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_1081" style="top: 300.484px; left: 457px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task will be replicated according to the 'runs' value specified in the replication script. The replication index is used in each task's instance to select the input."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Process</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_1084" style="top: 428.484px; left: 457px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="As a merge operation, we simply print the results from previous tasks."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Merge</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_1087" style="top: 556.484px; left: 457px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Clear the DataSpace."><img src="/studio/images/Groovy.png" width="20px">&nbsp;<span class="name">Clean_DataSpace</span></a></div><svg style="position:absolute;left:491.98171321138256px;top:83.5px" width="15.518286788617468" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88 C -10 38 -10 50 0 0 " transform="translate(15.018286788617468,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path></svg><svg style="position:absolute;left:522.4657867477086px;top:201.5px" width="15.034213252291345" height="99" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88 C -10 88 -10 -10 0 0 " transform="translate(14.534213252291345,10.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#e5db3d" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.889249999999999,77.41936575 L-0.6632823303137547,56.65542592021898 L-6.785898453911784,63.54843482802241 L-14.534213252291345,58.55207437413076 L-4.889249999999999,77.41936575" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(14.534213252291345,10.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.889249999999999,77.41936575 L-0.6632823303137547,56.65542592021898 L-6.785898453911784,63.54843482802241 L-14.534213252291345,58.55207437413076 L-4.889249999999999,77.41936575" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(14.534213252291345,10.5)"></path></svg><div class="_jsPlumb_overlay l1 component label" id="jsPlumb_1_1098" style="position: absolute; transform: translate(-50%, -50%); left: 529px; top: 251.75px;">replicate</div><svg style="position:absolute;left:491.98171321138256px;top:211.5px" width="15.518286788617468" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88 C -10 38 -10 50 0 0 " transform="translate(15.018286788617468,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path></svg><svg style="position:absolute;left:491.98171321138256px;top:339.5px" width="15.518286788617468" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88 C -10 38 -10 50 0 0 " transform="translate(15.018286788617468,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path></svg><svg style="position:absolute;left:496.5px;top:467.5px" width="29" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 8 88 C 18 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M10.149632,66.303232 L14.370633382220372,45.538282028201515 L8.249666052974282,52.43275510120006 L0.5001564834204357,47.438247975227235 L10.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M10.149632,66.303232 L14.370633382220372,45.538282028201515 L8.249666052974282,52.43275510120006 L0.5001564834204357,47.438247975227235 L10.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 497px; top: 74px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 497px; top: 202px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 497px; top: 162px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint replicate-source-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 527px; top: 202px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 497px; top: 330px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint replicate-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 527px; top: 290px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 497px; top: 290px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 497px; top: 458px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 497px; top: 418px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 505px; top: 586px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 505px; top: 546px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
