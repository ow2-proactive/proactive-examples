<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.13" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Data_Fusion_And_Encoding" onTaskError="continueJobExecution" priority="normal" projectName="4. Data Analytics" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd">
  <variables>
    <variable model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker" description="Container platform used for executing the workflow tasks." group="Container Parameters" hidden="false" advanced="true"/>
    <variable model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="False" description="If True, it will activate the use of GPU for the workflow tasks on the selected container platform." group="Container Parameters" hidden="false" advanced="true"/>
    <variable model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/rapidsai,docker://activeeon/nvidia:rapidsai)" name="CONTAINER_IMAGE" value="" description="Name of the container image being used." group="Container Parameters" hidden="false" advanced="true"/>
  </variables>
  <description>
    <![CDATA[ Fuse different data structures. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="machine-learning-workflows"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data_analytics.png"/>
<info name="NS" value="$NATIVE_SCHEDULER"/>
<info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
<info name="Documentation" value="PML/PMLUserGuide.html#_data_analytics"/>
<info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Import_LCL" preciousResult="true">
      <description>
        <![CDATA[ Load data from external sources. ]]>
      </description>
      <variables>
        <variable advanced="false" inherited="false" name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/MAC000002-3.csv" description="URL of a file accessible using HTTP or HTTPS protocols"/>
        <variable advanced="false" inherited="false" name="FILE_DELIMITER" value="," description="Delimiter to use."/>
        <variable advanced="false" inherited="false" model="PA:Boolean" name="IS_LABELED_DATA" value="False" description="If True, it means the data is labeled."/>
        <variable advanced="false" inherited="false" name="RENAME_COLUMNS" value="LCLid, stdorToU, DateTime, KWH_hh, Acorn, Acorn_grouped" description="List of the new column names."/>
        <variable advanced="false" inherited="false" name="ENCODE_COLUMNS" value="LCLid, stdorToU, Acorn, Acorn_grouped" description="List of columns to encode."/>
        <variable advanced="false" inherited="false" name="LIMIT_OUTPUT_VIEW" value="5" description="Maximum number of rows displayed in the output"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_import_data"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
RENAME_COLUMNS = variables.get("RENAME_COLUMNS")
FILTER_COLUMNS = variables.get("FILTER_COLUMNS")
ENCODE_COLUMNS = variables.get("ENCODE_COLUMNS")

assert FILE_URL is not None
assert FILE_DELIMITER is not None

dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)

if RENAME_COLUMNS is not None:
  RENAME_COLUMNS = [x.strip() for x in RENAME_COLUMNS.split(',')]
  dataframe.columns = RENAME_COLUMNS

if FILTER_COLUMNS is not None:
  FILTER_COLUMNS = [x.strip() for x in FILTER_COLUMNS.split(',')]
  dataframe = dataframe.filter(items=FILTER_COLUMNS)

if ENCODE_COLUMNS is not None:
  ENCODE_COLUMNS = [x.strip() for x in ENCODE_COLUMNS.split(',')]
  map_struct = {}
  for col in ENCODE_COLUMNS:
    unique_vector = dataframe[col].unique()
    LE = LabelEncoder()
    LE.fit(unique_vector)
    enc_values = LE.transform(unique_vector)
    enc_map = dict(zip(unique_vector, enc_values))
    dataframe[col] = dataframe[col].map(enc_map)
    map_struct[col] = enc_map
  print(map_struct)

# Format columns
dataframe['KWH_hh'] = dataframe['KWH_hh'].replace('Null', 0)
dataframe['KWH_hh'] = dataframe.KWH_hh.astype(float)
#dataframe['DateTime'] = dataframe['DateTime'].astype('datetime64[ns]')

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
variables.put("COLUMNS_NAME_LCL__JSON", COLUMNS_NAME_JSON)

DATAFRAME_JSON = dataframe.to_json(orient='split')
variables.put("DATAFRAME_LCL_JSON", DATAFRAME_JSON)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            133.640625
        </positionTop>
        <positionLeft>
            340.046875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Import_Holidays" preciousResult="true">
      <description>
        <![CDATA[ Load data from external sources. ]]>
      </description>
      <variables>
        <variable advanced="false" inherited="false" name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/holidays.csv" description="URL of a file accessible using HTTP or HTTPS protocols"/>
        <variable advanced="false" inherited="false" name="FILE_DELIMITER" value="," description="Delimiter to use."/>
        <variable advanced="false" inherited="false" name="RENAME_COLUMNS" value="Date, Description" description="List of the new column names to be used to rename the dataset columns."/>
        <variable advanced="false" inherited="false" name="FILTER_COLUMNS" value="Date, Description" description="List of columns to select/keep from the dataset."/>
        <variable advanced="false" inherited="false" name="LIMIT_OUTPUT_VIEW" value="5" description="Maximum number of rows displayed in the output"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_import_data"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
RENAME_COLUMNS = variables.get("RENAME_COLUMNS")
FILTER_COLUMNS = variables.get("FILTER_COLUMNS")
ENCODE_COLUMNS = variables.get("ENCODE_COLUMNS")

assert FILE_URL is not None
assert FILE_DELIMITER is not None

dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)

if RENAME_COLUMNS is not None:
  RENAME_COLUMNS = [x.strip() for x in RENAME_COLUMNS.split(',')]
  dataframe.columns = RENAME_COLUMNS

if FILTER_COLUMNS is not None:
  FILTER_COLUMNS = [x.strip() for x in FILTER_COLUMNS.split(',')]
  dataframe = dataframe.filter(items=FILTER_COLUMNS)

if ENCODE_COLUMNS is not None:
  ENCODE_COLUMNS = [x.strip() for x in ENCODE_COLUMNS.split(',')]
  map_struct = {}
  for col in ENCODE_COLUMNS:
    unique_vector = dataframe[col].unique()
    LE = LabelEncoder()
    LE.fit(unique_vector)
    enc_values = LE.transform(unique_vector)
    enc_map = dict(zip(unique_vector, enc_values))
    dataframe[col] = dataframe[col].map(enc_map)
    map_struct[col] = enc_map
  print(map_struct)

# Format columns
dataframe['Date'] = dataframe['Date'].astype('datetime64[ns]')
dataframe.set_index('Date', inplace=True)

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATAFRAME_JSON = dataframe.to_json(orient='split')

variables.put("COLUMNS_NAME_HOLIDAY_JSON", COLUMNS_NAME_JSON)
variables.put("DATAFRAME_HOLIDAY_JSON", DATAFRAME_JSON)


LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            133.640625
        </positionTop>
        <positionLeft>
            468.046875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Import_Tariffs" preciousResult="true">
      <description>
        <![CDATA[ Load data from external sources. ]]>
      </description>
      <variables>
        <variable inherited="false" name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/tariffs.csv" description="URL of a file accessible using HTTP or HTTPS protocols"/>
        <variable inherited="false" name="FILE_DELIMITER" value="," description="Delimiter to use."/>
        <variable inherited="false" name="RENAME_COLUMNS" value="DateTime, Tariff" description="List of the new column names to be used to rename the dataset columns."/>
        <variable inherited="false" name="ENCODE_COLUMNS" value="Tariff" description="List of columns to encode."/>
        <variable inherited="false" name="LIMIT_OUTPUT_VIEW" value="5" description="Maximum number of rows displayed in the output."/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_import_data"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
RENAME_COLUMNS = variables.get("RENAME_COLUMNS")
FILTER_COLUMNS = variables.get("FILTER_COLUMNS")
ENCODE_COLUMNS = variables.get("ENCODE_COLUMNS")

assert FILE_URL is not None
assert FILE_DELIMITER is not None

dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)

if RENAME_COLUMNS is not None:
  RENAME_COLUMNS = [x.strip() for x in RENAME_COLUMNS.split(',')]
  dataframe.columns = RENAME_COLUMNS

if FILTER_COLUMNS is not None:
  FILTER_COLUMNS = [x.strip() for x in FILTER_COLUMNS.split(',')]
  dataframe = dataframe.filter(items=FILTER_COLUMNS)

if ENCODE_COLUMNS is not None:
  ENCODE_COLUMNS = [x.strip() for x in ENCODE_COLUMNS.split(',')]
  map_struct = {}
  for col in ENCODE_COLUMNS:
    unique_vector = dataframe[col].unique()
    LE = LabelEncoder()
    LE.fit(unique_vector)
    enc_values = LE.transform(unique_vector)
    enc_map = dict(zip(unique_vector, enc_values))
    dataframe[col] = dataframe[col].map(enc_map)
    map_struct[col] = enc_map
  print(map_struct)

# Format columns
dataframe['DateTime'] = pd.to_datetime(dataframe['DateTime'], format='%m/%d/%y %H:%M')
dataframe['DateTime'] = dataframe['DateTime'].astype('datetime64[ns]')
dataframe.set_index('DateTime', inplace=True)

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
variables.put("COLUMNS_NAME_TARIFFS_JSON", COLUMNS_NAME_JSON)

DATAFRAME_JSON = dataframe.to_json(orient='split')
variables.put("DATAFRAME_TARIFFS_JSON", DATAFRAME_JSON)


LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            133.640625
        </positionTop>
        <positionLeft>
            596.046875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Data_Fusion" preciousResult="true">
      <description>
        <![CDATA[ Performs data fusion. ]]>
      </description>
      <variables>
        <variable inherited="false" name="OUTPUT_FORMAT" value="HTML" description="Format of the output file"/>
        <variable inherited="false" model="PA:Boolean" name="IS_LABELED_DATA" value="False" description="If True, it means the data is labeled."/>
        <variable inherited="false" name="LIMIT_OUTPUT_VIEW" value="5" description="Maximum number of rows displayed in the output"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/filled_filter.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_filter_data"/>
      </genericInformation>
      <depends>
        <task ref="Import_LCL"/>
        <task ref="Import_Holidays"/>
        <task ref="Import_Tariffs"/>
      </depends>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

DATAFRAME_LCL_JSON     = variables.get("DATAFRAME_LCL_JSON")
DATAFRAME_HOLIDAY_JSON = variables.get("DATAFRAME_HOLIDAY_JSON")
DATAFRAME_TARIFFS_JSON = variables.get("DATAFRAME_TARIFFS_JSON")
IS_LABELED_DATA        = variables.get("IS_LABELED_DATA")
OUTPUT_FORMAT          = variables.get("OUTPUT_FORMAT")

assert DATAFRAME_LCL_JSON is not None
assert DATAFRAME_HOLIDAY_JSON is not None
assert DATAFRAME_TARIFFS_JSON is not None
assert OUTPUT_FORMAT is not None

dataframe = pd.read_json(DATAFRAME_LCL_JSON, orient='split')
dataframe_holiday = pd.read_json(DATAFRAME_HOLIDAY_JSON, orient='split')
dataframe_tariffs = pd.read_json(DATAFRAME_TARIFFS_JSON, orient='split')

# Fuse holidays
dataframe['Holiday'] = 0
for holiday_date in dataframe_holiday.index:
    dataframe.loc[dataframe['DateTime'].dt.strftime('%d/%m/%y') == holiday_date.strftime('%d/%m/%y'), 'Holiday'] = 1

# Fuse tariffs
dataframe['Tariff'] = np.nan
for tariff_datetime in dataframe_tariffs.index:
    tariff_value = dataframe_tariffs.loc[tariff_datetime, 'Tariff']
    dataframe.loc[dataframe['DateTime'] == tariff_datetime, 'Tariff'] = tariff_value

# Remove NaN rows (Tariff == NaN)
dataframe.dropna(inplace=True)
dataframe['Tariff'] = dataframe['Tariff'].astype(int)
dataframe.reset_index(drop=True)

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
  data  = dataframe.values[:,0:columns_number-1]
  label = dataframe.values[:,columns_number-1]

  data_df = pd.DataFrame(data=data, columns=columns_name[0:columns_number-1])
  label_df = pd.DataFrame(data=label, columns=[columns_name[columns_number-1]])

  LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
  LABEL_TEST_DF_JSON = label_df.to_json(orient='split')

  variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
  variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)

else:
  data = dataframe.values
  data_df = pd.DataFrame(data=data, columns=columns_name)

DATAFRAME_JSON = dataframe.to_json(orient='split')
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
DATA_TEST_DF_JSON = data_df.to_json(orient='split')

variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)


LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            261.640625
        </positionTop>
        <positionLeft>
            468.046875
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2144px;
            height:2420px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-128.640625px;left:-335.046875px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_1" style="top: 133.641px; left: 340.047px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load data from external sources."><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_LCL</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_4" style="top: 133.641px; left: 468.047px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load data from external sources."><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_Holidays</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_7" style="top: 133.641px; left: 596.047px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load data from external sources."><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_Tariffs</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_10" style="top: 261.641px; left: 468.047px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Performs data fusion."><img src="/automation-dashboard/styles/patterns/img/wf-icons/filled_filter.png" width="20px">&nbsp;<span class="name">Data_Fusion</span></a></div><svg style="position:absolute;left:379.5px;top:173.5px" width="149" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 128 88 C 138 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M112.265984,60.999424000000005 L97.39194630220584,45.90760493917774 L99.69643205491549,54.834493838204 L91.22701614040983,58.47715688426225 L112.265984,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M112.265984,60.999424000000005 L97.39194630220584,45.90760493917774 L99.69643205491549,54.834493838204 L91.22701614040983,58.47715688426225 L112.265984,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:507.5px;top:173.5px" width="24.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 13.5 50 3.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.531265625,66.78168750000002 L5.922688671570663,47.35153935976458 L-1.5001906020674536,52.819707543808825 L-8.03929128462053,46.32046433683204 L-2.531265625,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.531265625,66.78168750000002 L5.922688671570663,47.35153935976458 L-1.5001906020674536,52.819707543808825 L-8.03929128462053,46.32046433683204 L-2.531265625,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:507.5px;top:173.5px" width="149" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 138 50 128 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M15.734015999999999,60.999424000000005 L36.77298385959016,58.47715688426225 L28.30356794508451,54.834493838204 L30.608053697794155,45.90760493917774 L15.734015999999999,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M15.734015999999999,60.999424000000005 L36.77298385959016,58.47715688426225 L28.30356794508451,54.834493838204 L30.608053697794155,45.90760493917774 L15.734015999999999,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 380px; top: 164px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 511.5px; top: 164px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 636px; top: 164px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 508px; top: 292px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 508px; top: 252px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
