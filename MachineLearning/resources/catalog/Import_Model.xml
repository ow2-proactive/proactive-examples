<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.11" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Import_Model" onTaskError="continueJobExecution" priority="normal" projectName="2. Input and Output Data" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd">
  <variables>
    <variable model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
  </variables>
  <description>
    <![CDATA[ Load a trained model, and use the model to make prediction for new data. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="machine-learning-new"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/load_model.png"/>
<info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_import_model"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task name="Import_Model">
      <description>
        <![CDATA[ Load a trained model, and use the model to make prediction for new data. ]]>
      </description>
      <variables>
        <variable inherited="false" name="MODEL_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/models/pima-indians-diabetes.model"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="true" name="DOCKER_IMAGE" value="activeeon/dlm3"/>
        <variable inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/load_model.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_import_model"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2, uuid, wget, pickle

MODEL_URL = variables.get("MODEL_URL")
assert MODEL_URL is not None and MODEL_URL is not ""

filename = wget.download(str(MODEL_URL))
model = pickle.load(open(filename, "rb"))

model_bin = pickle.dumps(model)
assert model_bin is not None

compressed_model = bz2.compress(model_bin)

model_id = str(uuid.uuid4())
variables.put(model_id, compressed_model)

print("model id: ", model_id)
print('model size (original):   ', sys.getsizeof(model_bin), " bytes")
print('model size (compressed): ', sys.getsizeof(compressed_model), " bytes")

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.model_id", model_id)

#result = model_bin
#resultMetadata.put("file.extension", ".model")
#resultMetadata.put("file.name", "myModel.model")
#resultMetadata.put("content.type", "application/octet-stream")

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            367.40234375
        </positionTop>
        <positionLeft>
            629.140625
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
</job>
