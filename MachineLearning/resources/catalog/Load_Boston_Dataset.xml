<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.10" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Load_Boston_Dataset" onTaskError="continueJobExecution" priority="normal" projectName="1. Public Datasets" xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd">
  <description>
    <![CDATA[ Load and return the boston house-prices dataset regression. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="machine-learning"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/load_dataset.png"/>
<info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_load_boston_dataset"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task name="Load_Boston_Dataset">
      <description>
        <![CDATA[ Load and return the boston house-prices dataset regression. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/load_dataset.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_load_boston_dataset"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Load_Boston_Dataset")

from sklearn.datasets import load_boston
import pandas as pd

boston = load_boston()
dataframe_load = pd.DataFrame(boston.data)
dataframe_load.columns = boston.feature_names 
data_label = boston.target

dataframe  = dataframe_load.assign(LABEL=data_label)

columns_name = dataframe.columns
columns_number = len(columns_name)

data  = dataframe.values[:,0:columns_number-1]
label = dataframe.values[:,columns_number-1]

data_df = pd.DataFrame(data=data,columns=columns_name[0:columns_number-1])
label_df = pd.DataFrame(data=label,columns=[columns_name[columns_number-1]])

DATAFRAME_JSON = dataframe.to_json(orient='split')
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
DATA_TEST_DF_JSON = data_df.to_json(orient='split')
LABEL_TEST_DF_JSON = label_df.to_json(orient='split')
IS_LABELED_DATA = 'True'

try:
  #**************Preview Data*********************
  result = dataframe.to_html()
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
  #***********************************************
  
  variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
  variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
  variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
  variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
  variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
  variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)
  variables.put("IS_LABELED_DATA", IS_LABELED_DATA)
except NameError:
  pass

print("END Load_Boston_Dataset")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
variables.put("PREVIOUS_PA_TASK_NAME", variables.get("PA_TASK_NAME"))
]]>
          </code>
        </script>
      </post>
    </task>
  </taskFlow>
</job>
