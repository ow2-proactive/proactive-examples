<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.10" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Train_Anomaly_Model" onTaskError="continueJobExecution" priority="normal" projectName="6. Train" xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd">
  <description>
    <![CDATA[ Train an anomaly model. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="machine-learning"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
<info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_train_model"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task name="Train_Anomaly_Model">
      <description>
        <![CDATA[ Train an anomaly model. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
      </genericInformation>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Train_Anomaly_Detection")

import pandas as pd
import random
import pickle

  
IS_UNSUPERVIDED_ALGORITHM = variables.get("UNSUPERVISED_ALGORITHM")
DATA_TRAIN_DF_JSON  = variables.get("DATA_TRAIN_DF_JSON")

if IS_UNSUPERVIDED_ALGORITHM == 'True'and DATA_TRAIN_DF_JSON != None:
  ALGORITHM_NAME = variables.get("ALGORITHM_NAME")
  data_train_df = pd.read_json(DATA_TRAIN_DF_JSON, orient='split')
  model = None

  
if IS_UNSUPERVIDED_ALGORITHM  == 'True' and DATA_TRAIN_DF_JSON != None:
  ALGORITHM_NAME = variables.get("ALGORITHM_NAME")
  data_train_df = pd.read_json(DATA_TRAIN_DF_JSON, orient='split') 
  model = None
  
  if ALGORITHM_NAME == 'OneClassSVM':
    from sklearn import svm
    nu_para = variables.get("NU_PARA")
    kernel_para = variables.get("KERNEL_PARA")
    gamma_para = variables.get("GAMMA_PARA")
    model = svm.OneClassSVM(nu=nu_para, kernel=kernel_para, gamma = gamma_para) 
    
  if ALGORITHM_NAME == 'LocalOutlierFactor':
    from sklearn.neighbors import LocalOutlierFactor
    neighbors_para = variables.get("N_NEIGHBORS_PARA")
    n_jobs_para = variables.get("N_JOBS_PARA")
    model = LocalOutlierFactor(n_neighbors=int(neighbors_para), n_jobs=int(n_jobs_para))
  
    
  model.fit(data_train_df.values)  
  model_bin = pickle.dumps(model)
  variables.put("MODEL", model_bin)
  print("END Train_Model")  
  
  print("END Train_Anomaly_Detection")

else:
  print('Please check your ML pipeline')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
    </task>
  </taskFlow>
</job>
