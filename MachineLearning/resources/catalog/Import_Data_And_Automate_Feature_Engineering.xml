<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.13" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Import_Data_And_Automate_Feature_Engineering" onTaskError="continueJobExecution" priority="normal" projectName="2. Input and Output Data" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd">
  <variables>
    <variable name="IMPORT_FROM" value="PA:URL" description="Method/protocol to import the data from the data source." hidden="false" model="PA:LIST(PA:URL,PA:URI,PA:USER_FILE,PA:GLOBAL_FILE)" advanced="false"/>
    <variable name="FILE_PATH" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/pima-indians-diabetes.csv" description="Path or name of the file that contains the dataset." hidden="false" model="$IMPORT_FROM" advanced="false"/>
    <variable name="FILE_DELIMITER" value=";" description="Delimiter to use." hidden="false" advanced="false"/>
    <variable name="LIMIT_OUTPUT_VIEW" value="100" description="Number of rows that will be previewed in the browser to check the encoding results." hidden="false" model="PA:Integer" advanced="false"/>
    <variable name="NATIVE_SCHEDULER" value="" description="Name of the Native Scheduler node source to use when the workflow tasks must be deployed inside a cluster such as SLURM, LSF, etc." group="Resource Management" advanced="true"/>
    <variable name="NATIVE_SCHEDULER_PARAMS" value="" description="Parameters given to the native scheduler (SLURM, LSF, etc) while requesting a ProActive node used to deploy the workflow tasks." group="Resource Management" hidden="false" advanced="true"/>
    <variable name="NODE_ACCESS_TOKEN" value="" description="If not empty, the workflow tasks will be run only on nodes that contains the specified token." group="Resource Management" hidden="false" advanced="true"/>
    <variable name="NODE_SOURCE_NAME" value="" description="If not empty, the workflow tasks will be run only on nodes belonging to the specified node source." group="Resource Management" hidden="false" advanced="true"/>
    <variable name="WORK_DIR" value="." description="Working directory for the data space used to transfer files automatically between the workflow tasks." hidden="true" advanced="false"/>
    <variable name="CONTAINER_PLATFORM" value="docker" description="Container platform used for executing the workflow tasks." group="Container Parameters" hidden="false" model="PA:LIST(no-container,docker,podman,singularity)" advanced="true"/>
    <variable name="CONTAINER_GPU_ENABLED" value="False" description="If True, containers will run based on images containing libraries that are compatible with GPU." hidden="false" group="Container Parameters" model="PA:Boolean" advanced="true"/>
    <variable name="CONTAINER_IMAGE" value="" description="Name of the container image being used." group="Container Parameters" hidden="false" model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/rapidsai,docker://activeeon/nvidia:rapidsai)" advanced="true"/>
  </variables>
  <description>
    <![CDATA[ This workflow provides a complete solution to assist data scientists to successfully load and encode their categorical data.
It currently supports different encoding methods such as Label, OneHot, Dummy, Binary, Base N, Hash and Target.
It also enables:

- Automatic identification of the best-suited method for encoding each categorical column, when no encoding method is selected (Auto mode).
- Data type recognition: identification of the data type of each column (categorical or numerical).
- Creation of summary statistics for each column: missing values, minimum, maximum, average, zeros, and cardinality.
- Editing of the data structure: modification of column information (name, type, category, etc.), deletion of a column, etc.

This workflow can be used:

- Stand-alone such that the results can be saved in the User Data Space or locally.
- In a larger workflow where the results will be sent to the next connected task.

For further information, please check the documentation link. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="machine-learning"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png"/>
<info name="NS" value="$NATIVE_SCHEDULER"/>
<info name="Documentation" value="PML/PMLUserGuide.html#_import_data_interactive"/>
<info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
<info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Import_Data_And_Automate_Feature_Engineering" preciousResult="true">
      <description>
        <![CDATA[ Load data from external sources, detect its features type and perform categorical data encoding. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_import_data_interactive"/>
      </genericInformation>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="data_type_identifier/*"/>
        <files accessMode="transferFromGlobalSpace" includes="templates/*"/>
      </inputFiles>
      <selection>
        <script type="static">
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/check_node_source_name/raw"/>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/machine-learning/resources/Import_Data_And_Automate_Feature_Engineering_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            166.50390625
        </positionTop>
        <positionLeft>
            167.75390625
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2645px;
            height:3500px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-161.50390625px;left:-162.75390625px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_706" style="top: 166.512px; left: 167.758px; z-index: 24;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load data from external sources."><img src="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png" width="20px">&nbsp;<span class="name">Import_Data_And_Automate_Feature_Engineering</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 207.758px; top: 196.512px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill:#a8a095; --darkreader-inline-stroke:none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
