<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.11" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Log_Parser" onTaskError="continueJobExecution" priority="normal" projectName="2. Input and Output Data" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd">
  <variables>
    <variable model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
  </variables>
  <description>
    <![CDATA[ Extracts a group of event templates, whereby raw logs can be structured. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="machine-learning"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/log_parser.png"/>
<info name="Documentation" value="https://www.activeeon.com/public_content/documentation/latest/MLOS/MLOSUserGuide.html#_log_analysis"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task name="Log_Parser">
      <description>
        <![CDATA[ Extracts a group of event templates, whereby raw logs can be structured. ]]>
      </description>
      <variables>
        <variable inherited="false" name="LOG_FILE" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/HDFS_2k.log"/>
        <variable inherited="false" name="PATTERNS_FILE" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/patterns.csv"/>
        <variable inherited="false" name="STRUCTURED_LOG_FILE" value="HTML"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="false" model="PA:Boolean" name="TASK_ENABLED" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/log_parser.png"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import pandas as pd
import numpy as np
import wget
import re
import time as clock
from datetime import datetime, timedelta
from time import gmtime, strftime
from argparse import ArgumentParser
from collections import OrderedDict
import sys, bz2, uuid

TIME_FORMAT = '%H%M%S'
DATE_FORMAT = '%d%m%Y'
PATTERNS_FILE = variables.get("PATTERNS_FILE")
LOG_FILE = variables.get("LOG_FILE")
STRUCTURED_LOG_FILE = variables.get("STRUCTURED_LOG_FILE")

INTERVAL   = 10000
LOG_FILE = wget.download(LOG_FILE)
PATTERN_FILE = PATTERNS_FILE
STRUCTERED_LOG_FILE = STRUCTURED_LOG_FILE
#===================================== Detect the different patterns =================================
print("Reading the Pattern_file")
df_patterns = pd.read_csv(PATTERN_FILE, sep = ';')
df_columns = pd.Series([''])
table = list()
for index, row in df_patterns.iterrows():
  for e in row[2].split(','):
    if e.strip() != '*':
      table.append(e.strip())
table.append('pattern_id')
myList = list(OrderedDict.fromkeys(table))
df_columns = pd.Series(myList)
print("The different patterns included in the Pattern_file were extracted")
#===================================== Parse raw logs =================================   
df_structured_logs = pd.DataFrame(columns = df_columns)
print("Processing " + LOG_FILE)
k = 0
t = clock.time()
#variables = list()
my_dict = OrderedDict()
print("Logs patterns matching is in progress")
with open(LOG_FILE) as infile:
  for line in infile:
    k = k + 1
    if k % INTERVAL == 0:
      elapsed_time = clock.time() - t
      print(str(k) + " " + str(elapsed_time) + "sec " + line)
    for index,variable_name in df_columns.iteritems():
      vide = np.nan
      my_dict.__setitem__(variable_name.strip(),vide)
    for index, row in df_patterns.iterrows():
      p = row[1]
      pattern = re.compile(p, re.IGNORECASE)
      m = pattern.match(line)
      if m:
        #print('Match found: ', m.group())
        i = 0
        for e in row[2].split(','):
          i = i+1
          if e.strip() != '*':
            var = m.group(i)
            if e.strip() == "date":
              if len(e.strip())<8:
                if len(var)==5:
                  idx=3
                elif len(var)==6:
                  idx=4
                str1_split1 = var[:idx]
                str1_split2 = var[idx:]
                tranformed_date =  str1_split1 + '20' + str1_split2
                my_dict.__setitem__(e.strip(),datetime.strptime(tranformed_date, DATE_FORMAT))
              else:
                my_dict.__setitem__(e.strip(),datetime.strptime(var, DATE_FORMAT))
            elif e.strip() == "time":
              my_dict.__setitem__(e.strip(),datetime.strptime(var.strip(), TIME_FORMAT).time())
            else:
              my_dict.__setitem__(e.strip(),repr(var.strip()).strip("0"))
              my_dict.__setitem__('pattern_id', int(row[0]))
        break
    df_inter = pd.DataFrame([my_dict.values()], columns=df_columns)
    df_structured_logs = df_structured_logs.append(df_inter, ignore_index=True)

        
print("All logs were matched")
#===================================== Preview results =================================
STRUCTURED_LOG_FILE=STRUCTURED_LOG_FILE.lower()
if STRUCTURED_LOG_FILE.endswith('csv'):
  result = df_structured_logs.to_csv()
  resultMetadata.put("file.extension", ".csv")
  resultMetadata.put("file.name", result+".csv")
  resultMetadata.put("content.type", "text/csv")
elif STRUCTURED_LOG_FILE.endswith('html'):
  result = df_structured_logs.to_html()
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", result+".html")
  resultMetadata.put("content.type", "text/html") 
else:
  print('Your data is empty')
#===================================== Save the linked variables =================================    
df_json_logs = df_structured_logs.to_json(orient='split').encode()
compressed_data = bz2.compress(df_json_logs)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id: ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(df_json_logs), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)
    
print("Finshed " + LOG_FILE + "PARSING")

with pd.option_context('display.max_colwidth', -1):
  result = df_structured_logs.to_html(escape=False)

css_style="""
table {
  border: 1px solid #999999;
  text-align: center;
  border-collapse: collapse;
  width: 100%; 
}
td {
  border: 1px solid #999999;         
  padding: 3px 2px;
  font-size: 13px;
  border-bottom: 1px solid #999999;
  #border-bottom: 1px solid #FF8C00;  
  border-bottom: 1px solid #0B6FA4;   
}
th {
  font-size: 17px;
  font-weight: bold;
  color: #FFFFFF;
  text-align: center;
  background: #0B6FA4;
  #background: #E7702A;       
  #border-left: 2px solid #999999
  border-bottom: 1px solid #FF8C00;            
}
"""
result = """

            
            
            
            
            
              
              
              
              
            <!DOCTYPE html>
            <html>
              <head>
                <meta charset="UTF-8" />
                <style>{0}</style>
              </head>
              <body>{1}</body></html>
""".format(css_style, result)
result = result.encode('utf-8')
resultMetadata.put("file.extension", ".html")
resultMetadata.put("file.name", "output.html")
resultMetadata.put("content.type", "text/html")

print("END " + __file__)
]]>
            </code>
          </script>
        </scriptExecutable>
        <controlFlow block="none"/>
        <metadata>
          <positionTop>
            433.09375
        </positionTop>
          <positionLeft>
            1051.1875
        </positionLeft>
        </metadata>
      </task>
    </taskFlow>
  </job>
