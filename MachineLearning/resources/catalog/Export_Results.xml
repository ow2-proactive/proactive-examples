<?xml version="1.0" encoding="UTF-8"?>
<job xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="urn:proactive:jobdescriptor:3.9"
	xsi:schemaLocation="urn:proactive:jobdescriptor:3.9 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.9/schedulerjob.xsd"
	name="Export_Results" projectName="2. Input and Output Data" priority="normal"
	onTaskError="continueJobExecution" maxNumberOfExecution="2">
	<description>
    <![CDATA[ Export the results. ]]>
	</description>
	<genericInformation>
		<info name="bucketName" value="machine-learning" />
		<info name="pca.action.icon"
			value="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png" />
		<info name="Documentation"
			value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_machine_learning_bucket" />
		<info name="group" value="public-objects" />
	</genericInformation>
	<taskFlow>
		<task name="Export_Results">
			<description>
        <![CDATA[ Export the results. ]]>
			</description>
			<variables>
				<variable name="OUTPUT_FILE" value="HTML" inherited="false" />
			</variables>
			<genericInformation>
				<info name="task.icon"
					value="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png" />
			</genericInformation>
			<forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre">
				<envScript>
					<script>
						<code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
						</code>
					</script>
				</envScript>
			</forkEnvironment>
			<scriptExecutable>
				<script>
					<code language="cpython">
            <![CDATA[
print("BEGIN Export_Results")

import pandas as pd
import numpy as np

OUTPUT_FILE = variables.get("OUTPUT_FILE")
DATA_TEST_DF_JSON = variables.get("DATA_TEST_DF_JSON")
PREDICT_DATA = variables.get("PREDICT_DATA_JSON")
OUTPUT_FILE=OUTPUT_FILE.lower()

if DATA_TEST_DF_JSON != None and PREDICT_DATA != None: 
  data_test_df  = pd.read_json(DATA_TEST_DF_JSON, orient='split')   
  predict_data  = pd.read_json(PREDICT_DATA, orient='split')    
  frame_prediction = pd.DataFrame(predict_data)    
  prediction_result = data_test_df.assign(predictions=frame_prediction.values)
  prediction_result = prediction_result.sort_index(ascending=True) 
  if OUTPUT_FILE == 'csv':
    result = prediction_result.to_csv()
    resultMetadata.put("file.extension", ".csv")
    resultMetadata.put("file.name", "result.csv")
    resultMetadata.put("content.type", "text/csv")
  elif OUTPUT_FILE == 'html':
    result = prediction_result.to_html()
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "result.html")
    resultMetadata.put("content.type", "text/html")          
  print("END Export_Results")  
else:
  print('It is not possible to export the data')
]]>
					</code>
				</script>
			</scriptExecutable>
			<controlFlow block="none"></controlFlow>
		</task>
	</taskFlow>
</job>
