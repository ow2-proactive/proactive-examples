<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.14" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Fetch_Satellite_Images_From_PEPS" onTaskError="continueJobExecution" priority="normal" tags="imagery,satellite" projectName="Satellite Imagery" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd">
  <description>
    <![CDATA[ Load and return a PEPS dataset including a
'metadata folder' with metadata files and 'images folder' containing satellite images. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="hpc-satellite-imagery"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/peps-logo.png"/>
<info name="Documentation" value="PAIO/PAIOUserGuide.html#_fetch_satellite_images_from_peps"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Fetch_Satellite_Images_From_PEPS">
      <description>
        <![CDATA[ Load and return a PEPS dataset including a
'metadata folder' with metadata files and 'images folder' containing satellite images.

Please access <https://peps.cnes.fr/rocket/#/register> to create a new user account from Peps website.

Please add third party credentials (`USER_NAME_PEPS` and `USER_PASS_PEPS`) in the Scheduling & Orchestration interface → Manage Third-Party Credentials to connect to PEPS. ]]>
      </description>
      <variables>
        <variable advanced="false" description="Defines a town name." hidden="false" inherited="false" name="LOCATION" value="Toulouse"/>
        <variable advanced="false" description="Specifies an instrument on a Sentinel satellite." hidden="false" inherited="false" model="PA:LIST(S1, S2, S2ST, S3)" name="PLATFORM_NAME" value="S1"/>
        <variable advanced="false" description="Limits the search to a Sentinel product type." hidden="false" inherited="false" model="PA:LIST(GRD, SLC, OCN, S2MSI1C)" name="PRODUCT_TYPE" value="GRD"/>
        <variable advanced="false" description="Specifies the search to a Sentinel sensor mode." hidden="false" inherited="false" model="PA:LIST(EW, IW , SM, WV, INS-NOBS, INS-RAW)" name="SENSOR_MODE" value="IW"/>
        <variable advanced="false" description="Determines a start date of the query in the format YYYYMMDD." hidden="false" inherited="false" model="PA:DATETIME(yyyy-MM-dd)" name="START_DATE" value="2015-11-01"/>
        <variable advanced="false" description="Defines an end date of the query in the format YYYYMMDD." hidden="false" inherited="false" model="PA:DATETIME(yyyy-MM-dd)" name="END_DATE" value="2015-12-01"/>
        <variable advanced="false" description="Limits the search to a tile number." hidden="false" inherited="false" name="TILE" value=""/>
        <variable advanced="false" description="Determines the search to a latitude in decimal degrees." hidden="false" inherited="false" name="LATITUDE" value=""/>
        <variable advanced="false" description="Limits the search to a longitude in decimal degrees." hidden="false" inherited="false" name="LONGITUDE" value=""/>
        <variable advanced="false" description="Specifies the path where the data should be downloaded." hidden="false" inherited="false" name="OUTPUT_PATH" value="/tmp/"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/peps-logo.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_satellite_imagery_bucket"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

import sys
import uuid
import json
import time
import shutil
import zipfile
import optparse
import random as r
from datetime import date
from zipfile import ZipFile
from os.path import join, exists, os, isfile


if 'variables' in locals():
  LOCATION      = variables.get("LOCATION") 		 # location
  PLATFORM_NAME    = variables.get("PLATFORM_NAME")        # Collection within theia collections  ----- choices=['S1', 'S2', 'S2ST', 'S3']
  PRODUCT_TYPE  = variables.get("PRODUCT_TYPE")      # GRD, SLC, OCN (for S1) | S2MSI1C S2MSI2A S2MSI2Ap (for S2)
  SENSOR_MODE   = variables.get("SENSOR_MODE")		 # EW, IW , SM, WV (for S1) | INS-NOBS, INS-RAW (for S3)
  START_DATE = variables.get("START_DATE")			 # Start date, fmt('2015-12-22')
  END_DATE = variables.get("END_DATE")				 # End date, fmt('2015-12-23')
  TILE = variables.get("TILE")						 # Sentinel-2 tile number type= string
  LATITUDE = variables.get("LATITUDE")               # Latitude in decimal degrees
  LONGITUDE = variables.get("LONGITUDE")             # Longitude in decimal degrees
  EMAIL = credentials.get("USER_NAME_PEPS")              # User email
  PASSWD = credentials.get("USER_PASS_PEPS")              # User password
  OUTPUT_PATH = variables.get("OUTPUT_PATH")         # Folder output path


PLATFORM_NAME =   PLATFORM_NAME.upper()
PRODUCT_TYPE  = PRODUCT_TYPE.upper()
SENSOR_MODE   =  SENSOR_MODE.upper()

if LOCATION == "": LOCATION = None
if TILE == "": TILE = None
LATITUDE = None if LATITUDE == "" else float(LATITUDE)
LONGITUDE = None if LONGITUDE == "" else float(LONGITUDE)


NO_DOWNLOAD = False  # Do not download products, just print curl command
LATMIN = None		 # Min latitude in decimal degrees
LATMAX = None		 # Max latitude in decimal degreess
LONMIN = None        # Min longitude in decimal degrees
LONMAX = None        # Max longitude in decimal degrees
ORBIT = None         # Orbit Path number # type int
SEARCH_JSON_FILE = None
WINDOWS = False

# Get an unique ID
ID = str(uuid.uuid4())

# Define the current 'dataset_path'
os.getcwd() if OUTPUT_PATH == "" else os.chdir(OUTPUT_PATH)

dataset_path = join(OUTPUT_PATH, ID, 'dataset')
output_path = join(OUTPUT_PATH, ID, 'peps')
output_path_metadata = join(OUTPUT_PATH, ID, 'peps', 'metadata')

os.makedirs(dataset_path, exist_ok=True)
os.makedirs(output_path, exist_ok=True)
os.makedirs(output_path_metadata, exist_ok=True)

print('The path input PEPS dataset', dataset_path)
print('The path output PEPS dataset', output_path)

class OptionParser (optparse.OptionParser):

    def check_required(self, opt):
        option = self.get_option(opt)

        # Assumes the option's 'default' is set to None!
        if getattr(self.values, option.dest) is None:
            self.error("%s option not supplied" % option)


###########################################################################
def check_rename(tmpfile, prodsize):
    print(os.path.getsize(tmpfile), prodsize)
    if os.path.getsize(tmpfile) != prodsize:
        with open(tmpfile) as f_tmp:
            try:
                tmp_data = json.load(f_tmp)
                print("Result is a json file (might come from a wrong password file)")
                print(tmp_data)
                sys.exit(-1)
            except ValueError:
                print("\ndownload was not complete, tmp file removed")
                os.remove(tmpfile)
                pass
    else:
        os.rename("%s" % tmpfile, "%s/%s.zip" % (dataset_path, prod))
        print("product saved as : %s/%s.zip" % (dataset_path, prod))

###########################################################################

def parse_catalog(SEARCH_JSON_FILE):
    # Filter catalog result
    with open(SEARCH_JSON_FILE) as data_file:
        data = json.load(data_file)

    if 'ErrorCode' in data:
        print(data['ErrorMessage'])
        sys.exit(-2)

    # Sort data
    download_dict = {}
    storage_dict = {}
    size_dict = {}
    if len(data["features"])>0:
        for i in range(len(data["features"])):
            prod = data["features"][i]["properties"]["productIdentifier"]
            print(prod, data["features"][i]["properties"]["storage"]["mode"])
            feature_id = data["features"][i]["id"]
            try:
                storage = data["features"][i]["properties"]["storage"]["mode"]
                platform = data["features"][i]["properties"]["platform"]
                resourceSize = int(data["features"][i]["properties"]["resourceSize"])
                # recup du numero d'orbite
                orbitN = data["features"][i]["properties"]["orbitNumber"]
                if platform == 'S1A':
                    # calcul de l'orbite relative pour Sentinel 1A
                    relativeOrbit = ((orbitN - 73) % 175) + 1
                elif platform == 'S1B':
                    # calcul de l'orbite relative pour Sentinel 1B
                    relativeOrbit = ((orbitN - 27) % 175) + 1

            # print data["features"][i]["properties"]["productIdentifier"],data["features"][i]["id"],data["features"][i]["properties"]["startDate"],storage

                if ORBIT is not None:
                    if platform.startswith('S2'):
                        if prod.find("_R%03d" % ORBIT) > 0:
                            download_dict[prod] = feature_id
                            storage_dict[prod] = storage
                            size_dict[prod] = resourceSize
                    elif platform.startswith('S1'):
                        if relativeOrbit == ORBIT:
                            download_dict[prod] = feature_id
                            storage_dict[prod] = storage
                            size_dict[prod] = resourceSize
                else:
                    download_dict[prod] = feature_id
                    storage_dict[prod] = storage
                    size_dict[prod] = resourceSize
            except:
                pass
    else:
        print(">>> no product corresponds to selection criteria")
        sys.exit(-1)

    return(prod, download_dict, storage_dict, size_dict)



if SEARCH_JSON_FILE is None or SEARCH_JSON_FILE == "":
    SEARCH_JSON_FILE = 'search.json'

if TILE is None:
    if LOCATION is None:
        if LATITUDE is None or LONGITUDE is None:
            if (LATMIN is None) or (LONMIN is None) or (LATMAX is None) or (LONMAX is None):
                print("provide at least a point or rectangle or tile number")
                sys.exit(-1)
            else:
                geom = 'rectangle'
        else:
            if (LATMIN is None) and (LONMIN is None) and (LATMAX is None) and (LONMAX is None):
                geom = 'point'
            else:
                print("please choose between point and rectangle, but not both")
                sys.exit(-1)
    else:
        if (LATMIN is None) and (LONMIN is None) and (LATMAX is None) and (LONMAX is None) and (LATITUDE is None) or (LONGITUDE is None):
            geom = 'LOCATION'
        else:
            print("please choose location and coordinates, but not both")
            sys.exit(-1)

# geometric parameters of catalog request

if TILE is not None:
    if TILE.startswith('T') and len(TILE)==6:
        tileid = TILE[1:6]
    elif len(TILE)==5:
        tileid = TILE[0:5]
    else:
        print("tile name is ill-formated : 31TCJ or T31TCJ are allowed")
        sys.exit(-4)
    query_geom="tileid=%s"%(tileid)
elif geom == 'point':
    query_geom = 'LATITUDE=%f\&LONGITUDE=%f' % (LATITUDE, LONGITUDE)
elif geom == 'rectangle':
    query_geom = 'box={LONMIN},{LATMIN},{LONMAX},{LATMAX}'.format(
        LATMIN=LATMIN, LATMAX=LATMAX, LONMIN=LONMIN, LONMAX=LONMAX)
elif geom == 'LOCATION':
    query_geom = "q=%s" % LOCATION

# date parameters of catalog request
if START_DATE is not None:
    START_DATE = START_DATE
    if END_DATE is not None:
        END_DATE = END_DATE
    else:
        END_DATE = date.today().isoformat()

# special case for Sentinel-2

if PLATFORM_NAME == 'S2':
    if START_DATE >= '2016-12-05':
        print("**** products after '2016-12-05' are stored in Tiled products collection")
        print("**** please use option -c S2ST")
    elif END_DATE >= '2016-12-05':
        print("**** products after '2016-12-05' are stored in Tiled products collection")
        print("**** please use option -c S2ST to get the products after that date")
        print("**** products before that date will be downloaded")

if PLATFORM_NAME == 'S2ST':
    if END_DATE < '2016-12-05':
        print("**** products before '2016-12-05' are stored in non-tiled products collection")
        print("**** please use option -c S2")
    elif START_DATE < '2016-12-05':
        print("**** products before '2016-12-05' are stored in non-tiled products collection")
        print("**** please use option -c S2 to get the products before that date")
        print("**** products after that date will be downloaded")


# ====================
# search in catalog
# ====================
if (PRODUCT_TYPE == "") and (SENSOR_MODE == ""):
    search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500' % (
        SEARCH_JSON_FILE, PLATFORM_NAME, query_geom, START_DATE, END_DATE)
else:
    search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500\&productType=%s\&sensorMode=%s' % (
        SEARCH_JSON_FILE, PLATFORM_NAME, query_geom, START_DATE, END_DATE, PRODUCT_TYPE, SENSOR_MODE)

if WINDOWS :
    search_catalog = search_catalog.replace('\&','^&')

print(search_catalog)
os.system(search_catalog)
time.sleep(5)

prod, download_dict, storage_dict, size_dict = parse_catalog(SEARCH_JSON_FILE)


# ====================
# Download
# ====================

if len(download_dict) == 0:
    print("No product matches the criteria")
else:
    # first try for the products on tape
    if dataset_path == None:
        dataset_path = os.getcwd()

    for prod in list(download_dict.keys()):
        file_exists = os.path.exists(("%s/%s.SAFE") % (dataset_path, prod)
                                     ) or os.path.exists(("%s/%s.zip") % (dataset_path, prod))
        if (not(NO_DOWNLOAD) and not(file_exists)):
            if storage_dict[prod] == "tape":
                tmticks = time.time()
                tmpfile = ("%s/tmp_%s.tmp") % (dataset_path, tmticks)
                print("\nStage tape product: %s" % prod)
                get_product = 'curl -o %s -k -u "%s:%s" https://peps.cnes.fr/resto/collections/%s/%s/download/?issuerId=peps &>/dev/null' % (
                    tmpfile, EMAIL, PASSWD, PLATFORM_NAME, download_dict[prod])
                os.system(get_product)
                if os.path.exists(tmpfile):
                    os.remove(tmpfile)

    NbProdsToDownload = len(list(download_dict.keys()))
    print("##########################")
    print("%d  products to download" % NbProdsToDownload)
    print("##########################")
    while (NbProdsToDownload > 0):
       # redo catalog search to update disk/tape status
        if (PRODUCT_TYPE == "") and (SENSOR_MODE == ""):
            search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500' % (
                SEARCH_JSON_FILE, PLATFORM_NAME, query_geom, START_DATE, END_DATE)
        else:
            search_catalog = 'curl -k -o %s https://peps.cnes.fr/resto/api/collections/%s/search.json?%s\&startDate=%s\&completionDate=%s\&maxRecords=500\&productType=%s\&sensorMode=%s' % (
                SEARCH_JSON_FILE, PLATFORM_NAME, query_geom, START_DATE, END_DATE, PRODUCT_TYPE, SENSOR_MODE)

        if WINDOWS :
            search_catalog = search_catalog.replace('\&','^&')

        os.system(search_catalog)
        time.sleep(2)

        prod, download_dict, storage_dict, size_dict = parse_catalog(SEARCH_JSON_FILE)

        NbProdsToDownload = 0
        # download all products on disk
        for prod in list(download_dict.keys()):
            file_exists = os.path.exists(("%s/%s.SAFE") % (dataset_path, prod)) or os.path.exists(("%s/%s.zip") % (dataset_path, prod))
            if (not(NO_DOWNLOAD) and not(file_exists)):
                if storage_dict[prod] == "disk":
                    tmticks = time.time()
                    tmpfile = ("%s/tmp_%s.tmp") % (dataset_path, tmticks)
                    print("\nDownload of product : %s" % prod)
                    get_product = 'curl -o %s -k -u "%s:%s" https://peps.cnes.fr/resto/collections/%s/%s/download/?issuerId=peps' % (
                        tmpfile, EMAIL, PASSWD, PLATFORM_NAME, download_dict[prod])
                    print(get_product)
                    os.system(get_product)
                    # check binary product, rename tmp file
                    if not os.path.exists(("%s/tmp_%s.tmp") % (dataset_path, tmticks)):
                        NbProdsToDownload += 1
                    else:
                         check_rename(tmpfile, size_dict[prod])

            elif file_exists:
                print("%s already exists" % prod)

        # download all products on tape
        for prod in list(download_dict.keys()):
            file_exists = os.path.exists(("%s/%s.SAFE") % (dataset_path, prod)
                                         ) or os.path.exists(("%s/%s.zip") % (dataset_path, prod))
            if (not(NO_DOWNLOAD) and not(file_exists)):
                if storage_dict[prod] == "tape" or storage_dict[prod] == "staging" :
                    NbProdsToDownload += 1

        if NbProdsToDownload > 0:
            print("##############################################################################")
            print("%d remaining products are on tape, lets's wait 1 minute before trying again" % NbProdsToDownload)
            print("##############################################################################")
            time.sleep(60)


# List all .zip folders
folder_zip = [i for i in [os.path.relpath(os.path.join(dataset_path, p)) for p in os.listdir(dataset_path)] if i.endswith('.zip')]

# Unzip folders
print('Extracting all the files...')
for file_name in folder_zip:
    with ZipFile(file_name, 'r') as zip:
        zip.printdir()
        # extracting all the files
        print('Unzip File name:', file_name)
        zip.extractall(dataset_path)
print('Finished!')

# List all .safe folders
folder_safe = [i for i in [os.path.relpath(os.path.join(dataset_path, p)) for p in os.listdir(dataset_path)] if i.endswith('.SAFE')]

# Copy and organize files
def folder_copy(image_path, path_dst):
    for root, dirs, files in os.walk(image_path, path_dst):
        os.makedirs(path_dst, exist_ok=True)
        for file in files:
            fullpath = join(root, file)
            shutil.copy(fullpath, path_dst)
            #print('Image Name:', fullpath)
            print('Image Name:', join(path_dst, file))

# Looking for the "measurement" and  "IMG_DATA" directories (S1 and S2 sensors)
def folder_search():
    print('Copying the images to the peps directory...')
    for foldername in folder_safe:
        for path, dirs, filename in os.walk(foldername): #omit files, loop through later
            for dirname in dirs:
                fullpath = os.path.join(path, dirname)
                if "measurement" in dirname:
                    path_dst = os.path.join(output_path, 'measurement')
                    folder_copy(fullpath, path_dst)
                if "IMG_DATA" in dirname:
                    path_dst = os.path.join(output_path, 'IMG_DATA')
                    folder_copy(fullpath, path_dst)
    print('Finished!')

# Searching for metadata files
def metadata_search(output_path_metadata, folder_safe):
    print('Searching for metadata files...')
    for file_xml in folder_safe:
        file_rename = r.randint(0,9999)
        for fn in os.listdir(file_xml):
            if fn.endswith(('.xml')):
                shutil.copy(os.path.join(file_xml,fn), os.path.join(output_path_metadata, fn))
                new_file_rename =  str(file_rename) + '_' +  fn
                os.rename(os.path.join(output_path_metadata, fn), os.path.join(output_path_metadata, new_file_rename))
                print('Metadata Name:', join(output_path_metadata, new_file_rename))
    print('Finished')

# Call folder_search function
folder_search()

# Call  metadata_search function
metadata_search(output_path_metadata, folder_safe)

# Remove the "dataset_path" directory
shutil.rmtree(dataset_path)
while os.path.exists(dataset_path):
  pass
print('Remove all directory in the', dataset_path)
print('Finished!')


if 'variables' in locals():
	variables.put("DATASET_PATH", output_path)

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            149.5625
        </positionTop>
        <positionLeft>
            388.46875
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2506px;
            height:3088px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-144.5625px;left:-383.46875px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_266" style="top: 149.562px; left: 388.469px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load and return a PEPS dataset including a
'metadata folder' with metadata files and 'images folder' containing satellite images.

Please access https://peps.cnes.fr/rocket/#/register to create a new user account from Peps website.

Please add third party credentials (USER_NAME_PEPS and USER_PASS_PEPS) in the Scheduling &amp; Orchestration interface → Manage Third-Party Credentials to connect to PEPS."><img src="/automation-dashboard/styles/patterns/img/wf-icons/peps-logo.png" width="20px">&nbsp;<span class="name">Fetch_Satellite_Images_From_PEPS</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 478.5px; top: 180px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
