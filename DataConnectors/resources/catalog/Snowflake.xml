<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.14" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd"  name="Snowflake" tags="Data Connectors,Snowflake,Data Warehouse" projectName="4. Cloud" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="USER" value="my_user" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="Data Warehouse user name" />
    <variable name="ACCOUNT" value="xy12345.east-us-2.azure" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="The name of your account (provided by Snowflake)" />
    <variable name="WAREHOUSE" value="my_warehouse" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="The warehouse name" />
    <variable name="DATABASE" value="my_user" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="Data Warehouse user name" />
    <variable name="SCHEMA" value="my_schema" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="The name of the default schema to use for the database. After login, you can use the SQL instruction &lt;b&gt;&lt;i&gt;USE SCHEMA&lt;/i&gt;&lt;/b&gt; to change the schema" />
    <variable name="ROLE" value="SYSADMIN" model="PA:LIST(SYSADMIN,ACCOUNTADMIN,PUBLIC,SECURITYADMIN)" group="Snowflake Connection" description="The name of the default role to use. After login, you can use the SQL instruction &lt;b&gt;&lt;i&gt;USE ROLE&lt;/i&gt;&lt;/b&gt; to change the role"/>
    <variable name="PROTOCOL" value="https" model="PA:LIST(https,http)" group="Snowflake Connection" description="The protocol used for the connection. Default value is https"/>
    <variable name="CREDENTIALS_KEY" value="snowflake://${USER}@${ACCOUNT}:${WAREHOUSE}" model="PA:Credential" group="Snowflake Connection" description="Third-party credential storing the password associated with the given user name"/>
  </variables>
  <description>
    <![CDATA[ Workflow template composed of two tasks to import data from (or export data to) Snowflake cloud Data Warehouse. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="data-connectors"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/snowflake.png"/>
    <info name="Documentation" value="user/ProActiveUserGuide.html#_snowflake"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Export_to_Snowflake" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ This task allows to export data to Snowflake cloud Data Warehouse.
It requires the following third-party credential: {key: snowflake://<user>@<account>:<warehouse>, value: SNOWFLAKE_PASSWORD}. Please refer to the User documentation to learn how to add third-party credentials.]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True" group="Docker Parameters" description="If true, the workflow tasks will be executed inside a docker container" advanced="true"/>
        <variable inherited="true" name="DOCKER_IMAGE" value="activeeon/dlm3" group="Docker Parameters" description="Name of the docker image used to execute the task" advanced="true"/>
        <variable inherited="true" name="USER" value="my_user" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="Data Warehouse user name" />
        <variable inherited="true" name="ACCOUNT" value="xy12345.east-us-2.azure" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="The name of your account (provided by Snowflake)" />
        <variable inherited="true" name="WAREHOUSE" value="my_warehouse" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="The warehouse name" />
        <variable inherited="true" name="DATABASE" value="my_user" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="Data Warehouse user name" />
        <variable inherited="true" name="SCHEMA" value="my_schema" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="The name of the default schema to use for the database. After login, you can use the SQL instruction &lt;b&gt;&lt;i&gt;USE SCHEMA&lt;/i&gt;&lt;/b&gt; to change the schema" />
        <variable inherited="true" name="ROLE" value="SYSADMIN" model="PA:LIST(SYSADMIN,ACCOUNTADMIN,PUBLIC,SECURITYADMIN)" group="Snowflake Connection" description="The name of the default role to use. After login, you can use the SQL instruction &lt;b&gt;&lt;i&gt;USE ROLE&lt;/i&gt;&lt;/b&gt; to change the role"/>
        <variable inherited="true" name="PROTOCOL" value="https" model="PA:LIST(https,http)" group="Snowflake Connection" description="The protocol used for the connection. Default value is https"/>
        <variable inherited="true" name="CREDENTIALS_KEY" value="snowflake://${USER}@${ACCOUNT}:${WAREHOUSE}" model="PA:Credential" group="Snowflake Connection" description="Third-party credential storing the password associated with the given user name"/>
        <variable name="TABLE" value="my_table" model="PA:NOT_EMPTY_STRING" group="Snowflake Parameters" inherited="false" description="The name of the table where data will be inserted"/>
        <variable name="INPUT_FILE" value="my_file" model="PA:NOT_EMPTY_STRING" group="Snowflake Parameters" inherited="false" description=" The relative path of a CSV file in the Global Data Space that contains data to be exported to Snowflake."/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/snowflake.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_snowflake"/>
      </genericInformation>
      <inputFiles>
        <files  includes="$INPUT_FILE" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_docker_vars/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
from sqlalchemy import create_engine
from snowflake.sqlalchemy import URL

print("BEGIN exporting data to snowflake cloud Data Warehouse")

CREDENTIALS_KEY_MSG = "snowflake://<user>@<account>:<warehouse>"

USER = variables.get("USER")
ACCOUNT = variables.get("ACCOUNT")
WAREHOUSE = variables.get("WAREHOUSE")
DATABASE = variables.get("DATABASE")
SCHEMA = variables.get("SCHEMA")
ROLE = variables.get("ROLE")
PROTOCOL = variables.get("PROTOCOL")


# This key is used for getting the password from 3rd party credentials.
CREDENTIALS_KEY = variables.get("CREDENTIALS_KEY")
PASSWORD = credentials.get(CREDENTIALS_KEY)

SQL_TABLE = variables.get("TABLE")
INPUT_FILE = variables.get("INPUT_FILE")

if not USER:
    print("ERROR: USER variable is not provided by the user.")
    sys.exit(1)
if not ACCOUNT:
    print("ERROR: ACCOUNT variable is not provided by the user.")
    sys.exit(1)
if not WAREHOUSE:
    print("ERROR: WAREHOUSE variable is not provided by the user.")
    sys.exit(1)    
if not DATABASE:
    print("ERROR: DATABASE variable is not provided by the user.")
    sys.exit(1)
if not SCHEMA:
    print("ERROR: SCHEMA variable is not provided by the user.")
    sys.exit(1)
if not PASSWORD:
    print('ERROR: Please add your database password to 3rd-party credentials in the scheduler-portal under the key :"{0}"'.format(CREDENTIALS_KEY_MSG))
    sys.exit(1)
if not INPUT_FILE:
    print("ERROR: INPUT_FILE variable is not provided by the user.")
    sys.exit(1)
if not SQL_TABLE:
    print("ERROR: TABLE variable is not provided by the user.")
    sys.exit(1)

print("INSERTING DATA IN SNOWFLAKE CLOUD DATA WAREHOUSE...")
print('USER= ', USER)
print('ACCOUNT= ', ACCOUNT)
print('WAREHOUSE= ', WAREHOUSE)
print('DATABASE= ', DATABASE)
print('SCHEMA= ', SCHEMA)
print('ROLE= ', ROLE)
print('PROTOCOL= ', PROTOCOL)
print('TABLE= ', SQL_TABLE)

# Please refer to SQLAlchemy doc for more info about snowflake urls.
#https://docs.snowflake.com/en/user-guide/python-connector-api.html
#https://docs.snowflake.com/en/user-guide/sqlalchemy.html#connection-parameters
engine = create_engine(URL(
    	user = USER,
        password = PASSWORD,
        #'<your_account_name>.<region_id>.<cloud>' (e.g. 'xy12345.east-us-2.azure').
        account = ACCOUNT,
        warehouse= WAREHOUSE,
        database = DATABASE,
    	schema = SCHEMA,
        role = ROLE,
        protocol = PROTOCOL
    )
)

connection = engine.connect()
try:
    sql = 'use role {}'.format('SYSADMIN')
    connection.execute(sql)
    
    #sql = 'drop table if exists TABLE'
    #connection.execute(sql)

    #sql = 'create table TABLE(column1 type1, column2 type2)'
    #connection.execute(sql)

    sql = 'drop stage if exists data_stage'
    connection.execute(sql)

    sql = 'create stage data_stage file_format = (type = "csv" field_delimiter = "," skip_header = 1)'
    connection.execute(sql)
    
    csv_file_path = os.path.abspath(INPUT_FILE)
    sql = "PUT file://" + csv_file_path + " @DATA_STAGE auto_compress=true"
    connection.execute(sql)
    
    sql = 'copy into diabetes from @DATA_STAGE/pima-indians-diabetes.csv.gz file_format = (type = "csv" field_delimiter = "," skip_header = 1)' \
          'ON_ERROR = "ABORT_STATEMENT" '
    connection.execute(sql)
    
finally:
    connection.close()
    engine.dispose()

print("END exporting data")
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            297.5
        </positionTop>
        <positionLeft>
            433.984375
        </positionLeft>
      </metadata>
    </task>
    <task name="Import_from_Snowflake" 
    
    
    
    preciousResult="true" 
    fork="true">
      <description>
        <![CDATA[ This task allows to import data from MySQL database.
It requires the following third-party credential:  {key: snowflake://<user>@<account>:<warehouse>, value: SNOWFLAKE_PASSWORD}. Please refer to the User documentation to learn how to add third-party credentials.]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True" group="Docker Parameters" description="If true, the workflow tasks will be executed inside a docker container" advanced="true"/>
        <variable inherited="true" name="DOCKER_IMAGE" value="activeeon/dlm3" group="Docker Parameters" description="Name of the docker image used to execute the task" advanced="true"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True" group="Docker Parameters" description="If true, the workflow tasks will be executed inside a docker container" advanced="true"/>
        <variable inherited="true" name="DOCKER_IMAGE" value="activeeon/dlm3" group="Docker Parameters" description="Name of the docker image used to execute the task" advanced="true"/>
        <variable inherited="true" name="USER" value="my_user" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="Data Warehouse user name" />
        <variable inherited="true" name="ACCOUNT" value="xy12345.east-us-2.azure" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="The name of your account (provided by Snowflake)" />
        <variable inherited="true" name="WAREHOUSE" value="my_warehouse" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="The warehouse name" />
        <variable inherited="true" name="DATABASE" value="my_user" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="Data Warehouse user name" />
        <variable inherited="true" name="SCHEMA" value="my_schema" model="PA:NOT_EMPTY_STRING" group="Snowflake Connection" description="The name of the default schema to use for the database. After login, you can use the SQL instruction &lt;b&gt;&lt;i&gt;USE SCHEMA&lt;/i&gt;&lt;/b&gt; to change the schema" />
        <variable inherited="true" name="ROLE" value="SYSADMIN" model="PA:LIST(SYSADMIN,ACCOUNTADMIN,PUBLIC,SECURITYADMIN)" group="Snowflake Connection" description="The name of the default role to use. After login, you can use the SQL instruction &lt;b&gt;&lt;i&gt;USE ROLE&lt;/i&gt;&lt;/b&gt; to change the role"/>
        <variable inherited="true" name="PROTOCOL" value="https" model="PA:LIST(https,http)" group="Snowflake Connection" description="The protocol used for the connection. Default value is https"/>
        <variable inherited="true" name="CREDENTIALS_KEY" value="snowflake://${USER}@${ACCOUNT}:${WAREHOUSE}" model="PA:Credential" group="Snowflake Connection" description="Third-party credential storing the password associated with the given user name"/>
        <variable name="SQL_QUERY" value="select * from my_table" model="PA:NOT_EMPTY_STRING" inherited="false" group="Snowflake Parameters" description="The user's sql query"/>
        <variable name="OUTPUT_FILE" value="" inherited="false" group="Snowflake Parameters" description="Relative path of a file inside the Global Data Space where the query results will be saved in CSV format"/>
        <variable name="OUTPUT_TYPE" value="HTML" inherited="false" group="Snowflake Parameters" model="PA:List(CSV,HTML)" description="Format of the output (CSV or HTML)"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/snowflake.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_snowflake"/>
      </genericInformation>
      <depends>
        <task ref="Export_to_Snowflake"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_docker_vars/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import pandas as pd
import numpy as np
import sys
from sqlalchemy import create_engine
from snowflake.sqlalchemy import URL

print("BEGIN importing data from snowflake cloud Data Warehouse")

CREDENTIALS_KEY_MSG = "snowflake://<user>@<account>:<warehouse>"

USER = variables.get("USER")
ACCOUNT = variables.get("ACCOUNT")
WAREHOUSE = variables.get("WAREHOUSE")
DATABASE = variables.get("DATABASE")
SCHEMA = variables.get("SCHEMA")
ROLE = variables.get("ROLE")
PROTOCOL = variables.get("PROTOCOL")


# This key is used for getting the password from 3rd party credentials.
CREDENTIALS_KEY = variables.get("CREDENTIALS_KEY")
PASSWORD = credentials.get(CREDENTIALS_KEY)

SQL_QUERY = variables.get("SQL_QUERY")
OUTPUT_FILE = variables.get("OUTPUT_FILE")
OUTPUT_TYPE = variables.get("OUTPUT_TYPE")


if not USER:
    print("ERROR: USER variable is not provided by the user.")
    sys.exit(1)
if not ACCOUNT:
    print("ERROR: ACCOUNT variable is not provided by the user.")
    sys.exit(1)
if not WAREHOUSE:
    print("ERROR: WAREHOUSE variable is not provided by the user.")
    sys.exit(1)    
if not DATABASE:
    print("ERROR: DATABASE variable is not provided by the user.")
    sys.exit(1)
if not SCHEMA:
    print("ERROR: SCHEMA variable is not provided by the user.")
    sys.exit(1)
if not PASSWORD:
    print('ERROR: Please add your database password to 3rd-party credentials in the scheduler-portal under the key :"{0}"'.format(CREDENTIALS_KEY_MSG))
    sys.exit(1)
if not SQL_QUERY:
    print("ERROR: SQL_QUERY variable is not provided by the user.")
    sys.exit(1)

print("EXECUTING QUERY...")
print('USER= ', USER)
print('ACCOUNT= ', ACCOUNT)
print('WAREHOUSE= ', WAREHOUSE)
print('DATABASE= ', DATABASE)
print('SCHEMA= ', SCHEMA)
print('ROLE= ', ROLE)
print('PROTOCOL= ', PROTOCOL)
print('QUERY= ', SQL_QUERY)
if OUTPUT_FILE:
    print('OUTPUT_FILE=' + OUTPUT_FILE)

# Please refer to SQLAlchemy doc for more info about snowflake urls.
#https://docs.snowflake.com/en/user-guide/python-connector-api.html
#https://docs.snowflake.com/en/user-guide/sqlalchemy.html#connection-parameters
engine = create_engine(URL(
    	user = USER,
        password = PASSWORD,
        #'<your_account_name>.<region_id>.<cloud>' (e.g. 'xy12345.east-us-2.azure').
        account = ACCOUNT,
        warehouse= WAREHOUSE,
        database = DATABASE,
    	schema = SCHEMA,
        role = ROLE,
        protocol = PROTOCOL
    )
)
try:
    with engine.connect() as connection, connection.begin():
        #pd.read_sql() can take either a SQL query as a parameter or a table name
        dataframe = pd.read_sql(SQL_QUERY, connection)
        #print(dataframe.to_string())
    
finally:
    connection.close()
    engine.dispose()

print("END exporting data")


#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("background", "#0B6FA4"),
                               ("color", "white")]),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 5px"),
                               ("border-bottom", "1px solid #999999")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                                  ("text-align", "center"),
                                  ("width", "100%"),
                                  ("border", "1px solid #999999")])
]
#******************************************************#
result = ''
if OUTPUT_TYPE == "HTML":
    print('The task result will be previewed in HTML format')
    result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")
else:
    # Write results to the task result in CSV format
    print('The task result will be written in csv file')
    result = dataframe.to_csv(index=False).encode('utf-8')
    resultMetadata.put("file.extension", ".csv")
    resultMetadata.put("file.name", "result.csv")
    resultMetadata.put("content.type", "text/csv")

# If an OUTPUT_FILE path in the dataspace is designated, then write to this file.
if OUTPUT_FILE:
    dataframe.to_csv(path_or_buf=OUTPUT_FILE, index=False)

print("END importing data")
]]>
          </code>
        </script>
      </scriptExecutable>
      <outputFiles>
        <files  includes="$OUTPUT_FILE" accessMode="transferToGlobalSpace"/>
      </outputFiles>
      <metadata>
        <positionTop>
            458.078125
        </positionTop>
        <positionLeft>
            411
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2144px;
            height:2908px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-292.5px;left:-406px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable active-task" id="jsPlumb_1_100" style="top: 297.5px; left: 433.993px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task allows to export data to Snowflake cloud Data Warehouse.
It requires the following third-party credential: {key: snowflake://<user>@<account>:<warehouse>, value: SNOWFLAKE_PASSWORD}. Please refer to the User documentation to learn how to add third-party credentials."><img src="/automation-dashboard/styles/patterns/img/wf-icons/snowflake.png" width="20px">&nbsp;<span class="name">Export_to_Snowflake</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_103" style="top: 458.09px; left: 411.007px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task allows to import data from MySQL database.
It requires the following third-party credential:  {key: snowflake://<user>@<account>:<warehouse>, value: SNOWFLAKE_PASSWORD}. Please refer to the User documentation to learn how to add third-party credentials."><img src="/automation-dashboard/styles/patterns/img/wf-icons/snowflake.png" width="20px">&nbsp;<span class="name">Import_from_Snowflake</span></a></div><svg style="position:absolute;left:470.5px;top:337.5px" width="38.5" height="121" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 120 C -10 70 27.5 50 17.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-0.807083125000001,91.31394750000001 L10.157287076542111,73.18158455184746 L2.072765622244636,77.61334637475761 L-3.543314048700294,70.30173580460283 L-0.807083125000001,91.31394750000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-0.807083125000001,91.31394750000001 L10.157287076542111,73.18158455184746 L2.072765622244636,77.61334637475761 L-3.543314048700294,70.30173580460283 L-0.807083125000001,91.31394750000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 488.5px; top: 328px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 471px; top: 488px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 471px; top: 448px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>