<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.10"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd"
    name="Cassandra" projectName="3. NoSQL"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
    <variable name="CASSANDRA_HOSTNAME" value="localhost" />
    <variable name="CASSANDRA_KEYSPACE" value="" />
    <variable name="CASSANDRA_PORT" value="9042" />
  </variables>
  <description>
    <![CDATA[ Import data from (or export data to) Cassandra database. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="data-connectors"/>
    <info name="Documentation" value="http://doc.activeeon.com/latest/user/ProActiveUserGuide.html#_nosql"/>
    <info name="group" value="public-objects"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/cassandra.png"/>
  </genericInformation>
  <taskFlow>
    <task name="Import_from_Cassandra">
      <description>
        <![CDATA[ This task allows importing data from Cassandra.
The task requires the following third-party credentials: CASSANDRA_USERNAME and CASSANDRA_PASSWORD. Please refer to the User documentation to learn how to add third-party credentials.
It uses the following variables:
$CASSANDRA_DATABASE (required) the database to use. It is created if it does not exist
$CASSANDRA_COLLECTION (required) the collection to use. It is created if it does not exist
$CASSANDRA_OUPUT (optional) is a relative path in the data space used to save the results in a CSV file.
The imported data is also exported in a JSON format using the variable $DATAFRAME_JSON. ]]>
      </description>
      <variables>
        <variable name="LABEL" value="" inherited="false" />
        <variable name="CASSANDRA_QUERY" value="" inherited="false" />
        <variable name="CASSANDRA_OUTPUT" value="" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/cassandra.png"/>
        <info name="task.documentation" value="http://doc.activeeon.com/latest/user/ProActiveUserGuide.html#_nosql"/>
      </genericInformation>
      <depends>
        <task ref="Export_to_Cassandra"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3'
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import pandas as pd
import numpy as np
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
from cassandra.query import dict_factory

print("BEGIN Import_Data from CASSANDRA ...")
PORT = 9042

if variables.get("CASSANDRA_HOSTNAME"):
    HOSTNAME = variables.get("CASSANDRA_HOSTNAME")
else:
    print("CASSANDRA_HOSTNAME not defined by the user.")
    sys.exit(1)
if variables.get("CASSANDRA_PORT"):
    PORT = variables.get("CASSANDRA_PORT")
else:
    
    print("CASSANDRA_PORT not defined by the user. Using the default value:" , PORT)
if variables.get("CASSANDRA_KEYSPACE"): 
    KEYSPACE = variables.get("CASSANDRA_KEYSPACE")
else:
    print("CASSANDRA_KEYSPACE not defined by the user.")
    sys.exit(1)
if credentials.get("CASSANDRA_USERNAME") is not None and credentials.get("CASSANDRA_PASSWORD") is not None:
    CASSANDRA_USERNAME = credentials.get("CASSANDRA_USERNAME")
    CASSANDRA_PASSWORD=credentials.get("CASSANDRA_PASSWORD")
else:
    print("You first need to add third-party credentials (CASSANDRA_USERNAME and CASSANDRA_PASSWORD) for the database in the scheduler-portal.")
    sys.exit(1)
if variables.get("CASSANDRA_QUERY"):
    QUERY = variables.get("CASSANDRA_QUERY")
else:
    print("CASSANDRA_QUERY not defined by the user.")
    sys.exit(1)
if variables.get("CASSANDRA_OUTPUT"):
    CASSANDRA_OUTPUT = variables.get("CASSANDRA_OUTPUT")

IS_LABELED_DATA = 'False'
try:
    LABEL = variables.get("LABEL")
    if LABEL:
        IS_LABELED_DATA='True'
except NameError:
    pass

########

def pandas_factory(colnames, rows):
    return pd.DataFrame(rows, columns=colnames)
auth_provider = PlainTextAuthProvider(
                    username=CASSANDRA_USERNAME, password=CASSANDRA_PASSWORD)
cluster = Cluster(contact_points=[HOSTNAME], port=PORT, auth_provider=auth_provider)
session = cluster.connect(KEYSPACE)
session.row_factory = pandas_factory
#10000000 needed for large queries, otherwise driver will do pagination. Default is 50000.
session.default_fetch_size = 10000000

print("EXECUTING QUERY...")
print('CASSANDRA_HOSTNAME='+HOSTNAME)
print('CASSANDRA_PORT=', PORT)
print('CASSANDRA_KEYSPACE='+KEYSPACE)
print('CASSANDRA_QUERY='+QUERY)
if CASSANDRA_OUTPUT:
    print('CASSANDRA_OUTPUT='+CASSANDRA_OUTPUT)

rows = session.execute(QUERY)
dataframe = rows._current_rows

columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
    label_index= dataframe.columns.get_loc(LABEL)
    data_indices=[x for i,x in enumerate(range(columns_number)) if i!=label_index]
    data  = dataframe.values[:,data_indices]
    label = dataframe.values[:,label_index]
    data_df = pd.DataFrame(data=data,columns=columns_name[data_indices])
    label_df = pd.DataFrame(data=label,columns=[columns_name[label_index]])
    LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
    LABEL_TEST_DF_JSON = label_df.to_json(orient='split')  
else:
    data = dataframe.values
    data_df = pd.DataFrame(data=data,columns=columns_name)


COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
DATA_TEST_DF_JSON = data_df.to_json(orient='split')
DATAFRAME_JSON = dataframe.to_json(orient='split')


try:
    if IS_LABELED_DATA == 'True':
        variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
        variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)
        dataframe=data_df.join(label_df)
    
    variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
    variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
    variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
    variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
    variables.put("IS_LABELED_DATA", IS_LABELED_DATA)
    
    # Write results to the task result in CSV format
    result = dataframe.to_csv(index=False).encode('utf-8')
    resultMetadata.put("file.extension", ".csv")
    resultMetadata.put("file.name", "result.csv")
    resultMetadata.put("content.type", "text/csv")
    
    # If an CASSANDRA_OUTPUT path in the dataspace is designated, then write to this file.
    if CASSANDRA_OUTPUT:
         dataframe.to_csv(path_or_buf=CASSANDRA_OUTPUT, index=False)
except NameError:
    pass

#***********************************************
print("END Import_Data")
]]>
          </code>
        </script>
      </scriptExecutable>
      <outputFiles>
        <files  includes="$CASSANDRA_OUTPUT" accessMode="transferToGlobalSpace"/>
      </outputFiles>
    </task>
    <task name="Export_to_Cassandra">
      <description>
        <![CDATA[ This task allows exporting data to Cassandra.
The task requires the following third-party credentials: CASSANDRA_USERNAME and CASSANDRA_PASSWORD. Please refer to the User documentation to learn how to add third-party credentials.
It requires the following variables:
$CASSANDRA_TABLE (required) Data is stored in tables containing rows of columns, similar to SQL definitions.. It is created if it does not exist
$CASSANDRA_KEY (required) A primary key identifies the location and order of stored data. The primary key is defined when the table is created and cannot be altered.
$CASSANDRA_INPUT (required) is the relative path of the CSV file that contains data to be imported. This variable can:
 - An URL. Valid URL schemes include http, ftp, s3, and file. 
 - A relative path in the data space of a csv file. ]]>
      </description>
      <variables>
        <variable name="CASSANDRA_TABLE" value="" inherited="false" />
        <variable name="PRIMARY_KEY" value="" inherited="false" />
        <variable name="CASSANDRA_INPUT" value="" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/cassandra.png"/>
        <info name="task.documentation" value="http://doc.activeeon.com/latest/user/ProActiveUserGuide.html#_nosql"/>
      </genericInformation>
      <inputFiles>
        <files  includes="$CASSANDRA_INPUT" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3'
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import pandas as pd
import numpy as np
import re
import sys
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
from cassandra.query import dict_factory

print("BEGIN Export_Data to CASSANDRA ...")
PORT = 9042

if variables.get("CASSANDRA_HOSTNAME"):
    HOSTNAME = variables.get("CASSANDRA_HOSTNAME")
else:
    print("CASSANDRA_HOSTNAME not defined by the user.")
    sys.exit(1)
if variables.get("CASSANDRA_PORT"):
    PORT = variables.get("CASSANDRA_PORT")
else:
    
    print("CASSANDRA_PORT not defined by the user. Using the default value:" , PORT)
if variables.get("CASSANDRA_KEYSPACE"): 
    KEYSPACE = variables.get("CASSANDRA_KEYSPACE")
else:
    print("CASSANDRA_KEYSPACE not defined by the user.")
    sys.exit(1)
if credentials.get("CASSANDRA_USERNAME") is not None and credentials.get("CASSANDRA_PASSWORD") is not None:
    CASSANDRA_USERNAME = credentials.get("CASSANDRA_USERNAME")
    CASSANDRA_PASSWORD=credentials.get("CASSANDRA_PASSWORD")
else:
    print("You first need to add third-party credentials (CASSANDRA_USERNAME and CASSANDRA_PASSWORD) for the database in the scheduler-portal.")
    sys.exit(1)
if variables.get("CASSANDRA_TABLE") is not None:
    TABLE = variables.get("CASSANDRA_TABLE")
else:
    print("CASSANDRA_TABLE not defined by the user.")
    sys.exit(1)
if variables.get("CASSANDRA_INPUT"):
    CASSANDRA_INPUT = variables.get("CASSANDRA_INPUT")
else:
    print("CASSANDRA_INPUT not defined by the user.")
    sys.exit(1)
if variables.get("PRIMARY_KEY"):
    PRIMARY_KEY = variables.get("PRIMARY_KEY")
else:
    print("PRIMARY_KEY not defined by the user.")
    sys.exit(1)

IS_LABELED_DATA = 'False'
try:
    LABEL = variables.get("LABEL")
    if LABEL:
        IS_LABELED_DATA='True'
except NameError:
 pass

########

auth_provider = PlainTextAuthProvider(
                    username=CASSANDRA_USERNAME, password=CASSANDRA_PASSWORD)
cluster = Cluster(contact_points=[HOSTNAME], port=PORT, auth_provider=auth_provider)
session = cluster.connect(KEYSPACE)

print("INSERTING DATA IN CASSANDRA...")
print('CASSANDRA_HOSTNAME='+HOSTNAME)
print('CASSANDRA_PORT=', PORT)
print('CASSANDRA_KEYSPACE='+KEYSPACE)
print('CASSANDRA_TABLE=' + TABLE)
print('PRIMARY_KEY=' + PRIMARY_KEY)

dataframe = pd.read_csv(CASSANDRA_INPUT, sep='\t|;|,',index_col=None, engine='python')
column_names = list(dataframe.columns.values) 
column_types= re.sub("\d", "",','.join('{}'.format(*k) for k in zip(dataframe.dtypes))).split(',')
TABLE_HEADER = ',\n'.join('{} {}'.format(*t) for t in zip(column_names, column_types))
CREATE_TABLE = """CREATE TABLE IF NOT EXISTS {0}.{1}({2},
  PRIMARY KEY ({3}));""".format(KEYSPACE, TABLE, TABLE_HEADER, PRIMARY_KEY)

session.execute(CREATE_TABLE)
INSERT_STATEMENT = """ INSERT INTO {0} ({1}) VALUES """.format(TABLE, ','.join(map(str, column_names)))
BATCH_SIZE = dataframe.size
BATCH_QUERY = 'BEGIN BATCH\n'
for row in dataframe.itertuples(index = False):
    BATCH_QUERY += """{0}({1})\n""".format(INSERT_STATEMENT ,','.join(map(str, row)))
BATCH_QUERY += 'APPLY BATCH;'
try:
    session.execute(BATCH_QUERY)
except Exception as e:
    print(e)
    sys.exit(1)
print("END Export_Data")
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
  </taskFlow>
</job>