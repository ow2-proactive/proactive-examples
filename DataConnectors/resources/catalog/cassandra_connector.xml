<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.10"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd"
    name="cassandra_connector" projectName="3. NoSQL Connectors"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
    <variable name="CASSANDRA_HOSTNAME" value="localhost" />
    <variable name="CASSANDRA_PORT" value="9042" />
    <variable name="CASSANDRA_KEYSPACE" value="" />
  </variables>
  <description>
    <![CDATA[ Load data from Cassandra. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="data-connectors"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/cassandra.png"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="import_from_cassandra">
      <description>
        <![CDATA[ Load data from Cassandra.
This task uses "cassandra-driver" as a driver to connect to the database.
The task requires the following third-party credentials : CASSANDRA_USERNAME and CASSANDRA_PASSWORD. Please refer to the User documentation to learn how to add third-party credentials.
It also requires a NoSQL query to fetch data. By default, it will fetch all documents from the specified collection.
The imported data is exported in a JSON format using the variable $DATAFRAME_JSON. ]]>
      </description>
      <variables>
        <variable name="LABEL" value="" inherited="false" />
        <variable name="CASSANDRA_QUERY" value="" inherited="true" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/cassandra.png"/>
      </genericInformation>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <code language="bash">
            <![CDATA[

]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import pandas as pd
import numpy as np
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
from cassandra.query import dict_factory

print("BEGIN Import_Data FROM CASSANDRA ...")


if variables.get("CASSANDRA_HOSTNAME") is not None:
    HOSTNAME = variables.get("CASSANDRA_HOSTNAME")
else:
    print("CASSANDRA_HOSTNAME not defined by the user.")
    sys.exit(1)
if variables.get("CASSANDRA_PORT") is not None:
    PORT = variables.get("CASSANDRA_PORT")
else:
    PORT="27018"
    print("CASSANDRA_PORT not defined by the user. Using the default value:"+PORT)
if variables.get("CASSANDRA_KEYSPACE") is not None:
    KEYSPACE = variables.get("CASSANDRA_KEYSPACE")
else:
    print("CASSANDRA_KEYSPACE not defined by the user.")
    sys.exit(1)
if credentials.get("CASSANDRA_USERNAME") is not None and credentials.get("CASSANDRA_PASSWORD") is not None:
    CASSANDRA_USERNAME = credentials.get("CASSANDRA_USERNAME")
    CASSANDRA_PASSWORD=credentials.get("CASSANDRA_PASSWORD")
else:
    print("You first need to add third-party credentials (CASSANDRA_USERNAME and CASSANDRA_PASSWORD) for the database in the scheduler-portal.")
    sys.exit(1)
if variables.get("CASSANDRA_QUERY") is not None:
    QUERY = variables.get("CASSANDRA_QUERY")
else:
    print("CASSANDRA_QUERY not defined by the user.")
    sys.exit(1)


IS_LABELED_DATA = 'False'
try:
    LABEL = variables.get("LABEL")
    if LABEL:
        IS_LABELED_DATA='True'
except NameError:
 pass


########

def pandas_factory(colnames, rows):
    return pd.DataFrame(rows, columns=colnames)

auth_provider = PlainTextAuthProvider(
                    username=CASSANDRA_USERNAME, password=CASSANDRA_PASSWORD)
cluster = Cluster(contact_points=[HOSTNAME], port=PORT, auth_provider=auth_provider)
session = cluster.connect(KEYSPACE)

        
        
session.row_factory = pandas_factory
#10000000 needed for large queries, otherwise driver will do pagination. Default is 50000.
session.default_fetch_size = 10000000

print("EXECUTING QUERY...")
print('HOSTNAME='+HOSTNAME)
print('PORT='+PORT)
print('KEYSPACE='+KEYSPACE)
print('QUERY='+QUERY)

rows = session.execute(QUERY)
dataframe = rows._current_rows

print(dataframe)

columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
    label_index= dataframe.columns.get_loc(LABEL)
    data_indices=[x for i,x in enumerate(range(columns_number)) if i!=label_index]
    data  = dataframe.values[:,data_indices]
    label = dataframe.values[:,label_index]
    data_df = pd.DataFrame(data=data,columns=columns_name[data_indices])
    label_df = pd.DataFrame(data=label,columns=[columns_name[label_index]])
    LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
    LABEL_TEST_DF_JSON = label_df.to_json(orient='split')  
else:
    data = dataframe.values
    data_df = pd.DataFrame(data=data,columns=columns_name)


COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
DATA_TEST_DF_JSON = data_df.to_json(orient='split')
DATAFRAME_JSON = dataframe.to_json(orient='split')


try:
    if IS_LABELED_DATA == 'True':
        variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
        variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)
        dataframe=data_df.join(label_df)
    
    variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
    variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
    variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
    variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
    variables.put("IS_LABELED_DATA", IS_LABELED_DATA)
except NameError:
    pass

#**************Preview Data*********************
styles = [
  dict(selector="th", props=[("font-weight", "bold"),
                             ("text-align", "center"),
                             ("background", "#0B6FA4"),
                             ("color", "white")]),
  dict(selector="td", props=[("text-align", "right"),
                             ("padding", "3px 5px"),
                             ("border-bottom", "1px solid #999999")]),
  dict(selector="table", props=[("border", "1px solid #999999"),
                                ("text-align", "center"),
                                ("width", "100%"),
                                ("border", "1px solid #999999")])
]
  
result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
resultMetadata.put("file.extension", ".html")
resultMetadata.put("file.name", "output.html")
resultMetadata.put("content.type", "text/html")
#***********************************************
print("END Import_Data")
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
  </taskFlow>
</job>