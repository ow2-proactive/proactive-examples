<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.10"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd"
    name="mysql_connector" projectName="2. SQL"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
    <variable name="MYSQL_HOSTNAME" value="localhost" />
    <variable name="MYSQL_PORT" value="3306" />
    <variable name="MYSQL_DATABASE" value="" />
    <variable name="MYSQL_QUERY" value="" />
  </variables>
  <description>
    <![CDATA[ Load data from a MySQL database. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="data-connectors"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/mysql.png"/>
    <info name="Documentation" value="https://www.activeeon.com/public_content/documentation/latest/user/ProActiveUserGuide.html#_sql"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="import_from_mysql">
      <description>
        <![CDATA[ Load data from a MySQL database.
This task uses the task variable RMDB_DRIVER as a driver to connect to the database. The specified default driver "mysqlconnector" as well as "pymysql" are already provided for this task. To use another driver, make sure you have it properly installed before.
The task requires the following third-party credentials: MYSQL_USERNAME and MYSQL_PASSWORD. Please refer to the User documentation to learn how to add third-party credentials.
It also requires an SQL query or a table name to fetch data from.
The imported data is exported in a JSON format using the variable $DATAFRAME_JSON. ]]>
      </description>
      <variables>
        <variable name="LABEL" value="" inherited="false" />
        <variable name="MYSQL_QUERY" value="" inherited="true" />
        <variable name="RDBMS_DRIVER" value="mysqlconnector" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/mysql.png"/>
        <info name="Documentation" value="https://www.activeeon.com/public_content/documentation/latest/user/ProActiveUserGuide.html#_sql"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
# In the Java Home location field, use the value: "/usr" to force using the JRE provided in the docker image below (Recommended).
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import pandas as pd
import numpy as np
from sqlalchemy import create_engine
import sys
  
RDBMS_NAME = 'mysql'
RDBMS_DRIVER = variables.get("RDBMS_DRIVER")
print("BEGIN Import_Data FROM " + RDBMS_NAME + " database using " + variables.get("RDBMS_DRIVER") + " connector")


if variables.get("MYSQL_HOSTNAME") is not None:
    HOSTNAME = variables.get("MYSQL_HOSTNAME")
else:
    print("MYSQL_HOSTNAME not defined by the user.")
    sys.exit(1)
if variables.get("MYSQL_PORT") is not None:
    PORT = variables.get("MYSQL_PORT")
else:
    PORT="3360"
    print("MYSQL_PORT not defined by the user. Using the default value:"+PORT)
if variables.get("MYSQL_DATABASE") is not None:
    DATABASE = variables.get("MYSQL_DATABASE")
else:
    print("MYSQL_DATABASE not defined by the user.")
    sys.exit(1)
if credentials.get("MYSQL_USERNAME") is not None and credentials.get("MYSQL_PASSWORD") is not None:
    MYSQL_USERNAME = credentials.get("MYSQL_USERNAME")
    MYSQL_PASSWORD=credentials.get("MYSQL_PASSWORD")
else:
    print("You first need to add third-party credentials (MYSQL_USERNAME and MYSQL_PASSWORD) for the database in the scheduler-portal.")
    sys.exit(1)
if variables.get("MYSQL_QUERY") is not None:
    SQL_QUERY = variables.get("MYSQL_QUERY")
else:
    print("MYSQL_QUERY not defined by the user.")
    sys.exit(1)


IS_LABELED_DATA = 'False'

try:
   LABEL = variables.get("LABEL")
   if LABEL:
     IS_LABELED_DATA='True'
except NameError:
   pass

# Please refer to SQLAlchemy doc for more info about database urls.
# http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls
# Never print this to avoid displaying your credentials in the logs
database_url = RDBMS_NAME + '+' + RDBMS_DRIVER + '://' + MYSQL_USERNAME + ':' + MYSQL_PASSWORD + '@' + HOSTNAME + ':' + PORT + '/' + DATABASE
        
engine = create_engine(database_url)

print("EXECUTING QUERY...")
print('HOSTNAME='+HOSTNAME)
print('PORT='+PORT)
print('DATABASE='+DATABASE)
print('QUERY='+SQL_QUERY)

with engine.connect() as conn, conn.begin():
    #pd.read_sql() can take either a SQL query as a parameter or a table name
    dataframe = pd.read_sql(SQL_QUERY, conn)

columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
  label_index= dataframe.columns.get_loc(LABEL)
  data_indices=[x for i,x in enumerate(range(columns_number)) if i!=label_index]
  data  = dataframe.values[:,data_indices]
  label = dataframe.values[:,label_index]
  data_df = pd.DataFrame(data=data,columns=columns_name[data_indices])
  label_df = pd.DataFrame(data=label,columns=[columns_name[label_index]])
  LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
  LABEL_TEST_DF_JSON = label_df.to_json(orient='split')
  
elif IS_LABELED_DATA == 'False':
  data = dataframe.values
  data_df = pd.DataFrame(data=data,columns=columns_name)
  
DATAFRAME_JSON = dataframe.to_json(orient='split')
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
DATA_TEST_DF_JSON = data_df.to_json(orient='split')
  
try:
  if IS_LABELED_DATA == 'True':
    variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
    variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)
    dataframe=data_df.join(label_df)
    
  variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
  variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
  variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
  variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
  variables.put("IS_LABELED_DATA", IS_LABELED_DATA)
    
  #**************Preview Data*********************
  styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("background", "#0B6FA4"),
                               ("color", "white")]),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 5px"),
                               ("border-bottom", "1px solid #999999")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border", "1px solid #999999")])
  ]
  
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
  #***********************************************
except NameError:
  pass

print("END Import_Data")
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
  </taskFlow>
</job>