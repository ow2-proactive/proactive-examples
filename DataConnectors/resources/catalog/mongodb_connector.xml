<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.9"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.9 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.9/schedulerjob.xsd"
    name="mongodb_connector" projectName="3. NoSQL Connectors"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
    <variable name="HOSTNAME" value="localhost" />
    <variable name="PORT" value="27018" />
    <variable name="DATABASE" value="" />
  </variables>
  <description>
    <![CDATA[ Load data from MongoDB. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="data-connectors"/>
    <info name="pca.action.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/mongodb.png"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="import_from_mongodb">
      <description>
        <![CDATA[ Load data from MongoDB.
This task uses the task variable NOSQL_DRIVER as a driver to connect to the database. The specified default driver "pymongo" is already provided for this task. To use another driver, make sure you have it properly installed before.
The task requires the following third-party credentials : MONGODB_USERNAME and MONGODB_PASSWORD. Please refer to the User documentation to learn how to add third-party credentials.
It also requires a NoSQL query to fetch data. By default, it will fetch all documents from the specified collection.
The imported data is in a JSON format compatible with Pandas DataFrame. ]]>
      </description>
      <variables>
        <variable name="LABEL" value="" inherited="false" />
        <variable name="NOSQL_QUERY" value="" inherited="false" />
        <variable name="COLLECTION" value="" inherited="false" />
        <variable name="NOSQL_DRIVER" value="pymongo" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/mongodb.png"/>
      </genericInformation>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <code language="bash">
            <![CDATA[

]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import pandas as pd
from pymongo import MongoClient


print("BEGIN Import_Data FROM mongoDB using " + variables.get("NOSQL_DRIVER") + " connector")
  
if variables.get("HOSTNAME") is not None:
    HOSTNAME = variables.get("HOSTNAME")
else:
    print("HOSTNAME not defined by the user.")
    sys.exit(1)
if variables.get("PORT") is not None:
    PORT = variables.get("PORT")
else:
    PORT="27018"
    print("PORT not defined by the user. Using the default value:"+PORT)
if variables.get("DATABASE") is not None:
    DATABASE = variables.get("DATABASE")
else:
    print("DATABASE not defined by the user.")
    sys.exit(1)
if variables.get("COLLECTION") is not None:
    COLLECTION = variables.get("COLLECTION")
else:
    print("COLLECTION not defined by the user.")
    sys.exit(1)
if credentials.get("MONGODB_USERNAME") is not None and credentials.get("MONGODB_PASSWORD") is not None:
    MONGODB_USERNAME = credentials.get("MONGODB_USERNAME")
    MONGODB_PASSWORD=credentials.get("MONGODB_PASSWORD")
else:
    print("You first need to add third-party credentials for the database in the scheduler-portal.")
    sys.exit(1)


IS_LABELED_DATA = 'False'
try:
    LABEL = variables.get("LABEL")
    if LABEL:
        IS_LABELED_DATA='True'
except NameError:
 pass

def _connect_mongo(host, port, username, password, db):
    """ A util for making a connection to mongo """

    if username and password:
        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db)
        conn = MongoClient(mongo_uri)
    else:
        conn = MongoClient(host, port)


    return conn[db]


def read_mongo(db, collection, query, host, port, username, password, no_id=True):
    """ Read from Mongo and Store into DataFrame """

    # Connect to MongoDB
    db = _connect_mongo(host=host, port=port, username=username, password=password, db=db)
    # Make a query to the specific DB and Collection
    cursor = db[collection].find(query)

    # Expand the cursor and construct the DataFrame
    df =  pd.DataFrame(list(cursor))

    # Delete the _id
    if no_id:
        del df['_id']

    return df
query={}
if variables.get("NOSQL_QUERY"):
    # This is a workaround to force the variable string value into json
    exec("query="+variables.get("NOSQL_QUERY"))

dataframe= read_mongo(DATABASE, COLLECTION, query, HOSTNAME,  int(PORT),  MONGODB_USERNAME,  MONGODB_PASSWORD)
columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
  label_index= dataframe.columns.get_loc(LABEL)
  data_indices=[x for i,x in enumerate(range(columns_number)) if i!=label_index]
  data  = dataframe.values[:,data_indices]
  label = dataframe.values[:,label_index]
  data_df = pd.DataFrame(data=data,columns=columns_name[data_indices])
  label_df = pd.DataFrame(data=label,columns=[columns_name[label_index]])
  LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
  LABEL_TEST_DF_JSON = label_df.to_json(orient='split')
  
elif IS_LABELED_DATA == 'False':
  data = dataframe.values
  data_df = pd.DataFrame(data=data,columns=columns_name)
  
DATAFRAME_JSON = dataframe.to_json(orient='split')
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
DATA_TEST_DF_JSON = data_df.to_json(orient='split')
  
try:
  if IS_LABELED_DATA == 'True':
    variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
    variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)
    dataframe=data_df.join(label_df)
    
  variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
  variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
  variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
  variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
  variables.put("IS_LABELED_DATA", IS_LABELED_DATA)
    
  #**************Preview Data*********************
  result = dataframe.to_html()
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
  #***********************************************
except NameError:
  pass

print("END Import_Data")
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
  </taskFlow>
</job>