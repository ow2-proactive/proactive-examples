<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.10"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd"
    name="sql_server_connector" projectName="2. SQL"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
    <variable name="SQL_SERVER_HOSTNAME" value="localhost" />
    <variable name="SQL_SERVER_PORT" value="1433" />
    <variable name="SQL_SERVER_DATABASE" value="" />
    <variable name="SQL_SERVER_QUERY" value="" />
  </variables>
  <description>
    <![CDATA[ Load data from an Microsoft SQL Server database. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="data-connectors"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/sql-server.png"/>
    <info name="Documentation" value="https://www.activeeon.com/public_content/documentation/latest/user/ProActiveUserGuide.html#_sql"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="import_from_sql_server">
      <description>
        <![CDATA[ Load data from an Microsoft SQL Server database.
This task uses the task variable RDBMS_DRIVER as a driver to connect to the database. The specified default driver "pyodbc" as well as "pymssql" are already provided for this task. To use another driver, make sure you have it properly installed before.
The task requires the following third-party credentials : MSSQL_USERNAME and MSSQL_PASSWORD. Please refer to the User documentation to learn how to add third-party credentials.
It also requires an SQL query or a table name to fetch data from.
The imported data is exported in a JSON format using the variable $DATAFRAME_JSON. ]]>
      </description>
      <variables>
        <variable name="LABEL" value="" inherited="false" />
        <variable name="SQL_SERVER_QUERY" value="" inherited="true" />
        <variable name="RDBMS_DRIVER" value="pyodbc" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/sql-server.png"/>
      </genericInformation>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import pandas as pd
import numpy as np
from sqlalchemy import create_engine
import sys

RDBMS_NAME='mssql'
RDBMS_DRIVER = variables.get("RDBMS_DRIVER")
print("BEGIN Import_Data FROM " + RDBMS_NAME + " database using " + variables.get("RDBMS_DRIVER") + " connector")


if variables.get("SQL_SERVER_HOSTNAME") is not None:
    HOSTNAME = variables.get("SQL_SERVER_HOSTNAME")
else:
    print("SQL_SERVER_HOSTNAME not defined by the user.")
    sys.exit(1)
if variables.get("SQL_SERVER_PORT") is not None:
    PORT = variables.get("SQL_SERVER_PORT")
else:
    PORT="1433"
    print("SQL_SERVER_PORT not defined by the user. Using the default value:"+PORT)
if variables.get("SQL_SERVER_DATABASE") is not None:
    DATABASE = variables.get("SQL_SERVER_DATABASE")
else:
    print("SQL_SERVER_DATABASE not defined by the user.")
    sys.exit(1)
if credentials.get("MSSQL_USERNAME") is not None and credentials.get("MSSQL_PASSWORD") is not None:
    MSSQL_USERNAME = credentials.get("MSSQL_USERNAME")
    MSSQL_PASSWORD=credentials.get("MSSQL_PASSWORD")
else:
    print("You first need to add third-party credentials (MSSQL_USERNAME and MSSQL_PASSWORD) for the database in the scheduler-portal.")
    sys.exit(1)
if variables.get("SQL_SERVER_QUERY") is not None:
    SQL_QUERY = variables.get("SQL_SERVER_QUERY")
else:
    print("SQL_SERVER_QUERY not defined by the user.")
    sys.exit(1)


IS_LABELED_DATA = 'False'

try:
   LABEL = variables.get("LABEL")
   if LABEL:
     IS_LABELED_DATA='True'
except NameError:
   pass

# Please refer to SQLAlchemy doc for more info about database urls.
# http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls
database_url = RDBMS_NAME + '+' + RDBMS_DRIVER + '://' + MSSQL_USERNAME + ':' + MSSQL_PASSWORD + '@' + HOSTNAME + ':' + PORT + '/' + DATABASE
        
engine = create_engine(database_url)

print("EXECUTING QUERY...")
print('HOSTNAME='+HOSTNAME)
print('PORT='+PORT)
print('DATABASE='+DATABASE)
print('QUERY='+SQL_QUERY)

with engine.connect() as conn, conn.begin():
    #pd.read_sql() can take either a SQL query as a parameter or a table name
    dataframe = pd.read_sql(SQL_QUERY, conn)

columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
  label_index= dataframe.columns.get_loc(LABEL)
  data_indices=[x for i,x in enumerate(range(columns_number)) if i!=label_index]
  data  = dataframe.values[:,data_indices]
  label = dataframe.values[:,label_index]
  data_df = pd.DataFrame(data=data,columns=columns_name[data_indices])
  label_df = pd.DataFrame(data=label,columns=[columns_name[label_index]])
  LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
  LABEL_TEST_DF_JSON = label_df.to_json(orient='split')
  
elif IS_LABELED_DATA == 'False':
  data = dataframe.values
  data_df = pd.DataFrame(data=data,columns=columns_name)
  
DATAFRAME_JSON = dataframe.to_json(orient='split')
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
DATA_TEST_DF_JSON = data_df.to_json(orient='split')
  
try:
  if IS_LABELED_DATA == 'True':
    variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
    variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)
    dataframe=data_df.join(label_df)
    
  variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
  variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
  variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
  variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)
  variables.put("IS_LABELED_DATA", IS_LABELED_DATA)
    
  #**************Preview Data*********************
  styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("background", "#0B6FA4"),
                               ("color", "white")]),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 5px"),
                               ("border-bottom", "1px solid #999999")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border", "1px solid #999999")])
  ]
  
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
  #***********************************************
except NameError:
  pass

print("END Import_Data")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
variables.put("PREVIOUS_PA_TASK_NAME", variables.get("PA_TASK_NAME"))
]]>
          </code>
        </script>
      </post>
    </task>
  </taskFlow>
</job>