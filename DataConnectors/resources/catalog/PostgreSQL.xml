<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"
    name="PostgreSQL" projectName="2. SQL"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
    <variable name="POSTGRES_DATABASE" value="" model=""/>
    <variable name="POSTGRES_HOST" value="localhost" model=""/>
    <variable name="POSTGRES_PORT" value="5432" model=""/>
    <variable name="POSTGRES_USER" value="" model=""/>
  </variables>
  <description>
    <![CDATA[ Import data from (or export data to) PostgreSQL database. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="data-connectors"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/postgresql.png"/>
    <info name="Documentation" value="https://doc.activeeon.com/latest/user/ProActiveUserGuide.html#_sql"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Import_from_PostgreSQL" >
      <description>
        <![CDATA[ This task allows to import data from PostgreSQL database.
It requires the following third-party credential: {key: postgres://<username>@<host>:<port>, value: POSTGRESQL_PASSWORD}. Please refer to the User documentation to learn how to add third-party credentials.
It uses the following variables: 
$LABEL (optional) used when the imported data is labeled. Then, the user can specify the label column name.
$POSTGRES_QUERY (required) is the user's sql query.
$OUTPUT_FILE (optional) is a relative path in the data space used to save the results in a CSV file.
$OUTPUT_TYPE (optional) if set to HTML, it allows to preview the results in Scheduler Portal in an HTML format. Default is CSV
This task uses also the task variable RMDB_DRIVER as a driver to connect to the database. The specified default driver "psycopg2" is already provided for this task. To use another driver, make sure you have it properly installed before.
The imported data is exported in a JSON format using the variable $DATAFRAME_JSON. ]]>
      </description>
      <variables>
        <variable name="LABEL" value="" inherited="false" />
        <variable name="POSTGRES_QUERY" value="" inherited="false" />
        <variable name="RDBMS_DRIVER" value="psycopg2" inherited="false" />
        <variable name="OUTPUT_FILE" value="" inherited="false" />
        <variable name="OUTPUT_TYPE" value="CSV" inherited="false" model="PA:List(CSV,HTML)"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/postgresql.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/user/ProActiveUserGuide.html#_sql"/>
      </genericInformation>
      <depends>
        <task ref="Export_to_PostgreSQL"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
# In the Java Home location field, use the value: "/usr" to force using the JRE provided in the docker image below (Recommended).
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters
containerName = 'activeeon/dlm3'
dockerRunCommand = 'docker run '
dockerParameters = '--rm '
# Prepare ProActive home volume
paHomeHost = variables.get("PA_SCHEDULER_HOME")
paHomeContainer = variables.get("PA_SCHEDULER_HOME")
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' '
# Prepare working directory (For Dataspaces and serialized task file)
workspaceHost = localspace
workspaceContainer = localspace
workspaceVolume = '-v '+localspace +':'+localspace+' '
# Prepare container working directory
containerWorkingDirectory = '-w '+workspaceContainer+' '
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/import_from_SQL_DB/raw" language="cpython">
            <arguments>
              <argument value="PostgreSQL"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <outputFiles>
        <files  includes="$OUTPUT_FILE" accessMode="transferToGlobalSpace"/>
      </outputFiles>
    </task>
    <task name="Export_to_PostgreSQL" >
      <description>
        <![CDATA[ This task allows to export data to PostgreSQL database.
It requires the following third-party credential: {key: postgres://<username>@<host>:<port>, value: POSTGRESQL_PASSWORD}. Please refer to the User documentation to learn how to add third-party credentials.
It uses the following variables: 
$POSTGRES_TABLE (required) is the table name.
$INSERT_MODE (required) indicates the behavior to follow when the table exists in the database amongst: 
. fail: If table exists, do nothing.
. replace: If table exists, drop it, recreate it, and insert data.
. append: (default) If table exists, insert data. Create if does not exist.
$INPUT_FILE (required) is the relative path in the data space of the CSV file that contains data to be imported. The string could also be a URL. Valid URL schemes include http, ftp, s3, and file. 
This task uses also the task variable RMDB_DRIVER as a driver to connect to the database. The specified default driver "psycopg2" is already provided for this task. To use another driver, make sure you have it properly installed before. ]]>
      </description>
      <variables>
        <variable name="POSTGRES_TABLE" value="" inherited="false" />
        <variable name="RDBMS_DRIVER" value="psycopg2" inherited="false" />
        <variable name="INSERT_MODE" value="append" inherited="false" model="PA:LIST(fail, replace, append)"/>
        <variable name="INPUT_FILE" value="" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/postgresql.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/user/ProActiveUserGuide.html#_sql"/>
      </genericInformation>
      <inputFiles>
        <files  includes="$INPUT_FILE" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
# In the Java Home location field, use the value: "/usr" to force using the JRE provided in the docker image below (Recommended).
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters
containerName = 'activeeon/dlm3'
dockerRunCommand = 'docker run '
dockerParameters = '--rm '
# Prepare ProActive home volume
paHomeHost = variables.get("PA_SCHEDULER_HOME")
paHomeContainer = variables.get("PA_SCHEDULER_HOME")
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' '
# Prepare working directory (For Dataspaces and serialized task file)
workspaceHost = localspace
workspaceContainer = localspace
workspaceVolume = '-v '+localspace +':'+localspace+' '
# Prepare container working directory
containerWorkingDirectory = '-w '+workspaceContainer+' '
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/export_to_SQL_DB/raw" language="cpython">
            <arguments>
              <argument value="PostgreSQL"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
    </task>
  </taskFlow>
</job>