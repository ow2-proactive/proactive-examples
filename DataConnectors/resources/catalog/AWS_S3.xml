<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.12" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd"  name="S3" projectName="4. Cloud" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="ACCESS_KEY" value="" />
    <variable name="SECRET_KEY" value="$ACCESS_KEY" model="PA:CREDENTIAL"/>
  </variables>
  <description>
    <![CDATA[ Import data from (or export data to) AWS S3. Before the execution, the user has to provide the $ACCESS_KEY value. Besides, this workflow templates requires the following third-party credential: {key: ACCESS_KEY, value: SECRET_KEY} Please refer to the User documentation to learn how to add third-party credentials. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="data-connectors"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/aws_s3.png"/>
    <info name="Documentation" value="user/ProActiveUserGuide.html#_amazon_s3"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Export_to_S3" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ This task allows to export data to S3.
The task requires the following third-party credential: {key: ACCESS_KEY, value: SECRET_KEY} Please refer to the User documentation to learn how to add third-party credentials.
It uses the following variables:
BUCKET (required) is the bucket name.
REGION (required) is the region where your bucket resides.
LOCAL_RELATIVE_PATH (optional) is the local relative path from which we upload file(s). LOCAL_RELATIVE_PATH can contain either a path to a file, a directory terminated by / or an empty value if you want to upload the entire localspace (user or global).
REMOTE_RELATIVE_PATH (optional) is the remote relative path to which we upload file(s). Empty value is allowed.
ACCESS_KEY (required) is the s3 user access key. ]]>
      </description>
      <variables>
        <variable name="BUCKET" value="" inherited="false" />
        <variable name="REGION" value="" inherited="false" />
        <variable name="LOCAL_RELATIVE_PATH" value="" inherited="false" />
        <variable name="REMOTE_RELATIVE_PATH" value="" inherited="false" />
        <variable name="ACCESS_KEY" value="" inherited="true" />
        <variable name="TRANSFER_DIRECTIVE" value="" inherited="false" model="PA:SPEL(! ( variables[&#39;LOCAL_RELATIVE_PATH&#39;].endsWith(&#39;/&#39;) || variables[&#39;LOCAL_RELATIVE_PATH&#39;].isEmpty() ? variables[&#39;TRANSFER_DIRECTIVE&#39;] = variables[&#39;LOCAL_RELATIVE_PATH&#39;] + &#39;**&#39; : variables[&#39;TRANSFER_DIRECTIVE&#39;] = variables[&#39;LOCAL_RELATIVE_PATH&#39;]).isEmpty())"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/aws_s3.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_amazon_s3"/>
      </genericInformation>
      <inputFiles>
        <files  includes="$TRANSFER_DIRECTIVE" accessMode="transferFromGlobalSpace"/>
        <files  includes="aws-java-sdk-fat-1.11.228.jar" accessMode="cacheFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment >
        <envScript>
          <script>
            <code language="groovy">
              <![CDATA[
def jarFile = new File(cachespace, "aws-java-sdk-fat-1.11.228.jar")

forkEnvironment.addAdditionalClasspath(jarFile.getAbsolutePath())
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import java.io.File
import java.io.FileNotFoundException
import java.io.IOException
import java.io.Serializable
import java.nio.file.Paths
import java.util.ArrayList
import java.util.List
import java.util.Map

import com.amazonaws.auth.AWSStaticCredentialsProvider
import com.amazonaws.auth.BasicAWSCredentials
import com.amazonaws.client.builder.AwsClientBuilder
import com.amazonaws.services.s3.AmazonS3
import com.amazonaws.services.s3.AmazonS3Client
import com.amazonaws.services.s3.AmazonS3ClientBuilder
import com.amazonaws.services.s3.internal.ServiceUtils
import com.amazonaws.services.s3.model.Bucket
import com.amazonaws.services.s3.transfer.MultipleFileUpload
import com.amazonaws.services.s3.transfer.TransferManager
import com.amazonaws.services.s3.transfer.TransferManagerBuilder
import com.amazonaws.services.s3.transfer.Upload
import com.amazonaws.AmazonClientException;
import com.amazonaws.services.s3.transfer.Transfer;
import com.amazonaws.services.s3.transfer.TransferProgress;
import com.amazonaws.util.AwsHostNameUtils
import com.amazonaws.AmazonServiceException
import com.amazonaws.regions.RegionUtils

//Set S3 connection parameters and retrieve the S3 secret key
bucket = variables.get("BUCKET")
region = variables.get("REGION")
localRelativePath = variables.get("LOCAL_RELATIVE_PATH")
remoteRelativePath = variables.get("REMOTE_RELATIVE_PATH")
accessKey = variables.get("ACCESS_KEY")
secretKey = checkParametersAndReturnSecretKey()

List<String> filesRelativePathName = new ArrayList<>()
File file = new File(localRelativePath)
AmazonS3 amazonS3 = getS3Client(accessKey, secretKey, region)

// Create Bucket if it does not exist
createBucketIfNotExists(bucket, amazonS3)

// If the path does not exists, raise an exception.
if (file.exists()) {
    if (file.isDirectory()) {
        uploadDir(localRelativePath, bucket, remoteRelativePath, true, false, amazonS3)
    } else {
        uploadFile(localRelativePath, bucket, remoteRelativePath, false, amazonS3)
    }
} else {
    throw new FileNotFoundException("The input file cannot be found at " + localRelativePath)
}


/**
* Upload a local directory to S3. <br>
* Requires a bucket name. <br>
* If recursive is set to true, upload all subdirectories recursively.
*
* @param dirPath local directory to upload
* @param bucket
* @param keyPrefix
* @param recursive
* @param pause
* @param s3Client
*/
def uploadDir(String dirPath, String bucket, String keyPrefix, boolean recursive, boolean pause,
              AmazonS3 s3Client) {
    println("directory: " + dirPath + (recursive ? " (recursive)" : "") +(pause ? " (pause)" : ""))

    File folder = new File(dirPath)
    String keyName = (keyPrefix != null) ? Paths.get(keyPrefix, folder.getName()).toString() : folder.getName()
    TransferManager transferManager = TransferManagerBuilder.standard().withS3Client(s3Client).build()
    try {
        MultipleFileUpload uploader = transferManager.uploadDirectory(bucket, keyName, folder, recursive)
        // loop with Transfer.isDone()
        showTransferProgress(uploader)
        // or block with Transfer.waitForCompletion()
        waitForCompletion(uploader)
    } catch (AmazonServiceException e) {
        throw new Exception(e.getErrorMessage())
    }
    transferManager.shutdownNow()
}

/**
* Upload a local file to S3. <br>
* Requires a bucket name. <br>
*
* @param filePath
* @param bucket
* @param keyPrefix
* @param pause
* @param s3Client
*/
def uploadFile(String filePath, String bucket, String keyPrefix, boolean pause, AmazonS3 s3Client) {
    println("file: " + filePath + (pause ? " (pause)" : ""))
    File file = new File(filePath);
    String keyName = (keyPrefix != null) ? Paths.get(keyPrefix, file.getName()).toString() : file.getName();
    TransferManager transferManager = TransferManagerBuilder.standard().withS3Client(s3Client).build();
    try {
        Upload uploader = transferManager.upload(bucket, keyName, file);
        // loop with Transfer.isDone()
        showTransferProgress(uploader);
        //  or block with Transfer.waitForCompletion()
        waitForCompletion(uploader);
    } catch (AmazonServiceException e) {
        throw new Exception(e.getErrorMessage());
    }
    transferManager.shutdownNow();
}

/**
* waits for the transfer to complete, catching any exceptions that occur.
* @param xfer
*/
def waitForCompletion(Transfer xfer) {
    try {
        xfer.waitForCompletion();
    } catch (AmazonServiceException e) {
        throw new Exception("Amazon service error: " + e.getMessage())
    } catch (AmazonClientException e) {
        throw new Exception("Amazon client error: " + e.getMessage())
    } catch (InterruptedException e) {
        println("Transfer interrupted: " + e.getMessage())
        Thread.currentThread().interrupt()
        System.exit(1)
    }
}

/**
* Prints progress while waiting for the transfer to finish.
* @param xfer
*/
def showTransferProgress(Transfer xfer) {
    // print the transfer's human-readable description
    println(xfer.getDescription())
    // print an empty progress bar...
    printProgressBar(0.0)
    // update the progress bar while the xfer is ongoing.
    while ({
        try {
            Thread.sleep(100)
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt()
            return;
        }
        // Note: so_far and total aren't used, they're just for
        // documentation purposes.
        TransferProgress progress = xfer.getProgress()
        double pct = progress.getPercentTransferred()
        eraseProgressBar()
        printProgressBar(pct)
        !xfer.isDone()
    }()) continue;
    // print the final state of the transfer.
    Transfer.TransferState xferState = xfer.getState()
    println(": " + xferState)
}

/**
 * prints a simple text progressbar: [#####     ]
 * @param pct
 */
def printProgressBar(double pct) {
    // if bar_size changes, then change erase_bar (in eraseProgressBar) to
    // match.
    final int bar_size = 40
    final String empty_bar = "                                        "
    final String filled_bar = "########################################"
    int amtFull = (int) (bar_size * (pct / 100.0))
    final String logMsg = String.format("  [%s%s]",
                                        filled_bar.substring(0, amtFull),
                                        empty_bar.substring(0, bar_size - amtFull))
    println(logMsg)
}

/**
* erases the progress bar.
*/
def eraseProgressBar() {
    // erase_bar is bar_size (from printProgressBar) + 4 chars.
    final String erase_bar = "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b";
    println(erase_bar)
}

/**
* Get or initialize the S3 client.
* Note: this method must be synchronized because we're accessing the
* field and we're calling this method from a worker thread.
*
* @return the S3 client
*/
def getS3Client(String accessKey, String secretKey, String... args) {
    BasicAWSCredentials credentials = new BasicAWSCredentials(accessKey, secretKey)
    AmazonS3ClientBuilder builder = AmazonS3ClientBuilder.standard().withCredentials(new AWSStaticCredentialsProvider(credentials))

    if (args.length == 1) {
        builder = builder.withRegion(args[0])

    } else {
        String endpoint = args[0] + "://" + args[1]
        String clientRegion = null
        if (!ServiceUtils.isS3USStandardEndpoint(endpoint) &&
            (clientRegion = AwsHostNameUtils.parseRegion(args[1], AmazonS3Client.S3_SERVICE_NAME)) == null) {
            throw new IllegalArgumentException("Invalid region in " + args[1])
        }
        builder = builder.withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(endpoint,
                                                                                               clientRegion))
    }
    builder = builder.withPathStyleAccessEnabled(true)
    return builder.build()
}

/**
* Check if an S3 bucket exists and returns its name if it does exist or null otherwise.
*
* @param bucket
* @param s3
* @return bucket name if it exists or null otherwise
*/
def getBucket(String bucket, AmazonS3 s3) {
    s3.listBuckets().stream().each{
        if(it.getName().equals(bucket)){
            return it
        }
    }
    /*for (b in s3.listBuckets())
    {
        if(b.getName().equals(bucket)){
            return b
        }
    }*/
    return null
}

/**
* Creates an S3 bucket if it does not exist and returns its name.
*
* @param bucket
* @param s3
* @return
*/
def createBucketIfNotExists(String bucket, AmazonS3 s3) {
    Bucket b
    if (s3.doesBucketExistV2(bucket)) {
        b = getBucket(bucket, s3)
    } else {
        println("Bucket " + bucket + " does not exist. Creating bucket ...")
        b = s3.createBucket(bucket)
        println("Bucket " + bucket + " created successfully!")
    }
    return b
}

/**
* Checks and initialize parameters
* returns the S3 secret key using the third party credentials mechanism
*/
def checkParametersAndReturnSecretKey() {
    if (bucket.isEmpty()) {
        throw new IllegalArgumentException("BUCKET variable is not provided by the user. Empty value is not allowed.")
    }
    if (region.isEmpty()) {
        throw new IllegalArgumentException("REGION variable is not provided by the user. Empty value is not allowed.")
    }
    if (localRelativePath.isEmpty()) {
        //Default value is getLocalSpace() because it will always be writable and moreover can be used to transfer files to another data space (global, user)
        localRelativePath = localspace
    }
    if (accessKey.isEmpty()) {
        throw new IllegalArgumentException("ACCESS_KEY variable is not provided by the user. Empty value is not allowed.")
    }
    def secretKey = credentials.get(accessKey)
    if (secretKey == null || secretKey.isEmpty()) {
        throw new IllegalArgumentException("Please add your secret key to 3rd-party credentials under the key :\"" +
                                           accessKey + "\"")
    }
    return secretKey
}
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            195.5
        </positionTop>
        <positionLeft>
            470
        </positionLeft>
      </metadata>
    </task>
    <task name="Import_from_S3" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ This task allows to export data to S3.
The task requires the following third-party credential: {key: ACCESS_KEY, value: SECRET_KEY} Please refer to the User documentation to learn how to add third-party credentials.
It uses the following variables:
URL (required) is the s3 Url that should respect a certain format.
LOCAL_RELATIVE_PATH (required) is the local relative path to which we download file(s). LOCAL_RELATIVE_PATH can contain either a path to a file, a directory terminated by / or an empty value for the root.
LOCAL_RELATIVE_PATH (optional) is the local relative path to which we download file(s). LOCAL_RELATIVE_PATH can contain either a path to a file, a directory terminated by / or an empty value if you want to download file(s) to the root of the localspace (user or global).
ACCESS_KEY (required) is the s3 user access key. ]]>
      </description>
      <variables>
        <variable name="LOCAL_RELATIVE_PATH" value="" inherited="false" />
        <variable name="URL" value="" inherited="false" />
        <variable name="ACCESS_KEY" value="" inherited="true" />
        <variable name="TRANSFER_DIRECTIVE" value="" inherited="false" model="PA:SPEL(! ( variables[&#39;LOCAL_RELATIVE_PATH&#39;].endsWith(&#39;/&#39;) || variables[&#39;LOCAL_RELATIVE_PATH&#39;].isEmpty() ? variables[&#39;TRANSFER_DIRECTIVE&#39;] = variables[&#39;LOCAL_RELATIVE_PATH&#39;] + &#39;**&#39; : variables[&#39;TRANSFER_DIRECTIVE&#39;] = variables[&#39;LOCAL_RELATIVE_PATH&#39;]).isEmpty())"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/aws_s3.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_amazon_s3"/>
      </genericInformation>
      <depends>
        <task ref="Export_to_S3"/>
      </depends>
      <inputFiles>
        <files  includes="aws-java-sdk-fat-1.11.228.jar" accessMode="cacheFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment >
        <envScript>
          <script>
            <code language="groovy">
              <![CDATA[
def jarFile = new File(cachespace, "aws-java-sdk-fat-1.11.228.jar")

forkEnvironment.addAdditionalClasspath(jarFile.getAbsolutePath())
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import java.io.File
import java.io.FileNotFoundException
import java.io.IOException
import java.io.Serializable
import java.nio.file.Paths
import java.util.ArrayList
import java.util.List
import java.util.Map

import com.amazonaws.auth.AWSStaticCredentialsProvider
import com.amazonaws.auth.BasicAWSCredentials
import com.amazonaws.client.builder.AwsClientBuilder
import com.amazonaws.services.s3.AmazonS3
import com.amazonaws.services.s3.AmazonS3Client
import com.amazonaws.services.s3.AmazonS3ClientBuilder
import com.amazonaws.services.s3.internal.ServiceUtils
import com.amazonaws.services.s3.model.Bucket
import com.amazonaws.services.s3.transfer.MultipleFileUpload
import com.amazonaws.services.s3.transfer.TransferManager
import com.amazonaws.services.s3.transfer.TransferManagerBuilder
import com.amazonaws.services.s3.transfer.Upload
import com.amazonaws.services.s3.transfer.Transfer
import com.amazonaws.services.s3.transfer.TransferProgress
import com.amazonaws.services.s3.AmazonS3URI
import com.amazonaws.services.s3.transfer.Download
import com.amazonaws.services.s3.transfer.MultipleFileDownload
import com.amazonaws.AmazonClientException
import com.amazonaws.util.AwsHostNameUtils
import com.amazonaws.AmazonServiceException
import com.amazonaws.regions.RegionUtils

//Set S3 connection parameters and retrieve the S3 secret key
url = variables.get("URL")
localRelativePath = variables.get("LOCAL_RELATIVE_PATH")
accessKey = variables.get("ACCESS_KEY")
scheme = ""
host = ""
bucket = ""
remoteRelativePath = ""
secretKey = checkParametersAndReturnSecretKey()

File file = new File(localRelativePath)
createDirIfNotExists(file)
AmazonS3 amazonS3 = getS3Client(accessKey, secretKey, scheme, host)

// Check that the key name (remoteRelativePath) is either a path to a directory terminated by / or a path for a file
if (isDirectoryPath(remoteRelativePath)) {
    downloadDir(bucket, remoteRelativePath, localRelativePath, false, amazonS3)
    println(listDirectoryContents(file, new ArrayList<>()))
} else {
    localRelativePath = Paths.get(localRelativePath, Paths.get(url).getFileName().toString()).toString()
    downloadFile(bucket, remoteRelativePath, localRelativePath, false, amazonS3)
    println(localRelativePath)
}

/**
     * Download a list of files from S3. <br>
     * Requires a bucket name. <br>
     * Requires a key prefix. <br>
     *
     * @param bucketName
     * @param keyPrefix
     * @param dirPath
     * @param pause
     * @param s3Client
     */
def downloadDir(String bucketName, String keyPrefix, String dirPath, boolean pause, AmazonS3 s3Client) {
    println("downloading to directory: " + dirPath + (pause ? " (pause)" : ""));
    TransferManager transferManager = TransferManagerBuilder.standard().withS3Client(s3Client).build()

    try {
        MultipleFileDownload xfer = transferManager.downloadDirectory(bucketName, keyPrefix, new File(dirPath))
        // loop with Transfer.isDone()
        showTransferProgress(xfer);
        // or block with Transfer.waitForCompletion()
        waitForCompletion(xfer);
    } catch (AmazonServiceException e) {
        throw new Exception(e.getMessage())
    } finally {
        transferManager.shutdownNow();
    }
}

/**
     * Download a file from S3. <br>
     * Requires a bucket name. <br>
     * Requires a key prefix. <br>
     *
     * @param bucketName
     * @param keyName
     * @param filePath
     * @param pause
     * @param s3Client
     */
def downloadFile(String bucketName, String keyName, String filePath, boolean pause, AmazonS3 s3Client) {
    println("Downloading to file: " + filePath + (pause ? " (pause)" : ""));
    File f = new File(filePath);
    TransferManager xferMgr = TransferManagerBuilder.standard().withS3Client(s3Client).build();
    try {
        Download xfer = xferMgr.download(bucketName, keyName, f);
        // loop with Transfer.isDone()
        showTransferProgress(xfer);
        // or block with Transfer.waitForCompletion()
        waitForCompletion(xfer);
    } catch (AmazonServiceException e) {
        throw new Exception(e.getMessage())
    } finally {
        xferMgr.shutdownNow();
    }
}

/**
* waits for the transfer to complete, catching any exceptions that occur.
* @param xfer
*/
def waitForCompletion(Transfer xfer) {
    try {
        xfer.waitForCompletion();
    } catch (AmazonServiceException e) {
        println("Amazon service error: " + e.getMessage());
        System.exit(1);
    } catch (AmazonClientException e) {
        println("Amazon client error: " + e.getMessage());
        System.exit(1);
    } catch (InterruptedException e) {
        println("Transfer interrupted: " + e.getMessage());
        Thread.currentThread().interrupt();
        System.exit(1);
    }
}

/**
* Prints progress while waiting for the transfer to finish.
* @param xfer
*/
def showTransferProgress(Transfer xfer) {
    // print the transfer's human-readable description
    println(xfer.getDescription());
    // print an empty progress bar...
    printProgressBar(0.0);
    // update the progress bar while the xfer is ongoing.
    while ({
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            return;
        }
        // Note: so_far and total aren't used, they're just for
        // documentation purposes.
        TransferProgress progress = xfer.getProgress();
        double pct = progress.getPercentTransferred();
        eraseProgressBar();
        printProgressBar(pct);
        !xfer.isDone();
    }()) continue;
    // print the final state of the transfer.
    Transfer.TransferState xferState = xfer.getState();
    println(": " + xferState);
}

/**
 * prints a simple text progressbar: [#####     ]
 * @param pct
 */
def printProgressBar(double pct) {
    // if bar_size changes, then change erase_bar (in eraseProgressBar) to
    // match.
    final int bar_size = 40;
    final String empty_bar = "                                        ";
    final String filled_bar = "########################################";
    int amtFull = (int) (bar_size * (pct / 100.0));
    final String logMsg = String.format("  [%s%s]",
                                        filled_bar.substring(0, amtFull),
                                        empty_bar.substring(0, bar_size - amtFull));
    println(logMsg);
}

/**
* erases the progress bar.
*/
def eraseProgressBar() {
    // erase_bar is bar_size (from printProgressBar) + 4 chars.
    final String erase_bar = "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b";
    println(erase_bar)
}

/**
* Get or initialize the S3 client.
* Note: this method must be synchronized because we're accessing the
* field and we're calling this method from a worker thread.
*
* @return the S3 client
*/
def getS3Client(String accessKey, String secretKey, String... args) {
    BasicAWSCredentials credentials = new BasicAWSCredentials(accessKey, secretKey)
    AmazonS3ClientBuilder builder = AmazonS3ClientBuilder.standard().withCredentials(new AWSStaticCredentialsProvider(credentials))

    if (args.length == 1) {
        builder = builder.withRegion(args[0])

    } else {
        String endpoint = args[0] + "://" + args[1]
        String clientRegion = null
        if (!ServiceUtils.isS3USStandardEndpoint(endpoint) &&
            (clientRegion = AwsHostNameUtils.parseRegion(args[1], AmazonS3Client.S3_SERVICE_NAME)) == null) {
            throw new IllegalArgumentException("Invalid region in " + args[1])
        }
        builder = builder.withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(endpoint,
                                                                                               clientRegion))
    }
    builder = builder.withPathStyleAccessEnabled(true)
    return builder.build()
}


/**
* List recursively the contents of a directory
* @param dir
* @param filesRelativePathName
* @return List of Files' names of the given directory
* @throws IOException
*/
def listDirectoryContents(File dir, List<String> filesRelativePathName) throws IOException {
    File[] files = dir.listFiles();
    if (files == null) {
        throw new IOException("Download failed. The resource in the given S3 URL does not exist or is not accessible");
    }
    for (File file : files) {
        if (file.isDirectory()) {
            listDirectoryContents(file, filesRelativePathName);
        } else {
            filesRelativePathName.add(file.getCanonicalPath());
        }
    }
    return filesRelativePathName;
}

/**
* Creates a directory if it does not exist
* @param file
*/
def createDirIfNotExists(File file) {
    // If the path already exists, print a warning.
    if (!file.exists()) {
        try {
            file.mkdir()
            println("The " + file.getName() + " directory is created")
        } catch (Exception e) {
            throw new Exception("Couldn't create destination directory! " + file.getName())
        }
    } else {
        println("The given local path " + file.getName() + " already exists");
    }
}

/**
* check whether or not the given file path is a path to a directory terminated by /
* @param filePath
* @return
*/
def isDirectoryPath(String filePath) {
    return filePath.endsWith(File.separator)
}

/**
* Parse an Amazon S3 Uri to extract four elements: scheme, host, bucket name and key name.
*
* @param s3Uri
*/
def parseAmazonS3URI(String s3Uri) {
    AmazonS3URI amazonS3URI = new AmazonS3URI(s3Uri);
    if ((scheme = amazonS3URI.getURI().getScheme()) == null) {
        throw new IllegalArgumentException("You have to specify a valid scheme in the provided s3 uri. Empty value is not allowed.");
    }
    if ((host = amazonS3URI.getURI().getHost()) == null) {
        throw new IllegalArgumentException("You have to specify a valid host in the provided s3 uri. Empty value is not allowed.");
    }
    if ((bucket = amazonS3URI.getBucket()) == null) {
        throw new IllegalArgumentException("You have to specify a valid bucket name in the provided s3 uri. Empty value is not allowed.");
    }
    if ((remoteRelativePath = amazonS3URI.getKey()) == null) {
        throw new IllegalArgumentException("You have to specify a valid key name in the provided s3 uri. Empty value is not allowed.");
    }    
}

/**
* Checks and initialize parameters
* returns the S3 secret key using the third party credentials mechanism
*/
def checkParametersAndReturnSecretKey() {
    if (url.isEmpty()) {
        throw new IllegalArgumentException("URL variable is not provided by the user. Empty value is not allowed.")
    } else {
        parseAmazonS3URI(url)
    }
    if (localRelativePath.isEmpty()) {
        //Default value is getLocalSpace() because it will always be writable and moreover can be used to transfer files to another data space (global, user)
        localRelativePath = localspace
    }
    if (accessKey.isEmpty()) {
        throw new IllegalArgumentException("ACCESS_KEY variable is not provided by the user. Empty value is not allowed.")
    }
    def secretKey = credentials.get(accessKey)
    if (secretKey == null || secretKey.isEmpty()) {
        throw new IllegalArgumentException("Please add your secret key to 3rd-party credentials under the key :\"" +
                                           accessKey + "\"")
    }
    return secretKey
}
]]>
          </code>
        </script>
      </scriptExecutable>
      <outputFiles>
        <files  includes="$TRANSFER_DIRECTIVE" accessMode="transferToGlobalSpace"/>
      </outputFiles>
      <metadata>
        <positionTop>
            301
        </positionTop>
        <positionLeft>
            465.5
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2144px;
            height:2712px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-190.5px;left:-460.5px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_286" style="top: 195.5px; left: 470px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/aws_s3.png" width="20px">&nbsp;<span class="name">Export_to_S3</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_289" style="top: 301px; left: 465.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/aws_s3.png" width="20px">&nbsp;<span class="name">Import_from_S3</span></a></div><svg style="position:absolute;left:508.5px;top:235.5px" width="22" height="66" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 65 C -10 15 11 50 1 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.5473279999999994,48.53152000000001 L4.928982647207693,28.704649871145858 L-2.2125090499099156,34.535524277270575 L-9.06701307552174,28.369830921055776 L-2.5473279999999994,48.53152000000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.5473279999999994,48.53152000000001 L4.928982647207693,28.704649871145858 L-2.2125090499099156,34.535524277270575 L-9.06701307552174,28.369830921055776 L-2.5473279999999994,48.53152000000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 510px; top: 226px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 509px; top: 331px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 509px; top: 291px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>