<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.10"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd"
    name="Computer_Vision" projectName="Vision"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
    <variable name="IMAGE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/images/city.jpg" model=""/>
    <variable name="AZURE_COMPUTER_VISION_ENDPOINT" value="https://eastus2.api.cognitive.microsoft.com/vision/v1.0" model=""/>
    <variable name="OUTPUT_FORMAT" value="HTML" model="PA:LIST(JSON, HTML)"/>
  </variables>
  <description>
    <![CDATA[ Computer Vision API extracts rich information from images to categorize and process visual data and machine-assisted moderation of images to help curate your services. 
https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/ ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="azure-cognitive-services"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_computer_vision.png"/>
    <info name="Documentation" value="https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Computer_Vision">
      <description>
        <![CDATA[ Computer Vision API extracts rich information from images to categorize and process visual data and machine-assisted moderation of images to help curate your services. 
https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/ ]]>
      </description>
      <variables>
        <variable name="IMAGE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/images/city.jpg" inherited="true" />
        <variable name="AZURE_COMPUTER_VISION_ENDPOINT" value="https://eastus2.api.cognitive.microsoft.com/vision/v1.0" inherited="true" />
        <variable name="OUTPUT_FORMAT" value="HTML" inherited="true" model="PA:LIST(JSON, HTML)"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_computer_vision.png"/>
        <info name="task.documentation" value="https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/"/>  
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Computer_Vision_API")

import ast
import json
import requests
from os import remove, listdir, makedirs
from os.path import basename, splitext, exists, join

if 'variables' in locals():
  GLOBALSPACE = str(variables.get("PA_SCHEDULER_HOME")) + '/data/defaultglobal/'
  
  # Replace the subscription_key string value with your valid subscription key.
  if credentials.get("AZURE_COMPUTER_VISION_KEY") is not None:
      AZURE_SUBSCRIPTION_KEY = credentials.get("AZURE_COMPUTER_VISION_KEY")
  else:
      print("You first need to add your Azure Cognitive Services API key (AZURE_COMPUTER_VISION_KEY) to the third party credentials")
      sys.exit(1)
  AZURE_SERVICE_ENDPOINT = variables.get("AZURE_COMPUTER_VISION_ENDPOINT")
  if variables.get("OUTPUT_FORMAT") is not None:
        OUTPUT_FORMAT = variables.get("OUTPUT_FORMAT")
  if variables.get("USE_IMAGE_DATASET") is not None and variables.get("USE_IMAGE_DATASET").lower() == 'true':
    USE_IMAGE_DATASET = True
  else:
    USE_IMAGE_DATASET = False
  
  if USE_IMAGE_DATASET:
    DATASET_PATH  = variables.get("DATASET_PATH")
    DATASET_NAME  = variables.get("DATASET_NAME")
  else:
    IMAGE_URL = variables.get("IMAGE_URL")


assert AZURE_SUBSCRIPTION_KEY is not None
assert AZURE_SERVICE_ENDPOINT is not None

vision_analyze_url = AZURE_SERVICE_ENDPOINT + "/analyze"

# Process an image dataset
if USE_IMAGE_DATASET:
  assert DATASET_PATH is not None
  assert DATASET_NAME is not None

  images_folder = join(DATASET_PATH, DATASET_NAME)
  assert exists(images_folder) == True
  
  analysis_results = []
  k = 0
  for root in listdir(images_folder):
    k = k + 1
    image_path = join(images_folder, root)
    print(k, image_path)
    
    headers = {
        'Ocp-Apim-Subscription-Key': AZURE_SUBSCRIPTION_KEY,
        'Content-Type': 'application/octet-stream'
    }
    params   = {'visualFeatures': 'Categories,Description,Color'}
    req_body = open(image_path,'rb').read()
    
    response = requests.post(vision_analyze_url, headers=headers, params=params, data=req_body)
    response.raise_for_status()
    analysis = response.json()
    #analysis_text = response.text # json.loads(analysis_text)
    #print(analysis)
    
    image_category_name = analysis["categories"][0]["name"]
    image_category_score = str(analysis["categories"][0]["score"])
    image_caption = analysis["description"]["captions"][0]["text"].capitalize()
    image_tags = ', '.join(analysis["description"]["tags"])
    
    print("IMAGE CATEGORY NAME:  " + image_category_name)
    print("IMAGE CATEGORY SCORE: " + image_category_score)
    print("IMAGE CAPTION:        " + image_caption)
    print("IMAGE TAGS:           " + image_category_name)
    
    analysis_results.append(analysis)
    #break
  
  output_json = json.dumps(analysis_results)


# Process single image
if not USE_IMAGE_DATASET:
  assert IMAGE_URL is not None
  
  headers  = {'Ocp-Apim-Subscription-Key': AZURE_SUBSCRIPTION_KEY }
  params   = {'visualFeatures': 'Categories,Description,Color'}
  data     = {'url': IMAGE_URL}
  response = requests.post(vision_analyze_url, headers=headers, params=params, json=data)
  response.raise_for_status()
  analysis = response.json()
  #print(analysis)
  
  image_category_name = analysis["categories"][0]["name"]
  image_category_score = str(analysis["categories"][0]["score"])
  image_caption = analysis["description"]["captions"][0]["text"].capitalize()
  image_tags = ', '.join(analysis["description"]["tags"])
  
  print("IMAGE CATEGORY NAME:  " + image_category_name)
  print("IMAGE CATEGORY SCORE: " + image_category_score)
  print("IMAGE CAPTION:        " + image_caption)
  print("IMAGE TAGS:           " + image_category_name)
  
  output_json = json.dumps(analysis)


print(output_json)

if 'variables' in locals():
  variables.put("AZURE_COMPUTER_VISION_OUTPUT_JSON", output_json)

########## PREVIEW ##########
from pandas.io.json import json_normalize
json_obj = json.loads(output_json)
df = json_normalize(json_obj)
#import pandas as pd
#df = pd.read_json(output_json)

css_style = """
table {
  border: 1px solid #999999;
  text-align: center;
  border-collapse: collapse;
  width: 100%;
}
td {
  border: 1px solid #999999;
  padding: 3px 2px;
  font-size: 13px;
  border-bottom: 1px solid #999999;
}
th {
  font-size: 17px;
  font-weight: bold;
  color: #FFFFFF;
  text-align: center;
  background: #0B6FA4;
  border-left: 2px solid #999999
}
"""

table = []
table.append("""<tr><td><a href="{0}"><img src="{0}" height="150" width="150"/></a></td><td>{1}</td>""".format(IMAGE_URL, df.to_html()))

html = """<table><th>Image</th><th>Reponse</th></tr>{0}</table>""".format("\n".join(table))

html_container = """
             <!DOCTYPE html>
            <html>
              <head>
                <meta charset="UTF-8">
                  <meta name="description" content="Face API">
                    <style>{0}</style>
                  </head>
                  <body>{1}</body></html>
""".format(css_style, html)

if 'variables' in locals():
  if OUTPUT_FORMAT == 'JSON':
       result = json.dumps(analysis).encode('utf-8')
       resultMetadata.put("file.extension", ".json")
       resultMetadata.put("file.name", "result.json")
       resultMetadata.put("content.type", "application/json")
  elif OUTPUT_FORMAT == 'HTML':
       result = html_container.encode('utf-8')
       resultMetadata.put("file.extension", ".html")
       resultMetadata.put("file.name", "result.html")
       resultMetadata.put("content.type", "text/html")

print("END Computer_Vision_API")
]]>
                </code>
              </script>
            </scriptExecutable>
            <controlFlow block="none"></controlFlow>
          </task>
        </taskFlow>
      </job>