<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.13" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd"  name="Text_Analytics" projectName="Language" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2" >
  <variables>
    <variable name="FUNCTION" value="sentiment" model="PA:LIST(languages, sentiment, keyPhrases)"/>
    <variable name="DOCUMENTS_JSON" value="{      &quot;documents&quot;: [          {              &quot;id&quot;: &quot;1&quot;,              &quot;text&quot;: &quot;This document is in English.&quot;          },          {              &quot;id&quot;: &quot;2&quot;,              &quot;text&quot;: &quot;Este documento está en inglés.&quot;          },          {              &quot;id&quot;: &quot;3&quot;,              &quot;text&quot;: &quot;Ce document est en anglais.&quot;          },          {              &quot;id&quot;: &quot;4&quot;,              &quot;text&quot;: &quot;Этот документ находится на английском языке.&quot;          }      ]  }" />
    <variable name="OUTPUT_FORMAT" value="HTML" model="PA:LIST(CSV, HTML, JSON)"/>
  </variables>
  <description>
    <![CDATA[ Text Analytics API is a cloud-based service that provides advanced natural language processing over raw text, and includes three main functions: sentiment analysis, key phrase extraction, and language detection. Learn how to analyze content in different ways with our quickstarts, tutorials, and samples. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="azure-cognitive-services"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_textanalytics.png"/>
    <info name="Documentation" value="https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Text_Analytics" >
      <description>
        <![CDATA[ This task wraps the Text Analytics API of Microsoft which is a cloud-based service that provides advanced natural language processing over raw text, and includes three main functions: sentiment analysis, key phrase extraction, and language detection.
The task requires this third-party credential : $TEXT_ANALYTICS_API_KEY which provides access to this API. Please refer to the User documentation to learn how to add third-party credentials.
$FUNCTION (required) is a list containing different types of text analysis. Possible values are {"sentiment, "language, "keyPhrases"}
$DOCUMENT_JSON (required) is the input json document.
The task's output $TEXT_ANALYTICS_OUTPUT is the result of the API call in a JSON format. ]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="true" name="DOCKER_IMAGE" value="activeeon/dlm3"/>
        <variable name="FUNCTION" value="sentiment" inherited="true" model="PA:LIST(languages, sentiment, keyPhrases)"/>
        <variable name="DOCUMENTS_JSON" value="{      &quot;documents&quot;: [          {              &quot;id&quot;: &quot;1&quot;,              &quot;text&quot;: &quot;This document is in English.&quot;          },          {              &quot;id&quot;: &quot;2&quot;,              &quot;text&quot;: &quot;Este documento está en inglés.&quot;          },          {              &quot;id&quot;: &quot;3&quot;,              &quot;text&quot;: &quot;Ce document est en anglais.&quot;          },          {              &quot;id&quot;: &quot;4&quot;,              &quot;text&quot;: &quot;本文件为英文&quot;          },                          {              &quot;id&quot;: &quot;5&quot;,              &quot;text&quot;: &quot;Этот документ находится на английском языке.&quot;          }      ]  }" inherited="true" />
        <variable name="OUTPUT_FORMAT" value="HTML" inherited="true" model="PA:LIST(CSV, HTML, JSON)"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_textanalytics.png"/>
        <info name="task.documentation" value="https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_docker_vars/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <code language="bash">
            <![CDATA[

]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import requests
import json
from pprint import pprint
import pandas as pd
import csv

# You can customize the api server location
api_location="westcentralus"

# Congitive Services - Text Analytics API URL:
text_analytics_base_url = "https://{0}.api.cognitive.microsoft.com/text/analytics/v2.0/".format(api_location)

functions_list = ["languages", "sentiment", "keyPhrases"]

# READ TASK VARIABLES
if 'variables' in locals():
    if variables.get('FUNCTION') is not None:
        FUNCTION = variables.get('FUNCTION')
        if FUNCTION in functions_list:
            function_url = text_analytics_base_url + FUNCTION
        else:
            print("You must provide a valid Azure Text Analytics function name.")
            sys.exit(1)
    if variables.get("DOCUMENTS_JSON") is not None:
        DOCUMENTS_JSON = variables.get("DOCUMENTS_JSON")        
    if variables.get("OUTPUT_FORMAT") is not None:
        OUTPUT_FORMAT = variables.get("OUTPUT_FORMAT")
    # Provide a valid subscription API token
    if credentials.get("TEXT_ANALYTICS_API_KEY") is not None:
        subscription_key = credentials.get("TEXT_ANALYTICS_API_KEY")
    else:
        print("You first need to add your Azure Text Analytics Service API key (TEXT_ANALYTICS_API_KEY) to the third party credentials")
        sys.exit(1)

# Example Input documents with different languages:
# Structure:
#           {
#            "documents": [
#                {
#                  "id": "string",
#                  "text": "string"
#                }
#            ]
#           }
documents=json.loads(DOCUMENTS_JSON)

print("******** Query params ********")
pprint(DOCUMENTS_JSON)

function_url = text_analytics_base_url + FUNCTION

# Send API request
headers   = {
    "Ocp-Apim-Subscription-Key": subscription_key,
    'Content-Type': 'application/json'
}
response  = requests.post(function_url, headers=headers, data=DOCUMENTS_JSON.encode('utf-8'))

# Get a JSON response
api_results = response.json()

if 'variables' in locals():
    variables.put('TEXT_ANALYTICS_OUTPUT', api_results)

# Print the results
#pprint(api_results)

print("BEGIN Export_Results")

OUTPUT_DATA = api_results["documents"]

# Convert the results into HTML
table = []
for document in OUTPUT_DATA:
    try: 
       text  = next(filter(lambda d: d["id"] == document["id"], documents["documents"]))["text"]
    except KeyError:
        text = None        
        pass
    try: 
       id  = next(filter(lambda d: d["id"] == document["id"], documents["documents"]))["id"]
    except KeyError:
        id = None        
        pass                 
    if(FUNCTION == functions_list[0]):
        try: 
           res = ", ".join(["{0}({1})".format(lang["name"], lang["score"]) for lang in document["detectedLanguages"]])
        except KeyError:
           res = None        
           pass           
    elif(FUNCTION == functions_list[1]):
        try: 
           res = "({0})".format(document["score"])
        except KeyError:
            res = None        
            pass          
    elif(FUNCTION == functions_list[2]):
        try: 
           res = ", ".join(['"{0}"'.format(lang) for lang in document["keyPhrases"]])
        except KeyError:
            res = None        
            pass         
    table.append("<tr><td>{0}</td><td>{1}</td><td>{2}</td>".format(id, text, res))

if(FUNCTION == functions_list[0]):
    table_header_column = "Detected languages (scores)"
elif(FUNCTION == functions_list[1]):
    table_header_column = "Sentiment score"
elif(FUNCTION == functions_list[2]):
    table_header_column = "Keyphrases"
    

css_style="""table {
  border: 1px solid #999999;
  text-align: center;
  border-collapse: collapse;
  width: 100%;
}
td {
  border: 1px solid #999999;
  padding: 3px 2px;
  font-size: 13px;
  border-bottom: 1px solid #999999;
}
th {
  font-size: 17px;
  font-weight: bold;
  color: #FFFFFF;
  text-align: center;
  background: #0B6FA4;
  border-left: 2px solid #999999;
}"""
html = ("""<table><tr><th>id</th><th width=65%>Text</th><th>"""+table_header_column+"</th></tr>{0}</table>").format("\n".join(table))
html_container="""<!DOCTYPE html>
            <html>
              <head>
                <meta charset="UTF-8">
                  <meta name="description" content="{2}">
                    <style>{0}</style>
                  </head>
                  <body>{1}</body></html>""".format(css_style,html,table_header_column)
if OUTPUT_DATA != None and 'resultMetadata' in locals(): 
    #dataframe = pd.read_json(json.dumps(OUTPUT_DATA), orient='table', encoding='utf-8')
    dataframe=pd.read_html(html_container,header=0, encoding='utf-8')[0]
    
    if OUTPUT_FORMAT == 'JSON':
        result = json.dumps(api_results).encode('utf-8')
        resultMetadata.put("file.extension", ".json")
        resultMetadata.put("file.name", "result.json")
        resultMetadata.put("content.type", "application/json")
    elif OUTPUT_FORMAT == 'CSV':
        result = dataframe.to_csv(index=False).encode('utf-8')
        resultMetadata.put("file.extension", ".csv")
        resultMetadata.put("file.name", "result.csv")
        resultMetadata.put("content.type", "text/csv")
    elif OUTPUT_FORMAT == 'HTML':
        result = html_container.encode('utf-8')
        resultMetadata.put("file.extension", ".html")
        resultMetadata.put("file.name", "result.html")
        resultMetadata.put("content.type", "text/html")
    print("END Export_Results")  
else:
    print('It is not possible to export the data')

# Uncomment this to render the HTML result locally in your python notebook
#from IPython.display import HTML
#HTML(html_container)
]]>
                </code>
              </script>
            </scriptExecutable>
          </task>
        </taskFlow>
        <metadata>
          <visualization>
            <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:1139px;
            height:566px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-333.9875030517578px;left:-497.5px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_229" style="top: 339px; left: 502.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_textanalytics.png" width="20px">&nbsp;<span class="name">TextAnalytics</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 542px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
          </visualization>
        </metadata>
      </job>