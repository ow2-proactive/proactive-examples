<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.10"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd"
    name="Face_API" projectName="Vision"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
    <variable name="AZURE_FACE_API_ENDPOINT" value="https://eastus2.api.cognitive.microsoft.com" model=""/>
    <variable name="IMAGE_URL" value="https://upload.wikimedia.org/wikipedia/commons/c/c3/RH_Louise_Lillian_Gish.jpg" model=""/>
    <variable name="OUTPUT_FORMAT" value="HTML" model="PA:LIST(JSON, HTML)"/>
  </variables>
  <description>
    <![CDATA[ The cloud-based Face API provides developers with access to advanced face algorithms. Microsoft Face algorithms enable face attribute detection and face recognition. Learn how to analyze content in different ways with our quickstarts, tutorials, and samples. https://azure.microsoft.com/en-us/services/cognitive-services/face/ ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="azure-cognitive-services"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_face.svg"/>
    <info name="Documentation" value="https://azure.microsoft.com/en-us/services/cognitive-services/face/"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Face_API">
      <description>
        <![CDATA[ The cloud-based Face API provides developers with access to advanced face algorithms. Microsoft Face algorithms enable face attribute detection and face recognition. Learn how to analyze content in different ways with our quickstarts, tutorials, and samples. https://azure.microsoft.com/en-us/services/cognitive-services/face/ ]]>
      </description>
      <variables>
        <variable name="AZURE_FACE_API_ENDPOINT" value="https://eastus2.api.cognitive.microsoft.com" inherited="true" />
        <variable name="IMAGE_URL" value="https://upload.wikimedia.org/wikipedia/commons/c/c3/RH_Louise_Lillian_Gish.jpg" inherited="true" />
        <variable name="OUTPUT_FORMAT" value="HTML" inherited="true" model="PA:LIST(HTML, JSON)"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_face.svg"/>
        <info name="task.documentation" value="https://azure.microsoft.com/en-us/services/cognitive-services/face/"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Face_API")

import http.client, urllib.request, urllib.parse, urllib.error, base64, requests, json
import pandas as pd
from pprint import pprint

from pandas.io.json import json_normalize

if 'variables' in locals():
  if variables.get("IMAGE_URL") is not None:
      IMAGE_URL = variables.get("IMAGE_URL")
  if variables.get("OUTPUT_FORMAT") is not None:
      OUTPUT_FORMAT = variables.get("OUTPUT_FORMAT")
  # Replace the subscription_key string value with your valid subscription key.
  if credentials.get("AZURE_FACE_API_KEY") is not None:
      subscription_key = credentials.get("AZURE_FACE_API_KEY")
  else:
      print("You first need to add your Azure Cognitive Services API key (AZURE_FACE_API_KEY) to the third party credentials")
      sys.exit(1)
  # Replace or verify the region.
  #
  # You must use the same region in your REST API call as you used to obtain your subscription keys.
  # For example, if you obtained your subscription keys from the westus region, replace 
  # "westcentralus" in the URI below with "westus".
  #
  # NOTE: Free trial subscription keys are generated in the westcentralus region, so if you are using
  # a free trial subscription key, you should not need to change this region.
  #uri_base = 'https://westcentralus.api.cognitive.microsoft.com'
  uri_base = variables.get("AZURE_FACE_API_ENDPOINT")

# Request headers.
headers = {
    'Content-Type': 'application/json',
    'Ocp-Apim-Subscription-Key': subscription_key,
}

# Request parameters.
params = {
    'returnFaceId': 'true',
    'returnFaceLandmarks': 'false',
    'returnFaceAttributes': 'age,gender,headPose,smile,facialHair,glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise',
}

print("******** Query params ********")
pprint(params)

# Body. The URL of a JPEG image to analyze.
body = {'url': IMAGE_URL}

try:
  # Execute the REST API call and get the response.
  response = requests.request('POST', uri_base + '/face/v1.0/detect', json=body, data=None, headers=headers, params=params)
  print('Response:')
  print(response)
  parsed = json.loads(response.text)
  """
  '[{"faceId":"79af2eb9-2653-4a65-8b7e-5311b3643f18","faceRectangle":{"top":131,"left":177,"width":162,"height":162},"faceAttributes":{"smile":0.0,"headPose":{"pitch":0.0,"roll":0.1,"yaw":-32.9},"gender":"female","age":22.9,"facialHair":{"moustache":0.0,"beard":0.0,"sideburns":0.0},"glasses":"NoGlasses","emotion":{"anger":0.0,"contempt":0.0,"disgust":0.0,"fear":0.0,"happiness":0.0,"neutral":0.986,"sadness":0.009,"surprise":0.005},"blur":{"blurLevel":"low","value":0.06},"exposure":{"exposureLevel":"goodExposure","value":0.67},"noise":{"noiseLevel":"low","value":0.0},"makeup":{"eyeMakeup":true,"lipMakeup":true},"accessories":[],"occlusion":{"foreheadOccluded":false,"eyeOccluded":false,"mouthOccluded":false},"hair":{"bald":0.0,"invisible":false,"hairColor":[{"color":"brown","confidence":1.0},{"color":"black","confidence":0.87},{"color":"other","confidence":0.51},{"color":"blond","confidence":0.08},{"color":"red","confidence":0.08},{"color":"gray","confidence":0.02}]}}}]'
  """
  #print (json.dumps(parsed, sort_keys=True, indent=2))
except Exception as e:
  print('Error:')
  print(e)

output_json = json.dumps(parsed)
print(output_json)

if 'variables' in locals():
  variables.put("AZURE_FACE_API_OUTPUT_JSON", output_json)

df = json_normalize(parsed)

table = []
table.append("""<tr><td><a href="{0}"><img src="{0}" height="150" width="150"/></a></td><td>{1}</td>""".format(IMAGE_URL, df.to_html()))
        
css_style="""
table {
  border: 1px solid #999999;
  text-align: center;
  border-collapse: collapse;
  width: 100%;
}
td {
  border: 1px solid #999999;
  padding: 3px 2px;
  font-size: 13px;
  border-bottom: 1px solid #999999;
}
th {
  font-size: 17px;
  font-weight: bold;
  color: #FFFFFF;
  text-align: center;
  background: #0B6FA4;
  border-left: 2px solid #999999
}
"""

html = """<table><th>Image</th><th>Reponse</th></tr>{0}</table>""".format("\n".join(table))

html_container = """
           <!DOCTYPE html>
            <html>
              <head>
                <meta charset="UTF-8">
                  <meta name="description" content="Face API">
                    <style>{0}</style>
                  </head>
                  <body>{1}</body></html>
""".format(css_style, html)

if 'variables' in locals():
  if OUTPUT_FORMAT == 'JSON':
       result = output_json.encode('utf-8')
       resultMetadata.put("file.extension", ".json")
       resultMetadata.put("file.name", "result.json")
       resultMetadata.put("content.type", "application/json")
  elif OUTPUT_FORMAT == 'HTML':
       result = html_container.encode('utf-8')
       resultMetadata.put("file.extension", ".html")
       resultMetadata.put("file.name", "result.html")
       resultMetadata.put("content.type", "text/html")

print("END Face_API")
]]>
                </code>
              </script>
            </scriptExecutable>
            <controlFlow block="none"></controlFlow>
          </task>
        </taskFlow>
      </job>