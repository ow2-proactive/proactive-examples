<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.8"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.8 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.8/schedulerjob.xsd"
    name="Visdom_Realtime_Digit_Classification" projectName="Visdom Workflows"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2"
>
  <variables>
    <variable name="instance_name" value="visdom-server-1" />
  </variables>
  <description>
    <![CDATA[ Shows an example of realtime plotting using the Visdom server for training a convolutional neural network (CNN) for MNIST digit classification. ]]>
  </description>
    <genericInformation>
    <info name="bucketName" value="data-visualization"/>
    <info name="pca.action.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png"/>
    <info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_visdom"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Bind_or_Start_Visdom_Service"
    
    
    onTaskError="cancelJob" >
      <description>
        <![CDATA[ The simplest task, ran by a groovy engine. ]]>
      </description>
      <variables>
        <variable name="service_model" value="http://models.activeeon.com/pca/visdom" inherited="false" />
        <variable name="instance_name" value="visdom-server-1" inherited="true" />
      </variables>
      <inputFiles>
        <files  includes="cloud-automation-service-client-1.0.0-all.jar" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment >
        <additionalClasspath>
          <pathElement path="cloud-automation-service-client-1.0.0-all.jar"/>
        </additionalClasspath>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import org.ow2.proactive.pca.client.api.CloudAutomationApi;

schedulerapi.connect()

pcaUrl = variables.get("PA_SCHEDULER_REST_URL").replaceAll("/rest\\z", "/cloud-automation-service");
sessionId = schedulerapi.getSession();

api = new CloudAutomationApi(pcaUrl, sessionId);

endpoint = api.getServiceEndpointOrCreate(variables.get("service_model"), variables.get("instance_name"));
endpoint = endpoint.replaceAll("\n",'');

println "Service " + variables.get("service_model") + " is available on " + endpoint

variables.put("endpoint", endpoint)
result = '<meta http-equiv="refresh" content="1; url=http://' + endpoint + '/" />'
result+= '<h2><span style="color:black">Please wait while redirecting...</span></h2>'
resultMetadata.put("content.type", "text/html")
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
    <task name="Train_CNN">
      <description>
        <![CDATA[ The simplest task, ran by a python engine. ]]>
      </description>
      <depends>
        <task ref="Bind_or_Start_Visdom_Service"/>
      </depends>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre/" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from torchvision import datasets, transforms
from torch.autograd import Variable
from visdom import Visdom

VISDOM_HOST,VISDOM_PORT = variables.get("endpoint").split(":")

# Training settings
parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
parser.add_argument('--batch-size', type=int, default=64, metavar='N',
                    help='input batch size for training (default: 64)')
parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
                    help='input batch size for testing (default: 1000)')
parser.add_argument('--epochs', type=int, default=3, metavar='N',
                    help='number of epochs to train (default: 3)')
parser.add_argument('--lr', type=float, default=0.01, metavar='LR',
                    help='learning rate (default: 0.01)')
parser.add_argument('--momentum', type=float, default=0.5, metavar='M',
                    help='SGD momentum (default: 0.5)')
parser.add_argument('--no-cuda', action='store_true', default=False,
                    help='disables CUDA training')
parser.add_argument('--seed', type=int, default=1, metavar='S',
                    help='random seed (default: 1)')
parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                    help='how many batches to wait before logging training status')
parser.add_argument('--visdom_host', type=str, default=VISDOM_HOST, 
                    help='IP of the visdom server')
parser.add_argument('--visdom_port', type=int, default=VISDOM_PORT, 
                    help='IP port of the visdom server')
args = parser.parse_args()
args.cuda = not args.no_cuda and torch.cuda.is_available()

print("Connecting to %s" % args.visdom_port)
viz = Visdom(server="http://"+args.visdom_host, port=args.visdom_port)
assert viz.check_connection()

win_epoch_loss = viz.line(Y = np.array([1]), X = np.array([1]),
                          opts = dict(
                                  xlabel = 'Iteration',
                                  ylabel = 'Loss',
                                  title = 'Training loss (per iteration)',
                                  ),
                          )
win_global_loss = viz.line(Y = np.array([1]), X = np.array([1]),
                           opts = dict(
                                  xlabel = 'Epoch',
                                  ylabel = 'Loss',
                                  title = 'Training loss (per epoch)',
                                  ),
                           )
win_test_loss = viz.line(Y = np.array([1]), X = np.array([1]),
                           opts = dict(
                                  xlabel = 'Epoch',
                                  ylabel = 'Loss',
                                  title = 'Test loss (per epoch)',
                                  ),
                           )
win_test_acc = viz.line(Y = np.array([1]), X = np.array([1]),
                           opts = dict(
                                  xlabel = 'Epoch',
                                  ylabel = 'Accuracy',
                                  title = 'Test accuracy (per epoch)',
                                  ),
                           )
win_train_log = viz.text("Training log:\n")
win_test_log = viz.text("Testing log:\n")

torch.manual_seed(args.seed)
if args.cuda:
  torch.cuda.manual_seed(args.seed)

kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}

train_loader = torch.utils.data.DataLoader(
  datasets.MNIST('../data', train=True, download=True,
                 transform=transforms.Compose([
                     transforms.ToTensor(),
                     transforms.Normalize((0.1307,), (0.3081,))
                 ])),
  batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
  datasets.MNIST('../data', train=False, transform=transforms.Compose([
                     transforms.ToTensor(),
                     transforms.Normalize((0.1307,), (0.3081,))
                 ])),
  batch_size=args.test_batch_size, shuffle=True, **kwargs)


class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()
    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
    self.conv2_drop = nn.Dropout2d()
    self.fc1 = nn.Linear(320, 50)
    self.fc2 = nn.Linear(50, 10)

  def forward(self, x):
    x = F.relu(F.max_pool2d(self.conv1(x), 2))
    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
    x = x.view(-1, 320)
    x = F.relu(self.fc1(x))
    x = F.dropout(x, training=self.training)
    x = self.fc2(x)
    return F.log_softmax(x)

model = Net()
if args.cuda:
  model.cuda()

optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)

epoch_loss_train = []
average_loss_train = 0
iteration_train = 0
def train(epoch):
  global iteration_train
  model.train()
  for batch_idx, (data, target) in enumerate(train_loader):
    if args.cuda:
      data, target = data.cuda(), target.cuda()
    iteration_train = iteration_train + 1
    data, target = Variable(data), Variable(target)
    optimizer.zero_grad()
    output = model(data)
    loss = F.nll_loss(output, target)
    loss.backward()
    optimizer.step()
    # store loss values
    epoch_loss_train.append(loss.data[0])
    average_loss_train = sum(epoch_loss_train) / len(epoch_loss_train)

    if batch_idx % args.log_interval == 0:
      print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
            epoch, batch_idx * len(data), len(train_loader.dataset),
            100. * batch_idx / len(train_loader), loss.data[0]))
      viz.text('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
            epoch, batch_idx * len(data), len(train_loader.dataset),
            100. * batch_idx / len(train_loader), loss.data[0]), win=win_train_log, append=True)
      # plot loss per iteration
      if iteration_train == 1:
        viz.line(Y = np.array([average_loss_train]), X = np.array([iteration_train]), win = win_epoch_loss, update='replace')
      else:
        viz.line(Y = np.array([average_loss_train]), X = np.array([iteration_train]), win = win_epoch_loss, update='append')

  # plot loss per epoch
  if epoch == 1:
    viz.line(Y = np.array([average_loss_train]), X = np.array([epoch]), win = win_global_loss, update='replace')
  else:
    viz.line(Y = np.array([average_loss_train]), X = np.array([epoch]), win = win_global_loss, update='append')


epoch_loss_test = []
average_loss_test = 0
def test(epoch):
  model.eval()
  test_loss = 0
  correct = 0
  for data, target in test_loader:
    if args.cuda:
        data, target = data.cuda(), target.cuda()
    data, target = Variable(data, volatile=True), Variable(target)
    output = model(data)
    test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss
    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability
    correct += pred.eq(target.data.view_as(pred)).cpu().sum()

  test_loss /= len(test_loader.dataset)
  test_acc = 100. * correct / len(test_loader.dataset)

  print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset), test_acc))
  viz.text('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset), test_acc), win=win_test_log, append=True)

  # plot loss per epoch
  if epoch == 1:
    viz.line(Y = np.array([test_loss]), X = np.array([epoch]), win = win_test_loss, update='replace')
    viz.line(Y = np.array([test_acc]), X = np.array([epoch]), win = win_test_acc, update='replace')
  else:
    viz.line(Y = np.array([test_loss]), X = np.array([epoch]), win = win_test_loss, update='append')
    viz.line(Y = np.array([test_acc]), X = np.array([epoch]), win = win_test_acc, update='append')


for epoch in range(1, args.epochs + 1):
  train(epoch)
  test(epoch)
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
    <task name="Wait_Until_Validation"
    
    
    onTaskError="pauseJob" >
      <description>
        <![CDATA[ Task to pause the job and send a validation message to the notification service ]]>
      </description>
      <depends>
        <task ref="Train_CNN"/>
      </depends>
      <scriptExecutable>
        <script>
          <code language="python">
            <![CDATA[
# Please fill variables
notification_message = 'Please validate to terminate the service'

# Don't change code below unless you know what you are doing
from org.ow2.proactive.addons.webhook import Webhook

jobid = variables.get("PA_JOB_ID")
schedulerURL =  variables.get("PA_SCHEDULER_REST_URL")

print schedulerURL
# get sessionid
schedulerapi.connect()

# pause job
schedulerapi.pauseJob(jobid)


# send web validation
print "Sending web validation..."
url = schedulerURL.replace("/rest", "") +'/notification-service/notifications'
headers = '{\"Content-Type\" : \"application/json\" }'
notification_content = '{\"description\": \"'+notification_message+'\", \"jobId\": \"'+jobid+'\" , \"validation\": \"true\"}'
Webhook.execute ( 'POST', url, headers, notification_content);
print "Web Validation sent"
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
    <task name="Terminate_Visdom_Service"
    
    
    onTaskError="cancelJob" >
      <description>
        <![CDATA[ The simplest task, ran by a groovy engine. ]]>
      </description>
      <variables>
        <variable name="service_model" value="http://models.activeeon.com/pca/visdom" inherited="false" />
        <variable name="instance_name" value="visdom-server-1" inherited="true" />
      </variables>
      <depends>
        <task ref="Wait_Until_Validation"/>
      </depends>
      <inputFiles>
        <files  includes="cloud-automation-service-client-1.0.0-all.jar" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment >
        <additionalClasspath>
          <pathElement path="cloud-automation-service-client-1.0.0-all.jar"/>
        </additionalClasspath>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
import org.ow2.proactive.pca.client.api.CloudAutomationApi;

schedulerapi.connect()
pcaUrl = variables.get("PA_SCHEDULER_REST_URL").replaceAll("/rest\\z", "/cloud-automation-service");
sessionId = schedulerapi.getSession();

api = new CloudAutomationApi(pcaUrl, sessionId);

println "Terminating " + variables.get("service_model") + " / " + variables.get("instance_name");
try{
  api.terminateServiceFromInstanceName(variables.get("service_model"), variables.get("instance_name"));
}catch(Exception ex){
  println "Service was already terminated"
}
]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
  </taskFlow>
</job>