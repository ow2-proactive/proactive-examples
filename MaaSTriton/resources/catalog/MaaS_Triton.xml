<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.13" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd"  name="MaaS_Triton" projectName="Service Automation - Deployment" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="NODE_NAME" value=""  description="Name of the node on which the service will be deployed." group="Resource Management" advanced="true" />
    <variable name="INSTANCE_NAME" value="maas-ml-$PA_JOB_ID"  description="Service instance name." group="Proactive Service Parameters"  />
    <variable name="ENDPOINT_ID" value="maas-ml-gui-$PA_JOB_ID"  description="The endpoint_id that will be used if PROXYFIED is set to True." group="Proactive Service Parameters" advanced="true" />
    <variable name="GPU_ENABLED" value="false" model="PA:Boolean" description="True if the service needs to be configured to use the GPU and the Nvidia Rapids library." group="MaaS_ML Service Configuration" advanced="true" />
    <variable name="PROXYFIED" value="True" model="PA:Boolean"   advanced="false" hidden="false"/>
    <variable name="HTTPS_ENABLED" value="False" model="PA:Boolean"    />
    <variable name="REPOSITORY_PATH" value="/home/activeeon/model_repository/server/docs/examples/model_repository"    advanced="false" hidden="false"/>
    <variable name="TRITON_HTTP_INFERENCE_SERVICE_PORT" value="-1"    advanced="true" hidden="false"/>
    <variable name="TRITON_GRPC_INFERENCE_SERVICE_PORT" value="-1"    advanced="true" hidden="false"/>
    <variable name="TRITON_METRICS_PORT" value="-1"    advanced="true" hidden="false"/>
  </variables>
  <description>
    <![CDATA[ This service allows to launch an instance of MaaS_Triton under the name: INSTANCE_NAME, through ProActive Service Automation (PSA) Portal. Using the launched instance, an already built, tested and validated ML model can be deployed and consumed by sending inference requests.
This is based on NVIDIA Triton Inference Server which is part of the NVIDIA AI platform. Triton is an open-source inference serving software that helps standardize model deployment and execution and delivers fast and scalable AI in production. ]]>
  </description>
  <genericInformation>
    <info name="NODESOURCENAME" value=""/>
    <info name="NS" value=""/>
    <info name="NODE_ACCESS_TOKEN" value=""/>
    <info name="NS_BATCH" value=""/>
    <info name="PYTHON_COMMAND" value="python3"/>
    <info name="bucketName" value="service-automation"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/model_as_service.png"/>
    <info name="pca.states" value="(VOID,RUNNING)"/>
    <info name="Documentation" value="PSA/PSAUserGuide.html#_model_service"/>
    <info name="pca.service.id" value="MaaS_Triton"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Start_MaaS_Triton_D" 
    
    onTaskError="cancelJob" 
    
    
    fork="true">
      <description>
        <![CDATA[ Pull Nvidia Triton image and start a container ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/model_as_service.png"/>
      </genericInformation>
      <inputFiles>
        <files  includes="certificate_mas.pem" accessMode="transferFromGlobalSpace"/>
        <files  includes="key_mas.pem" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <selection>
        <script type="static">
          <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/check_node_name_not_empty/raw" language="groovy">
            <arguments>
              <argument value="$NODE_NAME"/>
            </arguments>
          </file>
        </script>
      </selection>
      <scriptExecutable>
        <script>
          <code language="bash">
            <![CDATA[
echo BEGIN "$variables_PA_TASK_NAME"


################################################################################
### THIS PART IS IMAGE SPECIFIC. IF YOU NEED TO MODIFY SOMETHING, DO IT HERE ###
#DOCKER_IMAGE=$variables_DOCKER_IMAGE
ENGINE=$variables_ENGINE
GPU_ENABLED=$variables_GPU_ENABLED
DOCKER_IMAGE="nvcr.io/nvidia/tritonserver:22.03-py3"
################################################################################

TRITON_HTTP_SERVER_INTERNAL_PORT=8000
TRITON_GRPC_SERVER_INTERNAL_PORT=8001
TRITON_PROMETHEUS_SERVER_INTERNAL_PORT=8002

HTTPS_ENABLED=$variables_HTTPS_ENABLED
INSTANCE_NAME=$variables_INSTANCE_NAME
REPOSITORY_PATH=$variables_REPOSITORY_PATH
TRITON_HTTP_SERVER_PORT=$variables_TRITON_HTTP_INFERENCE_SERVICE_PORT
TRITON_GRPC_SERVER_PORT=$variables_TRITON_GRPC_INFERENCE_SERVICE_PORT
TRITON_PROMETHEUS_SERVER_PORT=$variables_TRITON_METRICS_PORT

PATH=$PATH:/usr/sbin

GET_RANDOM_PORT(){
    PCA_SERVICES_PORT_RANGE_FILE=$variables_PA_SCHEDULER_HOME/config/pca_services_port_range
    if [[ -f "$PCA_SERVICES_PORT_RANGE_FILE" ]]; then
        read LOWERPORT UPPERPORT < $PCA_SERVICES_PORT_RANGE_FILE
    else
        read LOWERPORT UPPERPORT < /proc/sys/net/ipv4/ip_local_port_range
    fi
    while :
    do
        RND_PORT="`shuf -i $LOWERPORT-$UPPERPORT -n 1`"
        ss -lpn | grep -q ":$RND_PORT " || break
    done
    echo $RND_PORT
}

if [ "$TRITON_HTTP_SERVER_PORT" -eq "-1" ]; then
    echo "[INFO] Picking a random port number for TRITON_HTTP_SERVER_PORT"
    TRITON_HTTP_SERVER_PORT=$(GET_RANDOM_PORT)
    echo "[INFO] TRITON_HTTP_SERVER_PORT is $TRITON_HTTP_SERVER_PORT"
fi

if [ "$TRITON_GRPC_SERVER_PORT" -eq "-1" ]; then
    echo "[INFO] Picking a random port number for TRITON_GRPC_SERVER_PORT"
    TRITON_GRPC_SERVER_PORT=$(GET_RANDOM_PORT)
    echo "[INFO] TRITON_GRPC_SERVER_PORT is $TRITON_GRPC_SERVER_PORT"
fi

if [ "$TRITON_PROMETHEUS_SERVER_PORT" -eq "-1" ]; then
    echo "[INFO] Picking a random port number for TRITON_PROMETHEUS_PORT"
    TRITON_PROMETHEUS_SERVER_PORT=$(GET_RANDOM_PORT)
    echo "[INFO] TRITON_PROMETHEUS_SERVER_PORT is $TRITON_PROMETHEUS_SERVER_PORT"
fi
echo "[INFO] The service will be initialized on port $TRITON_PROMETHEUS_SERVER_PORT"

if [ -z "$INSTANCE_NAME" ]; then
    echo "[ERROR] The INSTANCE_NAME is not provided by the user. Empty value is not allowed".
    exit 1
fi

echo "Pulling $DOCKER_IMAGE"
docker pull $DOCKER_IMAGE

if [ "$(docker ps -a --format '{{.Names}}' | grep "^$INSTANCE_NAME$")" ]; then
    echo [ERROR] "$INSTANCE_NAME" is already used by another service instance.
    exit 128
else
    echo "Running $INSTANCE_NAME container"
    if [ "${GPU_ENABLED,,}" = "true" ]; then
        echo "docker run -dit --rm --name $INSTANCE_NAME  -p $TRITON_HTTP_SERVER_PORT:$TRITON_HTTP_SERVER_INTERNAL_PORT -p $TRITON_GRPC_SERVER_PORT:$TRITON_GRPC_SERVER_INTERNAL_PORT -p $TRITON_PROMETHEUS_SERVER_PORT:$TRITON_PROMETHEUS_SERVER_INTERNAL_PORT -v $REPOSITORY_PATH:/models $DOCKER_IMAGE tritonserver --model-repository=/models"
        docker run -dit --rm -gpus=1 --name $INSTANCE_NAME  -p $TRITON_HTTP_SERVER_PORT:$TRITON_HTTP_SERVER_INTERNAL_PORT -p $TRITON_GRPC_SERVER_PORT:$TRITON_GRPC_SERVER_INTERNAL_PORT -p $TRITON_PROMETHEUS_SERVER_PORT:$TRITON_PROMETHEUS_SERVER_INTERNAL_PORT -v $REPOSITORY_PATH:/models $DOCKER_IMAGE tritonserver --model-repository=/models
    else
        echo "docker run -d --rm --name $INSTANCE_NAME  -p $TRITON_HTTP_SERVER_PORT:$TRITON_HTTP_SERVER_INTERNAL_PORT -p $TRITON_GRPC_SERVER_PORT:$TRITON_GRPC_SERVER_INTERNAL_PORT -p $TRITON_PROMETHEUS_SERVER_PORT:$TRITON_PROMETHEUS_SERVER_INTERNAL_PORT -v $REPOSITORY_PATH:/models $DOCKER_IMAGE tritonserver --model-repository=/models"
        docker run -d --rm --name $INSTANCE_NAME  -p $TRITON_HTTP_SERVER_PORT:$TRITON_HTTP_SERVER_INTERNAL_PORT -p $TRITON_GRPC_SERVER_PORT:$TRITON_GRPC_SERVER_INTERNAL_PORT -p $TRITON_PROMETHEUS_SERVER_PORT:$TRITON_PROMETHEUS_SERVER_INTERNAL_PORT -v $REPOSITORY_PATH:/models $DOCKER_IMAGE tritonserver --model-repository=/models
    fi
    echo "docker exec $INSTANCE_NAME mkdir -p $INSTANCE_PATH"

    if [ "$(docker ps -a --format '{{.Names}}' | grep "^$INSTANCE_NAME$")" ]; then
        RUNNING=$(docker inspect --format="{{ .State.Running }}" $INSTANCE_NAME 2> /dev/null)
        if [ "${RUNNING,,}" = "true" ]; then
            echo $INSTANCE_NAME > $INSTANCE_NAME"_status"
        fi
    else
        echo $INSTANCE_STATUS > $INSTANCE_NAME"_status"
    fi
fi

MODEL_SERVICE_PORT=$(docker inspect --format='{{(index (index .NetworkSettings.Ports "'$TRITON_PROMETHEUS_SERVER_PORT'/tcp") 0).HostPort}}' $INSTANCE_NAME)
echo "$TRITON_PROMETHEUS_SERVER_PORT" > $INSTANCE_NAME"_port"

containerID=$(docker ps -aqf "name=^$INSTANCE_NAME$")
echo "$containerID" > $INSTANCE_NAME"_containerID"

echo END "$variables_PA_TASK_NAME"
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
// Copyright Activeeon 2007-2022. All rights reserved.
/*********************************************************************************
* THIS POSTSCRIPT PROPAGATES USEFUL INFORMATION SUCH AS:                         *
* 1) SERVICE ENDPOINT (PROTOCOL://HOSTNAME:PORT)                                 *
* 2) CREDENTIALS (IF THERE ARE ANY) BY ADDING THEM TO 3RD PARTY CREDENTIALS      *
*********************************************************************************/

import org.ow2.proactive.pca.service.client.ApiClient
import org.ow2.proactive.pca.service.client.api.ServiceInstanceRestApi
import org.ow2.proactive.pca.service.client.model.ServiceInstanceData
import org.ow2.proactive.pca.service.client.model.Container
import org.ow2.proactive.pca.service.client.model.Endpoint
import org.ow2.proactive.pca.service.client.model.Deployment
import org.ow2.proactive.pca.service.client.model.Node
import java.net.URLEncoder;

// Acquire variables
def instanceId = variables.get("PCA_INSTANCE_ID") as long
def httpsEnabled = variables.get("HTTPS_ENABLED")
def instanceName = variables.get("INSTANCE_NAME")
def proxyfied = variables.get("PROXYFIED")
def hostname = variables.get("PA_NODE_HOST")
def endpointID = variables.get("ENDPOINT_ID")+"-"+instanceId
def engine = variables.get("ENGINE")
    
println("proxyfied: " + proxyfied)
println("httpsEnabled: " + httpsEnabled)


// Handle service parameters
def port = new File(instanceName+"_port").text.trim()
def containerUrl = hostname+":"+port
def containerID = ""
if (engine != null && "singularity".equalsIgnoreCase(engine)) {
    containerID = "0"
} else {
    containerID = new File(instanceName+"_containerID").text.trim()
}

// Determine Cloud Automation URL
def pcaUrl = variables.get('PA_CLOUD_AUTOMATION_REST_URL')

// Get schedulerapi access and acquire session id
schedulerapi.connect()
def sessionId = schedulerapi.getSession()

// Connect to Cloud Automation API
def apiClient = new ApiClient()
apiClient.setBasePath(pcaUrl)
def serviceInstanceRestApi = new ServiceInstanceRestApi(apiClient)

// Implement service model

// Container
def Container container = new Container()
container.setId(containerID)
container.setName(instanceName)
ENDPOINT_PATH = "/metrics"

// Endpoint
def Endpoint endpoint = new Endpoint();
endpoint.setId(endpointID);
// Set the endpoint parameters according to the Proxy settings
if (proxyfied.toLowerCase()=="true"){
    if (httpsEnabled.toLowerCase()=="true"){
        containerUrl = "https://"+containerUrl+ENDPOINT_PATH
    } else{
        containerUrl = "http://"+containerUrl+ENDPOINT_PATH
    }
    containerUrl = URLDecoder.decode(containerUrl, "UTF-8");
    proxyfiedURL = pcaUrl+"/services/"+instanceId+"/endpoints/"+endpointID
    endpoint.setProxyfied(true);
    endpoint.setProxyfiedUrl(proxyfiedURL)
}else{
    endpoint.setProxyfied(false)
    if (httpsEnabled.toLowerCase()=="true"){
        containerUrl = "https://"+containerUrl+ENDPOINT_PATH
    } else{
        containerUrl = "http://"+containerUrl+ENDPOINT_PATH
    }
    containerUrl = URLDecoder.decode(containerUrl, "UTF-8");
}
endpoint.setUrl(containerUrl);

// Node
def Node node = new Node();
node.setName(variables.get("PA_NODE_NAME"))
node.setHost(variables.get("PA_NODE_HOST"))
node.setNodeSourceName(variables.get("PA_NODE_SOURCE"))
node.setUrl(variables.get("PA_NODE_URL"))

// Deployment
def Deployment deployment = new Deployment()
deployment.setNode(node)
deployment.setContainer(container)
deployment.setEndpoint(endpoint)

// Update service instance model (add Deployment, Groups)
def serviceInstanceData = serviceInstanceRestApi.getServiceInstanceUsingGET(sessionId, instanceId)
serviceInstanceData.setInstanceStatus("RUNNING")
serviceInstanceData = serviceInstanceData.addDeploymentsItem(deployment)
if (proxyfied.toLowerCase()=="true"){
    serviceInstanceData = serviceInstanceData.addGroupsItem("scheduleradmins")
    serviceInstanceData = serviceInstanceData.addGroupsItem("rmcoreadmins")
}
serviceInstanceData = serviceInstanceRestApi.updateServiceInstanceUsingPUT(sessionId, instanceId, serviceInstanceData)
println(serviceInstanceData)

schedulerapi.registerService(variables.get("PA_JOB_ID"), instanceId as int, true)

// Inform other platforms that service is running through Synchronization API
channel = "Service_Instance_" + instanceId
synchronizationapi.createChannelIfAbsent(channel, false)
synchronizationapi.put(channel, "RUNNING", true)
synchronizationapi.put(channel, "INSTANCE_NAME", instanceName)

// Add token to the current node
token = instanceName
nodeUrl = variables.get("PA_NODE_URL")
println("Current nodeUrl: " + nodeUrl)
println("Adding token:    " + token)
rmapi.connect()
rmapi.addNodeToken(nodeUrl, token)

// Log output
println(variables.get("PA_JOB_NAME") + "_INSTANCE_ID: " + instanceId)
println(variables.get("PA_JOB_NAME") + "_ENDPOINT: " + endpoint)

println("END " + variables.get("PA_TASK_NAME"))
]]>
          </code>
        </script>
      </post>
      <cleaning>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Clean_Start_Service/raw" language="groovy"></file>
        </script>
      </cleaning>
      <metadata>
        <positionTop>
            328.22918701171875
        </positionTop>
        <positionLeft>
            492.30902099609375
        </positionLeft>
      </metadata>
    </task>
    <task name="Loop_Over_Instance_Status_D" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ Loop over service instance status and fetch docker container logs.
It will run every minute. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/model_as_service.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="Start_MaaS_Triton_D"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Check_Instance_Status/raw" language="groovy"></file>
        </script>
      </scriptExecutable>
      <controlFlow >
        <loop target="Loop_Over_Instance_Status_D">
          <script>
            <code language="groovy">
              <![CDATA[
// Check if loop task has ordered to finish the loop
def isFinished = variables.get('IS_FINISHED') as boolean
loop = isFinished ? false : '*/1 * * * *'

// Set a time marker to fetch logs since this marker.
variables.put("LAST_TIME_MARKER",new Date().format("yyyy-MM-dd'T'HH:mm:ssXXX"))
]]>
            </code>
          </script>
        </loop>
      </controlFlow>
      <metadata>
        <positionTop>
            456.232666015625
        </positionTop>
        <positionLeft>
            490.3125
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2386px;
            height:3139px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-323.22918701171875px;left:-485.3125px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable active-task" id="jsPlumb_1_74" style="top: 328.237px; left: 492.309px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Pull Nvidia Triton image and start a container"><img src="/automation-dashboard/styles/patterns/img/wf-icons/model_as_service.png" width="20px">&nbsp;<span class="name">Start_MaaS_Triton_D</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_77" style="top: 456.241px; left: 490.313px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Loop over service instance status and fetch docker container logs.
It will run every minute."><img src="/automation-dashboard/styles/patterns/img/wf-icons/model_as_service.png" width="20px">&nbsp;<span class="name">Loop_Over_Instance_Status_D</span></a></div><svg style="position:absolute;left:547px;top:367.5px" width="40.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 19.5 88 C 29.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M20.665968,66.303232 L21.850572046463647,45.146750410352304 L16.787023539475157,52.8513254484303 L8.398665494893953,49.02569487087714 L20.665968,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M20.665968,66.303232 L21.850572046463647,45.146750410352304 L16.787023539475157,52.8513254484303 L8.398665494893953,49.02569487087714 L20.665968,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:644.0266769263776px;top:405.5px" width="20.473323073622403" height="141" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 40 C -10 90 -10 -50 0 0 " transform="translate(19.973323073622403,50.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#316b31" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.4569999999999963,49.16001999999999 L-8.714346841294152,28.91537600442066 L-10.77778447022079,37.90104376767174 L-19.973323073622403,37.23616047464146 L-2.4569999999999963,49.16001999999999" class="" stroke="#316b31" fill="#316b31" transform="translate(19.973323073622403,50.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.4569999999999963,49.16001999999999 L-8.714346841294152,28.91537600442066 L-10.77778447022079,37.90104376767174 L-19.973323073622403,37.23616047464146 L-2.4569999999999963,49.16001999999999" class="" stroke="#316b31" fill="#316b31" transform="translate(19.973323073622403,50.5)"></path></svg><div class="_jsPlumb_overlay l1 component label" id="jsPlumb_1_88" style="position: absolute; transform: translate(-50%, -50%); left: 656px; top: 475.5px;">loop</div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 547.5px; top: 358px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 567px; top: 486px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 567px; top: 446px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint loop-source-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 654px; top: 446px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#316b31" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint loop-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 654px; top: 486px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#316b31" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>