<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.14" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="MaaS_Triton" onTaskError="continueJobExecution" priority="normal" tags="Model_monitoring,Triton,Service,Model_deployment,Service Automation" projectName="Service Automation - Deployment" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd">
  <variables>
    <variable advanced="true" description="Name of the node on which the service will be deployed." group="Resource Management" name="NODE_NAME" value=""/>
    <variable advanced="true" description="Service instance name." group="Proactive Service Parameters" hidden="false" name="INSTANCE_NAME" value="maas-triton-$PA_JOB_ID"/>
    <variable advanced="true" description="The endpoint_id that will be used if PROXYFIED is set to True." group="Proactive Service Parameters" hidden="false" name="ENDPOINT_ID" value="maas-triton-gui-$PA_JOB_ID"/>
    <variable advanced="false" description="If True, container will run with NVIDIA GPU support." group="MaaS_Triton Service Configuration" hidden="false" model="PA:Boolean" name="GPU_ENABLED" value="false"/>
    <variable advanced="true" description="True if a proxy is needed to protect the access to the service endpoint." group="Proactive Service Parameters" hidden="false" model="PA:Boolean" name="PROXYFIED" value="True"/>
    <variable advanced="true" description="True if an https endpoint will be exposed as the service endpoint." group="Proactive Service Parameters" hidden="false" model="PA:Boolean" name="HTTPS_ENABLED" value="False"/>
    <variable advanced="false" description="Path to the model repository." group="MaaS_Triton Service Configuration" hidden="false" name="MODEL_REGISTRY_PATH" value="/tmp/models"/>
    <variable advanced="true" description="If specified, it specifies the port number for the HTTP inference." group="MaaS_Triton Service Configuration" hidden="false" name="TRITON_HTTP_INFERENCE_SERVICE_PORT" value="-1"/>
    <variable advanced="true" description="If specified, it specifies the port number for the GRPC inference." group="MaaS_Triton Service Configuration" hidden="false" name="TRITON_GRPC_INFERENCE_SERVICE_PORT" value="-1"/>
    <variable advanced="true" description="If specified, it specifies the port number for the HTTP metrics." group="MaaS_Triton Service Configuration" hidden="false" name="TRITON_METRICS_PORT" value="-1"/>
    <variable advanced="false" description="Docker image used to start the NVIDIA Triton Inference Server." group="MaaS_Triton Service Configuration" hidden="false" name="DOCKER_IMAGE" value="nvcr.io/nvidia/tritonserver:22.09-py3"/>
  </variables>
  <description>
    <![CDATA[ This service is based on NVIDIA Triton Inference Server which is part of the NVIDIA AI platform. Triton is an open-source inference serving software that helps standardize model deployment and execution and delivers fast and scalable AI in production. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="service-automation"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/nvidia.png"/>
<info name="NODESOURCENAME" value=""/>
<info name="pca.states" value="(VOID,RUNNING)"/>
<info name="NS" value=""/>
<info name="PYTHON_COMMAND" value="python3"/>
<info name="NODE_ACCESS_TOKEN" value=""/>
<info name="Documentation" value="PSA/PSAUserGuide.html"/>
<info name="pca.service.id" value="MaaS_Triton"/>
<info name="NS_BATCH" value=""/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Start_MaaS_Triton_D" onTaskError="cancelJob">
      <description>
        <![CDATA[ Download NVIDIA Triton Server container image and start it. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/nvidia.png"/>
      </genericInformation>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="certificate_mas.pem"/>
        <files accessMode="transferFromGlobalSpace" includes="key_mas.pem"/>
      </inputFiles>
      <selection>
        <script type="static">
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/check_node_name_not_empty/raw">
            <arguments>
              <argument value="$NODE_NAME"/>
            </arguments>
          </file>
        </script>
      </selection>
      <scriptExecutable>
        <script>
          <code language="bash">
            <![CDATA[
echo BEGIN "$variables_PA_TASK_NAME"

################################################################################
### THIS PART IS IMAGE SPECIFIC. IF YOU NEED TO MODIFY SOMETHING, DO IT HERE ###
DOCKER_IMAGE=$variables_DOCKER_IMAGE
GPU_ENABLED=$variables_GPU_ENABLED
################################################################################

TRITON_HTTP_SERVER_INTERNAL_PORT=8000
TRITON_GRPC_SERVER_INTERNAL_PORT=8001
TRITON_PROMETHEUS_SERVER_INTERNAL_PORT=8002

HTTPS_ENABLED=$variables_HTTPS_ENABLED
INSTANCE_NAME=$variables_INSTANCE_NAME
MODEL_REGISTRY_PATH=$variables_MODEL_REGISTRY_PATH
TRITON_HTTP_SERVER_PORT=$variables_TRITON_HTTP_INFERENCE_SERVICE_PORT
TRITON_GRPC_SERVER_PORT=$variables_TRITON_GRPC_INFERENCE_SERVICE_PORT
TRITON_PROMETHEUS_SERVER_PORT=$variables_TRITON_METRICS_PORT

PATH=$PATH:/usr/sbin

GET_RANDOM_PORT(){
    PCA_SERVICES_PORT_RANGE_FILE=$variables_PA_SCHEDULER_HOME/config/pca_services_port_range
    if [[ -f "$PCA_SERVICES_PORT_RANGE_FILE" ]]; then
        read LOWERPORT UPPERPORT < $PCA_SERVICES_PORT_RANGE_FILE
    else
        read LOWERPORT UPPERPORT < /proc/sys/net/ipv4/ip_local_port_range
    fi
    while :
    do
        RND_PORT="`shuf -i $LOWERPORT-$UPPERPORT -n 1`"
        ss -lpn | grep -q ":$RND_PORT " || break
    done
    echo $RND_PORT
}

if [ "$TRITON_HTTP_SERVER_PORT" -eq "-1" ]; then
    echo "[INFO] Picking a random port number for TRITON_HTTP_SERVER_PORT"
    TRITON_HTTP_SERVER_PORT=$(GET_RANDOM_PORT)
    echo "[INFO] TRITON_HTTP_SERVER_PORT is $TRITON_HTTP_SERVER_PORT"
fi

if [ "$TRITON_GRPC_SERVER_PORT" -eq "-1" ]; then
    echo "[INFO] Picking a random port number for TRITON_GRPC_SERVER_PORT"
    TRITON_GRPC_SERVER_PORT=$(GET_RANDOM_PORT)
    echo "[INFO] TRITON_GRPC_SERVER_PORT is $TRITON_GRPC_SERVER_PORT"
fi

if [ "$TRITON_PROMETHEUS_SERVER_PORT" -eq "-1" ]; then
    echo "[INFO] Picking a random port number for TRITON_PROMETHEUS_PORT"
    TRITON_PROMETHEUS_SERVER_PORT=$(GET_RANDOM_PORT)
    echo "[INFO] TRITON_PROMETHEUS_SERVER_PORT is $TRITON_PROMETHEUS_SERVER_PORT"
fi
echo "[INFO] The service will be initialized on port $TRITON_PROMETHEUS_SERVER_PORT"

if [ -z "$INSTANCE_NAME" ]; then
    echo "[ERROR] The INSTANCE_NAME is not provided by the user. Empty value is not allowed".
    exit 1
fi

echo "Pulling $DOCKER_IMAGE"
docker pull $DOCKER_IMAGE

if [ "$(docker ps -a --format '{{.Names}}' | grep "^$INSTANCE_NAME$")" ]; then
    echo [ERROR] "$INSTANCE_NAME" is already used by another service instance.
    exit 128
else
    echo "Running $INSTANCE_NAME container"
    GPU_PARAMS=''
    if [ "${GPU_ENABLED,,}" = "true" ]; then
        GPU_PARAMS='--gpus=all'
    fi
    MOUNT_PATH=''
    MODEL_REPOSITORY=''
    if [[ $MODEL_REGISTRY_PATH = s3://* ]]; then
        MODEL_REPOSITORY="--model-repository=$MODEL_REGISTRY_PATH"
    else
        MOUNT_PATH="-v $MODEL_REGISTRY_PATH:/models"
        MODEL_REPOSITORY="--model-repository=/models"
    fi
    echo "docker run -d --rm $GPU_PARAMS --name $INSTANCE_NAME -p $TRITON_HTTP_SERVER_PORT:$TRITON_HTTP_SERVER_INTERNAL_PORT -p $TRITON_GRPC_SERVER_PORT:$TRITON_GRPC_SERVER_INTERNAL_PORT -p $TRITON_PROMETHEUS_SERVER_PORT:$TRITON_PROMETHEUS_SERVER_INTERNAL_PORT $MOUNT_PATH $DOCKER_IMAGE tritonserver $MODEL_REPOSITORY"
    docker run -d --rm $GPU_PARAMS --name $INSTANCE_NAME -p $TRITON_HTTP_SERVER_PORT:$TRITON_HTTP_SERVER_INTERNAL_PORT -p $TRITON_GRPC_SERVER_PORT:$TRITON_GRPC_SERVER_INTERNAL_PORT -p $TRITON_PROMETHEUS_SERVER_PORT:$TRITON_PROMETHEUS_SERVER_INTERNAL_PORT $MOUNT_PATH $DOCKER_IMAGE tritonserver $MODEL_REPOSITORY

    if [ "$(docker ps -a --format '{{.Names}}' | grep "^$INSTANCE_NAME$")" ]; then
        RUNNING=$(docker inspect --format="{{ .State.Running }}" $INSTANCE_NAME 2> /dev/null)
        if [ "${RUNNING,,}" = "true" ]; then
            echo $INSTANCE_NAME > $INSTANCE_NAME"_status"
        fi
    else
        echo $INSTANCE_STATUS > $INSTANCE_NAME"_status"
    fi
fi

MODEL_SERVICE_PORT=$(docker inspect --format='{{(index (index .NetworkSettings.Ports "'$TRITON_PROMETHEUS_SERVER_PORT'/tcp") 0).HostPort}}' $INSTANCE_NAME)
echo "$TRITON_PROMETHEUS_SERVER_PORT" > $INSTANCE_NAME"_port_prometheus"
echo "$TRITON_HTTP_SERVER_PORT" > $INSTANCE_NAME"_port_http"
echo "$TRITON_GRPC_SERVER_PORT" > $INSTANCE_NAME"_port_grpc"

containerID=$(docker ps -aqf "name=^$INSTANCE_NAME$")
echo "$containerID" > $INSTANCE_NAME"_containerID"

echo END "$variables_PA_TASK_NAME"
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
/*********************************************************************************
* THIS POSTSCRIPT PROPAGATES USEFUL INFORMATION SUCH AS:                         *
* 1) SERVICE ENDPOINT (PROTOCOL://HOSTNAME:PORT)                                 *
* 2) CREDENTIALS (IF THERE ARE ANY) BY ADDING THEM TO 3RD PARTY CREDENTIALS      *
*********************************************************************************/

import org.ow2.proactive.pca.service.client.ApiClient
import org.ow2.proactive.pca.service.client.api.ServiceInstanceRestApi
import org.ow2.proactive.pca.service.client.model.ServiceInstanceData
import org.ow2.proactive.pca.service.client.model.Container
import org.ow2.proactive.pca.service.client.model.Endpoint
import org.ow2.proactive.pca.service.client.model.Deployment
import org.ow2.proactive.pca.service.client.model.Node
import java.net.URLEncoder;

// Acquire variables
def instanceId = variables.get("PCA_INSTANCE_ID") as long
def httpsEnabled = variables.get("HTTPS_ENABLED")
def instanceName = variables.get("INSTANCE_NAME")
def proxyfied = variables.get("PROXYFIED")
def hostname = variables.get("PA_NODE_HOST")
def endpointID = variables.get("ENDPOINT_ID")+"-"+instanceId
def engine = variables.get("ENGINE")

println("proxyfied:    " + proxyfied)
println("httpsEnabled: " + httpsEnabled)

// Handle service parameters
def port_prometheus = new File(instanceName+"_port_prometheus").text.trim()
def containerUrlPrometheus = hostname+":"+port_prometheus
def prometheusMetricsEndpoint = "/metrics"

def port_http = new File(instanceName+"_port_http").text.trim()
def containerUrlHttp = hostname+":"+port_http

def port_grpc = new File(instanceName+"_port_grpc").text.trim()
def containerUrlGrpc = hostname+":"+port_grpc

def containerID = ""
if (engine != null && "singularity".equalsIgnoreCase(engine)) {
    containerID = "0"
} else {
    containerID = new File(instanceName+"_containerID").text.trim()
}

// Determine Cloud Automation URL
def pcaUrl = variables.get('PA_CLOUD_AUTOMATION_REST_URL')

// Get schedulerapi access and acquire session id
schedulerapi.connect()
def sessionId = schedulerapi.getSession()

// Connect to Cloud Automation API
def apiClient = new ApiClient()
apiClient.setBasePath(pcaUrl)
def serviceInstanceRestApi = new ServiceInstanceRestApi(apiClient)

// Implement service model

// Https
if ("true".equalsIgnoreCase(httpsEnabled)){
    containerUrlPrometheusMetrics = "https://"+containerUrlPrometheus+prometheusMetricsEndpoint
} else{
    containerUrlPrometheusMetrics = "http://"+containerUrlPrometheus+prometheusMetricsEndpoint
}
containerUrlPrometheusMetrics = URLDecoder.decode(containerUrlPrometheusMetrics, "UTF-8");
containerUrlPrometheus = URLDecoder.decode(containerUrlPrometheus, "UTF-8");
containerUrlHttp = URLDecoder.decode(containerUrlHttp, "UTF-8");
containerUrlGrpc = URLDecoder.decode(containerUrlGrpc, "UTF-8");

// Container
def Container container = new Container()
container.setId(containerID)
container.setName(instanceName)

// Node
def Node node = new Node();
node.setName(variables.get("PA_NODE_NAME"))
node.setHost(variables.get("PA_NODE_HOST"))
node.setNodeSourceName(variables.get("PA_NODE_SOURCE"))
node.setUrl(variables.get("PA_NODE_URL"))

// Endpoint (primary)
def Endpoint endpoint = new Endpoint();
endpointIDmetrics = endpointID + "-metrics"
endpoint.setId(endpointIDmetrics);
// Set the endpoint parameters according to the Proxy settings
if ("true".equalsIgnoreCase(proxyfied)){
    proxyfiedURL = pcaUrl+"/services/"+instanceId+"/endpoints/"+endpointIDmetrics
    endpoint.setProxyfied(true);
    endpoint.setProxyfiedUrl(proxyfiedURL)
}else{
    endpoint.setProxyfied(false)
}
endpoint.setUrl(containerUrlPrometheusMetrics);

// Endpoint (secondary)
// def Endpoint endpointPrometheusMetrics = new Endpoint();
// endpointIDmetrics = endpointID + "-metrics"
// endpointPrometheusMetrics.setId(endpointIDmetrics);
// endpointPrometheusMetrics.setUrl(containerUrlPrometheusMetrics);

def Endpoint endpointPrometheus = new Endpoint();
endpointIDprom = endpointID + "-prom"
endpointPrometheus.setId(endpointIDprom);
endpointPrometheus.setUrl(containerUrlPrometheus);

def Endpoint endpointHttp = new Endpoint();
endpointIDhttp = endpointID + "-http"
endpointHttp.setId(endpointIDhttp);
endpointHttp.setUrl(containerUrlHttp);

def Endpoint endpointGrpc = new Endpoint();
endpointIDgrpc = endpointID + "-grpc"
endpointGrpc.setId(endpointIDgrpc);
endpointGrpc.setUrl(containerUrlGrpc);

// Deployment (primary)
def Deployment deployment = new Deployment()
deployment.setNode(node)
deployment.setContainer(container)
deployment.setEndpoint(endpoint)

// Deployment (secondary)

// def Deployment deploymentPrometheusMetrics = new Deployment()
// // deploymentPrometheusMetrics.setNode(node)
// // deploymentPrometheusMetrics.setContainer(container)
// deploymentPrometheusMetrics.setEndpoint(endpointPrometheusMetrics)

def Deployment deploymentPrometheus = new Deployment()
// deploymentPrometheus.setNode(node)
// deploymentPrometheus.setContainer(container)
deploymentPrometheus.setEndpoint(endpointPrometheus)

def Deployment deploymentHttp = new Deployment()
// deploymentHttp.setNode(node)
// deploymentHttp.setContainer(container)
deploymentHttp.setEndpoint(endpointHttp)

def Deployment deploymentGrpc = new Deployment()
// deploymentGrpc.setNode(node)
// deploymentGrpc.setContainer(container)
deploymentGrpc.setEndpoint(endpointGrpc)

// Update service instance model (add Deployment, Groups)
def serviceInstanceData = serviceInstanceRestApi.getServiceInstanceUsingGET(sessionId, instanceId)
serviceInstanceData.setInstanceStatus("RUNNING")
serviceInstanceData = serviceInstanceData.addDeploymentsItem(deployment)
// serviceInstanceData = serviceInstanceData.addDeploymentsItem(deploymentPrometheusMetrics)
serviceInstanceData = serviceInstanceData.addDeploymentsItem(deploymentPrometheus)
serviceInstanceData = serviceInstanceData.addDeploymentsItem(deploymentHttp)
serviceInstanceData = serviceInstanceData.addDeploymentsItem(deploymentGrpc)
if ("true".equalsIgnoreCase(proxyfied)){
    serviceInstanceData = serviceInstanceData.addGroupsItem("scheduleradmins")
    serviceInstanceData = serviceInstanceData.addGroupsItem("rmcoreadmins")
}
serviceInstanceData = serviceInstanceRestApi.updateServiceInstanceUsingPUT(sessionId, instanceId, serviceInstanceData)
println(serviceInstanceData)

schedulerapi.registerService(variables.get("PA_JOB_ID"), instanceId as int, true)

// Inform other platforms that service is running through Synchronization API
channel = "Service_Instance_" + instanceId
synchronizationapi.createChannelIfAbsent(channel, false)
synchronizationapi.put(channel, "RUNNING", true)
synchronizationapi.put(channel, "INSTANCE_NAME", instanceName)

// Add token to the current node
token = instanceName
nodeUrl = variables.get("PA_NODE_URL")
println("Current nodeUrl: " + nodeUrl)
println("Adding token:    " + token)
rmapi.connect()
rmapi.addNodeToken(nodeUrl, token)

// Log output
println(variables.get("PA_JOB_NAME") + "_INSTANCE_ID: " + instanceId)
println(variables.get("PA_JOB_NAME") + "_ENDPOINT: " + endpoint)

println("END " + variables.get("PA_TASK_NAME"))
]]>
          </code>
        </script>
      </post>
      <cleaning>
        <script>
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Clean_Start_Service/raw"/>
        </script>
      </cleaning>
      <metadata>
        <positionTop>
            139.6166534423828
        </positionTop>
        <positionLeft>
            13.633331298828125
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Loop_Over_Instance_Status_D">
      <description>
        <![CDATA[ Loop over service instance status and fetch docker container logs.
It will run every minute. ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/model_as_service.png"/>
        <info name="NODE_ACCESS_TOKEN" value="$INSTANCE_NAME"/>
      </genericInformation>
      <depends>
        <task ref="Start_MaaS_Triton_D"/>
      </depends>
      <scriptExecutable>
        <script>
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Check_Instance_Status/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow>
        <loop target="Loop_Over_Instance_Status_D">
          <script>
            <code language="groovy">
              <![CDATA[
// Check if loop task has ordered to finish the loop
def isFinished = variables.get('IS_FINISHED') as boolean
loop = isFinished ? false : '*/1 * * * *'

// Set a time marker to fetch logs since this marker.
variables.put("LAST_TIME_MARKER",new Date().format("yyyy-MM-dd'T'HH:mm:ssXXX"))
]]>
            </code>
          </script>
        </loop>
      </controlFlow>
      <metadata>
        <positionTop>
            267.6166534423828
        </positionTop>
        <positionLeft>
            13.633331298828125
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2710px;
            height:3036px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-134.6166534423828px;left:-8.633331298828125px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable active-task" style="top: 139.61px; left: 13.625px;" id="jsPlumb_1_16"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Download NVIDIA Triton Server container image and start it."><img src="/automation-dashboard/styles/patterns/img/wf-icons/nvidia.png" width="20px">&nbsp;<span class="name">Start_MaaS_Triton_D</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" style="top: 267.61px; left: 13.625px;" id="jsPlumb_1_19"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Loop over service instance status and fetch docker container logs.
It will run every minute."><img src="/automation-dashboard/styles/patterns/img/wf-icons/model_as_service.png" width="20px">&nbsp;<span class="name">Loop_Over_Instance_Status_D</span></a></div><svg style="position:absolute;left:69px;top:179.5px" width="42.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 21.5 88 C 31.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style="--darkreader-inline-stroke: #a8a095;" data-darkreader-inline-stroke=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M22.494896,66.303232 L23.16866373995708,45.12432652703957 L18.292495623246907,52.94883830079128 L9.814270040748365,49.32672690379266 L22.494896,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" style="--darkreader-inline-fill: #a8a095; --darkreader-inline-stroke: #a8a095;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M22.494896,66.303232 L23.16866373995708,45.12432652703957 L18.292495623246907,52.94883830079128 L9.814270040748365,49.32672690379266 L22.494896,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" style="--darkreader-inline-fill: #a8a095; --darkreader-inline-stroke: #a8a095;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></path></svg><svg style="position:absolute;left:168.0266769263776px;top:217.5px" width="20.473323073622403" height="141" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 40 C -10 90 -10 -50 0 0 " transform="translate(19.973323073622403,50.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#316b31" style="--darkreader-inline-stroke: #91cd91;" data-darkreader-inline-stroke=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.4569999999999963,49.16001999999999 L-8.714346841294157,28.915376004420658 L-10.777784470220794,37.90104376767174 L-19.973323073622403,37.23616047464146 L-2.4569999999999963,49.16001999999999" class="" stroke="#316b31" fill="#316b31" transform="translate(19.973323073622403,50.5)" style="--darkreader-inline-fill: #91cd91; --darkreader-inline-stroke: #91cd91;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.4569999999999963,49.16001999999999 L-8.714346841294157,28.915376004420658 L-10.777784470220794,37.90104376767174 L-19.973323073622403,37.23616047464146 L-2.4569999999999963,49.16001999999999" class="" stroke="#316b31" fill="#316b31" transform="translate(19.973323073622403,50.5)" style="--darkreader-inline-fill: #91cd91; --darkreader-inline-stroke: #91cd91;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></path></svg><div style="position: absolute; transform: translate(-50%, -50%); left: 180px; top: 287.5px;" class="_jsPlumb_overlay l1 component label" id="jsPlumb_1_30">loop</div><div style="position: absolute; height: 20px; width: 20px; left: 69.5px; top: 170px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: #a8a095; --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 91px; top: 298px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: #a8a095; --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 91px; top: 258px;" class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill: #a8a095; --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 178px; top: 258px;" class="_jsPlumb_endpoint source-endpoint loop-source-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#316b31" stroke="none" style="--darkreader-inline-fill: #91cd91; --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div style="position: absolute; height: 20px; width: 20px; left: 178px; top: 298px;" class="_jsPlumb_endpoint target-endpoint loop-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#316b31" stroke="none" style="--darkreader-inline-fill: #91cd91; --darkreader-inline-stroke: none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
