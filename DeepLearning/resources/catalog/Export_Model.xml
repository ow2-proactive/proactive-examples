<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.10" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Export_Model" onTaskError="continueJobExecution" priority="normal" projectName="1. Input and Output" xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd">
  <variables>
    <variable name="GPU_NODES_ONLY" value="False"/>
    <variable name="DOCKER_ENABLED" value="True"/>
  </variables>
  <description>
    <![CDATA[ Export a trained model by a deep learning algorithm. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="deep-learning"/>
<info name="pca.action.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_deep_model.png"/>
<info name="Documentation" value="http://activeeon.com/resources/automated-machine-learning-activeeon.pdf"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task name="Export_Model">
      <description>
        <![CDATA[ Export a trained model by a deep learning algorithm. ]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="GPU_NODES_ONLY" value="False"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_deep_model.png"/>
      </genericInformation>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </inputFiles>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Export_Model")

import os
import uuid
import zipfile
import shutil

from os import remove, listdir, makedirs
from os.path import exists, join, isfile

if 'variables' in locals():
  MODEL_PATH  = variables.get("MODEL_PATH")
  LABELS_PATH = variables.get("LABELS_PATH")
  TEXT_PATH   = variables.get("TEXT_PATH")

assert MODEL_PATH is not None
assert LABELS_PATH is not None

'''
assert MODEL_DIR_PATH is not None
assert exists(MODEL_DIR_PATH) == True

def zipdir(_path, _ziph):
  # ziph is zipfile handle
  for root, dirs, files in os.walk(_path):
    for file in files:
      _ziph.write(join(root, file))

zipf = zipfile.ZipFile('model.zip', 'w', zipfile.ZIP_DEFLATED)
zipdir(MODEL_DIR_PATH, zipf)
zipf.close()
'''

# Get an unique ID
ID = str(uuid.uuid4())
FILE_NAME = ID + '.zip'

zipf = zipfile.ZipFile(FILE_NAME, 'w', zipfile.ZIP_DEFLATED)
zipf.write(MODEL_PATH)
zipf.write(LABELS_PATH)
if TEXT_PATH is not None:
  zipf.write(TEXT_PATH)
zipf.close()

assert isfile(FILE_NAME) == True

# Read the whole file at once
FILE_BIN = None
with open(FILE_NAME, "rb") as binary_file:
  FILE_BIN = binary_file.read()
assert FILE_BIN is not None

if 'variables' in locals():
  result = FILE_BIN
  resultMetadata.put("file.extension", ".zip")
  resultMetadata.put("file.name", "model.zip")
  resultMetadata.put("content.type", "application/octet-stream")

print("END Export_Model")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
    </task>
  </taskFlow>
</job>
