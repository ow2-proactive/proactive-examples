<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.14" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="SegNet" onTaskError="continueJobExecution" priority="normal" tags="Segmentation,Natural Language Processing,Text Analysis,Computer Vision,Image Analysis,Machine Learning,Deep Learning" projectName="2.2 Image Segmentation" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd">
  <variables>
    <variable advanced="true" description="Container platform used for executing the workflow tasks." group="Container Parameters" hidden="false" model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker"/>
    <variable advanced="true" description="If True, it will activate the use of GPU for the workflow tasks on the selected container platform." group="Container Parameters" hidden="false" model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="True"/>
    <variable advanced="true" description="Name of the container image being used to run the workflow tasks." group="Container Parameters" hidden="false" model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/rapidsai,docker://activeeon/tensorflow:latest,docker://activeeon/tensorflow:latest-gpu)" name="CONTAINER_IMAGE" value=""/>
  </variables>
  <description>
    <![CDATA[ SegNet is a deep convolutional encoder-decoder architecture for robust semantic pixel-wise labelling.
 ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="ai-deep-learning"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_segmentation.png"/>
<info name="Documentation" value="PAIO/PAIOUserGuide.html#_segnet"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="SegNet">
      <description>
        <![CDATA[ SegNet is a deep convolutional encoder-decoder architecture for robust semantic pixel-wise labelling. ]]>
      </description>
      <variables>
        <variable advanced="false" description="(Width, Height) of the images as a tuple with 2 elements." hidden="false" inherited="false" name="IMG_SIZE" value="(64, 64)"/>
        <variable advanced="false" description="Number of classes or labels." hidden="false" inherited="false" name="NUM_CLASSES" value="3"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_segmentation.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_segnet"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-deep-learning/resources/SegNet_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            209.171875
        </positionTop>
        <positionLeft>
            257.140625
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2144px;
            height:2820px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-204.171875px;left:-252.140625px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_4" style="top: 209.172px; left: 257.141px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="SegNet is a deep convolutional encoder-decoder architecture for robust semantic pixel-wise labelling.
You can see more details in: http://mi.eng.cam.ac.uk/projects/segnet/"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_segmentation.png" width="20px">&nbsp;<span class="name">SegNet</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 297px; top: 239px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
