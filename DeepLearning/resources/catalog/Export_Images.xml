<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.10"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd"
    name="Export_Images" projectName="1. Input and Output"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2"
>
  <variables>
    <variable name="GPU_NODES_ONLY" value="False" model="PA:Boolean"/>
    <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ Download a zip file of your results ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="deep-learning"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_images.png"/>
    <info name="Documentation" value="https://www.activeeon.com/public_content/documentation/latest/MLOS/MLOSUserGuide.html#_export_images"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Export_Images">
      <description>
        <![CDATA[ Download a zip file of your results ]]>
      </description>
      <variables>
        <variable name="GPU_NODES_ONLY" value="False" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_images.png"/>
        <info name="task.documentation" value="https://www.activeeon.com/public_content/documentation/latest/MLOS/MLOSUserGuide.html#_export_images"/>
      </genericInformation>
      <inputFiles>
        <files  includes="$DATASET_PATH/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <selection>
        <script
         type="static" >
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Export_Images")

import pandas as pd
import zipfile
import shutil
import torch
import json
import uuid
import os

from os.path import join
from torch.autograd import Variable
from torch.utils.data import DataLoader
from torchvision import datasets, models, transforms

from os import remove, listdir, makedirs
from os.path import basename, splitext, exists, join, isfile

if 'variables' in locals():
  DATASET_PATH   = variables.get("DATASET_PATH")
  CNN_TRANSFORM  = variables.get("CNN_TRANSFORM")
  PREDICT_DATA   = variables.get("PREDICT_DATA_JSON")
  BATCH_SIZE   = variables.get("BATCH_SIZE")   
  NUM_WORKERS   = variables.get("NUM_WORKERS")  
  SHUFFLE   = variables.get("SHUFFLE")  
 
assert DATASET_PATH is not None
assert CNN_TRANSFORM is not None

# Load CNN transform
# data_transforms
exec(CNN_TRANSFORM)

# Load dataset
image_dataset = {x: 
  datasets.ImageFolder(join(DATASET_PATH, x), data_transforms[x]) 
  for x in ['test']}

data_loader = {x: 
  DataLoader(image_dataset[x], batch_size=BATCH_SIZE, shuffle=SHUFFLE, num_workers=NUM_WORKERS) 
  for x in ['test']}

# Get an unique ID
ID = str(uuid.uuid4())

# Define localspace
LOCALSPACE = join('results', ID)
if exists(LOCALSPACE):
  shutil.rmtree(LOCALSPACE)
makedirs(LOCALSPACE)


if PREDICT_DATA != None: 
  prediction_result  = pd.read_json(PREDICT_DATA, orient='split')
  df = pd.DataFrame(prediction_result)
  preds = df['Prediction']

  for index, elem in enumerate(preds):
    #create a new folder
    foldoutcheck = os.path.exists(LOCALSPACE + '/' + preds[index])
    
    if foldoutcheck == False:
      teste = os.makedirs(LOCALSPACE + '/' + preds[index])
    
    foldcheck = os.path.exists(LOCALSPACE + '/' + preds[index])  
    print(foldcheck)
    
    if foldcheck == True:
       shutil.copy2(data_loader['test'].dataset.imgs[index][0], LOCALSPACE + '/' + preds[index])
    else:
      os.makedirs(LOCALSPACE + '/' + preds[index])
      shutil.copy2(data_loader['test'].dataset.imgs[index][0], LOCALSPACE + '/' + preds[index])


  FILE_NAME = '.zip'  
  FILE_PATH = join(LOCALSPACE, FILE_NAME)
  print("FILE_PATH: " + FILE_PATH)
  
  def zipdir(_path, _ziph):
    # ziph is zipfile handle
    for root, dirs, files in os.walk(_path):
      for file in files:
        _ziph.write(join(root, file))

  zipf = zipfile.ZipFile(FILE_PATH, 'w', zipfile.ZIP_DEFLATED)
  zipdir(LOCALSPACE, zipf)
  zipf.close()
  
  assert isfile(FILE_PATH) == True

  # Read the whole file at once
  FILE_BIN = None
  with open(FILE_PATH, "rb") as binary_file:
    FILE_BIN = binary_file.read()
  assert FILE_BIN is not None

  if 'variables' in locals():
    result = FILE_BIN
    resultMetadata.put("file.extension", ".zip")
    resultMetadata.put("file.name", "result.zip")
    resultMetadata.put("content.type", "application/octet-stream")

    print("END Export_Images")
else:
    print("It is not possible to export the images")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
  </taskFlow>
</job>