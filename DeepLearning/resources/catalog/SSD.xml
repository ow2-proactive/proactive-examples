<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.14" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="SSD" onTaskError="continueJobExecution" priority="normal" tags="Natural Language Processing,Text Analysis,Computer Vision,Image Analysis,Detection,Machine Learning,Deep Learning" projectName="2.3. Image Object Detection" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd">
  <variables>
    <variable advanced="true" description="Container platform used for executing the workflow tasks." group="Container Parameters" hidden="false" model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker"/>
    <variable advanced="true" description="If True, it will activate the use of GPU for the workflow tasks on the selected container platform." group="Container Parameters" hidden="false" model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="True"/>
    <variable advanced="true" description="Name of the container image being used to run the workflow tasks." group="Container Parameters" hidden="false" model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/rapidsai,docker://activeeon/tensorflow:latest,docker://activeeon/tensorflow:latest-gpu)" name="CONTAINER_IMAGE" value=""/>
  </variables>
  <description>
    <![CDATA[ SSD produces a fixed-size collection of bounding boxes and scores for the presence of object class instances in those boxes, followed by a non-maximum suppression step to produce the final detections.
 ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="ai-deep-learning"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_detection.png"/>
<info name="Documentation" value="PAIO/PAIOUserGuide.html#_ssd"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="SSD">
      <description>
        <![CDATA[ SSD produces a fixed-size collection of bounding boxes and scores for the presence of object class instances in those boxes, followed by a non-maximum suppression step to produce the final detections. ]]>
      </description>
      <variables>
        <variable advanced="false" description="Initial iteration number." hidden="false" inherited="false" name="START_ITERATION" value="0"/>
        <variable advanced="false" description="Maximum number of iteration to be performed." hidden="false" inherited="false" name="MAX_ITERATION" value="5"/>
        <variable advanced="false" description="Learning steps update for SGD (Stochastic Gradient Descent)." hidden="false" inherited="false" name="LR_STEPS" value="(80000, 100000, 120000)"/>
        <variable advanced="false" description="Learning rate update for SGD." hidden="false" inherited="false" name="LR_FACTOR" value="1e-3"/>
        <variable advanced="false" description="Gamma update for SGD." hidden="false" inherited="false" name="GAMMA" value="0.1"/>
        <variable advanced="false" description="Minimum object size to be detected by specifying numerical values or reference areas on the screen. Objects smaller than that are ignored." hidden="false" inherited="false" name="MIN_SIZES" value="[30, 60, 111, 162, 213, 264]"/>
        <variable advanced="false" description="Maximum object size to be detected by specifying numerical values or reference areas on the screen. Objects larger than that are ignored." hidden="false" inherited="false" name="MAX_SIZES" value="[60, 111, 162, 213, 264, 315]"/>
        <variable advanced="false" description="Initial learning rate." hidden="false" inherited="false" name="LEARNING_RATE" value="1e-8"/>
        <variable advanced="false" description="Momentum value for optimization." hidden="false" inherited="false" name="MOMENTUM" value="0.9"/>
        <variable advanced="false" description="Weight decay for SGD" hidden="false" inherited="false" name="WEIGHT_DECAY" value="5e-4"/>
        <variable advanced="false" description="(Width, height) of the images as a tuple with 2 elements." hidden="false" inherited="false" name="IMG_SIZE" value="(300, 300)"/>
        <variable advanced="false" description="Number of classes or labels." hidden="false" inherited="false" name="NUM_CLASSES" value="21"/>
        <variable advanced="false" description="URL of the file containing the class names of the dataset." hidden="false" inherited="false" name="LABEL_PATH" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/voc.names"/>
        <variable advanced="false" description="If True, the pre-trained model with the corresponding number of layers is loaded and used for training. Otherwise, the network is trained from scratch." hidden="false" inherited="false" name="USE_PRETRAINED_MODEL" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_detection.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_ssd"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/ai-deep-learning/resources/SSD_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            188.171875
        </positionTop>
        <positionLeft>
            250.140625
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2144px;
            height:2820px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-183.171875px;left:-245.140625px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_4" style="top: 188.172px; left: 250.141px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Single Shot MultiBox Detector (SSD) produces a fixed-size collection of bounding boxes and scores for the presence of object class instances in those boxes, followed by a non-maximum suppression step to produce the final detections.
You can see more details in: https://www.cs.unc.edu/~wliu/papers/ssd.pdf
https://github.com/amdegroot/ssd.pytorch"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_detection.png" width="20px">&nbsp;<span class="name">SSD</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 290px; top: 218px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
