<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"
    name="Predict_Text_Classification_Model" projectName="5. Predict"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
    <variable name="GPU_NODES_ONLY" value="False" model="PA:Boolean"/>
    <variable name="GPU_CUDA_PATH" value="/usr/local/cuda" />
    <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ Predict results based on new data ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="deep-learning"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png"/>
    <info name="Documentation" value="http://activeeon.com/resources/automated-machine-learning-activeeon.pdf"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Predict_Text_Classification_Model" >
      <description>
        <![CDATA[ Predict results based on new data ]]>
      </description>
      <variables>
        <variable name="GPU_NODES_ONLY" value="False" inherited="true" model="PA:Boolean"/>
        <variable name="GPU_CUDA_PATH" value="/usr/local/cuda" inherited="true" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="LOSS_FUNCTION" value="NLLLoss" inherited="false" model="PA:List(L1Loss, MSELoss, CrossEntropyLoss, NLLLoss)"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png"/>
      </genericInformation>
      <inputFiles>
        <files  includes="$DATASET_PATH/**" accessMode="transferFromGlobalSpace"/>
        <files  includes="$MODEL_FOLDER/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <selection>
        <script type="static">
          <code language="javascript">
            <![CDATA[
selected = ((variables.get("GPU_NODES_ONLY").equalsIgnoreCase("false")) || (variables.get("GPU_NODES_ONLY").equalsIgnoreCase("true") && org.ow2.proactive.scripting.helper.selection.SelectionUtils.checkFileExist(variables.get("GPU_CUDA_PATH"))));
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Predict_Text_Classification_Model")

from torchtext import data
from torchtext import datasets
from torchtext import vocab
from torchtext.vocab import Vectors, FastText, GloVe, CharNGram
from tqdm import tqdm
import time, random
import os
from torch.autograd import Variable
import torch.optim as optim
import time
#import spacy
from itertools import *
import torch
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
import dill as pickle

pd.options.display.max_colwidth = 500
DEVICE = -1
#-------------------------main code --------------------------
DATASET_ITERATOR_UNL = None
DATASET_ITERATOR = None
#--------Get varaiables from previous tasks--------
if 'variables' in locals():
    if variables.get("MODEL_PATH") is not None:
        MODEL_PATH = variables.get("MODEL_PATH")
    if variables.get("LOSS_FUNCTION") is not None:
        LOSS_FUNCTION = variables.get("LOSS_FUNCTION")
    if variables.get("BATCH_SIZE") is not None:
        BATCH_SIZE = variables.get("BATCH_SIZE")
    if variables.get("USE_GPU") is not None:
        USE_GPU = variables.get("USE_GPU")
    if variables.get("DEVICE") is not None:
        DEVICE = variables.get("DEVICE") 
    if variables.get("IS_LABELED_DATA") is not None:
        IS_LABELED_DATA = variables.get("IS_LABELED_DATA")
    if variables.get("vocab_size") is not None:
        vocab_size = variables.get("vocab_size")
    if variables.get("label_size") is not None:
        label_size = variables.get("label_size")
    if variables.get("BATCH_SIZE") is not None:
        label_size = variables.get("BATCH_SIZE")
    if variables.get("MODEL_CLASS") is not None:
        MODEL_CLASS = variables.get("MODEL_CLASS")
    if variables.get("MODEL_DEF") is not None:
        MODEL_DEF = variables.get("MODEL_DEF")


#--------Load Dataset--------

if 'variables' in locals():
    if variables.get("DATASET_PATH") is not None:
        DATASET_PATH = variables.get("DATASET_PATH")
    if variables.get("DATASET_ITERATOR") is not None:
        DATASET_ITERATOR = variables.get("DATASET_ITERATOR")
        DATASET_PATH = variables.get("DATASET_PATH")
        exec(DATASET_ITERATOR)
    if variables.get("DATASET_ITERATOR_UNL") is not None:
        DATASET_ITERATOR_UNL = variables.get("DATASET_ITERATOR_UNL")
        DATASET_PATH = variables.get("DATASET_PATH")
        exec(DATASET_ITERATOR_UNL)
    #Load model files
    if variables.get("LABELS_PATH") is not None:
        LABELS_PATH = variables.get("LABELS_PATH")
    if variables.get("TEXT_PATH") is not None:
        TEXT_PATH = variables.get("TEXT_PATH")
   
#-------Main--------
def evaluate(model, test, data_iter, label_field, loss_function, name):
    model.eval()
    avg_loss = 0.0
    truth_res = []
    pred_res = []
    i=0
    acc = 0
    pd.options.display.max_colwidth = 500
    result =  pd.DataFrame(columns=['text','Predictions','Targets'])
    for batch in data_iter:
        i=i+1
        sent, label = batch.text, batch.label
        label.data.sub_(1)
        truth_res += list(label.data)
        model.batch_size = len(test)
        model.hidden = model.init_hidden()
        pred = model(sent)
        pred_label = pred.data.max(1)[1].numpy()
        for i in range(model.batch_size):
            test_fields = vars(test[i])
            test_text = test_fields["text"]
            test_label = test_fields["label"]
            prede_label = pred_label[i]
            gd_label = label[i]
            result.loc[i] = [' '.join(test_text),label_field.vocab.itos[prede_label+1], test_label]
        pred_res += [x for x in pred_label]
        if name is 'test_labeled':
            loss = loss_function(pred, label)
            avg_loss += loss.data[0]
    if name is 'test_labeled':
        avg_loss /= len(test)
        pred_res = torch.LongTensor(pred_res)
        acc = get_accuracy(truth_res, pred_res)
        print(name + ': loss %.2f acc %.1f' % (avg_loss, acc*100))
    return acc, result
    
def get_accuracy(truth, pred):
     assert len(truth)==len(pred)
     right = 0
     for i in range(len(truth)):
         if truth[i]==pred[i]:
             right += 1.0
     return right/len(truth)
     
LOSS ="""loss_function = nn."""+LOSS_FUNCTION+"""()"""

exec(LOSS)


label_field = pickle.load(open(LABELS_PATH,'rb'))
text_field = pickle.load(open(TEXT_PATH,'rb'))
exec(MODEL_CLASS)

MODEL=torch.load(MODEL_PATH)
if variables.get("DATASET_ITERATOR_UNL") is not None:
    print('I am testing the unlabeled dataset')
    test_acc, results = evaluate(MODEL, test, test_iter, label_field, loss_function, 'test_unlabeled')
else:
    print('I am testing the labeled dataset')
    test_acc, results = evaluate(MODEL, test, test_iter, label_field, loss_function, 'test_labeled')

#------plot results-----
# Forward results for preview 
try:
    variables.put("PREDICT_DATA_JSON", results.to_json(orient='split'))
except NameError as err:
    print("{0}".format(err))
    print("Warning: this script is running outside from ProActive.")
    pass

print("END Predict_Text_Classification_Model")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            499.0972595214844
        </positionTop>
        <positionLeft>
            1055.920166015625
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
</job>