<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.13" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd"  name="Emotion_Detection_In_Bing_Images" projectName="1. Azure Cognitive Services" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="NATIVE_SCHEDULER" value="" model="" description="Name of the Native Scheduler node source to use when the workflow tasks must be deployed inside a cluster such as SLURM, LSF, etc." group="Resource Management" advanced="true" hidden="false"/>
    <variable name="NATIVE_SCHEDULER_PARAMS" value="" model="" description="Parameters given to the native scheduler (SLURM, LSF, etc) while requesting a ProActive node used to deploy the workflow tasks." group="Resource Management" advanced="true" hidden="false"/>
    <variable name="NODE_ACCESS_TOKEN" value="" model="" description="If not empty, the workflow tasks will be run only on nodes belonging to the specified node source." group="Resource Management" advanced="true" hidden="false"/>
    <variable name="CONTAINER_PLATFORM" value="docker" model="PA:LIST(no-container,docker,podman,singularity)" description="Container platform used for executing the workflow tasks." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="CONTAINER_GPU_ENABLED" value="True" model="PA:Boolean" description="If True, it will activate the use of GPU for the workflow tasks on the selected container platform." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="CONTAINER_IMAGE" value="" model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2)" description="Name of the container image being used to run the workflow tasks." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="SEARCH_TERM" value="Denis Caromel"  description="Used to specify the user&#39;s search terms."  advanced="false" hidden="false"/>
    <variable name="LICENCE" value=""  description="Filter images by the type of license associated with the site."  advanced="false" hidden="false"/>
    <variable name="IMAGE_TYPE" value=""  description="Filter images by type (for example, clip art, animated GIFs, or transparent backgrounds)."  advanced="false" hidden="false"/>
    <variable name="OUTPUT_FORMAT" value="HTML" model="PA:LIST(CSV, HTML)" description="The format of the output file."  advanced="false" hidden="false"/>
    <variable name="COUNT" value="10"  description="Used to page image results."  advanced="false" hidden="false"/>
    <variable name="MARKET" value="fr-FR"  description="Used to specify the market where the results come from, which is typically the market where the user is making the request from."  advanced="false" hidden="false"/>
  </variables>
  <description>
    <![CDATA[ Search for images of a person using Azure Bing Image Search then perform an emotion detection using Azure Emotion API. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="deep-learning-workflows"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/cognitive_services.png"/>
    <info name="PYTHON_COMMAND" value="python3"/>
    <info name="NS" value="$NATIVE_SCHEDULER"/>
    <info name="Documentation" value="PML/PMLUserGuide.html#_azure_cognitive_services"/>
    <info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
    <info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="BingImageSearch" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ This task wraps the Bing Image Search API of Microsoft which provides an experience similar to Bing.com/images by returning images that Bing determines are relevant to a query.
The task requires this third-party credential : $BING_SEARCH_API_KEY which provides access to this API. Please refer to the User documentation to learn how to add third-party credentials.
$SEARCH_TERM (required) is the user's search query string.
$LICENCE (optional) filters images by the following license types: {"Any", "Public", "Share" ,"ShareCommercially" ,"Modify" ,"ModifyCommercially", "All"}
$IMAGE_TYPE (optional) filter images by the following image types: {"AnimatedGif", "Clipart", "Line" ,"Photo" ,"Modify" ,"Shopping", "Transparent"}
The task's output $BING_IMAGE_SEARCH_OUTPUT is the result of the API call in a JSON format. ]]>
      </description>
      <variables>
        <variable name="SEARCH_TERM" value="activeeon" inherited="true"  description="Used to specify the user&#39;s search terms."  advanced="false" hidden="false"/>
        <variable name="LICENCE" value="" inherited="true"  description="Filter images by the type of license associated with the site."  advanced="false" hidden="false"/>
        <variable name="IMAGE_TYPE" value="" inherited="true"  description="Filter images by type (for example, clip art, animated GIFs, or transparent backgrounds)."  advanced="false" hidden="false"/>
        <variable name="COUNT" value="2" inherited="true" model="PA:Integer" description="Used to page image results." group="" advanced="false" hidden="false"/>
        <variable name="OUTPUT_FORMAT" value="HTML" inherited="true" model="PA:LIST(CSV, HTML)" description="The format of the output file."  advanced="false" hidden="false"/>
        <variable name="MARKET" value="" inherited="true"  description="Used to specify the market where the results come from, which is typically the market where the user is making the request from."  advanced="false" hidden="false"/>
      </variables>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_bing_image_search.png"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import requests
import json
import urllib
from pprint import pprint
import pandas as pd

# You can customize the api server location
#api_location="westcentralus"

# Congitive Services - Bing Image Search API URL:
#bing_image_search_url = "https://{0}.api.cognitive.microsoft.com/bing/v7.0/images/search".format(api_location)
bing_image_search_url = "https://api.cognitive.microsoft.com/bing/v7.0/images/search"


# READ TASK VARIABLES
if 'variables' in locals():
    if variables.get("SEARCH_TERM") is not None:
        SEARCH_TERM = variables.get("SEARCH_TERM")
    else:
        print("You first need to specify the search term")
        sys.exit(1)
    if variables.get("LICENCE") is not None:
        LICENCE = variables.get("LICENCE")
    if variables.get("IMAGE_TYPE") is not None:
        IMAGE_TYPE = variables.get("IMAGE_TYPE")
    if variables.get("COUNT") is not None:
        COUNT = int(variables.get("COUNT"))
    if variables.get("MARKET") is not None:
        MARKET = variables.get("MARKET")
    if variables.get("OUTPUT_FORMAT") is not None:
        OUTPUT_FORMAT = variables.get("OUTPUT_FORMAT")
    # Provide a valid subscription API token
    if credentials.get("BING_SEARCH_API_KEY") is not None:
        subscription_key = credentials.get("BING_SEARCH_API_KEY")
    else:
        print("You first need to add your Azure Cognitive Services API key to the third party credentials")
        sys.exit(1)

# Set API request parameters
#params  = {"q": SEARCH_TERM, "licence": LICENCE, "imageType": IMAGE_TYPE}
params={'q':SEARCH_TERM}
if LICENCE is not None and len(LICENCE)>0:
    params['licence'] = LICENCE
if IMAGE_TYPE is not None and len(IMAGE_TYPE)>0:
    params['imageType'] = IMAGE_TYPE
if COUNT >0:
    params['count'] = COUNT
# Market Code: https://docs.microsoft.com/fr-fr/rest/api/cognitiveservices/bing-images-api-v7-reference#market-codes
if MARKET is not None and len(MARKET)>0:
    params['mkt'] = MARKET

# Send API request
headers   = {
    "Ocp-Apim-Subscription-Key": subscription_key,
    'Content-Type': 'text/plain'
}
response = requests.get(bing_image_search_url, headers=headers, params=params)
response.raise_for_status()

# Get a JSON response
search_results = response.json()

# Print the results
#pprint(search_results)

if 'variables' in locals():
    variables.put('BING_IMAGE_SEARCH_OUTPUT', search_results)

OUTPUT_DATA = search_results["value"]
table = []
for document in OUTPUT_DATA:
    thumbnail= document["thumbnailUrl"]
    image_url= document["contentUrl"]
    encodingFormat= document["encodingFormat"]
    name= document["name"]
    table.append("""<tr><td><a href="{3}"><img src="{0}" alt="{2}" height="150" width="150"/></a></td><td>{1}</td><td>{2}</td>""".format(thumbnail, encodingFormat, name, image_url))
    
css_style="""table {
  border: 1px solid #999999;
  text-align: center;
  border-collapse: collapse;
  width: 100%;
}
td {
  border: 1px solid #999999;
  padding: 3px 2px;
  font-size: 13px;
  border-bottom: 1px solid #999999;
}
th {
  font-size: 17px;
  font-weight: bold;
  color: #FFFFFF;
  text-align: center;
  background: #0B6FA4;
  border-left: 2px solid #999999;
}"""
html = ("""<table><tr><th width="100">Image</th><th width="100">Type</th><th>Description</th></tr>{0}</table>""").format("\n".join(table))
html_container="""<!DOCTYPE html>
            <html>
              <head>
                <meta charset="UTF-8">
                  <meta name="description" content="Bing Video Search API Results">
                    <style>{0}</style>
                  </head>
                  <body>{1}</body></html>""".format(css_style,html)
if OUTPUT_DATA != None and 'resultMetadata' in locals(): 
    dataframe=pd.read_html(html_container,header=0, encoding='utf-8')[0]
    
    if OUTPUT_FORMAT == 'JSON':
        result = json.dumps(search_results).encode('utf-8')
        resultMetadata.put("file.extension", ".json")
        resultMetadata.put("file.name", "result.json")
        resultMetadata.put("content.type", "application/json")
    elif OUTPUT_FORMAT == 'CSV':
        result = dataframe.to_csv(index=False)
        resultMetadata.put("file.extension", ".csv")
        resultMetadata.put("file.name", "result.csv")
        resultMetadata.put("content.type", "text/csv")
    elif OUTPUT_FORMAT == 'HTML':
        result = html_container.encode('utf-8')
        resultMetadata.put("file.extension", ".html")
        resultMetadata.put("file.name", "result.html")
        resultMetadata.put("content.type", "text/html")
    print("END Export_Results")  
else:
    print('It is not possible to export the data')

# Uncomment this to render the HTML result locally in your python notebook
#from IPython.display import HTML
#HTML(html_container)
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            75.4600830078125
        </positionTop>
        <positionLeft>
            279.765625
        </positionLeft>
      </metadata>
    </task>
    <task name="Split" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ Defines some input, here strings to be processed. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_replicate"/>
      </genericInformation>
      <depends>
        <task ref="BingImageSearch"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print(variables.get("BING_IMAGE_SEARCH_OUTPUT"))
OUTPUT_DATA=variables.get("BING_IMAGE_SEARCH_OUTPUT")["value"]
urls=[]
for document in OUTPUT_DATA:
    image_url=str('{0}'.format(document["contentUrl"]))
    print(image_url)
    urls.append(image_url)

result=urls  
print(result)
#print("image_urls= ", image_urls)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow >
        <replicate>
          <script>
            <code language="groovy">
              <![CDATA[
runs=variables.get("COUNT")
]]>
            </code>
          </script>
        </replicate>
      </controlFlow>
      <metadata>
        <positionTop>
            204.46182250976562
        </positionTop>
        <positionLeft>
            278.76739501953125
        </positionLeft>
      </metadata>
    </task>
    <task name="Merge" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ As a merge operation, we simply print the results from previous tasks. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_replicate"/>
      </genericInformation>
      <depends>
        <task ref="Emotion_API"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
from bs4 import BeautifulSoup
import copy


print("results=",results)
print("values=",results[0].value().decode("utf-8"))
merged_html=BeautifulSoup(str(results[0].value().decode("utf-8") ))
print('len==',len(results))
i=0
for html in results:
    if i==0:
        i=i+1
        continue
    i=i+1
    soup = BeautifulSoup(html.value())
    print('***************')
    print('BODY==',soup)
    for element in soup.body:
        print('element=====',element)
        merged_html.body.append(copy.copy(element))

result=str(merged_html).encode('utf-8')
resultMetadata.put("file.extension", ".html")
resultMetadata.put("file.name", "result.html")
resultMetadata.put("content.type", "text/html")
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            459.46185302734375
        </positionTop>
        <positionLeft>
            277.76043701171875
        </positionLeft>
      </metadata>
    </task>
    <task name="Emotion_API" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ Welcome to the Microsoft Emotion API, which allows you to build more personalized apps with Microsoft as cutting edge cloud-based emotion recognition algorithm. https://azure.microsoft.com/en-us/services/cognitive-services/emotion/ ]]>
      </description>
      <variables>
        <variable name="AZURE_EMOTION_API_ENDPOINT" value="https://westus.api.cognitive.microsoft.com" inherited="false"  description="The Azure emotion API endpoint."  advanced="false" hidden="false"/>
        <variable name="IMAGE_URL" value="https://upload.wikimedia.org/wikipedia/commons/c/c3/RH_Louise_Lillian_Gish.jpg" inherited="true"  description="The image that will be used to detect the emotions."  advanced="false" hidden="false"/>
      </variables>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_emotion.png"/>
      </genericInformation>
      <depends>
        <task ref="Split"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Emotion_API")

import http.client, urllib.request, urllib.parse, urllib.error, base64, requests, json
import pandas as pd
from pandas.io.json import json_normalize

if 'variables' in locals():
  replication = variables.get('PA_TASK_REPLICATION')
  IMAGE_URL = str(results[0].value()[replication])
  #print(URL_IMAGE)
  #print(variables.get("URL_IMAGE"))
  #IMAGE_URL = variables.get("IMAGE_URL")
  # Replace the subscription_key string value with your valid subscription key.
  subscription_key = credentials.get("AZURE_EMOTION_API_KEY")
  # Replace or verify the region.
  #
  # You must use the same region in your REST API call as you used to obtain your subscription keys.
  # For example, if you obtained your subscription keys from the westus region, replace 
  # "westcentralus" in the URI below with "westus".
  #
  # NOTE: Free trial subscription keys are generated in the westcentralus region, so if you are using
  # a free trial subscription key, you should not need to change this region.
  #uri_base = 'https://westcentralus.api.cognitive.microsoft.com'
  uri_base = variables.get("AZURE_EMOTION_API_ENDPOINT")

# Request headers.
headers = {
    'Content-Type': 'application/json',
    'Ocp-Apim-Subscription-Key': subscription_key,
}

# Request parameters.
params = {
    'returnFaceId': 'true',
    'returnFaceLandmarks': 'false',
    'returnFaceAttributes': 'age,gender,headPose,smile,facialHair,glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise',
}

# Body. The URL of a JPEG image to analyze.
body = {'url': IMAGE_URL}

try:
  # Execute the REST API call and get the response.
  #response = requests.request('POST', uri_base + '/face/v1.0/detect', json=body, data=None, headers=headers, params=params)
  response = requests.request('POST', uri_base + '/emotion/v1.0/recognize', json=body, data=None, headers=headers, params=params)
  print('Response:')
  print(response)
  parsed = json.loads(response.text)
  if len(response.text) > 2 and response.status_code == 200:
    emotion = parsed[0]["scores"]
  else:
    emotion = {'error': 'face or emotion not detected.' }
  #rect = parsed[0]["faceAttributes"]["emotion"]
  #print(rect)
  #print (json.dumps(max(rect, key=rect.get), sort_keys=True, indent=2))
except Exception as ex:
  print('Error:')
  print(ex)

output_json = json.dumps(parsed).encode('utf-8')
print(output_json)

if 'variables' in locals():
  variables.put("AZURE_EMOTION_API_OUTPUT_JSON", output_json)

df = json_normalize(emotion)

table = []
table.append("""<tr><td><a href="{0}"><img src="{0}" height="150" width="150"/></a></td><td>{1}</td>""".format(IMAGE_URL, df.to_html()))
        
css_style="""
table {
  border: 1px solid #999999;
  text-align: center;
  border-collapse: collapse;
  width: 100%;
}
td {
  border: 1px solid #999999;
  padding: 3px 2px;
  font-size: 13px;
  border-bottom: 1px solid #999999;
}
th {
  font-size: 17px;
  font-weight: bold;
  color: #FFFFFF;
  text-align: center;
  background: #0B6FA4;
  border-left: 2px solid #999999
}
"""

html = """<table><th width=200>Image</th><th>Reponse</th></tr>{0}</table>""".format("\n".join(table))

html_container = """<!DOCTYPE html>
                  <html>
                    <head>
                      <meta charset="UTF-8">
                        <meta name="description" content="Face API">
                          <style>{0}</style>
                        </head>
                        <body>{1}</body></html>
""".format(css_style, html)

if 'variables' in locals():
  result = html_container.encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "result.html")
  resultMetadata.put("content.type", "text/html")

print("END Emotion_API")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            331.4583435058594
        </positionTop>
        <positionLeft>
            278.76739501953125
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2386px;
            height:3139px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-70.4600830078125px;left:-272.76043701171875px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_16" style="top: 75.4683px; left: 279.766px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task wraps the Bing Image Search API of Microsoft which provides an experience similar to Bing.com/images by returning images that Bing determines are relevant to a query.
The task requires this third-party credential : $BING_SEARCH_API_KEY which provides access to this API. Please refer to the User documentation to learn how to add third-party credentials.
$SEARCH_TERM (required) is the user's search query string.
$LICENCE (optional) filters images by the following license types: {&quot;Any&quot;, &quot;Public&quot;, &quot;Share&quot; ,&quot;ShareCommercially&quot; ,&quot;Modify&quot; ,&quot;ModifyCommercially&quot;, &quot;All&quot;}
$IMAGE_TYPE (optional) filter images by the following image types: {&quot;AnimatedGif&quot;, &quot;Clipart&quot;, &quot;Line&quot; ,&quot;Photo&quot; ,&quot;Modify&quot; ,&quot;Shopping&quot;, &quot;Transparent&quot;}
The task's output $BING_IMAGE_SEARCH_OUTPUT is the result of the API call in a JSON format."><img src="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_bing_image_search.png" width="20px">&nbsp;<span class="name">BingImageSearch</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_19" style="top: 204.47px; left: 278.768px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Defines some input, here strings to be processed."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Split</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_22" style="top: 459.47px; left: 277.761px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="As a merge operation, we simply print the results from previous tasks."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Merge</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_25" style="top: 331.467px; left: 278.768px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Welcome to the Microsoft Emotion API, which allows you to build more personalized apps with Microsoft as cutting edge cloud-based emotion recognition algorithm. https://azure.microsoft.com/en-us/services/cognitive-services/emotion/"><img src="/automation-dashboard/styles/patterns/img/wf-icons/azure/api_emotion.png" width="20px">&nbsp;<span class="name">Emotion_API</span></a></div><svg style="position:absolute;left:318.5px;top:115.5px" width="29" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88 C -10 38 18 50 8 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.149632,66.303232 L7.49984351657956,47.438247975227235 L-0.24966605297428535,52.43275510120006 L-6.370633382220376,45.538282028201515 L-2.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.149632,66.303232 L7.49984351657956,47.438247975227235 L-0.24966605297428535,52.43275510120006 L-6.370633382220376,45.538282028201515 L-2.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:344.46578674770865px;top:233.5px" width="15.034213252291345" height="99" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88 C -10 88 -10 -10 0 0 " transform="translate(14.534213252291345,10.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#e5db3d" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.889249999999999,77.41936575 L-0.6632823303137547,56.65542592021898 L-6.785898453911784,63.54843482802241 L-14.534213252291345,58.55207437413076 L-4.889249999999999,77.41936575" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(14.534213252291345,10.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.889249999999999,77.41936575 L-0.6632823303137547,56.65542592021898 L-6.785898453911784,63.54843482802241 L-14.534213252291345,58.55207437413076 L-4.889249999999999,77.41936575" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(14.534213252291345,10.5)"></path></svg><div class="_jsPlumb_overlay l1 component label" id="jsPlumb_1_36" style="position: absolute; transform: translate(-50%, -50%); left: 351px; top: 283.75px;">replicate</div><svg style="position:absolute;left:317.5px;top:371.5px" width="22" height="88" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 87 C -10 37 11 50 1 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.73415625,65.86284375000001 L5.097889276531336,46.17378427854886 L-2.1474192361323814,51.875144165130536 L-8.88981030833814,45.58704726468124 L-2.73415625,65.86284375000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.73415625,65.86284375000001 L5.097889276531336,46.17378427854886 L-2.1474192361323814,51.875144165130536 L-8.88981030833814,45.58704726468124 L-2.73415625,65.86284375000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:313.98171321138256px;top:243.5px" width="15.518286788617468" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 -10 50 0 0 " transform="translate(15.018286788617468,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 327px; top: 106px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 319px; top: 234px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 319px; top: 194px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint replicate-source-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 349px; top: 234px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 318px; top: 489px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 318px; top: 449px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 319px; top: 362px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint replicate-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 349px; top: 322px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 319px; top: 322px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>