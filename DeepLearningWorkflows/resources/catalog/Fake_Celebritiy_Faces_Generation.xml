<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.13" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Fake_Celebritiy_Faces_Generation" onTaskError="continueJobExecution" priority="normal" projectName="5. Prediction Pytorch Workflows" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd">
  <variables>
    <variable name="NATIVE_SCHEDULER" value=""/>
    <variable name="NATIVE_SCHEDULER_PARAMS" value=""/>
    <variable name="NODE_ACCESS_TOKEN" value=""/>
    <variable model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker"/>
    <variable model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="True"/>
    <variable model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/nvidia:pytorch)" name="CONTAINER_IMAGE" value=""/>
    <variable model="PA:Integer" name="NB_IMAGES" value="64"/>
  </variables>
  <description>
    <![CDATA[ Generate  a wild diversity of fake faces  using a GAN model. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="deep-learning-workflows"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
<info name="NS" value="$NATIVE_SCHEDULER"/>
<info name="PYTHON_COMMAND" value="python3"/>
<info name="Documentation" value="PML/PMLUserGuide.html#_prediction_custom_ai_workflows_pytorch_library"/>
<info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
<info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Split_Images">
      <description>
        <![CDATA[ This task defines some input, here strings to be processed. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_replicate"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
if 'variables' in locals():
  NB_IMAGES = int(variables.get("NB_IMAGES"))
  
result = []
for i in range(1,NB_IMAGES+1):
	img_name = str(i)+".png"
	result.append(img_name)


variables.put("IMAGES_LIST", result)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow>
        <replicate>
          <script>
            <code language="groovy">
              <![CDATA[
runs=variables.get("NB_IMAGES")
]]>
            </code>
          </script>
        </replicate>
      </controlFlow>
      <metadata>
        <positionTop>
            271.515625
        </positionTop>
        <positionLeft>
            316.546875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Face_Generator">
      <description>
        <![CDATA[ This task will be replicated according to the 'runs' value specified in the replication script. It will generate a different image during each run. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
      </genericInformation>
      <depends>
        <task ref="Split_Images"/>
      </depends>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import wget  
import argparse
import shutil
import numpy as np
import torchvision.utils as vutils
import urllib.request
import time
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from os import remove, listdir, makedirs
from torch.autograd import Variable, grad
from torch.nn.init import xavier_normal
from torchvision import datasets, transforms
from os.path import join, exists

replication = variables.get('PA_TASK_REPLICATION')
image_path = results[0].value()[replication]
#result = image_path

#DATA_PATH = '/home/xander/data/img_align_celeba/'
MODEL_FOLDER = join('models', 'ID')
if exists(MODEL_FOLDER):
  shutil.rmtree(MODEL_FOLDER)
makedirs(MODEL_FOLDER)

resume_file = 'Epoch+018.pt'
#cuda = torch.cuda.is_available()
batch_size = 1
z_dim = 128
tag_num = 19
imsize = 128
start_epoch = 0
max_epochs = 100000
lambda_adv = tag_num
lambda_gp = 0.5
learning_rate = 0.0002


url = "https://s3.eu-west-2.amazonaws.com/activeeon-public/models/Epoch+018.pt"
request = urllib.request.Request(url)


urllib.request.urlretrieve(url, resume_file)  


def swish(x):
    return x * F.sigmoid(x)

class StableBCELoss(nn.modules.Module):
   def __init__(self):
         super(StableBCELoss, self).__init__()
   def forward(self, input, target):
         neg_abs = - input.abs()
         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()
         return loss.mean()

class FeatureExtractor(nn.Module):
    def __init__(self, cnn, feature_layer=11):
        super(FeatureExtractor, self).__init__()
        self.features = nn.Sequential(*list(cnn.features.children())[:(feature_layer+1)])

    def forward(self, x):
        return self.features(x)

class residualBlock(nn.Module):
    def __init__(self, in_channels=64, k=3, n=64, s=1):
        super(residualBlock, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, n, k, stride=s, padding=1)
        self.bn1 = nn.BatchNorm2d(n)
        self.conv2 = nn.Conv2d(n, n, k, stride=s, padding=1)
        self.bn2 = nn.BatchNorm2d(n)

        self.ac = nn.ReLU()

    def forward(self, x):
        y = self.ac(self.bn1(self.conv1(x)))
        # print y.size()
        return self.bn2(self.conv2(y)) + x


class upsampleBlock(nn.Module):
    # Implements resize-convolution
    def __init__(self, in_channels, out_channels):
        super(upsampleBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1)
        self.shuffler = nn.PixelShuffle(2)
        self.bn = nn.BatchNorm2d(in_channels)

        self.ac = nn.ReLU()

    def forward(self, x):
        return self.ac(self.bn(self.shuffler(self.conv(x))))


class ResBlock(nn.Module):
    def __init__(self, in_channels=64, k=3, n=64, s=1):
        super(ResBlock, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, n, k, stride=s, padding=1)
        self.conv2 = nn.Conv2d(n, n, k, stride=s, padding=1)

        self.ac = nn.LeakyReLU()

    def forward(self, x):
        y = self.ac(self.conv1(x))
        return self.ac(self.conv2(y) + x)

class DBlock(nn.Module):
    def __init__(self, n=64, k=3, s=1):
        super(DBlock, self).__init__()

        self.block1 = ResBlock(n, k, n, s)
        self.block2 = ResBlock(n, k, n, s)

        self.conv1 = nn.Conv2d(n, 2*n, 4, stride=2, padding=1)

        self.ac = nn.LeakyReLU()

    def forward(self, x):
        x = self.block1(x)
        x = self.block2(x)
        return self.ac(self.conv1(x))


# custom weights initialization called on G and D
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)


class Generator(nn.Module):
    def __init__(self, n_residual_blocks=16, upsample_factor=6, tag_num=19):
        super(Generator, self).__init__()
        self.n_residual_blocks = n_residual_blocks
        self.upsample_factor = upsample_factor

        self.dense = nn.Linear(128+tag_num, 64*16*16)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(True)

        for i in range(self.n_residual_blocks):
            self.add_module('residual_block' + str(i+1), residualBlock())

        self.bn2 = nn.BatchNorm2d(64)

        for i in range(self.upsample_factor//2):
            self.add_module('upsample' + str(i+1), upsampleBlock(64, 256))

        self.conv3 = nn.Conv2d(64, 3, 9, stride=1, padding=4)
        self.tanh = nn.Tanh()

    def forward(self, x):
        x = self.dense(x)
        x = x.view(-1, 64, 16, 16)
        x = self.relu(self.bn1(x))

        y = x.clone()
        for i in range(self.n_residual_blocks):
            y = self.__getattr__('residual_block' + str(i+1))(y)

        x = self.relu(self.bn2(y)) + x

        for i in range(self.upsample_factor//2):
            x = self.__getattr__('upsample' + str(i+1))(x)

        return self.tanh(self.conv3(x))

#class Discriminator(nn.Module):
#    def __init__(self, tag_num=19):
#        super(Discriminator, self).__init__()
#        self.conv1 = nn.Conv2d(3, 32, 4, stride=2, padding=1)

#        self.block1 = DBlock(n=32)
#        self.block2 = DBlock(n=64)
#        self.block3 = DBlock(n=128)
#        self.block4 = DBlock(n=256)
#        self.block5 = DBlock(n=512)

#        self.head1 = nn.Linear(1024*2*2, 1)
#        self.head2 = nn.Linear(1024*2*2, tag_num)

#        self.ac = nn.LeakyReLU()
#        self.sigmoid = nn.Sigmoid()

#    def forward(self, x):
#        x = self.ac(self.conv1(x))
#        x = self.block1(x)
#        x = self.block2(x)
#        x = self.block3(x)
#        x = self.block4(x)
#        x = self.block5(x)
#        x = x.view(x.size()[0], -1)

#        return self.head1(x), self.head2(x) # Use with numerically stable torch.nn.BCEWithLogitsLoss() during training
        # return self.sigmoid(self.head1(x)), self.sigmoid(self.head2(x))
generator = Generator()
generator.apply(weights_init)

#discriminator = Discriminator()
#discriminator.apply(weights_init)

opt_g = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))
#opt_d = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))


if resume_file:
    if os.path.isfile(resume_file):
        print("=> loading checkpoint '{}'".format(resume_file))
        checkpoint = torch.load(resume_file, map_location={'cuda:0': 'cpu'})
        start_epoch = checkpoint['epoch']
        best_loss = checkpoint['loss_g'] + checkpoint['loss_d']
        generator.load_state_dict(checkpoint['g_state_dict'])
        #discriminator.load_state_dict(checkpoint['d_state_dict'])
        opt_g.load_state_dict(checkpoint['g_optimizer'])
        #opt_d.load_state_dict(checkpoint['d_optimizer'])
        print("=> loaded checkpoint '{}' (epoch {})"
              .format(resume_file, checkpoint['epoch']))
    else:
        print("=> no checkpoint found at '{}'".format(resume_file))



#criterion = torch.nn.BCEWithLogitsLoss() # StableBCELoss() #
#X = Variable(torch.FloatTensor(batch_size, 3, imsize, imsize))
z = Variable(torch.FloatTensor(batch_size, z_dim))
tags = Variable(torch.FloatTensor(batch_size, tag_num))
#labels = Variable(torch.FloatTensor(batch_size))

z.data.normal_(0, 1)
tags.data.uniform_(to=1)
rep = torch.cat((z, tags.clone()), 1)
    
fake = generator(rep)
    
IMAGE_FOLDER = "face_images"
if exists(IMAGE_FOLDER):
  shutil.rmtree(IMAGE_FOLDER)
makedirs(IMAGE_FOLDER)
IMAGE_PATH = join(IMAGE_FOLDER, image_path)

vutils.save_image(fake.data.view(batch_size, 3, imsize, imsize),IMAGE_PATH)

#image_path = 'fake_samples_epoch.png'

with open(IMAGE_PATH, "rb") as binary_file:
    FILE_BIN = binary_file.read()

result = FILE_BIN
resultMetadata.put("file.name", "output_image.png")
resultMetadata.put("content.type", "image/png")

if 'variables' in locals():
  variables.put("IMAGE_FOLDER", IMAGE_FOLDER)
]]>
          </code>
        </script>
      </scriptExecutable>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$IMAGE_FOLDER/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            399.515625
        </positionTop>
        <positionLeft>
            316.546875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Export_Images" preciousResult="true">
      <description>
        <![CDATA[ As a merge operation, we simply compress the different images generated by previous tasks. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
      </genericInformation>
      <depends>
        <task ref="Face_Generator"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$IMAGE_FOLDER/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import os
import zipfile
import shutil

if 'variables' in locals():
	IMAGE_FOLDER   = variables.get("IMAGE_FOLDER")
    
shutil.make_archive("images", 'zip', IMAGE_FOLDER)


with open("images.zip", "rb") as binary_file:
    FILE_BIN = binary_file.read()
assert FILE_BIN is not None
result = FILE_BIN

if 'variables' in locals():
	resultMetadata.put("file.extension", ".zip")
	resultMetadata.put("file.name", "images.zip")
	resultMetadata.put("content.type", "application/octet-stream")
	print("END Export_Images")
else:
	print("It is not possible to export the images")
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            527.515625
        </positionTop>
        <positionLeft>
            252.546875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Visualize_Images" preciousResult="true">
      <description>
        <![CDATA[ As a merge operation, we simply visualize the different images generated by previous tasks. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
      </genericInformation>
      <depends>
        <task ref="Face_Generator"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$IMAGE_FOLDER/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import os
from PIL import Image
from torchvision.utils import make_grid
import torch
import torchvision.transforms as transforms
import numpy as np

if 'variables' in locals():
	IMAGE_FOLDER   = variables.get("IMAGE_FOLDER")
	IMAGES_LIST   = variables.get("IMAGES_LIST")
    
list_images = []
for i in range(len(IMAGES_LIST)):
	x = Image.open(os.path.join(IMAGE_FOLDER, IMAGES_LIST[i]))
	try:
		image = np.asarray( x, dtype='uint8' )
	except SystemError:
		image = np.asarray( x.getdata(), dtype='uint8' )
	im = transforms.ToTensor()(image)
	list_images.append(im)
    
grid = make_grid(list_images,padding=10)
ndarr = grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()
im = Image.fromarray(ndarr)
im.save("image.png")

with open("image.png", "rb") as binary_file:
    FILE_BIN = binary_file.read()
assert FILE_BIN is not None
result = FILE_BIN
if 'variables' in locals():
	resultMetadata.put("file.extension", ".png")
	resultMetadata.put("content.type", "image/png")
	print("END Visualize_Images")
else:
	print("It is not possible to visualize the images")
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            527.515625
        </positionTop>
        <positionLeft>
            380.546875
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2144px;
            height:3048px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-266.515625px;left:-247.546875px"><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_453" style="top: 271.516px; left: 316.547px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task defines some input, here strings to be processed."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Split_Images</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_456" style="top: 399.516px; left: 316.547px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task will be replicated according to the 'runs' value specified in the replication script. It will generate a different image during each run."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Face_Generator</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_ active-task" id="jsPlumb_1_459" style="top: 527.516px; left: 252.547px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="As a merge operation, we simply compress the different images generated by previous tasks."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Export_Images</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_462" style="top: 527.516px; left: 380.547px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="As a merge operation, we simply visualize the different images generated by previous tasks."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Visualize_Images</span></a></div><svg style="position:absolute;left:386.5px;top:301.5px" width="26.600000000000023" height="99" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 5.600000000000023 88 C 15.600000000000023 88 -10 -10 0 0 " transform="translate(10.5,10.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#e5db3d" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M7.87512690000002,77.41936575 L12.982743866927905,56.85453536122338 L6.571740202092891,63.480169822123855 L-0.9564520609482345,58.157922059130506 L7.87512690000002,77.41936575" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(10.5,10.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M7.87512690000002,77.41936575 L12.982743866927905,56.85453536122338 L6.571740202092891,63.480169822123855 L-0.9564520609482345,58.157922059130506 L7.87512690000002,77.41936575" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(10.5,10.5)"></path></svg><div class="_jsPlumb_overlay l1 component label" id="jsPlumb_1_470" style="position: absolute; transform: translate(-50%, -50%); left: 399.3px; top: 351.75px;">replicate</div><svg style="position:absolute;left:356.5px;top:311.5px" width="24.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 3.5 88 C 13.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M6.031265625,66.78168750000002 L11.53929128462053,46.32046433683204 L5.000190602067454,52.819707543808825 L-2.422688671570663,47.35153935976458 L6.031265625,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M6.031265625,66.78168750000002 L11.53929128462053,46.32046433683204 L5.000190602067454,52.819707543808825 L-2.422688671570663,47.35153935976458 L6.031265625,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:293.5px;top:439.5px" width="87.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88 C -10 38 76.5 50 66.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M4.679576999999997,63.554236 L23.772863110405535,54.36476237491162 L14.580583003685717,53.656252361148134 L13.874879471553665,44.4637563712259 L4.679576999999997,63.554236" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M4.679576999999997,63.554236 L23.772863110405535,54.36476237491162 L14.580583003685717,53.656252361148134 L13.874879471553665,44.4637563712259 L4.679576999999997,63.554236" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:360px;top:439.5px" width="88" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 67 88 C 77 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M62.263534,63.554236 L53.00043640121157,44.4965597808142 L52.327410175632586,53.69150598509854 L43.1377063863101,54.432683605181616 L62.263534,63.554236" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M62.263534,63.554236 L53.00043640121157,44.4965597808142 L52.327410175632586,53.69150598509854 L43.1377063863101,54.432683605181616 L62.263534,63.554236" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 357px; top: 302px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint replicate-source-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 387px; top: 302px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 360.5px; top: 430px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint replicate-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 392.6px; top: 390px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 360.5px; top: 390px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 294px; top: 558px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 294px; top: 518px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 427.5px; top: 558px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 427.5px; top: 518px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
