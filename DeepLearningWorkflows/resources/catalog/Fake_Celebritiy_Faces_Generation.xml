<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.13" xsi:schemaLocation="urn:proactive:jobdescriptor:3.13 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.13/schedulerjob.xsd"  name="Fake_Celebritiy_Faces_Generation" projectName="5. Prediction Pytorch Workflows" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="NATIVE_SCHEDULER" value="" model="" description="Name of the Native Scheduler node source to use when the workflow tasks must be deployed inside a cluster such as SLURM, LSF, etc." group="Resource Management" advanced="true" hidden="false"/>
    <variable name="NATIVE_SCHEDULER_PARAMS" value="" model="" description="Parameters given to the native scheduler (SLURM, LSF, etc) while requesting a ProActive node used to deploy the workflow tasks." group="Resource Management" advanced="true" hidden="false"/>
    <variable name="NODE_SOURCE_NAME" value=""  description="If not empty, the workflow tasks will be run only on nodes belonging to the specified node source." group="Resource Management" advanced="true" hidden="false"/>
    <variable name="NODE_ACCESS_TOKEN" value="" model="" description="If not empty, the workflow tasks will be run only on nodes belonging to the specified node source." group="Resource Management" advanced="true" hidden="false"/>
    <variable name="CONTAINER_PLATFORM" value="docker" model="PA:LIST(no-container,docker,podman,singularity)" description="Container platform used for executing the workflow tasks." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="CONTAINER_IMAGE" value="" model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/nvidia:pytorch)" description="Name of the container image being used to run the workflow tasks." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="CONTAINER_GPU_ENABLED" value="False" model="PA:Boolean" description="If True, it will activate the use of GPU for the workflow tasks on the selected container platform." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="NB_IMAGES" value="64" model="PA:Integer" description="Number of images to be genrated" group="" advanced="false" hidden="false"/>
  </variables>
  <description>
    <![CDATA[ Generate  a wild diversity of fake faces  using a GAN model. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="deep-learning-workflows"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
    <info name="PYTHON_COMMAND" value="python3"/>
    <info name="NS" value="$NATIVE_SCHEDULER"/>
    <info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
    <info name="Documentation" value="PML/PMLUserGuide.html#_prediction_custom_ai_workflows_pytorch_library"/>
    <info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Split_Images" fork="true">
      <description>
        <![CDATA[ This task defines some input, here strings to be processed. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
        <info name="task.documentation" value="user/ProActiveUserGuide.html#_replicate"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
if 'variables' in locals():
  NB_IMAGES = int(variables.get("NB_IMAGES"))
  
result = []
for i in range(1,NB_IMAGES+1):
	img_name = str(i)+".png"
	result.append(img_name)


variables.put("IMAGES_LIST", result)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow >
        <replicate>
          <script>
            <code language="groovy">
              <![CDATA[
runs=variables.get("NB_IMAGES")
]]>
            </code>
          </script>
        </replicate>
      </controlFlow>
      <metadata>
        <positionTop>
            146.6319580078125
        </positionTop>
        <positionLeft>
            161.701416015625
        </positionLeft>
      </metadata>
    </task>
    <task name="Face_Generator" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ This task will be replicated according to the 'runs' value specified in the replication script. It will generate a different image during each run. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
      </genericInformation>
      <depends>
        <task ref="Split_Images"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import wget  
import argparse
import shutil
import numpy as np
import torchvision.utils as vutils
import urllib.request
import time
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from os import remove, listdir, makedirs
from torch.autograd import Variable, grad
from torch.nn.init import xavier_normal
from torchvision import datasets, transforms
from os.path import join, exists

replication = variables.get('PA_TASK_REPLICATION')
image_path = results[0].value()[replication]
#result = image_path

#DATA_PATH = '/home/xander/data/img_align_celeba/'
MODEL_FOLDER = join('models', 'ID')
if exists(MODEL_FOLDER):
  shutil.rmtree(MODEL_FOLDER)
makedirs(MODEL_FOLDER)

resume_file = 'Epoch+018.pt'
#cuda = torch.cuda.is_available()
batch_size = 1
z_dim = 128
tag_num = 19
imsize = 128
start_epoch = 0
max_epochs = 100000
lambda_adv = tag_num
lambda_gp = 0.5
learning_rate = 0.0002


url = "https://s3.eu-west-2.amazonaws.com/activeeon-public/models/Epoch+018.pt"
request = urllib.request.Request(url)


urllib.request.urlretrieve(url, resume_file)  


def swish(x):
    return x * F.sigmoid(x)

class StableBCELoss(nn.modules.Module):
   def __init__(self):
         super(StableBCELoss, self).__init__()
   def forward(self, input, target):
         neg_abs = - input.abs()
         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()
         return loss.mean()

class FeatureExtractor(nn.Module):
    def __init__(self, cnn, feature_layer=11):
        super(FeatureExtractor, self).__init__()
        self.features = nn.Sequential(*list(cnn.features.children())[:(feature_layer+1)])

    def forward(self, x):
        return self.features(x)

class residualBlock(nn.Module):
    def __init__(self, in_channels=64, k=3, n=64, s=1):
        super(residualBlock, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, n, k, stride=s, padding=1)
        self.bn1 = nn.BatchNorm2d(n)
        self.conv2 = nn.Conv2d(n, n, k, stride=s, padding=1)
        self.bn2 = nn.BatchNorm2d(n)

        self.ac = nn.ReLU()

    def forward(self, x):
        y = self.ac(self.bn1(self.conv1(x)))
        # print y.size()
        return self.bn2(self.conv2(y)) + x


class upsampleBlock(nn.Module):
    # Implements resize-convolution
    def __init__(self, in_channels, out_channels):
        super(upsampleBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1)
        self.shuffler = nn.PixelShuffle(2)
        self.bn = nn.BatchNorm2d(in_channels)

        self.ac = nn.ReLU()

    def forward(self, x):
        return self.ac(self.bn(self.shuffler(self.conv(x))))


class ResBlock(nn.Module):
    def __init__(self, in_channels=64, k=3, n=64, s=1):
        super(ResBlock, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, n, k, stride=s, padding=1)
        self.conv2 = nn.Conv2d(n, n, k, stride=s, padding=1)

        self.ac = nn.LeakyReLU()

    def forward(self, x):
        y = self.ac(self.conv1(x))
        return self.ac(self.conv2(y) + x)

class DBlock(nn.Module):
    def __init__(self, n=64, k=3, s=1):
        super(DBlock, self).__init__()

        self.block1 = ResBlock(n, k, n, s)
        self.block2 = ResBlock(n, k, n, s)

        self.conv1 = nn.Conv2d(n, 2*n, 4, stride=2, padding=1)

        self.ac = nn.LeakyReLU()

    def forward(self, x):
        x = self.block1(x)
        x = self.block2(x)
        return self.ac(self.conv1(x))


# custom weights initialization called on G and D
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)


class Generator(nn.Module):
    def __init__(self, n_residual_blocks=16, upsample_factor=6, tag_num=19):
        super(Generator, self).__init__()
        self.n_residual_blocks = n_residual_blocks
        self.upsample_factor = upsample_factor

        self.dense = nn.Linear(128+tag_num, 64*16*16)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(True)

        for i in range(self.n_residual_blocks):
            self.add_module('residual_block' + str(i+1), residualBlock())

        self.bn2 = nn.BatchNorm2d(64)

        for i in range(self.upsample_factor//2):
            self.add_module('upsample' + str(i+1), upsampleBlock(64, 256))

        self.conv3 = nn.Conv2d(64, 3, 9, stride=1, padding=4)
        self.tanh = nn.Tanh()

    def forward(self, x):
        x = self.dense(x)
        x = x.view(-1, 64, 16, 16)
        x = self.relu(self.bn1(x))

        y = x.clone()
        for i in range(self.n_residual_blocks):
            y = self.__getattr__('residual_block' + str(i+1))(y)

        x = self.relu(self.bn2(y)) + x

        for i in range(self.upsample_factor//2):
            x = self.__getattr__('upsample' + str(i+1))(x)

        return self.tanh(self.conv3(x))

#class Discriminator(nn.Module):
#    def __init__(self, tag_num=19):
#        super(Discriminator, self).__init__()
#        self.conv1 = nn.Conv2d(3, 32, 4, stride=2, padding=1)

#        self.block1 = DBlock(n=32)
#        self.block2 = DBlock(n=64)
#        self.block3 = DBlock(n=128)
#        self.block4 = DBlock(n=256)
#        self.block5 = DBlock(n=512)

#        self.head1 = nn.Linear(1024*2*2, 1)
#        self.head2 = nn.Linear(1024*2*2, tag_num)

#        self.ac = nn.LeakyReLU()
#        self.sigmoid = nn.Sigmoid()

#    def forward(self, x):
#        x = self.ac(self.conv1(x))
#        x = self.block1(x)
#        x = self.block2(x)
#        x = self.block3(x)
#        x = self.block4(x)
#        x = self.block5(x)
#        x = x.view(x.size()[0], -1)

#        return self.head1(x), self.head2(x) # Use with numerically stable torch.nn.BCEWithLogitsLoss() during training
        # return self.sigmoid(self.head1(x)), self.sigmoid(self.head2(x))
generator = Generator()
generator.apply(weights_init)

#discriminator = Discriminator()
#discriminator.apply(weights_init)

opt_g = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))
#opt_d = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))


if resume_file:
    if os.path.isfile(resume_file):
        print("=> loading checkpoint '{}'".format(resume_file))
        checkpoint = torch.load(resume_file, map_location={'cuda:0': 'cpu'})
        start_epoch = checkpoint['epoch']
        best_loss = checkpoint['loss_g'] + checkpoint['loss_d']
        generator.load_state_dict(checkpoint['g_state_dict'])
        #discriminator.load_state_dict(checkpoint['d_state_dict'])
        opt_g.load_state_dict(checkpoint['g_optimizer'])
        #opt_d.load_state_dict(checkpoint['d_optimizer'])
        print("=> loaded checkpoint '{}' (epoch {})"
              .format(resume_file, checkpoint['epoch']))
    else:
        print("=> no checkpoint found at '{}'".format(resume_file))



#criterion = torch.nn.BCEWithLogitsLoss() # StableBCELoss() #
#X = Variable(torch.FloatTensor(batch_size, 3, imsize, imsize))
z = Variable(torch.FloatTensor(batch_size, z_dim))
tags = Variable(torch.FloatTensor(batch_size, tag_num))
#labels = Variable(torch.FloatTensor(batch_size))

z.data.normal_(0, 1)
tags.data.uniform_(to=1)
rep = torch.cat((z, tags.clone()), 1)
    
fake = generator(rep)
    
IMAGE_FOLDER = "face_images"
if exists(IMAGE_FOLDER):
  shutil.rmtree(IMAGE_FOLDER)
makedirs(IMAGE_FOLDER)
IMAGE_PATH = join(IMAGE_FOLDER, image_path)

vutils.save_image(fake.data.view(batch_size, 3, imsize, imsize),IMAGE_PATH)

#image_path = 'fake_samples_epoch.png'

with open(IMAGE_PATH, "rb") as binary_file:
    FILE_BIN = binary_file.read()

result = FILE_BIN
resultMetadata.put("file.name", "output_image.png")
resultMetadata.put("content.type", "image/png")

if 'variables' in locals():
  variables.put("IMAGE_FOLDER", IMAGE_FOLDER)
]]>
          </code>
        </script>
      </scriptExecutable>
      <outputFiles>
        <files  includes="$IMAGE_FOLDER/**" accessMode="transferToGlobalSpace"/>
      </outputFiles>
      <metadata>
        <positionTop>
            274.62677001953125
        </positionTop>
        <positionLeft>
            161.701416015625
        </positionLeft>
      </metadata>
    </task>
    <task name="Export_Images" 
    
    
    
    preciousResult="true" 
    fork="true">
      <description>
        <![CDATA[ As a merge operation, we simply compress the different images generated by previous tasks. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
      </genericInformation>
      <depends>
        <task ref="Face_Generator"/>
      </depends>
      <inputFiles>
        <files  includes="$IMAGE_FOLDER/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import os
import zipfile
import shutil

if 'variables' in locals():
	IMAGE_FOLDER   = variables.get("IMAGE_FOLDER")
    
shutil.make_archive("images", 'zip', IMAGE_FOLDER)


with open("images.zip", "rb") as binary_file:
    FILE_BIN = binary_file.read()
assert FILE_BIN is not None
result = FILE_BIN

if 'variables' in locals():
	resultMetadata.put("file.extension", ".zip")
	resultMetadata.put("file.name", "images.zip")
	resultMetadata.put("content.type", "application/octet-stream")
	print("END Export_Images")
else:
	print("It is not possible to export the images")
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            402.6302490234375
        </positionTop>
        <positionLeft>
            97.69964599609375
        </positionLeft>
      </metadata>
    </task>
    <task name="Visualize_Images" 
    
    
    
    preciousResult="true" 
    fork="true">
      <description>
        <![CDATA[ As a merge operation, we simply visualize the different images generated by previous tasks. ]]>
      </description>
      <genericInformation>
        <info name="TASK.ICON" value="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png"/>
      </genericInformation>
      <depends>
        <task ref="Face_Generator"/>
      </depends>
      <inputFiles>
        <files  includes="$IMAGE_FOLDER/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import os
from PIL import Image
from torchvision.utils import make_grid
import torch
import torchvision.transforms as transforms
import numpy as np

if 'variables' in locals():
	IMAGE_FOLDER   = variables.get("IMAGE_FOLDER")
	IMAGES_LIST   = variables.get("IMAGES_LIST")
    
list_images = []
for i in range(len(IMAGES_LIST)):
	x = Image.open(os.path.join(IMAGE_FOLDER, IMAGES_LIST[i]))
	try:
		image = np.asarray( x, dtype='uint8' )
	except SystemError:
		image = np.asarray( x.getdata(), dtype='uint8' )
	im = transforms.ToTensor()(image)
	list_images.append(im)
    
grid = make_grid(list_images,padding=10)
ndarr = grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()
im = Image.fromarray(ndarr)
im.save("image.png")

with open("image.png", "rb") as binary_file:
    FILE_BIN = binary_file.read()
assert FILE_BIN is not None
result = FILE_BIN
if 'variables' in locals():
	resultMetadata.put("file.extension", ".png")
	resultMetadata.put("content.type", "image/png")
	print("END Visualize_Images")
else:
	print("It is not possible to visualize the images")
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            402.6302490234375
        </positionTop>
        <positionLeft>
            225.703125
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2386px;
            height:2885px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-141.6319580078125px;left:-92.69964599609375px"><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2799" style="top: 146.635px; left: 161.703px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task defines some input, here strings to be processed."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Split_Images</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2802" style="top: 274.635px; left: 161.703px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="This task will be replicated according to the 'runs' value specified in the replication script. It will generate a different image during each run."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Face_Generator</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2805" style="top: 402.635px; left: 97.7034px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="As a merge operation, we simply compress the different images generated by previous tasks."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Export_Images</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2808" style="top: 402.635px; left: 225.703px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="As a merge operation, we simply visualize the different images generated by previous tasks."><img src="/automation-dashboard/styles/patterns/img/wf-icons/controls_replicate.png" width="20px">&nbsp;<span class="name">Visualize_Images</span></a></div><svg style="position:absolute;left:231.5px;top:176.5px" width="27.400000000000006" height="98" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 6.400000000000006 87 C 16.400000000000006 87 -10 -10 0 0 " transform="translate(10.5,10.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#e5db3d" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M8.588051100000005,76.5282105 L13.504451781131369,55.91683004301529 L7.155260244615329,62.60172097949534 L-0.42203773937328837,57.34962089839997 L8.588051100000005,76.5282105" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(10.5,10.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M8.588051100000005,76.5282105 L13.504451781131369,55.91683004301529 L7.155260244615329,62.60172097949534 L-0.42203773937328837,57.34962089839997 L8.588051100000005,76.5282105" class="" stroke="rgba(229,219,61,0.5)" fill="rgba(229,219,61,0.5)" transform="translate(10.5,10.5)"></path></svg><div class="_jsPlumb_overlay l1 component label" id="jsPlumb_1_2816" style="position: absolute; transform: translate(-50%, -50%); left: 244.7px; top: 226.25px;">replicate</div><svg style="position:absolute;left:201.5px;top:186.5px" width="25" height="88" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 4 87 C 14 37 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M6.4906875,65.86284375000001 L11.845090901811737,45.360883740999235 L5.35492106709401,51.908989995216565 L-2.108762852971707,46.49665017390523 L6.4906875,65.86284375000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M6.4906875,65.86284375000001 L11.845090901811737,45.360883740999235 L5.35492106709401,51.908989995216565 L-2.108762852971707,46.49665017390523 L6.4906875,65.86284375000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:138.5px;top:313.5px" width="88" height="90" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 89 C -10 39 77 50 67 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M4.736465999999997,64.440458 L23.79718168726826,55.18361634157647 L14.602456890667273,54.50757202736998 L13.864295714638235,45.31762545090919 L4.736465999999997,64.440458" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M4.736465999999997,64.440458 L23.79718168726826,55.18361634157647 L14.602456890667273,54.50757202736998 L13.864295714638235,45.31762545090919 L4.736465999999997,64.440458" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:205.5px;top:313.5px" width="87.5" height="90" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 66.5 89 C 76.5 39 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M61.820423000000005,64.440458 L52.760616030536845,45.28530470705905 L51.98979722236549,54.472569717113416 L42.792727747650254,55.11593048469357 L61.820423000000005,64.440458" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M61.820423000000005,64.440458 L52.760616030536845,45.28530470705905 L51.98979722236549,54.472569717113416 L42.792727747650254,55.11593048469357 L61.820423000000005,64.440458" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 202px; top: 177px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint replicate-source-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 232px; top: 177px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 206px; top: 304px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint replicate-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected _jsPlumb_endpoint_full" style="position: absolute; height: 20px; width: 20px; left: 238.4px; top: 264px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#e5db3d" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 206px; top: 264px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 139px; top: 433px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 139px; top: 393px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 272.5px; top: 433px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 272.5px; top: 393px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
