<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.12" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Deep_Model_Explainability" onTaskError="continueJobExecution" priority="normal" projectName="4. Training Pytorch Workflows" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd">
  <variables>
    <variable model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
    <variable model="PA:Boolean" name="DOCKER_GPU_ENABLED" value="False"/>
    <variable model="PA:LIST(,activeeon/dlm3,activeeon/cuda)" name="DOCKER_IMAGE" value=""/>
  </variables>
  <description>
    <![CDATA[ Explain a VGG16 model using GradientExplainer. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="deep-learning-workflows"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
<info name="Documentation" value="MLOS/MLOSUserGuide.html#_training_custom_ai_workflows_pytorch_library"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Import_Image_Dataset">
      <description>
        <![CDATA[ Load and return an image dataset. ]]>
      </description>
      <variables>
        <variable inherited="false" name="DATA_PATH" value="https://activeeon-public.s3.eu-west-2.amazonaws.com/datasets/vehicles.zip"/>
        <variable inherited="false" name="TRAIN_SPLIT" value="0.10"/>
        <variable inherited="false" name="VAL_SPLIT" value="0.10"/>
        <variable inherited="false" name="TEST_SPLIT" value="0.80"/>
        <variable inherited="false" model="PA:LIST(Classification, Detection, Segmentation)" name="DATASET_TYPE" value="Classification"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_image.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_import_image_dataset"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_docker_cuda_v2/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Import_Image_Dataset/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$DATASET_PATH/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            322.484375
        </positionTop>
        <positionLeft>
            552
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Train_Image_Classification_Model">
      <description>
        <![CDATA[ Train a model using an image classification network. ]]>
      </description>
      <variables>
        <variable inherited="false" name="NUM_EPOCHS" value="1"/>
        <variable inherited="false" name="BATCH_SIZE" value="4"/>
        <variable inherited="false" name="NUM_WORKERS" value="2"/>
        <variable inherited="false" model="PA:Boolean" name="SHUFFLE" value="True"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_train_image_classification_model"/>
      </genericInformation>
      <depends>
        <task ref="Import_Image_Dataset"/>
        <task ref="VGG_16"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_docker_cuda_v2/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Train_Image_Classification_Model/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <post>
        <script>
          <code language="bash">
            <![CDATA[

]]>
          </code>
        </script>
      </post>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            451.5
        </positionTop>
        <positionLeft>
            631.25
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="VGG_16">
      <description>
        <![CDATA[ The VGG-16 is a convolutional neural network. It contains the definition of each layer along with pre-trained set of weights. You can see more details in: http://pytorch.org/docs/master/torchvision/models.html ]]>
      </description>
      <variables>
        <variable inherited="false" model="PA:Boolean" name="USE_PRETRAINED_MODEL" value="True"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_learning.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_vgg-16"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_docker_cuda_v2/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/VGG_16/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            323.484375
        </positionTop>
        <positionLeft>
            710.5
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Model_Explainability" preciousResult="true">
      <description>
        <![CDATA[ Explain a Deep learning Model using GradientExplainer. ]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="false" name="IMG_SAMPLES" value="2"/>
        <variable inherited="false" name="IMG_LIST" value="1,4"/>
        <variable inherited="false" name="FEATURE_LAYER" value="features[7]"/>
        <variable inherited="false" name="RANKED_OUTPUTS" value="4"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_model-explainability.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_predict_image_classification_model"/>
      </genericInformation>
      <depends>
        <task ref="Train_Image_Classification_Model"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
        <files accessMode="transferFromGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_docker_cuda_v2/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Model_Explainability/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            579.5
        </positionTop>
        <positionLeft>
            632.25
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2864px;
            height:3432px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-317.484375px;left:-547px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_1" style="top: 322.484px; left: 552px; z-index: 24;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load and return an image dataset."><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_image.png" width="20px">&nbsp;<span class="name">Import_Image_Dataset</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_4" style="top: 451.5px; left: 631.25px; z-index: 24;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Train a model using an image classification network."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png" width="20px">&nbsp;<span class="name">Train_Image_Classification_Model</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_7" style="top: 323.5px; left: 710.5px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="The VGG-16 is a convolutional neural network. It contains the definition of each layer along with pre-trained set of weights. You can see more details in: http://pytorch.org/docs/master/torchvision/models.html"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_learning.png" width="20px">&nbsp;<span class="name">VGG_16</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_10" style="top: 579.5px; left: 632.25px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Explain a Deep learning Model using GradientExplainer."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_model-explainability.png" width="20px">&nbsp;<span class="name">Model_Explainability</span></a></div><svg style="position:absolute;left:610px;top:361.984375px" width="125.75" height="90.015625" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 104.75 89.015625 C 114.75 39.015625 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M93.5441815,62.709851531249996 L80.23937392958003,46.217971847172265 L81.64763288361424,55.3293277681306 L72.85885016646064,58.11452046355802 L93.5441815,62.709851531249996" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M93.5441815,62.709851531249996 L80.23937392958003,46.217971847172265 L81.64763288361424,55.3293277681306 L72.85885016646064,58.11452046355802 L93.5441815,62.709851531249996" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:714.75px;top:362.5px" width="56.75" height="89.5" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88.5 C -10 38.5 45.75 50 35.75 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M0.5187664999999981,65.816793 L15.938837446775464,51.283334636746915 L6.962732971043046,53.387983880857774 L3.5100283276332345,44.839368165703874 L0.5187664999999981,65.816793" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M0.5187664999999981,65.816793 L15.938837446775464,51.283334636746915 L6.962732971043046,53.387983880857774 L3.5100283276332345,44.839368165703874 L0.5187664999999981,65.816793" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:684.5px;top:491px" width="51.25" height="89.5" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88.5 C -10 38.5 40.25 50 30.25 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-0.12679206250000183,66.285722625 L14.280435264113791,50.747646786619214 L5.466286376899875,53.4514920843435 L1.4462047234572832,45.15456834721934 L-0.12679206250000183,66.285722625" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-0.12679206250000183,66.285722625 L14.280435264113791,50.747646786619214 L5.466286376899875,53.4514920843435 L1.4462047234572832,45.15456834721934 L-0.12679206250000183,66.285722625" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 610.5px; top: 352.484px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 715.25px; top: 481.5px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 715.25px; top: 441.5px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 751px; top: 353px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 685px; top: 610px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 685px; top: 570px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
