<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.12" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="CNTK_SimpleNet" onTaskError="continueJobExecution" priority="normal" projectName="2. Microsoft Cognitive Toolkit" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd">
  <variables>
    <variable model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
    <variable model="PA:Boolean" name="GPU_NODES_ONLY" value="False"/>
  </variables>
  <description>
    <![CDATA[ CNTK SimpleNet workflow trains a 2-layer fully connected deep neural network with 50 hidden dimensions per layer. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="deep-learning-workflows"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/cntk.png"/>
<info name="Documentation" value="MLOS/MLOSUserGuide.html#_microsoft_cognitive_toolkit"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="CNTK_SimpleNet">
      <description>
        <![CDATA[ Train a 2-layer fully connected deep neural network with 50 hidden dimensions per layer. 
https://www.cntk.ai/pythondocs/gettingstarted.html ]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="true" model="PA:Boolean" name="GPU_NODES_ONLY" value="False"/>
      </variables>
      <genericInformation>
        <info name="PYTHON_COMMAND" value="/root/anaconda3/envs/cntk-py35/bin/python"/>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/cntk.png"/>
      </genericInformation>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
#%% node_selection (python)
# job/task variables:
# GPU_NODES_ONLY: False (default)
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_docker_nvidia_cntk_v2/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
# Add 'PYTHON_COMMAND' Generic Info to run a specific Python version
# Go to http://doc.activeeon.com/latest/user/ProActiveUserGuide.html#_python_script_engine for more info
import numpy as np
import cntk as C

from cntk.learners import sgd
from cntk.logging import ProgressPrinter
from cntk.layers import Dense, Sequential

# explicitly set the device to GPU
#from cntk.device import try_set_default_device, gpu
#try_set_default_device(gpu(0))

print('CNTK VERSION: ' + str(C.__version__))
print('CNTK DEVICES:')
print(C.all_devices())

def generate_random_data(sample_size, feature_dim, num_classes):
  # Create synthetic data using NumPy.
  Y = np.random.randint(size=(sample_size, 1), low=0, high=num_classes)

  # Make sure that the data is separable
  X = (np.random.randn(sample_size, feature_dim) + 3) * (Y + 1)
  X = X.astype(np.float32)
  # converting class 0 into the vector "1 0 0",
  # class 1 into vector "0 1 0", ...
  class_ind = [Y == class_number for class_number in range(num_classes)]
  Y = np.asarray(np.hstack(class_ind), dtype=np.float32)
  return X, Y

def ffnet():
  inputs = 2
  outputs = 2
  layers = 2
  hidden_dimension = 50

  # input variables denoting the features and label data
  features = C.input_variable((inputs), np.float32)
  label = C.input_variable((outputs), np.float32)

  # Instantiate the feedforward classification model
  my_model = Sequential ([
                  Dense(hidden_dimension, activation=C.sigmoid),
                  Dense(outputs)])
  z = my_model(features)

  ce = C.cross_entropy_with_softmax(z, label)
  pe = C.classification_error(z, label)

  # Instantiate the trainer object to drive the model training
  lr_per_minibatch = C.learning_parameter_schedule(0.125)
  progress_printer = ProgressPrinter(0)
  trainer = C.Trainer(z, (ce, pe), [sgd(z.parameters, lr=lr_per_minibatch)], [progress_printer])

  # Get minibatches of training data and perform model training
  minibatch_size = 25
  num_minibatches_to_train = 1024

  aggregate_loss = 0.0
  for i in range(num_minibatches_to_train):
    train_features, labels = generate_random_data(minibatch_size, inputs, outputs)
    # Specify the mapping of input variables in the model to actual minibatch data to be trained with
    trainer.train_minibatch({features : train_features, label : labels})
    sample_count = trainer.previous_minibatch_sample_count
    aggregate_loss += trainer.previous_minibatch_loss_average * sample_count

  last_avg_error = aggregate_loss / trainer.total_number_of_samples_seen

  test_features, test_labels = generate_random_data(minibatch_size, inputs, outputs)
  avg_error = trainer.test_minibatch({features : test_features, label : test_labels})
  print(' error rate on an unseen minibatch: {}'.format(avg_error))
  return last_avg_error, avg_error

np.random.seed(98052)
ffnet()
]]>
          </code>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            147.46530151367188
        </positionTop>
        <positionLeft>
            360.3819580078125
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2351px;
            height:3072px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-142.46530151367188px;left:-355.3819580078125px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable active-task" id="jsPlumb_1_13" style="top: 147.472px; left: 360.386px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/cntk.png" width="20px">&nbsp;<span class="name">CNTK_SimpleNet</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 407px; top: 178px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>
