<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.11" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="IMDB_Sentiment_Analysis" onTaskError="continueJobExecution" priority="normal" projectName="4. Custom Pytorch Workflows" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd">
  <variables>
    <variable model="PA:Boolean" name="GPU_NODES_ONLY" value="False"/>
    <variable name="GPU_CUDA_PATH" value="/usr/local/cuda"/>
    <variable model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
  </variables>
  <description>
    <![CDATA[ IMDB Sentiment Analysis workflow trains a model for opinions identification and categorization expressed in a piece of text, especially in order to determine the opinion of IMDB users regarding specific movies [positive or negative]. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="deep-learning-workflows"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
<info name="Documentation" value="https://ow2-proactive.github.io/proactive-examples/MachineLearning/resources/doc/V1/automated-machine-learning-activeeon.pdf"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task name="Import_Text_Dataset">
      <description>
        <![CDATA[ Load and return a text dataset. ]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="GPU_NODES_ONLY" value="False"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="false" name="DATASET_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/IMDB.zip"/>
        <variable inherited="false" name="TRAIN_SPLIT" value="0.6"/>
        <variable inherited="false" name="TEST_SPLIT" value="0.3"/>
        <variable inherited="false" name="VAL_SPLIT" value="0.1"/>
        <variable inherited="false" model="PA:BOOLEAN" name="TOY_MODE" value="True"/>
        <variable inherited="false" model="PA:LIST(str.split,moses,spacy,revtok,subword)" name="TOKENIZER" value="str.split"/>
        <variable inherited="false" name="SENTENCE_SEPARATOR" value="\r"/>
        <variable inherited="false" name="CHARSET" value="utf-8"/>
        <variable inherited="false" model="PA:BOOLEAN" name="IS_LABELED_DATA" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_text.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_import_text_dataset"/>
      </genericInformation>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Import_Text_Dataset/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$DATASET_PATH/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            263.5
        </positionTop>
        <positionLeft>
            489.25
        </positionLeft>
      </metadata>
    </task>
    <task name="RNN">
      <description>
        <![CDATA[ A Recurrent Neural Network (RNN) is a class of artificial neural network where connections between units form a directed cycle.
You can see more details in: http://pytorch.org/docs/0.3.1/nn.html#torch.nn.RNN ]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="GPU_NODES_ONLY" value="False"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="false" name="EMBEDDING_DIM" value="50"/>
        <variable inherited="false" name="HIDDEN_DIM" value="40"/>
        <variable inherited="false" name="BATCH_SIZE" value="2"/>
        <variable inherited="false" name="DROPOUT" value="0.5"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_text_classification.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_rnn"/>
      </genericInformation>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/RNN/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            263.5
        </positionTop>
        <positionLeft>
            640.75
        </positionLeft>
      </metadata>
    </task>
    <task name="Train_Text_Classification_Model">
      <description>
        <![CDATA[ Train a model using a text classification network. ]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="GPU_NODES_ONLY" value="False"/>
        <variable inherited="true" name="GPU_CUDA_PATH" value="/usr/local/cuda"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="true" model="PA:Boolean" name="USE_GPU" value="False"/>
        <variable inherited="false" name="LEARNING_RATE" value="0.001"/>
        <variable inherited="false" model="PA:List(Adam,RMS, SGD, Adagrad, Adadelta)" name="OPTIMIZER" value="Adam"/>
        <variable inherited="false" model="PA:List(L1Loss, MSELoss, CrossEntropyLoss, NLLLoss)" name="LOSS_FUNCTION" value="NLLLoss"/>
        <variable inherited="false" model="PA:Integer" name="EPOCHS" value="10"/>
        <variable inherited="false" model="PA:Boolean" name="TRAINABLE" value="False"/>
        <variable inherited="false" model="PA:List(42B, 840B, twitter.27B,6B)" name="GLOVE" value="6B"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png"/>
      </genericInformation>
      <depends>
        <task ref="Import_Text_Dataset"/>
        <task ref="RNN"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
        <files accessMode="transferFromGlobalSpace" includes=".vector_cache/**"/>
      </inputFiles>
      <selection>
        <script type="static">
          <code language="javascript">
            <![CDATA[
selected = ((variables.get("GPU_NODES_ONLY").equalsIgnoreCase("false")) || (variables.get("GPU_NODES_ONLY").equalsIgnoreCase("true") && org.ow2.proactive.scripting.helper.selection.SelectionUtils.checkFileExist(variables.get("GPU_CUDA_PATH"))));
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Train_Text_Classification_Model/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$MODEL_FOLDER/**"/>
        <files accessMode="transferToGlobalSpace" includes=".vector_cache/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            391.5
        </positionTop>
        <positionLeft>
            565
        </positionLeft>
      </metadata>
    </task>
    <task name="Download_Model">
      <description>
        <![CDATA[ Download a trained model by a deep learning algorithm. ]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="GPU_NODES_ONLY" value="False"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="false" model="PA:LIST(PyTorch, ONNX)" name="MODEL_TYPE" value="PyTorch"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_deep_model.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_export_model"/>
      </genericInformation>
      <depends>
        <task ref="Train_Text_Classification_Model"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </inputFiles>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Download_Model/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            519.5
        </positionTop>
        <positionLeft>
            471.25
        </positionLeft>
      </metadata>
    </task>
    <task name="Preview_Results">
      <description>
        <![CDATA[ Preview the predicted results. ]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="GPU_NODES_ONLY" value="False"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="false" name="OUTPUT_FILE" value="HTML"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_export_results.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_export_results"/>
      </genericInformation>
      <depends>
        <task ref="Predict_Text_Classification_Model"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
        <files accessMode="transferFromGlobalSpace" includes="$OUTPUT_FOLDER/**"/>
      </inputFiles>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Preview_Results/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            647.5
        </positionTop>
        <positionLeft>
            658.75
        </positionLeft>
      </metadata>
    </task>
    <task name="Predict_Text_Classification_Model">
      <description>
        <![CDATA[ Predict a model using a text classification network. ]]>
      </description>
      <variables>
        <variable inherited="true" model="PA:Boolean" name="GPU_NODES_ONLY" value="False"/>
        <variable inherited="true" model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
        <variable inherited="false" model="PA:List(L1Loss, MSELoss, CrossEntropyLoss, NLLLoss)" name="LOSS_FUNCTION" value="NLLLoss"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png"/>
      </genericInformation>
      <depends>
        <task ref="Train_Text_Classification_Model"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
        <files accessMode="transferFromGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </inputFiles>
      <selection>
        <script type="static">
          <code language="javascript">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Predict_Text_Classification_Model/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            519.5
        </positionTop>
        <positionLeft>
            658.75
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2864px;
            height:3436px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-258.5px;left:-466.25px"><div class="task ui-draggable active-task" id="jsPlumb_1_231" style="top: 263.5px; left: 489.25px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_text.png" width="20px">&nbsp;<span class="name">Import_Text_Dataset</span></a></div><div class="task ui-draggable" id="jsPlumb_1_234" style="top: 263.5px; left: 640.75px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_text_classification.png" width="20px">&nbsp;<span class="name">RNN</span></a></div><div class="task ui-draggable" id="jsPlumb_1_237" style="top: 391.5px; left: 565px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png" width="20px">&nbsp;<span class="name">Train_Text_Classification_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_240" style="top: 519.5px; left: 471.25px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/export_deep_model.png" width="20px">&nbsp;<span class="name">Download_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_243" style="top: 647.5px; left: 658.75px; z-index: 24;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_export_results.png" width="20px">&nbsp;<span class="name">Preview_Results</span></a></div><div class="task ui-draggable" id="jsPlumb_1_246" style="top: 519.5px; left: 658.75px; z-index: 24;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png" width="20px">&nbsp;<span class="name">Predict_Text_Classification_Model</span></a></div><svg style="position:absolute;left:542px;top:303.5px" width="122.5" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 101.5 88 C 111.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M90.73087100000001,61.830692 L77.53854889082004,45.248694612241145 L78.8847998762344,54.36941872188677 L70.07727561270681,57.09476573600676 L90.73087100000001,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M90.73087100000001,61.830692 L77.53854889082004,45.248694612241145 L78.8847998762344,54.36941872188677 L70.07727561270681,57.09476573600676 L90.73087100000001,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:643.5px;top:303.5px" width="58" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 47 50 37 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M0.6369939999999978,65.364084 L16.287082124974148,51.078610900359834 L7.2785269871448195,53.039716284751194 L3.9627144097253364,44.437077913215006 L0.6369939999999978,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M0.6369939999999978,65.364084 L16.287082124974148,51.078610900359834 L7.2785269871448195,53.039716284751194 L3.9627144097253364,44.437077913215006 L0.6369939999999978,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:516.5px;top:431.5px" width="148" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88 C -10 38 137 50 127 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M15.588863999999997,60.999424000000005 L36.62017047610894,58.414052090974465 L28.139864815648103,54.79681337820529 L30.41755985431422,45.863051275326356 L15.588863999999997,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M15.588863999999997,60.999424000000005 L36.62017047610894,58.414052090974465 L28.139864815648103,54.79681337820529 L30.41755985431422,45.863051275326356 L15.588863999999997,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 542.5px; top: 294px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 681px; top: 294px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected endpointDrag" style="position: absolute; height: 20px; width: 20px; left: 644px; top: 422px; visibility: visible;" dragid="jsPlumb_1_257" elid="jsPlumb_1_237"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 644px; top: 382px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 517px; top: 550px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 517px; top: 510px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 703.5px; top: 678px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable endpointDrag _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 742.5px; top: 550px; visibility: visible;" dragid="jsPlumb_1_269" elid="jsPlumb_1_246"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><svg style="position:absolute;left:643.5px;top:431.5px" width="119.5" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 98.5 88 C 108.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M88.13396900000001,61.830692 L75.15923071428756,45.07789622086905 L76.38630595689463,54.21541701969522 L67.54395573398278,56.82555926397443 L88.13396900000001,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected connected" style="position: absolute; height: 20px; width: 20px; left: 742.5px; top: 510px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><svg style="position:absolute;left:703px;top:559.5px" width="60" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88 C -10 38 49 50 39 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M0.8261579999999977,65.364084 L16.769100218015062,51.4061975757224 L7.721817134665953,53.1800828058726 L4.58509902388766,44.510538441056454 L0.8261579999999977,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected connected" style="position: absolute; height: 20px; width: 20px; left: 703.5px; top: 638px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>
