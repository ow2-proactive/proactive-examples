<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"  name="IMDB_Sentiment_Analysis" projectName="4. Custom Pytorch Workflows" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2" >
  <variables>
    <variable name="GPU_NODES_ONLY" value="False" model="PA:Boolean"/>
    <variable name="GPU_CUDA_PATH" value="/usr/local/cuda" />
    <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ IMDB Sentiment Analysis workflow trains a model for opinions identification and categorization expressed in a piece of text, especially in order to determine the opinion of IMDB users regarding specific movies [positive or negative]. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="deep-learning-workflows"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
    <info name="Documentation" value="https://ow2-proactive.github.io/proactive-examples/MachineLearning/resources/doc/V1/automated-machine-learning-activeeon.pdf"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Import_Text_Dataset" >
      <description>
        <![CDATA[ Load and return a text dataset. ]]>
      </description>
      <variables>
        <variable name="GPU_NODES_ONLY" value="False" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="DATASET_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/IMDB.zip" inherited="false" />
        <variable name="TRAIN_SPLIT" value="0.6" inherited="false" />
        <variable name="TEST_SPLIT" value="0.3" inherited="false" />
        <variable name="VAL_SPLIT" value="0.1" inherited="false" />
        <variable name="TOY_MODE" value="True" inherited="false" model="PA:BOOLEAN"/>
        <variable name="TOKENIZER" value="str.split" inherited="false" model="PA:LIST(str.split,moses,spacy,revtok,subword)"/>
        <variable name="SENTENCE_SEPARATOR" value="\r" inherited="false" />
        <variable name="CHARSET" value="utf-8" inherited="false" />
        <variable name="IS_LABELED_DATA" value="True" inherited="false" model="PA:BOOLEAN"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_text.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_import_text_dataset"/>
      </genericInformation>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Import_Text_Dataset/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <outputFiles>
        <files  includes="$DATASET_PATH/**" accessMode="transferToGlobalSpace"/>
      </outputFiles>
      <metadata>
        <positionTop>
            263.5
        </positionTop>
        <positionLeft>
            489.25
        </positionLeft>
      </metadata>
    </task>
    <task name="RNN" >
      <description>
        <![CDATA[ A Recurrent Neural Network (RNN) is a class of artificial neural network where connections between units form a directed cycle.
You can see more details in: http://pytorch.org/docs/0.3.1/nn.html#torch.nn.RNN ]]>
      </description>
      <variables>
        <variable name="GPU_NODES_ONLY" value="False" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="EMBEDDING_DIM" value="50" inherited="false" />
        <variable name="HIDDEN_DIM" value="40" inherited="false" />
        <variable name="BATCH_SIZE" value="2" inherited="false" />
        <variable name="DROPOUT" value="0.5" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_text_classification.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_rnn"/>
      </genericInformation>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/RNN/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            263.5
        </positionTop>
        <positionLeft>
            640.75
        </positionLeft>
      </metadata>
    </task>
    <task name="Train_Text_Classification_Model" >
      <description>
        <![CDATA[ Train a model using a text classification network. ]]>
      </description>
      <variables>
        <variable name="GPU_NODES_ONLY" value="False" inherited="true" model="PA:Boolean"/>
        <variable name="GPU_CUDA_PATH" value="/usr/local/cuda" inherited="true" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="USE_GPU" value="False" inherited="true" model="PA:Boolean"/>
        <variable name="LEARNING_RATE" value="0.001" inherited="false" />
        <variable name="OPTIMIZER" value="Adam" inherited="false" model="PA:List(Adam,RMS, SGD, Adagrad, Adadelta)"/>
        <variable name="LOSS_FUNCTION" value="NLLLoss" inherited="false" model="PA:List(L1Loss, MSELoss, CrossEntropyLoss, NLLLoss)"/>
        <variable name="EPOCHS" value="10" inherited="false" model="PA:Integer"/>
        <variable name="TRAINABLE" value="False" inherited="false" model="PA:Boolean"/>
        <variable name="GLOVE" value="6B" inherited="false" model="PA:List(42B, 840B, twitter.27B,6B)"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png"/>
      </genericInformation>
      <depends>
        <task ref="Import_Text_Dataset"/>
        <task ref="RNN"/>
      </depends>
      <inputFiles>
        <files  includes="$DATASET_PATH/**" accessMode="transferFromGlobalSpace"/>
        <files  includes=".vector_cache/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <selection>
        <script type="static">
          <code language="javascript">
            <![CDATA[
selected = ((variables.get("GPU_NODES_ONLY").equalsIgnoreCase("false")) || (variables.get("GPU_NODES_ONLY").equalsIgnoreCase("true") && org.ow2.proactive.scripting.helper.selection.SelectionUtils.checkFileExist(variables.get("GPU_CUDA_PATH"))));
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Train_Text_Classification_Model/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <outputFiles>
        <files  includes="$MODEL_FOLDER/**" accessMode="transferToGlobalSpace"/>
        <files  includes=".vector_cache/**" accessMode="transferToGlobalSpace"/>
      </outputFiles>
      <metadata>
        <positionTop>
            391.5
        </positionTop>
        <positionLeft>
            565
        </positionLeft>
      </metadata>
    </task>
    <task name="Download_Model" 
    
    
    preciousResult="true" >
      <description>
        <![CDATA[ Download a trained model by a deep learning algorithm. ]]>
      </description>
      <variables>
        <variable name="GPU_NODES_ONLY" value="False" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="MODEL_TYPE" value="PyTorch" inherited="false" model="PA:LIST(PyTorch, ONNX)"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_deep_model.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_export_model"/>
      </genericInformation>
      <depends>
        <task ref="Train_Text_Classification_Model"/>
      </depends>
      <inputFiles>
        <files  includes="$MODEL_FOLDER/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Download_Model/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            520.5
        </positionTop>
        <positionLeft>
            471.25
        </positionLeft>
      </metadata>
    </task>
    <task name="Preview_Results" 
    
    
    preciousResult="true" >
      <description>
        <![CDATA[ Preview the predicted results. ]]>
      </description>
      <variables>
        <variable name="GPU_NODES_ONLY" value="False" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="OUTPUT_FILE" value="HTML" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_export_results.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_export_results"/>
      </genericInformation>
      <depends>
        <task ref="Predict_Text_Classification_Model"/>
      </depends>
      <inputFiles>
        <files  includes="$DATASET_PATH/**" accessMode="transferFromGlobalSpace"/>
        <files  includes="$OUTPUT_FOLDER/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <selection>
        <script type="static">
          <code language="python">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Preview_Results/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            647.5
        </positionTop>
        <positionLeft>
            658.75
        </positionLeft>
      </metadata>
    </task>
    <task name="Predict_Text_Classification_Model" >
      <description>
        <![CDATA[ Predict a model using a text classification network. ]]>
      </description>
      <variables>
        <variable name="GPU_NODES_ONLY" value="False" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="LOSS_FUNCTION" value="NLLLoss" inherited="false" model="PA:List(L1Loss, MSELoss, CrossEntropyLoss, NLLLoss)"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png"/>
      </genericInformation>
      <depends>
        <task ref="Train_Text_Classification_Model"/>
      </depends>
      <inputFiles>
        <files  includes="$DATASET_PATH/**" accessMode="transferFromGlobalSpace"/>
        <files  includes="$MODEL_FOLDER/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <selection>
        <script type="static">
          <code language="javascript">
            <![CDATA[
import os

GPU_NODES_ONLY = False
if variables.get("GPU_NODES_ONLY") is not None:
  if str(variables.get("GPU_NODES_ONLY")).lower() == 'true':
    GPU_NODES_ONLY = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
  if os.path.isdir(CUDA_HOME) == True:
    CUDA_ENABLED = True
else:
  if os.path.isdir(CUDA_HOME_DEFAULT) == True:
    CUDA_ENABLED = True

selected = ((GPU_NODES_ONLY == False) or (GPU_NODES_ONLY == True and CUDA_ENABLED == True))
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Predict_Text_Classification_Model/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            519.5
        </positionTop>
        <positionLeft>
            658.75
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2864px;
            height:3432px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-258.5px;left:-466.25px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_770" style="top: 263.5px; left: 489.25px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_text.png" width="20px">&nbsp;<span class="name">Import_Text_Dataset</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_773" style="top: 263.5px; left: 640.75px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_text_classification.png" width="20px">&nbsp;<span class="name">RNN</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_776" style="top: 391.5px; left: 565px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png" width="20px">&nbsp;<span class="name">Train_Text_Classification_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_779" style="top: 520.5px; left: 471.25px; z-index: 24;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/export_deep_model.png" width="20px">&nbsp;<span class="name">Download_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_ active-task" id="jsPlumb_1_782" style="top: 647.5px; left: 658.75px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_export_results.png" width="20px">&nbsp;<span class="name">Preview_Results</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_785" style="top: 519.5px; left: 658.75px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png" width="20px">&nbsp;<span class="name">Predict_Text_Classification_Model</span></a></div><svg style="position:absolute;left:542px;top:303.5px" width="122.5" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 101.5 88 C 111.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M90.73087100000001,61.830692 L77.53854889082004,45.248694612241145 L78.8847998762344,54.36941872188677 L70.07727561270681,57.09476573600676 L90.73087100000001,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M90.73087100000001,61.830692 L77.53854889082004,45.248694612241145 L78.8847998762344,54.36941872188677 L70.07727561270681,57.09476573600676 L90.73087100000001,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:643.5px;top:303.5px" width="58" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 47 50 37 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M0.6369939999999978,65.364084 L16.287082124974148,51.078610900359834 L7.2785269871448195,53.039716284751194 L3.9627144097253364,44.437077913215006 L0.6369939999999978,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M0.6369939999999978,65.364084 L16.287082124974148,51.078610900359834 L7.2785269871448195,53.039716284751194 L3.9627144097253364,44.437077913215006 L0.6369939999999978,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:516.75px;top:431.5px" width="147.75" height="89.5" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88.5 C -10 38.5 136.75 50 126.75 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M15.552575999999998,61.42684800000001 L36.57388386926011,58.761399545089816 L28.079863872631694,55.176483326141785 L30.323519195401882,46.23411167245813 L15.552575999999998,61.42684800000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M15.552575999999998,61.42684800000001 L36.57388386926011,58.761399545089816 L28.079863872631694,55.176483326141785 L30.323519195401882,46.23411167245813 L15.552575999999998,61.42684800000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:703px;top:559.5px" width="60" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 49 50 39 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M0.8261579999999977,65.364084 L16.769100218015062,51.4061975757224 L7.721817134665953,53.1800828058726 L4.58509902388766,44.510538441056454 L0.8261579999999977,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M0.8261579999999977,65.364084 L16.769100218015062,51.4061975757224 L7.721817134665953,53.1800828058726 L4.58509902388766,44.510538441056454 L0.8261579999999977,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:643.5px;top:431.5px" width="119.5" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 98.5 88 C 108.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M88.13396900000001,61.830692 L75.15923071428756,45.07789622086905 L76.38630595689463,54.21541701969522 L67.54395573398278,56.82555926397443 L88.13396900000001,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M88.13396900000001,61.830692 L75.15923071428756,45.07789622086905 L76.38630595689463,54.21541701969522 L67.54395573398278,56.82555926397443 L88.13396900000001,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 542.5px; top: 294px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 681px; top: 294px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 644px; top: 422px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 644px; top: 382px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 517.25px; top: 550.5px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 517.25px; top: 510.5px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 703.5px; top: 678px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 703.5px; top: 638px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 742.5px; top: 550px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 742.5px; top: 510px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>