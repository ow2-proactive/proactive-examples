<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.14" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd"  name="Train_Image_Object_Detection" tags="Training,Cognitive Services,Artificial Intelligence,Cloud,Machine Learning,Deep Learning" projectName="4. Training Pytorch Workflows" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="CONTAINER_PLATFORM" value="docker" model="PA:LIST(no-container,docker,podman,singularity)" description="Container platform used for executing the workflow tasks." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="CONTAINER_GPU_ENABLED" value="True" model="PA:Boolean" description="If True, it will activate the use of GPU for the workflow tasks on the selected container platform." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="CONTAINER_IMAGE" value="" model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/nvidia:pytorch)" description="Name of the container image being used to run the workflow tasks." group="Container Parameters" advanced="true" hidden="false"/>
  </variables>
  <description>
    <![CDATA[ Detect objects an image dataset using a pre-trained model. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="ai-deep-learning-workflows"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
    <info name="Documentation" value="PAIO/PAIOUserGuide.html#_training_custom_ai_workflows_pytorch_library"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Import_Image_Dataset" fork="true">
      <description>
        <![CDATA[ Load and return an image dataset. ]]>
      </description>
      <variables>
        <variable name="IMPORT_FROM" value="PA:URL" inherited="false" model="PA:LIST(PA:URL,PA:URI,PA:USER_FILE,PA:GLOBAL_FILE)" description="Method/protocol to import the data source."  advanced="false" hidden="false"/>
        <variable name="DATA_PATH" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/coco.zip" inherited="false" model="$IMPORT_FROM" description="Path or name of the file that contains the image dataset." group="" advanced="false" hidden="false"/>
        <variable name="TRAIN_SPLIT" value="0.60" inherited="false"  description="Float between 0.0 and 1.0 representing the ratio of data to be used for the model training."  advanced="false" hidden="false"/>
        <variable name="VAL_SPLIT" value="0.15" inherited="false"  description="Float between 0.0 and 1.0 representing the ratio of data to be used for the model validation."  advanced="false" hidden="false"/>
        <variable name="TEST_SPLIT" value="0.25" inherited="false"  description="Float between 0.0 and 1.0 representing the ratio of data to be used for the model testing."  advanced="false" hidden="false"/>
        <variable name="DATASET_TYPE" value="Detection" inherited="false" model="PA:LIST(Classification, Detection, Segmentation)" description="Dataset type to be imported. Check the documentation for more information about the organization of your dataset folders and files according to each dataset type." group="" advanced="false" hidden="false"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_image.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_import_image_dataset"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/ai-deep-learning/resources/Import_Image_Dataset_Script/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <outputFiles>
        <files  includes="$DATASET_PATH/**" accessMode="transferToGlobalSpace"/>
      </outputFiles>
      <metadata>
        <positionTop>
            114.9132080078125
        </positionTop>
        <positionLeft>
            396.97052001953125
        </positionLeft>
      </metadata>
    </task>
    <task name="Train_Image_Object_Detection_Model" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ Train a model using an image object detection network. ]]>
      </description>
      <variables>
        <variable name="NUM_EPOCHS" value="1" inherited="false"  description="Hyperparameter that defines the number of times that the learning algorithm will work through the entire training dataset to update weights."  advanced="false" hidden="false"/>
        <variable name="BATCH_SIZE" value="1" inherited="false"  description="Number of samples that are going to be propagated through the network"  advanced="false" hidden="false"/>
        <variable name="NUM_WORKERS" value="1" inherited="false"  description="Number of subprocesses to use for data loading. 0 means that the data will be loaded in the main process."  advanced="false" hidden="false"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_train_image_object_detection_model"/>
      </genericInformation>
      <depends>
        <task ref="Import_Image_Dataset"/>
        <task ref="YOLO"/>
      </depends>
      <inputFiles>
        <files  includes="$DATASET_PATH/**" accessMode="transferFromGlobalSpace"/>
        <files  includes="$LABEL_PATH/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/ai-deep-learning/resources/Train_Image_Object_Detection_Model_Script/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <post>
        <script>
          <code language="bash">
            <![CDATA[

]]>
          </code>
        </script>
      </post>
      <outputFiles>
        <files  includes="$MODEL_FOLDER/**" accessMode="transferToGlobalSpace"/>
      </outputFiles>
      <metadata>
        <positionTop>
            261.076416015625
        </positionTop>
        <positionLeft>
            272.6475830078125
        </positionLeft>
      </metadata>
    </task>
    <task name="Predict_Image_Object_Detection_Model" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ Predict a model using an image object detection network. ]]>
      </description>
      <variables>
        <variable name="BATCH_SIZE" value="1" inherited="false"  description="Number of samples that are going to be propagated through the network"  advanced="false" hidden="false"/>
        <variable name="NUM_WORKERS" value="1" inherited="false"  description="Number of subprocesses to use for data loading. 0 means that the data will be loaded in the main process."  advanced="false" hidden="false"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_predict_image_object_detection_model"/>
      </genericInformation>
      <depends>
        <task ref="Train_Image_Object_Detection_Model"/>
      </depends>
      <inputFiles>
        <files  includes="$DATASET_PATH/**" accessMode="transferFromGlobalSpace"/>
        <files  includes="$MODEL_FOLDER/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/ai-deep-learning/resources/Predict_Image_Object_Detection_Model_Script/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <outputFiles>
        <files  includes="$OUTPUT_FOLDER/**" accessMode="transferToGlobalSpace"/>
      </outputFiles>
      <metadata>
        <positionTop>
            387.29168701171875
        </positionTop>
        <positionLeft>
            268.56768798828125
        </positionLeft>
      </metadata>
    </task>
    <task name="Preview_Results" 
    
    
    
    preciousResult="true" 
    fork="true">
      <description>
        <![CDATA[ Preview the results of the predictions generated by the trained model. ]]>
      </description>
      <variables>
        <variable name="OUTPUT_FILE" value="HTML" inherited="false"  description="Converts the prediction results into the specified file type."  advanced="false" hidden="false"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_export_results.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_preview_results_2"/>
      </genericInformation>
      <depends>
        <task ref="Predict_Image_Object_Detection_Model"/>
      </depends>
      <inputFiles>
        <files  includes="$DATASET_PATH/**" accessMode="transferFromGlobalSpace"/>
        <files  includes="$OUTPUT_FOLDER/**" accessMode="transferFromGlobalSpace"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/ai-deep-learning/resources/Preview_Results_Script/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            519.1319580078125
        </positionTop>
        <positionLeft>
            316.97052001953125
        </positionLeft>
      </metadata>
    </task>
    <task name="YOLO" 
    
    
    
    
    fork="true">
      <description>
        <![CDATA[ YOLO is a single neural network to predict bounding boxes and class probabilities. ]]>
      </description>
      <variables>
        <variable name="LEARNING_RATE" value="0.001" inherited="false"  description="Initial learning rate."  advanced="false" hidden="false"/>
        <variable name="MOMENTUM" value="0.9" inherited="false"  description="Momentum value for optimization."  advanced="false" hidden="false"/>
        <variable name="WEIGHT_DECAY" value="0.0005" inherited="false"  description="Weight decay for SGD"  advanced="false" hidden="false"/>
        <variable name="IMG_SIZE" value="(416, 416)" inherited="false"  description="(Width, Height) of the images as a tuple with 2 elements."  advanced="false" hidden="false"/>
        <variable name="NUM_CLASSES" value="81" inherited="false"  description="Number of classes or labels."  advanced="false" hidden="false"/>
        <variable name="CONF_THRESHOLD" value="0.5" inherited="false"  description="Certainty on how the predicted bounding box actually encloses some object. This score does not say anything about what kind of object is in the box, just if the shape of the box is any good."  advanced="false" hidden="false"/>
        <variable name="NMS_THRESHOLD" value="0.45" inherited="false"  description="Threshold to select only the most accurate (highest probability)."  advanced="false" hidden="false"/>
        <variable name="LABEL_PATH" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/coco.names" inherited="false"  description="URL of the file containing the class names of the dataset."  advanced="false" hidden="false"/>
        <variable name="USE_PRETRAINED_MODEL" value="True" inherited="false"  description="If True, the pre-trained model with the corresponding number of layers is loaded and used for training. Otherwise, the network is trained from scratch."  advanced="false" hidden="false"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_detection.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_yolo"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <file url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw" language="groovy"></file>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/ai-deep-learning/resources/YOLO_Script/raw" language="cpython"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            109.10591125488281
        </positionTop>
        <positionLeft>
            188.9757080078125
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2386px;
            height:2885px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-104.10591125488281px;left:-183.9757080078125px"><div class="task ui-draggable" id="jsPlumb_1_1761" style="top: 114.921px; left: 396.971px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load and return an image dataset."><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_image.png" width="20px">&nbsp;<span class="name">Import_Image_Dataset</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_1764" style="top: 261.085px; left: 272.648px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Train a model using an image object detection network."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png" width="20px">&nbsp;<span class="name">Train_Image_Object_Detection_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_1767" style="top: 387.3px; left: 268.568px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Predict a model using an image object detection network."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png" width="20px">&nbsp;<span class="name">Predict_Image_Object_Detection_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_1770" style="top: 519.14px; left: 316.971px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Preview the results of the predictions generated by the trained model."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_export_results.png" width="20px">&nbsp;<span class="name">Preview_Results</span></a></div><div class="task ui-draggable" id="jsPlumb_1_1773" style="top: 109.106px; left: 188.976px; z-index: 24;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="YOLO is a single neural network to predict bounding boxes and class probabilities."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_detection.png" width="20px">&nbsp;<span class="name">YOLO</span></a></div><svg style="position:absolute;left:365.5px;top:154.5px" width="110.5" height="107" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 106 C -10 56 99.5 50 89.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M9.156736999999998,77.412104 L28.694530564990366,69.20999313682455 L19.550445983532533,68.03282825154079 L19.31525481653116,58.81628415329201 L9.156736999999998,77.412104" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M9.156736999999998,77.412104 L28.694530564990366,69.20999313682455 L19.550445983532533,68.03282825154079 L19.31525481653116,58.81628415329201 L9.156736999999998,77.412104" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:364.5px;top:300.5px" width="22" height="87" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 86 C -10 36 11 50 1 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.73415625,64.94400000000002 L5.108873024641382,45.2593132664724 L-2.139615276695144,50.956629945873985 L-8.878497029484652,44.66477229316754 L-2.73415625,64.94400000000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.73415625,64.94400000000002 L5.108873024641382,45.2593132664724 L-2.139615276695144,50.956629945873985 L-8.878497029484652,44.66477229316754 L-2.73415625,64.94400000000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:361px;top:426.5px" width="24.5" height="93" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 92 C -10 42 13.5 50 3.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.534544,69.96108799999999 L5.919546069551019,50.530998934431636 L-1.5033714141456864,55.99911524905313 L-8.042426681395836,49.49982634857733 L-2.534544,69.96108799999999" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-2.534544,69.96108799999999 L5.919546069551019,50.530998934431636 L-1.5033714141456864,55.99911524905313 L-8.042426681395836,49.49982634857733 L-2.534544,69.96108799999999" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 455.5px; top: 145px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 366px; top: 291px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected connected" style="position: absolute; height: 20px; width: 20px; left: 366px; top: 251px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 365px; top: 417px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 365px; top: 377px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 361.5px; top: 549px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 361.5px; top: 509px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable endpointDrag _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 229px; top: 139px; visibility: visible;" dragid="jsPlumb_1_1786" elid="jsPlumb_1_1773"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><svg style="position:absolute;left:228.5px;top:148.5px" width="158" height="113" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 137 112 C 147 62 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M119.18932075000001,80.9751845 L105.91219344329481,64.46101208714373 L107.30516809446021,73.57471724043954 L98.51172618373435,76.34516474268352 L119.18932075000001,80.9751845" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
