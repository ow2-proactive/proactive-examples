<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!-- Copyright Activeeon 2007-2021. All rights reserved. --><job xmlns="urn:proactive:jobdescriptor:3.12" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Train_Image_Object_Detection" onTaskError="continueJobExecution" priority="normal" projectName="4. Training Pytorch Workflows" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd">
  <variables>
    <variable name="NATIVE_SCHEDULER" value=""/>
    <variable name="NATIVE_SCHEDULER_PARAMS" value=""/>
    <variable name="NODE_ACCESS_TOKEN" value=""/>
    <variable model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker"/>
    <variable model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="True"/>
    <variable model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/nvidia:pytorch)" name="CONTAINER_IMAGE" value=""/>
  </variables>
  <description>
    <![CDATA[ Detect objects an image dataset using a pre-trained model. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="deep-learning-workflows"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
<info name="NS" value="$NATIVE_SCHEDULER"/>
<info name="PYTHON_COMMAND" value="python3"/>
<info name="Documentation" value="PML/PMLUserGuide.html#_training_custom_ai_workflows_pytorch_library"/>
<info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
<info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="YOLO">
      <description>
        <![CDATA[ You Only Look Once (YOLO) is a  single neural network to predict bounding boxes and class probabilities.
You can see more details in: https://pjreddie.com/media/files/papers/YOLOv3.pdf
https://github.com/eriklindernoren/PyTorch-YOLOv3 ]]>
      </description>
      <variables>
        <variable inherited="false" name="LEARNING_RATE" value="0.001"/>
        <variable inherited="false" name="MOMENTUM" value="0.9"/>
        <variable inherited="false" name="WEIGHT_DECAY" value="0.0005"/>
        <variable inherited="false" name="IMG_SIZE" value="(416, 416)"/>
        <variable inherited="false" name="NUM_CLASSES" value="81"/>
        <variable inherited="false" name="CONF_THRESHOLD" value="0.5"/>
        <variable inherited="false" name="NMS_THRESHOLD" value="0.45"/>
        <variable inherited="false" name="LABEL_PATH" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/coco.names"/>
        <variable inherited="false" name="USE_PRETRAINED_MODEL" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_detection.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_segnet"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning/resources/YOLO_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            288.515625
        </positionTop>
        <positionLeft>
            252.546875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Predict_Image_Object_Detection_Model">
      <description>
        <![CDATA[ Predict a model using an image object detection network. ]]>
      </description>
      <variables>
        <variable inherited="false" name="BATCH_SIZE" value="1"/>
        <variable inherited="false" name="NUM_WORKERS" value="1"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_predict_image_segmentation_model"/>
      </genericInformation>
      <depends>
        <task ref="Train_Image_Object_Detection_Model"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
        <files accessMode="transferFromGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning/resources/Predict_Image_Object_Detection_Model_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$OUTPUT_FOLDER/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            544.515625
        </positionTop>
        <positionLeft>
            316.546875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Preview_Results" preciousResult="true">
      <description>
        <![CDATA[ Preview the predicted results. ]]>
      </description>
      <variables>
        <variable inherited="false" name="OUTPUT_FILE" value="HTML"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_export_results.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_export_results"/>
      </genericInformation>
      <depends>
        <task ref="Predict_Image_Object_Detection_Model"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
        <files accessMode="transferFromGlobalSpace" includes="$OUTPUT_FOLDER/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning/resources/Preview_Results_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            672.515625
        </positionTop>
        <positionLeft>
            316.546875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Import_Image_Dataset">
      <description>
        <![CDATA[ Load and return an image dataset. ]]>
      </description>
      <variables>
        <variable inherited="false" name="DATA_PATH" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/coco.zip"/>
        <variable inherited="false" name="TRAIN_SPLIT" value="0.60"/>
        <variable inherited="false" name="VAL_SPLIT" value="0.15"/>
        <variable inherited="false" name="TEST_SPLIT" value="0.25"/>
        <variable inherited="false" model="PA:LIST(Classification, Detection, Segmentation)" name="DATASET_TYPE" value="Detection"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_image.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_import_image_dataset"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning/resources/Import_Image_Dataset_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$DATASET_PATH/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            288.515625
        </positionTop>
        <positionLeft>
            380.546875
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Train_Image_Object_Detection_Model">
      <description>
        <![CDATA[ Train a model using an image object detection network. ]]>
      </description>
      <variables>
        <variable inherited="false" name="NUM_EPOCHS" value="1"/>
        <variable inherited="false" name="BATCH_SIZE" value="1"/>
        <variable inherited="false" name="NUM_WORKERS" value="1"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html#_train_image_segmentation_model"/>
      </genericInformation>
      <depends>
        <task ref="YOLO"/>
        <task ref="Import_Image_Dataset"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
        <files accessMode="transferFromGlobalSpace" includes="$LABEL_PATH/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_ai/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning/resources/Train_Image_Object_Detection_Model_Script/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <post>
        <script>
          <code language="bash">
            <![CDATA[

]]>
          </code>
        </script>
      </post>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            416.515625
        </positionTop>
        <positionLeft>
            316.546875
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2144px;
            height:3048px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-283.515625px;left:-247.546875px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_61" style="top: 288.516px; left: 252.547px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="You Only Look Once (YOLO) is a  single neural network to predict bounding boxes and class probabilities.
You can see more details in: https://pjreddie.com/media/files/papers/YOLOv3.pdf
https://github.com/eriklindernoren/PyTorch-YOLOv3"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_detection.png" width="20px">&nbsp;<span class="name">YOLO</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_64" style="top: 544.516px; left: 316.547px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Predict a model using an image object detection network."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png" width="20px">&nbsp;<span class="name">Predict_Image_Object_Detection_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_67" style="top: 672.516px; left: 316.547px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Preview the predicted results."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_export_results.png" width="20px">&nbsp;<span class="name">Preview_Results</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_70" style="top: 288.516px; left: 380.547px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load and return an image dataset."><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_image.png" width="20px">&nbsp;<span class="name">Import_Image_Dataset</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_73" style="top: 416.516px; left: 316.547px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Train a model using an image object detection network."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png" width="20px">&nbsp;<span class="name">Train_Image_Object_Detection_Model</span></a></div><svg style="position:absolute;left:409px;top:456.5px" width="25.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 4.5 88 C 14.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M6.950109375,66.78168750000002 L12.19383263091469,46.25114034666338 L5.739082405354392,52.834163932040326 L-1.7536909370449987,47.46216731630898 L6.950109375,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M6.950109375,66.78168750000002 L12.19383263091469,46.25114034666338 L5.739082405354392,52.834163932040326 L-1.7536909370449987,47.46216731630898 L6.950109375,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:361px;top:584.5px" width="73.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 62.5 50 52.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M2.5799999999999983,64.44800000000001 L20.361299813410913,52.923010761584514 L11.153084637840395,53.379927909865025 L9.29322772327593,44.34992612374412 L2.5799999999999983,64.44800000000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M2.5799999999999983,64.44800000000001 L20.361299813410913,52.923010761584514 L11.153084637840395,53.379927909865025 L9.29322772327593,44.34992612374412 L2.5799999999999983,64.44800000000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:292.5px;top:328.5px" width="137.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 116.5 88 C 126.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M103.08112987499999,61.4125935 L88.8603453753114,45.703701488994994 L90.7842677881597,54.7202708226906 L82.168022698002,58.00056357583529 L103.08112987499999,61.4125935" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M103.08112987499999,61.4125935 L88.8603453753114,45.703701488994994 L90.7842677881597,54.7202708226906 L82.168022698002,58.00056357583529 L103.08112987499999,61.4125935" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:409px;top:328.5px" width="50.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 39.5 50 29.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-0.19430087500000195,65.8307285 L14.119682683751062,50.20671254123305 L5.321872471305423,52.963256657656245 L1.2522108414072983,44.69053919492763 L-0.19430087500000195,65.8307285" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M-0.19430087500000195,65.8307285 L14.119682683751062,50.20671254123305 L5.321872471305423,52.963256657656245 L1.2522108414072983,44.69053919492763 L-0.19430087500000195,65.8307285" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 293px; top: 319px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 414px; top: 575px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 414px; top: 535px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 361.5px; top: 703px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 361.5px; top: 663px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 439px; top: 319px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 409.5px; top: 447px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 409.5px; top: 407px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
