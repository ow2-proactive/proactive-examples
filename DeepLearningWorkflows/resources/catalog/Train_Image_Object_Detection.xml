<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.12" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Train_Image_Object_Detection" onTaskError="continueJobExecution" priority="normal" projectName="4. Training Pytorch Workflows" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd">
  <variables>
    <variable name="NATIVE_SCHEDULER" value=""/>
    <variable name="NATIVE_SCHEDULER_PARAMS" value=""/>
    <variable name="NODE_ACCESS_TOKEN" value=""/>
    <variable model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker"/>
    <variable model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="True"/>
    <variable model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/rapidsai,docker://activeeon/tensorflow:latest,docker://activeeon/tensorflow:latest-gpu)" name="CONTAINER_IMAGE" value=""/>
  </variables>
  <description>
    <![CDATA[ Image Object Detection workflow uses a pre-trained deep neural network to detect objects an image dataset. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="deep-learning-workflows"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
<info name="Documentation" value="MLOS/MLOSUserGuide.html#_training_custom_ai_workflows_pytorch_library"/>
<info name="NS" value="$NATIVE_SCHEDULER"/>
<info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
<info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="YOLO">
      <description>
        <![CDATA[ You Only Look Once (YOLO) is a  single neural network to predict bounding boxes and class probabilities.
You can see more details in: https://pjreddie.com/media/files/papers/YOLOv3.pdf
https://github.com/eriklindernoren/PyTorch-YOLOv3 ]]>
      </description>
      <variables>
        <variable inherited="false" name="LEARNING_RATE" value="0.001"/>
        <variable inherited="false" name="MOMENTUM" value="0.9"/>
        <variable inherited="false" name="WEIGHT_DECAY" value="0.0005"/>
        <variable inherited="false" name="IMG_SIZE" value="(416, 416)"/>
        <variable inherited="false" name="NUM_CLASSES" value="81"/>
        <variable inherited="false" name="CONF_THRESHOLD" value="0.5"/>
        <variable inherited="false" name="NMS_THRESHOLD" value="0.45"/>
        <variable inherited="false" name="LABEL_PATH" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/coco.names"/>
        <variable inherited="false" name="USE_PRETRAINED_MODEL" value="True"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_detection.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_segnet"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_cuda_universal/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/YOLO/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            235
        </positionTop>
        <positionLeft>
            465.734375
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Predict_Image_Object_Detection_Model">
      <description>
        <![CDATA[ Predict a model using an image object detection network. ]]>
      </description>
      <variables>
        <variable inherited="false" name="BATCH_SIZE" value="1"/>
        <variable inherited="false" name="NUM_WORKERS" value="1"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_predict_image_segmentation_model"/>
      </genericInformation>
      <depends>
        <task ref="Train_Image_Object_Detection_Model"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
        <files accessMode="transferFromGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_cuda_universal/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Predict_Image_Object_Detection_Model/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$OUTPUT_FOLDER/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            491
        </positionTop>
        <positionLeft>
            544
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Preview_Results" preciousResult="true">
      <description>
        <![CDATA[ Preview the predicted results. ]]>
      </description>
      <variables>
        <variable inherited="false" name="OUTPUT_FILE" value="HTML"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_export_results.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_export_results"/>
      </genericInformation>
      <depends>
        <task ref="Predict_Image_Object_Detection_Model"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
        <files accessMode="transferFromGlobalSpace" includes="$OUTPUT_FOLDER/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_cuda_universal/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Preview_Results/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            619
        </positionTop>
        <positionLeft>
            544
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Import_Image_Dataset">
      <description>
        <![CDATA[ Load and return an image dataset. ]]>
      </description>
      <variables>
        <variable inherited="false" name="DATA_PATH" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/coco.zip"/>
        <variable inherited="false" name="TRAIN_SPLIT" value="0.60"/>
        <variable inherited="false" name="VAL_SPLIT" value="0.15"/>
        <variable inherited="false" name="TEST_SPLIT" value="0.25"/>
        <variable inherited="false" model="PA:LIST(Classification, Detection, Segmentation)" name="DATASET_TYPE" value="Detection"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_image.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_import_image_dataset"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_cuda_universal/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Import_Image_Dataset/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$DATASET_PATH/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            235
        </positionTop>
        <positionLeft>
            622.25
        </positionLeft>
      </metadata>
    </task>
    <task fork="true" name="Train_Image_Object_Detection_Model">
      <description>
        <![CDATA[ Train a model using an image object detection network. ]]>
      </description>
      <variables>
        <variable inherited="false" name="NUM_EPOCHS" value="1"/>
        <variable inherited="false" name="BATCH_SIZE" value="1"/>
        <variable inherited="false" name="NUM_WORKERS" value="1"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_train_image_segmentation_model"/>
      </genericInformation>
      <depends>
        <task ref="YOLO"/>
        <task ref="Import_Image_Dataset"/>
      </depends>
      <inputFiles>
        <files accessMode="transferFromGlobalSpace" includes="$DATASET_PATH/**"/>
        <files accessMode="transferFromGlobalSpace" includes="$LABEL_PATH/**"/>
      </inputFiles>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_cuda_universal/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <file language="cpython" url="${PA_CATALOG_REST_URL}/buckets/deep-learning-scripts/resources/Train_Image_Object_Detection_Model/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <post>
        <script>
          <code language="bash">
            <![CDATA[

]]>
          </code>
        </script>
      </post>
      <outputFiles>
        <files accessMode="transferToGlobalSpace" includes="$MODEL_FOLDER/**"/>
      </outputFiles>
      <metadata>
        <positionTop>
            362.984375
        </positionTop>
        <positionLeft>
            544
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2864px;
            height:3432px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-230px;left:-460.734375px"><div class="task ui-draggable" id="jsPlumb_1_191" style="top: 235px; left: 465.75px; z-index: 24;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="You Only Look Once (YOLO) is a  single neural network to predict bounding boxes and class probabilities.
You can see more details in: https://pjreddie.com/media/files/papers/YOLOv3.pdf
https://github.com/eriklindernoren/PyTorch-YOLOv3"><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_detection.png" width="20px">&nbsp;<span class="name">YOLO</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_194" style="top: 491px; left: 544px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Predict a model using an image object detection network."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_predict.png" width="20px">&nbsp;<span class="name">Predict_Image_Object_Detection_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_197" style="top: 619px; left: 544px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Preview the predicted results."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_export_results.png" width="20px">&nbsp;<span class="name">Preview_Results</span></a></div><div class="task ui-draggable" id="jsPlumb_1_200" style="top: 235px; left: 622.25px; z-index: 24;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Load and return an image dataset."><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_image.png" width="20px">&nbsp;<span class="name">Import_Image_Dataset</span></a></div><div class="task ui-draggable" id="jsPlumb_1_203" style="top: 363px; left: 544px; z-index: 24;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Train a model using an image object detection network."><img src="/automation-dashboard/styles/patterns/img/wf-icons/deep_train.png" width="20px">&nbsp;<span class="name">Train_Image_Object_Detection_Model</span></a></div><svg style="position:absolute;left:588px;top:530.5px" width="73.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 62.5 50 52.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M2.5799999999999983,64.44800000000001 L20.361299813410913,52.923010761584514 L11.153084637840395,53.379927909865025 L9.29322772327593,44.34992612374412 L2.5799999999999983,64.44800000000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M2.5799999999999983,64.44800000000001 L20.361299813410913,52.923010761584514 L11.153084637840395,53.379927909865025 L9.29322772327593,44.34992612374412 L2.5799999999999983,64.44800000000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable endpointDrag _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 506px; top: 265px; visibility: visible;" dragid="jsPlumb_1_214" elid="jsPlumb_1_191"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 641px; top: 521px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 641px; top: 481px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 588.5px; top: 649px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 588.5px; top: 609px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable endpointDrag _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 680.5px; top: 265px; visibility: visible;" dragid="jsPlumb_1_230" elid="jsPlumb_1_200"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable endpointDrag _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 637px; top: 393px; visibility: visible;" dragid="jsPlumb_1_222" elid="jsPlumb_1_203"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><svg style="position:absolute;left:505.5px;top:274.5px" width="152" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 131 88 C 141 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M114.830528,60.999424000000005 L99.82448778854632,46.03885057608891 L102.20730427004384,54.945150908746896 L93.7702146972932,58.66207430604508 L114.830528,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected connected" style="position: absolute; height: 20px; width: 20px; left: 637px; top: 353px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><svg style="position:absolute;left:636.5px;top:402.5px" width="25" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 4 88 C 14 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M6.4906875,66.78168750000002 L11.866605249283193,46.285358356640174 L5.369566595211646,52.82664941632405 L-2.0884328343927736,47.40647926142853 L6.4906875,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:636.5px;top:274.5px" width="64.5" height="89" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector"><path d="M 0 88 C -10 38 53.5 50 43.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M1.4445258749999976,64.9032055 L18.104367513746922,51.809326144672404 L8.975829843879806,53.10153356216274 L6.302695575909668,44.27802217579259 L1.4445258749999976,64.9032055" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
