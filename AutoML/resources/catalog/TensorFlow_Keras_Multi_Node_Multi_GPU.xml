<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.12" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="TensorFlow_Keras_Multi_Node_Multi_GPU" onTaskError="continueJobExecution" priority="normal" projectName="5. Distributed Training" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd">
  <variables>
    <variable name="NATIVE_SCHEDULER" value="SLURM"/>
    <variable name="NATIVE_SCHEDULER_PARAMS" value="-p DL380_GPU --nodelist=gpu[01,02] --ntasks=2 --nodes=2"/>
    <variable name="NODE_ACCESS_TOKEN" value=""/>
    <variable name="NODE_SOURCE_NAME" value=""/>
    <variable model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="singularity"/>
    <variable model="PA:LIST(,python3,/nfs/virtualenvs/tf-nightly-gpu/bin/python3)" name="PYTHON_COMMAND" value="/nfs/virtualenvs/tf-nightly-gpu/bin/python3"/>
    <variable model="PA:LIST(,/nfs/singularity/images/activeeon_cuda2.sif,activeeon/cuda2)" name="CONTAINER_IMAGE" value="/nfs/singularity/images/activeeon_cuda2.sif"/>
    <variable name="TOKEN" value="{&quot;_token_id&quot;: 0}"/>
    <variable name="SEARCH_SPACE" value="{&quot;OPTIMIZER&quot;: {&quot;choice&quot;: [&quot;Adam&quot;, &quot;SGD&quot;, &quot;RMSprop&quot;]}, &quot;NUM_EPOCHS&quot;: {&quot;choice&quot;: [10, 20, 30, 40]}}"/>
    <variable model="PA:JSON" name="INPUT_VARIABLES" value="{&quot;OPTIMIZER&quot;: &quot;Adam&quot;, &quot;NUM_EPOCHS&quot;: 10}"/>
  </variables>
  <description>
    <![CDATA[ This is a TensorFlow + Keras workflow template for distributed training (multi-node multi-gpu) with AutoML support. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="auto-ml-optimization"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/tensorflow.png"/>
<info name="NODESOURCENAME" value="$NODE_SOURCE_NAME"/>
<info name="NS" value="$NATIVE_SCHEDULER"/>
<info name="PYTHON_COMMAND" value="$PYTHON_COMMAND"/>
<info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
<info name="Documentation" value="PML/PMLUserGuide.html"/>
<info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="false" name="TensorFlow_Multi_Node_Task" preciousResult="true">
      <description>
        <![CDATA[ Simple Python task template for AutoML. ]]>
      </description>
      <variables>
        <variable inherited="false" model="PA:URI" name="DATASET_PATH" value="/nfs/activeeon/slurm_mnist/mnist.pickle"/>
        <variable inherited="false" model="PA:URI" name="SCRIPT_PATH" value="/nfs/activeeon/main.py"/>
        <variable inherited="false" model="PA:LIST(,/nfs/shared/tensorboard-logs)" name="TENSORBOARD_LOG_DIR" value=""/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/python.png"/>
        <info name="task.documentation" value="PML/PMLUserGuide.html"/>
        <info name="PRE_SCRIPT_AS_FILE" value="$SCRIPT_PATH"/>
      </genericInformation>
      <depends>
        <task ref="get_automl_variables"/>
      </depends>
      <pre>
        <script>
          <code language="cpython">
            <![CDATA[
from __future__ import print_function
from __future__ import absolute_import
from __future__ import division

import re
import os
import sys
import json
import time
import pickle
import shutil
import socket

import numpy as np

__file__ = os.environ['variables_PA_TASK_NAME']
print("BEGIN " + __file__)
print("Running on: ", socket.gethostname())

# Get the job ID from Proactive
PA_JOB_ID = int(os.environ['variables_PA_JOB_ID'])

############################ INPUT FROM AUTOML ############################
# Get the workflow input variables generated by AutoML.
# The AutoML workflow uses the SEARCH_SPACE workflow variable
# to generate a set of parameters to be used to train your model.
#
# Example of search space for hyper parameter optimization:
#   SEARCH_SPACE: {"OPTIMIZER": {"choice": ["Adam", "SGD", "RMSprop"]}, "NUM_EPOCHS": {"choice": [10, 20, 30, 40]}}
# Put it in your workflow variables.
#
# For more info, please see:
# https://try.activeeon.com/doc/PML/PMLUserGuide.html#_AutoML
#
input_variables = os.environ['variables_INPUT_VARIABLES']
if input_variables is not None and input_variables != '':
    input_variables = json.loads(input_variables)
    OPTIMIZER = input_variables["OPTIMIZER"]
    NUM_EPOCHS = int(input_variables["NUM_EPOCHS"])
    # ...
print('Selected optimizer: ', OPTIMIZER)
print('Selected epochs:    ', NUM_EPOCHS)
###########################################################################

################################## SLURM ##################################
#
# from tensorflow_on_slurm import tf_config_from_slurm
#
def tf_config_from_slurm(ps_number, port_number=2222):
    """
    Creates configuration for a distributed tensorflow session
    from environment variables  provided by the Slurm cluster
    management system.

    @param: ps_number number of parameter servers to run
    @param: port_number port number to be used for communication
    @return: a tuple containing cluster with fields cluster_spec,
             task_name and task_id
    """

    nodelist = os.environ["SLURM_JOB_NODELIST"]
    nodename = os.environ["SLURMD_NODENAME"]
    nodelist = _expand_nodelist(nodelist)
    num_nodes = int(os.getenv("SLURM_JOB_NUM_NODES"))

    if len(nodelist) != num_nodes:
        raise ValueError("Number of slurm nodes {} not equal to {}".format(len(nodelist), num_nodes))

    if nodename not in nodelist:
        raise ValueError("Nodename({}) not in nodelist({}). This should not happen! ".format(nodename,nodelist))

    ps_nodes = [node for i, node in enumerate(nodelist) if i < ps_number]
    worker_nodes = [node for i, node in enumerate(nodelist) if i >= ps_number]

    if nodename in ps_nodes:
        my_job_name = "ps"
        my_task_index = ps_nodes.index(nodename)
    else:
        my_job_name = "worker"
        my_task_index = worker_nodes.index(nodename)
        # if len(worker_nodes) > 0:
        #     my_task_index = worker_nodes.index(nodename)
        # else:
        #     my_task_index = 1

    worker_sockets = [":".join([node, str(port_number)]) for node in worker_nodes]
    # if len(worker_nodes) > 0:
    #     worker_sockets = [":".join([node, str(port_number)]) for node in worker_nodes]
    # else:
    #     worker_sockets = [":".join([node, str(port_number+1)]) for node in ps_nodes]

    ps_sockets = [":".join([node, str(port_number)]) for node in ps_nodes]
    cluster = {"worker": worker_sockets, "ps" : ps_sockets}

    return cluster, my_job_name, my_task_index

def _pad_zeros(iterable, length):
    return (str(t).rjust(length, '0') for t in iterable) # default
    # return (str(t) for t in iterable) # for IDRIS

def _expand_ids(ids):
    ids = ids.split(',')
    result = []
    for id in ids:
        if '-' in id:
            begin, end = [int(token) for token in id.split('-')]
            token = [int(token) for token in id.split('-')]
            result.extend(_pad_zeros(range(begin, end+1), len(token)))
        else:
            result.append(id)
    return result

def _expand_nodelist(nodelist):
    nodes = nodelist.split(',')
    result = []
    for node in nodes:
        try:
            prefix, ids = re.findall("(.*)\[(.*)\]", node)[0]
            ids = _expand_ids(ids)
            result_aux = [prefix + str(id) for id in ids]
            result = result + result_aux
        except IndexError:
            result.append(node)
    return result

def _worker_task_id(nodelist, nodename):
    return nodelist.index(nodename)

cluster, my_job_name, my_task_index = tf_config_from_slurm(ps_number=1)
print("cluster: ", cluster, ", my_job_name: ", my_job_name, ", my_task_index: ", my_task_index)
os.environ['TF_CONFIG'] = json.dumps(cluster)
num_workers = len(cluster['worker'])
# per_worker_batch_size = 128
per_worker_batch_size = 16

import tensorflow as tf
print("tf.__version__: ", tf.__version__)
# https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory
# config = tf.ConfigProto()
# config.gpu_options.allow_growth=True
# sess = tf.Session(config=config)
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

############################### TENSORBOARD ###############################
from tensorflow.keras.callbacks import TensorBoard
tensorboard = None
tensorboard_logs_base_dir = os.environ['variables_TENSORBOARD_LOG_DIR']
if len(tensorboard_logs_base_dir) > 0:
    PA_JOB_ID_LOG = "job_ID_" + str(PA_JOB_ID)
    tensorboard_log_dir = os.path.join(tensorboard_logs_base_dir, PA_JOB_ID_LOG)
    try:
        os.mkdir(tensorboard_log_dir)
    except:
        pass
    tensorboard = TensorBoard(log_dir=tensorboard_log_dir)
else:
    print("Tensorboard disabled")
###########################################################################

# https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy
# strategy = tf.distribute.MultiWorkerMirroredStrategy()
strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

def mnist_dataset(batch_size, train_size):
    # (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
    DATASET_PATH = os.environ['variables_DATASET_PATH']
    with open(DATASET_PATH, 'rb') as fp:
        x_train, y_train, x_test, y_test = pickle.load(fp)
    # The `x` arrays are in uint8 and have values in the range [0, 255].
    # You need to convert them to float32 with values in the range [0, 1]
    x_train, x_test = x_train / 255.0, x_test / 255.0
    y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)
    # Create the tf.data.Dataset from the existing data
    dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
    # Split the data into a train and a test set.
    SAMPLES_TRAINING = int(len(x_train)*train_size) # e.g. 80% of data for training, 20% for validation
    train_dataset = dataset.take(SAMPLES_TRAINING)
    val_dataset = dataset.skip(SAMPLES_TRAINING)
    # Both datasets have to be repeated and batched appropriately
    # train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).repeat().batch(batch_size)
    train_dataset = train_dataset.repeat().batch(batch_size)
    val_dataset = val_dataset.repeat().batch(batch_size)
    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).repeat().batch(batch_size)
    train_len = len(x_train)
    return train_len, train_dataset, val_dataset, test_dataset


def build_and_compile_cnn_model(optimizer):
    model = tf.keras.Sequential([
            tf.keras.Input(shape=(28, 28)),
            tf.keras.layers.Reshape(target_shape=(28, 28, 1)),
            tf.keras.layers.Conv2D(32, 3, activation='relu'),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10)
    ])
    model.compile(
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
            optimizer=optimizer,
            metrics=['accuracy'])
    return model


# Here the batch size scales up by number of workers since
# `tf.data.Dataset.batch` expects the global batch size. Previously, you used 64,
# and now this becomes 128.
global_batch_size = per_worker_batch_size * num_workers
train_size = 0.8
train_len, train_dataset, val_dataset, test_dataset = mnist_dataset(global_batch_size, train_size)

# learning_rate = 0.001
learning_rate = 0.01
optimizer = None
if OPTIMIZER.lower() == 'adam':
    optimizer = tf.keras.optimizers.Adam(learning_rate)
if OPTIMIZER.lower() == 'sgd':
    optimizer = tf.keras.optimizers.SGD(learning_rate)
if OPTIMIZER.lower() == 'rmsprop':
    optimizer = tf.keras.optimizers.RMSprop(learning_rate)
if optimizer is None:
    sys.exit("Optimizer not defined!")

with strategy.scope():
    # Model building/compiling need to be within `strategy.scope()`.
    multi_worker_model = build_and_compile_cnn_model(optimizer)

# Keras' `model.fit()` trains the model with specified number of epochs and
# number of steps per epoch. Note that the numbers here are for demonstration
# purposes only and may not sufficiently produce a model with good quality.
callbacks = None
if tensorboard is not None:
    callbacks=[tensorboard]
# steps_per_epoch = (train_len*train_size)//global_batch_size
# validation_steps = (train_len*(1-train_size))//global_batch_size
steps_per_epoch = 30
validation_steps = 10
print("steps_per_epoch:  ", steps_per_epoch)
print("validation_steps: ", validation_steps)
history = multi_worker_model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=NUM_EPOCHS,
    steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps,
    callbacks=callbacks
)
# print(history.history)

################################# RESULTS #################################
if my_job_name == 'ps':
    train_acc = history.history['accuracy'][-1]
    train_loss = history.history['loss'][-1]
    val_acc = history.history['val_accuracy'][-1]
    val_loss = history.history['val_loss'][-1]
    print("train_acc:  ", train_acc)
    print("train_loss: ", train_loss)
    print("val_acc:    ", val_acc)
    print("val_loss:   ", val_loss)
############################ OUTPUT FOR AUTOML ############################
    data={}
    data['train_loss'] = train_loss
    data['train_acc'] = train_acc
    data['val_loss'] = val_loss
    data['val_acc'] = val_acc
    result_file = 'job_id_'+str(PA_JOB_ID)+'_result.json'
    with open(result_file, 'w') as outfile:
        json.dump(data, outfile)
###########################################################################

print("END " + __file__)
]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="bash">
            <![CDATA[
echo "SLURM_JOB_ID:$SLURM_JOB_ID SLURM_JOB_NAME:$SLURM_JOB_NAME SLURM_JOB_NODELIST:$SLURM_JOB_NODELIST SLURMD_NODENAME:$SLURMD_NODENAME SLURM_JOB_NUM_NODES:$SLURM_JOB_NUM_NODES"
echo "---------------------------------------"
CONTAINER_PLATFORM=$variables_CONTAINER_PLATFORM
CONTAINER_IMAGE=$variables_CONTAINER_IMAGE
PYTHON_COMMAND=$variables_PYTHON_COMMAND
DATASET_PATH=$variables_DATASET_PATH
SCRIPT_PATH=$variables_SCRIPT_PATH
TENSORBOARD_LOG_DIR=$variables_TENSORBOARD_LOG_DIR
echo "Runtime configuration:"
echo "CONTAINER_PLATFORM:  $CONTAINER_PLATFORM"
echo "CONTAINER_IMAGE:     $CONTAINER_IMAGE"
echo "PYTHON_COMMAND:      $PYTHON_COMMAND"
echo "DATASET_PATH:        $DATASET_PATH"
echo "SCRIPT_PATH:         $SCRIPT_PATH"
echo "TENSORBOARD_LOG_DIR: $TENSORBOARD_LOG_DIR"
echo "---------------------------------------"
#
# no-container mode (baremetal)
#
if [[ "$CONTAINER_PLATFORM" == "no-container" ]]; then
	# source /nfs/activeeon/virtualenvs/tf-nightly-gpu/bin/activate
	export PATH=/usr/local/cuda/bin:$PATH
	export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
    echo "PATH: $PATH"
    echo "LD_LIBRARY_PATH: $LD_LIBRARY_PATH"
    echo "srun $PYTHON_COMMAND $SCRIPT_PATH"
    srun $PYTHON_COMMAND $SCRIPT_PATH
fi
#
# singularity container
#
if [[ "$CONTAINER_PLATFORM" == "singularity" ]]; then
	echo "srun singularity exec --nv $CONTAINER_IMAGE python3 $SCRIPT_PATH"
    srun singularity exec --nv $CONTAINER_IMAGE python3 $SCRIPT_PATH
fi
#
# docker container
#
if [[ "$CONTAINER_PLATFORM" == "docker" ]]; then
	# TO SEE: https://gitlab.inria.fr/dkalaina/titanic-docs/-/tree/master/scripts
	# echo "srun docker run --rm --shm-size=256M --runtime=nvidia --privileged --network=host -v $DATASET_PATH:$DATASET_PATH -v $SCRIPT_PATH:$SCRIPT_PATH -v $TENSORBOARD_LOG_DIR:$TENSORBOARD_LOG_DIR $CONTAINER_IMAGE bash -c 'python3 $SCRIPT_PATH'"
    echo "docker not supported!"
fi
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="end"/>
      <post>
        <script>
          <code language="cpython">
            <![CDATA[
import os
import json

__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

# Get the job ID from Proactive
PA_JOB_ID = int(variables.get("PA_JOB_ID"))

############################ OUTPUT FOR AUTOML ############################
# Read and send the loss to AutoML
loss = 0
acc = 0
result_file = 'job_id_'+str(PA_JOB_ID)+'_result.json'
if os.path.isfile(result_file):
    with open(result_file) as json_file:
        data = json.load(json_file)
    loss = data['val_loss']
    acc = data['val_acc']
else:
    print(result_file + " does not exists!")
print('Loss:', loss)
print('Accuracy:', acc)

# Return the token + loss value
token = variables.get("TOKEN")
token = json.loads(token)
result_map = {'token': token, 'loss':  loss}
resultMap.put("RESULT_JSON", json.dumps(result_map))

# To appear in Job Analytics
resultMap.put("LOSS", str(loss))
resultMap.put("ACCURACY", str(acc))
###########################################################################

print("END " + __file__)
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
            294.47265625
        </positionTop>
        <positionLeft>
            83.1640625
        </positionLeft>
      </metadata>
    </task>
    <task fork="false" name="get_automl_variables">
      <description>
        <![CDATA[ The simplest task, ran by a Groovy engine. ]]>
      </description>
      <scriptExecutable>
        <script>
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/get_automl_variables/raw"/>
        </script>
      </scriptExecutable>
      <controlFlow block="start"/>
      <metadata>
        <positionTop>
            165.46875
        </positionTop>
        <positionLeft>
            84.16015625
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2645px;
            height:3500px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-160.46875px;left:-78.1640625px"><div class="task block-end ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_273" style="top: 294.473px; left: 83.1642px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Simple Python task template for AutoML."><img src="/automation-dashboard/styles/patterns/img/wf-icons/python.png" width="20px">&nbsp;<span class="name">TensorFlow_Multi_Node_Task</span></a></div><div class="task block-start _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_276" style="top: 165.469px; left: 84.1603px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="The simplest task, ran by a Groovy engine."><img src="/studio/images/Groovy.png" width="20px">&nbsp;<span class="name">get_automl_variables</span></a></div><svg style="position:absolute;left:139px;top:204.5px" width="39.5" height="91" pointer-events="none" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 18.5 90 C 28.5 40 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style="--darkreader-inline-fill:none; --darkreader-inline-stroke:#a8a095;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M19.684430125,67.650705 L21.139893578817006,46.511130119350135 L15.978085868352057,54.15022307337187 L7.6394116521888735,50.21747437599807 L19.684430125,67.650705" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill:#a8a095; --darkreader-inline-stroke:#a8a095;"></path><path pointer-events="all" version="1.1" xmlns="http://www.w3.org/1999/xhtml" d="M19.684430125,67.650705 L21.139893578817006,46.511130119350135 L15.978085868352057,54.15022307337187 L7.6394116521888735,50.21747437599807 L19.684430125,67.650705" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)" data-darkreader-inline-fill="" data-darkreader-inline-stroke="" style="--darkreader-inline-fill:#a8a095; --darkreader-inline-stroke:#a8a095;"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 158px; top: 325px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill:#a8a095; --darkreader-inline-stroke:none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 158px; top: 285px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill:#a8a095; --darkreader-inline-stroke:none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 139.5px; top: 195px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style="--darkreader-inline-fill:#a8a095; --darkreader-inline-stroke:none;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
