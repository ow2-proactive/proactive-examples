<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.11" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="1" name="CIFAR10_CNN" onTaskError="cancelJob" priority="normal" projectName="2. Objective ML Examples" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd">
  <variables>
    <variable model="PA:LIST(,CPU,GPU)" name="NODE_SOURCE_NAME" value=""/>
    <variable model="PA:Boolean" name="DOCKER_ENABLED" value="True"/>
    <variable model="PA:Boolean" name="DOCKER_GPU_ENABLED" value="False"/>
    <variable model="PA:LIST(activeeon/dlm3,activeeon/cuda,activeeon/tensorflow:latest,activeeon/tensorflow:latest-gpu)" name="DOCKER_IMAGE" value="activeeon/dlm3"/>
    <variable name="INPUT_VARIABLES" value=""/>
    <variable name="SEARCH_SPACE" value="{&quot;OPTIMIZER&quot;: choice([&quot;Adam&quot;, &quot;SGD&quot;, &quot;RMSprop&quot;]),&quot;LEARNING_RATE&quot;: choice([0.0001, 0.00025]), &quot;BATCH_SIZE&quot;: choice([32, 64]), &quot;WEIGHT_DECAY&quot;: choice([0.0005, 0.005])}"/>
  </variables>
  <description>
    <![CDATA[ Train a simple deep CNN on the CIFAR10 images dataset using the Keras library. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="auto-ml-optimization"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/keras.png"/>
<info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task name="CIFAR10_CNN">
      <description>
        <![CDATA[ Train a simple deep CNN on the CIFAR10 images dataset using keras library.
You can see more details in: https://github.com/prakritidev/DeepLearning/blob/master/Keras/Convolutional%20Neural%20Network/CIFAR10_cnn.py ]]>
      </description>
      <variables>
        <variable inherited="false" name="NUM_EPOCHS" value="3"/>
        <variable inherited="false" name="BATCH_SIZE" value="32"/>
        <variable inherited="false" name="LEARNING_RATE" value="0.0001"/>
        <variable inherited="false" name="WEIGHT_DECAY" value="1e-6"/>
        <variable inherited="false" model="PA:LIST(Adam, SGD, RMSprop)" name="OPTIMIZER" value="Adam"/>
        <variable inherited="true" name="TOKEN" value="{&quot;_token_id&quot;: 0}"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/keras.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_segnet"/>
      </genericInformation>
      <selection>
        <script type="static">
          <code language="groovy">
            <![CDATA[
selected = false
NODE_SOURCE_NAME = variables.get("NODE_SOURCE_NAME")
if (NODE_SOURCE_NAME) {
	selected = (System.getProperty("proactive.node.nodesource").equals(NODE_SOURCE_NAME));
} else {
    selected = true
}
]]>
          </code>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#%% fork environment (python)
import os

DOCKER_ENABLED = True
if variables.get("DOCKER_ENABLED") is not None:
    if str(variables.get("DOCKER_ENABLED")).lower() == 'false':
        DOCKER_ENABLED = False

DOCKER_IMAGE = 'activeeon/dlm3'
if variables.get("DOCKER_IMAGE") is not None:
    DOCKER_IMAGE = variables.get("DOCKER_IMAGE")

DOCKER_GPU_ENABLED = False
if variables.get("DOCKER_GPU_ENABLED") is not None:
    if str(variables.get("DOCKER_GPU_ENABLED")).lower() == 'true':
        DOCKER_GPU_ENABLED = True

CUDA_ENABLED = False
CUDA_HOME = os.getenv('CUDA_HOME', None)
CUDA_HOME_DEFAULT = '/usr/local/cuda'
if CUDA_HOME is not None:
    if os.path.isdir(CUDA_HOME) == True:
        CUDA_ENABLED = True
else:
    if os.path.isdir(CUDA_HOME_DEFAULT) == True:
        CUDA_ENABLED = True

DOCKER_RUN_CMD = 'docker run '
if DOCKER_GPU_ENABLED and CUDA_ENABLED:
    DOCKER_RUN_CMD += '--runtime=nvidia '

print('Fork environment info...')
print('DOCKER_ENABLED:     ' + str(DOCKER_ENABLED))
print('DOCKER_IMAGE:       ' + DOCKER_IMAGE)
print('DOCKER_GPU_ENABLED: ' + str(DOCKER_GPU_ENABLED))
print('DOCKER_RUN_CMD:     ' + DOCKER_RUN_CMD)

if DOCKER_ENABLED == True:
    # Prepare Docker parameters
    containerName = DOCKER_IMAGE
    dockerRunCommand =  DOCKER_RUN_CMD
    dockerParameters = '--rm '
    # Prepare ProActive home volume
    paHomeHost = variables.get("PA_SCHEDULER_HOME")
    paHomeContainer = variables.get("PA_SCHEDULER_HOME")
    proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' '
    # Prepare working directory (For Dataspaces and serialized task file)
    workspaceHost = localspace
    workspaceContainer = localspace
    workspaceVolume = '-v '+localspace +':'+localspace+' '
    # Prepare container working directory
    containerWorkingDirectory = '-w '+workspaceContainer+' '
    # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node
    preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName

    print('DOCKER_FULL_CMD:    ' + preJavaHomeCmd)
else:
    print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <code language="groovy">
            <![CDATA[
params_encoded = variables.get('params_encoded')
token_encoded = variables.get('token_encoded')

// If encoded variables are found
if ((params_encoded != null && params_encoded.length() > 0) &&
    (token_encoded != null && token_encoded.length() > 0))
{
    println "Found encoded variables:"
    println "params_encoded: " + params_encoded
    println "token_encoded: " + token_encoded
    
    byte[] params_decoded = params_encoded.decodeBase64()
    byte[] token_decoded = token_encoded.decodeBase64()
    
    input_variables = new String(params_decoded)
    token = new String(token_decoded)
    
    variables.put('INPUT_VARIABLES', input_variables)
    variables.put('TOKEN', token)
}
]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN CIFAR10_CNN")

import os, json

import keras
from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D

# https://github.com/tensorflow/tensorflow/issues/24828
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

NUM_EPOCHS    = 3
LEARNING_RATE = 0.0001
BATCH_SIZE    = 32
WEIGHT_DECAY  = 1e-6
OPTIMIZER     = 'Adam' # Adam, RMSPROP, SGD

######################## AUTOML SETTINGS ##########################
# SEARCH_SPACE:
# {"OPTIMIZER": choice(["Adam", "SGD", "RMSprop"]),
#  "LEARNING_RATE": choice([0.0001, 0.00025]), 
#  "BATCH_SIZE": choice([32, 64]), 
#  "WEIGHT_DECAY": choice([0.0005, 0.005])}
#"""
NUM_EPOCHS    = int(variables.get("NUM_EPOCHS"))
LEARNING_RATE = float(variables.get("LEARNING_RATE"))
BATCH_SIZE    = int(variables.get("BATCH_SIZE"))
WEIGHT_DECAY  = float(variables.get("WEIGHT_DECAY"))
OPTIMIZER     = (variables.get("OPTIMIZER"))

input_variables = variables.get("INPUT_VARIABLES")
if input_variables is not None and input_variables != '':
    input_variables = json.loads(input_variables)
    LEARNING_RATE = input_variables["LEARNING_RATE"]
    BATCH_SIZE = input_variables["BATCH_SIZE"]
    WEIGHT_DECAY = input_variables["WEIGHT_DECAY"]
    OPTIMIZER = input_variables["OPTIMIZER"]
#"""
###################################################################

OPTIMIZER = OPTIMIZER.upper()

NUM_CLASSES = 10
DATA_AUGMENTATION = False

print('-' * 30)
print('NUM_EPOCHS:        ', NUM_EPOCHS)
print('LEARNING_RATE:     ', LEARNING_RATE)
print('BATCH_SIZE:        ', BATCH_SIZE)
print('WEIGHT_DECAY:      ', WEIGHT_DECAY)
print('OPTIMIZER:         ', OPTIMIZER)
print('NUM_CLASSES:       ', NUM_CLASSES)
print('DATA_AUGMENTATION: ', DATA_AUGMENTATION)
print('-' * 30)

# The data, split between train and test sets:
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# Convert class vectors to binary class matrices.
y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)
y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)
print(x_train.shape[1:])

# Implemnting above stack into code.
model = Sequential()
# Adding layers to the sequential model 
# .add() will push the layer into the stack(sequential model)
# filter -> 32
# strides ->(3,3)
model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))
# Reulu is an activation function faster than sigmoid and reduce the liklehod of vanishing gradient 
model.add(Activation('relu'))

# We dont have to define parameters again.
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
# Maxpooling is done for downsampling the input and reducing its dimensionality
# and also help over-fitting by providing an abstracted form of the representation
model.add(MaxPooling2D(pool_size=(2, 2)))
# Drop put is a regularization technique where randomly selected neurons are ignored during training
# Here 25% connection will drop
model.add(Dropout(0.25))

# Depth is changed into 64
model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# Conver matrix into a vector by streching it.
model.add(Flatten())

# Dense layer is use to collect all the info 
model.add(Dense(512))

model.add(Activation('relu'))

model.add(Dropout(0.5))
# Number of target classes
model.add(Dense(NUM_CLASSES))
# Softmax convert probabilty into binary number.
model.add(Activation('softmax'))

# Initiate RMSprop optimizer
if OPTIMIZER == 'RMSPROP':
    opt = keras.optimizers.rmsprop(lr=LEARNING_RATE, decay=WEIGHT_DECAY)
elif OPTIMIZER == 'SGD':
    opt = keras.optimizers.SGD(lr=LEARNING_RATE, decay=WEIGHT_DECAY)
else:
    opt = keras.optimizers.Adam(lr=LEARNING_RATE, decay=WEIGHT_DECAY)

# Let's train the model using RMSprop
model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

if not DATA_AUGMENTATION:
    print('Not using data augmentation.')
    model.fit(x_train, y_train,
             batch_size =BATCH_SIZE,
              epochs=NUM_EPOCHS,
              validation_data=(x_test, y_test),
              shuffle=True)
else:
    print('Using real-time data augmentation.')
    # This will do preprocessing and realtime data augmentation:
    datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False)  # randomly flip images
    
    # Compute quantities required for feature-wise normalization
    # (std, mean, and principal components if ZCA whitening is applied).
    datagen.fit(x_train)

    # Fit the model on the batches generated by datagen.flow().
    model.fit_generator(
      datagen.flow(x_train, y_train, batch_size=BATCH_SIZE), 
      steps_per_epoch=x_train.shape[0], 
      epochs=NUM_EPOCHS, 
      validation_data=(x_test, y_test)
    )

# Score trained model.
scores = model.evaluate(x_test, y_test, verbose=1)
loss = scores[0]
acc = scores[1]
print('Test loss:', loss)
print('Test accuracy:', acc)

######################## AUTOML SETTINGS ##########################
#"""
token = variables.get("TOKEN")
# Convert from JSON to dict
token = json.loads(token)

# Return the loss value
result_map = {'token': token, 'loss':  loss}
print('result_map: ', result_map)

resultMap.put("RESULT_JSON", json.dumps(result_map))

# To appear in Job Analytics
resultMap.put("LOSS", str(loss))
resultMap.put("ACCURACY", str(acc))
#"""
###################################################################

print("END CIFAR10_CNN")
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            173.16668701171875
        </positionTop>
        <positionLeft>
            255.71664428710938
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2683px;
            height:3635px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-168.16668701171875px;left:-250.71664428710938px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" style="top: 173.172px; left: 255.719px;" id="jsPlumb_1_100"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/keras.png" width="20px">&nbsp;<span class="name">CIFAR10_CNN</span></a></div><div style="position: absolute; height: 20px; width: 20px; left: 297px; top: 203px;" class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>
