<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<job xmlns="urn:proactive:jobdescriptor:3.12" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" maxNumberOfExecution="2" name="Handwritten_Digit_Classification" onTaskError="continueJobExecution" priority="normal" projectName="4.  Neural Architecture Search" xsi:schemaLocation="urn:proactive:jobdescriptor:3.12 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.12/schedulerjob.xsd">
  <variables>
    <variable name="NATIVE_SCHEDULER" value=""/>
    <variable name="NATIVE_SCHEDULER_PARAMS" value=""/>
    <variable name="NODE_SOURCE_NAME" value=""/>
    <variable name="NODE_ACCESS_TOKEN" value=""/>
    <variable model="PA:LIST(no-container,docker,podman,singularity)" name="CONTAINER_PLATFORM" value="docker"/>
    <variable model="PA:LIST(,docker://activeeon/dlm3,docker://activeeon/cuda,docker://activeeon/cuda2,docker://activeeon/rapidsai,docker://activeeon/tensorflow:latest,docker://activeeon/tensorflow:latest-gpu)" name="CONTAINER_IMAGE" value=""/>
    <variable model="PA:Boolean" name="CONTAINER_GPU_ENABLED" value="true"/>
    <variable model="PA:Boolean" name="CONTAINER_ROOTLESS_ENABLED" value="false"/>
    <variable model="PA:Boolean" name="CONTAINER_NO_HOME_ENABLED" value="false"/>
    <variable model="PA:Integer" name="NUM_EPOCHS" value="10"/>
    <variable model="PA:JSON" name="INPUT_VARIABLES" value="{ &quot;CONV&quot;: &quot;nn.Conv2d(1, 4, kernel_size=5, stride=1, padding=2)&quot;,   &quot;DROPOUT&quot;:&quot;nn.AlphaDropout()&quot;,     &quot;ACTIVATION&quot;: &quot;nn.ReLU(inplace=True)&quot;,       &quot;POOLING&quot;: &quot;nn.MaxPool2d(kernel_size=2, stride=2)&quot;,       &quot;NORMALIZATION&quot;: &quot;nn.InstanceNorm2d(100)&quot;,  &quot;CONV2&quot;: &quot;nn.Conv2d(4, 4, kernel_size=5, stride=1, padding=2)&quot;,      &quot;DROPOUT2&quot;:&quot;nn.Dropout()&quot;,      &quot;ACTIVATION2&quot;: &quot;nn.ReLU6(inplace=True)&quot;,       &quot;POOLING2&quot;: &quot;nn.MaxPool2d(kernel_size=2, stride=2)&quot;,       &quot;NORMALIZATION2&quot;: &quot;nn.BatchNorm2d(4)&quot;,    &quot;CRITERION&quot;:&quot;nn.CrossEntropyLoss()&quot;,  &quot;OPTIMIZER&quot;: &quot;torch.optim.Adam(model.parameters(), lr=0.01)&quot; , &quot;MODEL&quot;: &quot;arch2&quot;}"/>
    <variable model="PA:CATALOG_OBJECT" name="SEARCH_SPACE" value="auto-ml-optimization/Handwritten_Digit_Classification_Search_Space"/>
    <variable model="PA:Boolean" name="TENSORBOARD_ENABLED" value="false"/>
    <variable name="INSTANCE_NAME" value="tensorboard-server"/>
    <variable name="CONTAINER_LOG_PATH" value="/tmp/$INSTANCE_NAME"/>
    <variable name="HOST_LOG_PATH" value="/shared/$INSTANCE_NAME"/>
  </variables>
  <description>
    <![CDATA[ Train a simple deep CNN on the MNIST dataset using the Pytorch library. ]]>
  </description>
  <genericInformation>
<info name="bucketName" value="auto-ml-optimization"/>
<info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
<info name="NS" value="$NATIVE_SCHEDULER"/>
<info name="NODE_ACCESS_TOKEN" value="$NODE_ACCESS_TOKEN"/>
<info name="Documentation" value="MLOS/MLOSUserGuide.html#_neural_architecture_search"/>
<info name="NS_BATCH" value="$NATIVE_SCHEDULER_PARAMS"/>
<info name="group" value="public-objects"/>
</genericInformation>
  <taskFlow>
    <task fork="true" name="Handwritten_Digit_Classification">
      <description>
        <![CDATA[ Train a simple deep CNN on the MNIST dataset using the Pytorch library. ]]>
      </description>
      <variables>
        <variable inherited="true" name="TOKEN" value="{&quot;_token_id&quot;: 0}"/>
        <variable inherited="false" model="PA:Json" name="LAYER1" value="{&quot;CONV&quot;: &quot;nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1)&quot;,                          &quot;ACTIVATION&quot;: &quot;nn.ReLU(inplace=True)&quot;,                          &quot;POOLING&quot;: &quot;nn.MaxPool2d(kernel_size=2, stride=2)&quot;, &quot;NORMALIZATION&quot;: &quot;nn.BatchNorm2d(4)&quot;}"/>
        <variable inherited="false" model="PA:Json" name="LAYER2" value="{&quot;CONV&quot;: &quot;nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1)&quot;,                          &quot;ACTIVATION&quot;: &quot;nn.ReLU(inplace=True)&quot;,                          &quot;POOLING&quot;: &quot;nn.MaxPool2d(kernel_size=2, stride=2)&quot;, &quot;NORMALIZATION&quot;: &quot;nn.BatchNorm2d(4)&quot;}"/>
        <variable inherited="false" model="PA:Json" name="LOSS" value="{&quot;CRITERION&quot;: &quot;nn.CrossEntropyLoss()&quot;}"/>
        <variable inherited="false" model="PA:Json" name="OPTIMIZER" value="{&quot;OPTIM&quot;: &quot;torch.optim.Adam(model.parameters(), lr=0.01)&quot;}"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_objective_ml_examples"/>
      </genericInformation>
      <selection>
        <script type="static">
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/check_node_source_name/raw"/>
        </script>
      </selection>
      <forkEnvironment javaHome="/usr">
        <envScript>
          <script>
            <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/fork_env_cuda_universal/raw"/>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <file language="groovy" url="${PA_CATALOG_REST_URL}/buckets/scripts/resources/get_automl_variables/raw"/>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")
print("BEGIN " + __file__)

import json
import torch
import numpy as np

from torch import nn, optim
from torch.autograd import Variable
from torchvision import datasets, transforms

# Hyperparameters
num_classes = 10
batch_size = 32
num_epochs = int(variables.get("NUM_EPOCHS"))

############################# AUTOML SETTINGS #############################
# SEARCH_SPACE:
# [{"MODEL": "arch1", 
# "CONV": choice([
#   "nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1)",
#   "nn.Conv2d(1, 4, kernel_size=5, stride=1, padding=2)"]),
# "ACTIVATION": choice([
#   "nn.ReLU(inplace=True)",
#   "nn.ReLU6(inplace=True)",
#   "nn.SELU(inplace=True)"]),
# "POOLING": choice([
#   "nn.MaxPool2d(kernel_size=2, stride=2)",
#   "nn.MaxPool2d(2, stride=2)"]),
# "NORMALIZATION": choice([
#   "nn.BatchNorm2d(4)",
#   "nn.InstanceNorm2d(100)"]),
# "CONV2": choice([
#   "nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1)",
#   "nn.Conv2d(4, 4, kernel_size=5, stride=1, padding=2)"]),
# "ACTIVATION2": choice([
#   "nn.ReLU(inplace=True)",
#   "nn.ReLU6(inplace=True)",
#   "nn.SELU(inplace=True)"]),
# "POOLING2": choice([
#   "nn.MaxPool2d(kernel_size=2, stride=2)",
#   "nn.MaxPool2d(2, stride=2)"]),
# "NORMALIZATION2": choice([
#   "nn.BatchNorm2d(4)",
#   "nn.InstanceNorm2d(100)"]),
# "CRITERION": choice([
#   "nn.CrossEntropyLoss()"]),
# "OPTIMIZER": choice([
#   "optim.Adam(model.parameters(), lr=0.01)",
#   "optim.Adadelta(model.parameters(), lr=0.01)",
#   "optim.RMSprop(model.parameters(), lr=0.01)"])},
# {"MODEL": "arch2",                     
# "CONV": choice([
#   "nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1)",
#   "nn.Conv2d(1, 4, kernel_size=5, stride=1, padding=2)"]),
# "DROPOUT": choice([
#   "nn.AlphaDropout()",
#   "nn.Dropout()"]),
# "ACTIVATION": choice([
#   "nn.ReLU(inplace=True)",
#   "nn.ReLU6(inplace=True)",
#   "nn.SELU(inplace=True)"]),
# "POOLING": choice([
#   "nn.MaxPool2d(kernel_size=2, stride=2)",
#   "nn.MaxPool2d(2, stride=2)"]),
# "NORMALIZATION": choice([
#   "nn.BatchNorm2d(4)",
#   "nn.InstanceNorm2d(100)"]),
# "CONV2": choice([
#   "nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1)",
#   "nn.Conv2d(4, 4, kernel_size=5, stride=1, padding=2)"]),
# "DROPOUT2": choice([
#   "nn.AlphaDropout()",
#   "nn.Dropout()"]),
# "ACTIVATION2": choice([
#   "nn.ReLU(inplace=True)",
#   "nn.ReLU6(inplace=True)",
#   "nn.SELU(inplace=True)"]),
# "POOLING2": choice([
#   "nn.MaxPool2d(kernel_size=2, stride=2)",
#   "nn.MaxPool2d(2, stride=2)"]),
# "NORMALIZATION2": choice([
#   "nn.BatchNorm2d(4)",
#   "nn.InstanceNorm2d(100)"]),
# "CRITERION": choice([
#   "nn.CrossEntropyLoss()"]),
# "OPTIMIZER": choice([
#   "optim.Adam(model.parameters(), lr=0.01)",
#   "optim.Adadelta(model.parameters(), lr=0.01)",
#   "optim.RMSprop(model.parameters(), lr=0.01)"])}]

CONV = str(variables.get("CONV"))
ACTIVATION = str(variables.get("ACTIVATION"))
POOLING = str(variables.get("POOLING"))
NORMALIZATION = str(variables.get("NORMALIZATION"))
CONV2 = str(variables.get("CONV2"))
ACTIVATION2 = str(variables.get("ACTIVATION2"))
POOLING2 = str(variables.get("POOLING2"))
NORMALIZATION2 = str(variables.get("NORMALIZATION2"))
CRITERION = str(variables.get("CRITERION"))
OPTIMIZER = str(variables.get("OPTIMIZER"))
MODEL = str(variables.get("MODEL"))
TENSORBOARD_ENABLED = variables.get("TENSORBOARD_ENABLED")

if MODEL == 'arch2':
    DROPOUT = str(variables.get("DROPOUT"))
    DROPOUT2 = str(variables.get("DROPOUT2"))

input_variables = variables.get("INPUT_VARIABLES")
if input_variables is not None and input_variables != '':
    input_variables = json.loads(input_variables)
    CONV = input_variables["CONV"]
    ACTIVATION = input_variables["ACTIVATION"]
    POOLING = input_variables["POOLING"]
    NORMALIZATION = input_variables["NORMALIZATION"]
    CONV2 = input_variables["CONV2"]
    ACTIVATION2 = input_variables["ACTIVATION2"]
    POOLING2 = input_variables["POOLING2"]
    NORMALIZATION2 = input_variables["NORMALIZATION2"]
    CRITERION = input_variables["CRITERION"]
    OPTIMIZER = input_variables["OPTIMIZER"]
    MODEL = input_variables["MODEL"]

    if MODEL == 'arch2':
        DROPOUT = input_variables["DROPOUT"]
        DROPOUT2 = input_variables["DROPOUT2"]
###########################################################################

# Get current job ID
PA_JOB_ID = variables.get("PA_JOB_ID")

# Check parent job ID
PARENT_JOB_ID = genericInformation.get('PARENT_JOB_ID')

############################## BEGIN VISDOM ###############################
VISDOM_ENABLED = variables.get("VISDOM_ENABLED")
VISDOM_ENDPOINT = variables.get("VISDOM_ENDPOINT")

if VISDOM_ENABLED is not None and VISDOM_ENABLED.lower() == "true":
    VISDOM_ENABLED = True
else:
    VISDOM_ENABLED = False

if VISDOM_ENABLED is True and VISDOM_ENDPOINT is not None:
    from visdom import Visdom

    VISDOM_ENDPOINT = VISDOM_ENDPOINT.replace("http://", "")
    print("VISDOM_ENDPOINT: ", VISDOM_ENDPOINT)
    (VISDOM_HOST, VISDOM_PORT) = VISDOM_ENDPOINT.split(":")

    print("VISDOM_HOST: ", VISDOM_HOST)
    print("VISDOM_PORT: ", VISDOM_PORT)

    print("Connecting to %s:%s" % (VISDOM_HOST, VISDOM_PORT))
    vis = Visdom(server="http://" + VISDOM_HOST, port=int(VISDOM_PORT))
    assert vis.check_connection()

env = 'main'
if PARENT_JOB_ID is not None:
    env = 'job_id_' + PARENT_JOB_ID
###########################################################################

print('-' * 30)
print('MODEL:', MODEL)
print('CONV:', CONV)
print('ACTIVATION:', ACTIVATION)
print('POOLING:', POOLING)
print('NORMALIZATION:', NORMALIZATION)
print('CONV2:', CONV)
print('ACTIVATION2:', ACTIVATION)
print('POOLING2:', POOLING)
print('NORMALIZATION2:', NORMALIZATION)
print('CRITERION:', CRITERION)
print('OPTIMIZER:', OPTIMIZER)
if MODEL == 'arch2':
    print('DROPOUT :', DROPOUT)
    print('DROPOUT2:', DROPOUT2)
print('-' * 30)

# transformations to be applied on images
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)), ])

# defining the training and testing set
trainset = datasets.MNIST('./data', download=True, train=True, transform=transform)
testset = datasets.MNIST('./', download=True, train=False, transform=transform)

# defining trainloader and testloader
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)

# shape of training data
dataiter = iter(trainloader)
images, labels = dataiter.next()

# defining the model architecture
if MODEL == 'arch1':
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()

            self.cnn_layers = nn.Sequential(
                # Defining a 2D convolution layer
                eval(CONV),
                eval(NORMALIZATION),
                eval(ACTIVATION),
                eval(POOLING),
                # Defining another 2D convolution layer
                eval(CONV2),
                eval(NORMALIZATION2),
                eval(ACTIVATION2),
                eval(POOLING2),
            )

            self.linear_layers = nn.Sequential(
                nn.Linear(4 * 7 * 7, num_classes)
            )

        # Defining the forward pass
        def forward(self, x):
            x = self.cnn_layers(x)
            x = x.view(x.size(0), -1)
            x = self.linear_layers(x)
            return x
else:
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()

            self.cnn_layers = nn.Sequential(
                # Defining a 2D convolution layer
                eval(CONV),
                eval(DROPOUT),
                eval(NORMALIZATION),
                eval(ACTIVATION),
                eval(POOLING),
                # Defining another 2D convolution layer
                eval(CONV2),
                eval(DROPOUT2),
                eval(NORMALIZATION2),
                eval(ACTIVATION2),
                eval(POOLING2),
            )

            self.linear_layers = nn.Sequential(
                nn.Linear(4 * 7 * 7, num_classes)
            )

        # Defining the forward pass
        def forward(self, x):
            x = self.cnn_layers(x)
            x = x.view(x.size(0), -1)
            x = self.linear_layers(x)
            return x

# defining the model
model = Net()
# defining the optimizer
optimizer = eval(OPTIMIZER)
# defining the loss function
criterion = eval(CRITERION)
# checking if GPU is available

# Returns a bool indicating if CUDA is currently available.
use_gpu = torch.cuda.is_available()

if use_gpu:
    model = model.cuda()
    criterion = criterion.cuda()

print(model)

# training model
for i in range(num_epochs):
    running_loss = 0
    for data in trainloader:

        # get the inputs
        inputs, labels = data

        # wrap them in Variable
        if use_gpu:
            inputs = Variable(inputs.cuda())
            labels = Variable(labels.cuda())
        else:
            inputs, labels = Variable(inputs), Variable(labels)

        # Training pass
        optimizer.zero_grad()

        # forward
        outputs = model(inputs)
        _, preds = torch.max(outputs.data, 1)
        loss = criterion(outputs, labels)

        # This is where the model learns by backpropagating
        loss.backward()

        # And optimizes its weights here
        optimizer.step()

        # statistics
        running_loss += loss.item()
        # running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(trainloader)
        # epoch_acc = running_corrects.item() / len(trainloader)

    else:
        print("Epoch {} - Training loss: {:.4f}".format(i + 1, epoch_loss))

        ############################## BEGIN VISDOM ###############################
        if VISDOM_ENABLED is True:
            # Line plot
            win_gloss = 'win_gloss_' + str(PA_JOB_ID)
            update = 'append' if vis.win_exists(win_gloss, env=env) else None
            vis.line(Y=np.array([i]), X=np.array([epoch_loss]), env=env, win=win_gloss, update=update)
        ###########################################################################

# getting predictions on test set and measuring the performance
correct_count, all_count = 0, 0
for images, labels in testloader:
    for i in range(len(labels)):
        if torch.cuda.is_available():
            images = images.cuda()
            labels = labels.cuda()
        img = images[i].view(1, 1, 28, 28)
        with torch.no_grad():
            logps = model(img)

        ps = torch.exp(logps)
        probab = list(ps.cpu()[0])
        pred_label = probab.index(max(probab))
        true_label = labels.cpu()[i]
        if true_label == pred_label:
            correct_count += 1
        all_count += 1

print("Number of tested images: ", all_count)
print("Model accuracy:", (correct_count / all_count))

# Score trained model
acc = (correct_count / all_count)
loss = 1 - acc
loss = float("{:.4f}".format(loss))
print("Test loss: {:.4f}".format(loss))
print("Test accuracy: {:.4f}".format(acc))

############################# AUTOML SETTINGS #############################
# """
token = variables.get("TOKEN")
# Convert from JSON to dict
token = json.loads(token)

# Return the loss value
result_map = {'token': token, 'loss': loss}
print('result_map: ', result_map)

resultMap.put("RESULT_JSON", json.dumps(result_map))

# To appear in Job Analytics
resultMap.put("LOSS", str(loss))
resultMap.put("ACCURACY", str(acc))
# """
###########################################################################

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"/>
      <metadata>
        <positionTop>
            202.0880584716797
        </positionTop>
        <positionLeft>
            152.54257202148438
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2603px;
            height:2665px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-197.0880584716797px;left:-147.54257202148438px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_1" style="top: 202.088px; left: 152.543px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Train a simple deep CNN on the MNIST dataset using the Pytorch library."><img src="/automation-dashboard/styles/patterns/img/wf-icons/pytorch-logo-dark.png" width="20px">&nbsp;<span class="name">Handwritten_Digit_Classification</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 232px; top: 232px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>
