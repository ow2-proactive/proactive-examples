<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"  name="Data_Fusion_And_Encoding" projectName="5. Data Analytics" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2" >
  <variables>
    <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ Fuse different data structures ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="machine-learning-workflows"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data_analytics.png"/>
    <info name="Documentation" value="MLOS/MLOSUserGuide.html#_import_data"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Import_LCL" >
      <description>
        <![CDATA[ Load data from external sources. ]]>
      </description>
      <variables>
        <variable name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/MAC000002-3.csv" inherited="false" />
        <variable name="FILE_DELIMITER" value="," inherited="false" />
        <variable name="IS_LABELED_DATA" value="False" inherited="false" model="PA:Boolean"/>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="RENAME_COLUMNS" value="LCLid, stdorToU, DateTime, KWH_hh, Acorn, Acorn_grouped" inherited="false" />
        <variable name="ENCODE_COLUMNS" value="LCLid, stdorToU, Acorn, Acorn_grouped" inherited="false" />
        <variable name="LIMIT_OUTPUT_VIEW" value="5" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_import_data"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
RENAME_COLUMNS = variables.get("RENAME_COLUMNS")
FILTER_COLUMNS = variables.get("FILTER_COLUMNS")
ENCODE_COLUMNS = variables.get("ENCODE_COLUMNS")

assert FILE_URL is not None
assert FILE_DELIMITER is not None

dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)

if RENAME_COLUMNS is not None:
  RENAME_COLUMNS = [x.strip() for x in RENAME_COLUMNS.split(',')]
  dataframe.columns = RENAME_COLUMNS

if FILTER_COLUMNS is not None:
  FILTER_COLUMNS = [x.strip() for x in FILTER_COLUMNS.split(',')]
  dataframe = dataframe.filter(items=FILTER_COLUMNS)

if ENCODE_COLUMNS is not None:
  ENCODE_COLUMNS = [x.strip() for x in ENCODE_COLUMNS.split(',')]
  map_struct = {}
  for col in ENCODE_COLUMNS:
    unique_vector = dataframe[col].unique()
    LE = LabelEncoder()
    LE.fit(unique_vector)
    enc_values = LE.transform(unique_vector)
    enc_map = dict(zip(unique_vector, enc_values))
    dataframe[col] = dataframe[col].map(enc_map)
    map_struct[col] = enc_map
  print(map_struct)

# Format columns
dataframe['KWH_hh'] = dataframe['KWH_hh'].replace('Null', 0)
dataframe['KWH_hh'] = dataframe.KWH_hh.astype(float)
#dataframe['DateTime'] = dataframe['DateTime'].astype('datetime64[ns]')

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
variables.put("COLUMNS_NAME_LCL__JSON", COLUMNS_NAME_JSON)

DATAFRAME_JSON = dataframe.to_json(orient='split')
variables.put("DATAFRAME_LCL_JSON", DATAFRAME_JSON)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
    <task name="Import_Holidays" >
      <description>
        <![CDATA[ Load data from external sources. ]]>
      </description>
      <variables>
        <variable name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/holidays.csv" inherited="false" />
        <variable name="FILE_DELIMITER" value="," inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="RENAME_COLUMNS" value="Date, Description" inherited="false" />
        <variable name="FILTER_COLUMNS" value="Date, Description" inherited="false" />
        <variable name="LIMIT_OUTPUT_VIEW" value="5" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_import_data"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
RENAME_COLUMNS = variables.get("RENAME_COLUMNS")
FILTER_COLUMNS = variables.get("FILTER_COLUMNS")
ENCODE_COLUMNS = variables.get("ENCODE_COLUMNS")

assert FILE_URL is not None
assert FILE_DELIMITER is not None

dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)

if RENAME_COLUMNS is not None:
  RENAME_COLUMNS = [x.strip() for x in RENAME_COLUMNS.split(',')]
  dataframe.columns = RENAME_COLUMNS

if FILTER_COLUMNS is not None:
  FILTER_COLUMNS = [x.strip() for x in FILTER_COLUMNS.split(',')]
  dataframe = dataframe.filter(items=FILTER_COLUMNS)

if ENCODE_COLUMNS is not None:
  ENCODE_COLUMNS = [x.strip() for x in ENCODE_COLUMNS.split(',')]
  map_struct = {}
  for col in ENCODE_COLUMNS:
    unique_vector = dataframe[col].unique()
    LE = LabelEncoder()
    LE.fit(unique_vector)
    enc_values = LE.transform(unique_vector)
    enc_map = dict(zip(unique_vector, enc_values))
    dataframe[col] = dataframe[col].map(enc_map)
    map_struct[col] = enc_map
  print(map_struct)

# Format columns
dataframe['Date'] = dataframe['Date'].astype('datetime64[ns]')
dataframe.set_index('Date', inplace=True)

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATAFRAME_JSON = dataframe.to_json(orient='split')

variables.put("COLUMNS_NAME_HOLIDAY_JSON", COLUMNS_NAME_JSON)
variables.put("DATAFRAME_HOLIDAY_JSON", DATAFRAME_JSON)


LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
    <task name="Import_Tariffs" >
      <description>
        <![CDATA[ Load data from external sources. ]]>
      </description>
      <variables>
        <variable name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/tariffs.csv" inherited="false" />
        <variable name="FILE_DELIMITER" value="," inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="RENAME_COLUMNS" value="DateTime, Tariff" inherited="false" />
        <variable name="ENCODE_COLUMNS" value="Tariff" inherited="false" />
        <variable name="LIMIT_OUTPUT_VIEW" value="5" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_import_data"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
RENAME_COLUMNS = variables.get("RENAME_COLUMNS")
FILTER_COLUMNS = variables.get("FILTER_COLUMNS")
ENCODE_COLUMNS = variables.get("ENCODE_COLUMNS")

assert FILE_URL is not None
assert FILE_DELIMITER is not None

dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)

if RENAME_COLUMNS is not None:
  RENAME_COLUMNS = [x.strip() for x in RENAME_COLUMNS.split(',')]
  dataframe.columns = RENAME_COLUMNS

if FILTER_COLUMNS is not None:
  FILTER_COLUMNS = [x.strip() for x in FILTER_COLUMNS.split(',')]
  dataframe = dataframe.filter(items=FILTER_COLUMNS)

if ENCODE_COLUMNS is not None:
  ENCODE_COLUMNS = [x.strip() for x in ENCODE_COLUMNS.split(',')]
  map_struct = {}
  for col in ENCODE_COLUMNS:
    unique_vector = dataframe[col].unique()
    LE = LabelEncoder()
    LE.fit(unique_vector)
    enc_values = LE.transform(unique_vector)
    enc_map = dict(zip(unique_vector, enc_values))
    dataframe[col] = dataframe[col].map(enc_map)
    map_struct[col] = enc_map
  print(map_struct)

# Format columns
dataframe['DateTime'] = pd.to_datetime(dataframe['DateTime'], format='%m/%d/%y %H:%M')
dataframe['DateTime'] = dataframe['DateTime'].astype('datetime64[ns]')
dataframe.set_index('DateTime', inplace=True)

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
variables.put("COLUMNS_NAME_TARIFFS_JSON", COLUMNS_NAME_JSON)

DATAFRAME_JSON = dataframe.to_json(orient='split')
variables.put("DATAFRAME_TARIFFS_JSON", DATAFRAME_JSON)


LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
    <task name="Data_Fusion" >
      <description>
        <![CDATA[ Performs data fusion. ]]>
      </description>
      <variables>
        <variable name="OUTPUT_FORMAT" value="HTML" inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="IS_LABELED_DATA" value="False" inherited="false" model="PA:Boolean"/>
        <variable name="LIMIT_OUTPUT_VIEW" value="5" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/filled_filter.png"/>
        <info name="task.documentation" value="MLOS/MLOSUserGuide.html#_filter_data"/>
      </genericInformation>
      <depends>
        <task ref="Import_LCL"/>
        <task ref="Import_Holidays"/>
        <task ref="Import_Tariffs"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

DATAFRAME_LCL_JSON     = variables.get("DATAFRAME_LCL_JSON")
DATAFRAME_HOLIDAY_JSON = variables.get("DATAFRAME_HOLIDAY_JSON")
DATAFRAME_TARIFFS_JSON = variables.get("DATAFRAME_TARIFFS_JSON")
IS_LABELED_DATA        = variables.get("IS_LABELED_DATA")
OUTPUT_FORMAT          = variables.get("OUTPUT_FORMAT")

assert DATAFRAME_LCL_JSON is not None
assert DATAFRAME_HOLIDAY_JSON is not None
assert DATAFRAME_TARIFFS_JSON is not None
assert OUTPUT_FORMAT is not None

dataframe = pd.read_json(DATAFRAME_LCL_JSON, orient='split')
dataframe_holiday = pd.read_json(DATAFRAME_HOLIDAY_JSON, orient='split')
dataframe_tariffs = pd.read_json(DATAFRAME_TARIFFS_JSON, orient='split')

# Fuse holidays
dataframe['Holiday'] = 0
for holiday_date in dataframe_holiday.index:
    dataframe.loc[dataframe['DateTime'].dt.strftime('%d/%m/%y') == holiday_date.strftime('%d/%m/%y'), 'Holiday'] = 1

# Fuse tariffs
dataframe['Tariff'] = np.nan
for tariff_datetime in dataframe_tariffs.index:
    tariff_value = dataframe_tariffs.loc[tariff_datetime, 'Tariff']
    dataframe.loc[dataframe['DateTime'] == tariff_datetime, 'Tariff'] = tariff_value

# Remove NaN rows (Tariff == NaN)
dataframe.dropna(inplace=True)
dataframe['Tariff'] = dataframe['Tariff'].astype(int)
dataframe.reset_index(drop=True)

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
  data  = dataframe.values[:,0:columns_number-1]
  label = dataframe.values[:,columns_number-1]
  
  data_df = pd.DataFrame(data=data, columns=columns_name[0:columns_number-1])
  label_df = pd.DataFrame(data=label, columns=[columns_name[columns_number-1]])
  
  LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
  LABEL_TEST_DF_JSON = label_df.to_json(orient='split')
  
  variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
  variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)

else:
  data = dataframe.values
  data_df = pd.DataFrame(data=data, columns=columns_name)

DATAFRAME_JSON = dataframe.to_json(orient='split')
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
DATA_TEST_DF_JSON = data_df.to_json(orient='split')

variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)


LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2854px;
            height:3444px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-417.5px;left:-500px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_221" style="top: 422.5px; left: 505px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_LCL</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_224" style="top: 422.5px; left: 646.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_Holidays</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_227" style="top: 422.5px; left: 788px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_Tariffs</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_ active-task" id="jsPlumb_1_230" style="top: 550.5px; left: 646.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/filled_filter.png" width="20px">&nbsp;<span class="name">Data_Fusion</span></a></div><svg style="position:absolute;left:544.5px;top:462.5px" width="163" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 142 88 C 152 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M123.436007,60.59109050000001 L107.92407127644917,46.1557224718399 L110.61193557604916,54.97475787867073 L102.30773865511988,58.97979389579074 L123.436007,60.59109050000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M123.436007,60.59109050000001 L107.92407127644917,46.1557224718399 L110.61193557604916,54.97475787867073 L102.30773865511988,58.97979389579074 L123.436007,60.59109050000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:686.5px;top:462.5px" width="24.5" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 13.5 50 3.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.531265625,66.78168750000002 L5.922688671570663,47.35153935976458 L-1.5001906020674536,52.819707543808825 L-8.03929128462053,46.32046433683204 L-2.531265625,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-2.531265625,66.78168750000002 L5.922688671570663,47.35153935976458 L-1.5001906020674536,52.819707543808825 L-8.03929128462053,46.32046433683204 L-2.531265625,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:686.5px;top:462.5px" width="162" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 151 50 141 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M18.413330249999998,60.59109050000001 L39.537473516545795,58.92658719437167 L31.223216198065135,54.94247810423737 L33.888861120783154,46.116701246306526 L18.413330249999998,60.59109050000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M18.413330249999998,60.59109050000001 L39.537473516545795,58.92658719437167 L31.223216198065135,54.94247810423737 L33.888861120783154,46.116701246306526 L18.413330249999998,60.59109050000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 545px; top: 453px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 690.5px; top: 453px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 828px; top: 453px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 687px; top: 581px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 687px; top: 541px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>