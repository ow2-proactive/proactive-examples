<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"  name="Parallel_Classification_Model_Training" projectName="1. Basic Machine Learning" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2" >
  <variables>
    <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ Train three different classification models. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="machine-learning-workflows"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/machine_learning.png"/>
    <info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_import_data"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Import_Data" >
      <description>
        <![CDATA[ Load data from external sources. ]]>
      </description>
      <variables>
        <variable name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/datasets/pima-indians-diabetes.csv" inherited="false" />
        <variable name="FILE_DELIMITER" value=";" inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
        <variable name="LIMIT_OUTPUT_VIEW" value="5" inherited="false" model="PA:Integer"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_import_data"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid
import pandas as pd
import numpy as np

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")

assert FILE_URL is not None and FILE_URL is not ""
assert FILE_DELIMITER is not None and FILE_DELIMITER is not ""

FILE_URL = variables.get(FILE_URL[1:]) if FILE_URL.startswith("$") else FILE_URL
dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id: ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)

LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
            </code>
          </script>
        </scriptExecutable>
        <controlFlow block="none"></controlFlow>
      </task>
      <task name="Split_Data" >
        <description>
          <![CDATA[ Separate data into training and testing sets. ]]>
        </description>
        <variables>
          <variable name="TRAIN_SIZE" value="0.7" inherited="false" />
          <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
          <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
          <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
        </variables>
        <genericInformation>
          <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png"/>
          <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_split_data"/>
        </genericInformation>
        <depends>
          <task ref="Import_Data"/>
        </depends>
        <forkEnvironment javaHome="/usr" >
          <envScript>
            <script>
              <code language="python">
                <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
              </code>
            </script>
          </envScript>
        </forkEnvironment>
        <scriptExecutable>
          <script>
            <code language="cpython">
              <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split

TRAIN_SIZE = variables.get("TRAIN_SIZE")
assert TRAIN_SIZE is not None and TRAIN_SIZE is not ""
TRAIN_SIZE = float(TRAIN_SIZE)
test_size = 1 - TRAIN_SIZE

input_variables = {'task.dataframe_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = input_variables['task.dataframe_id']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

# Split dataframe into train/test sets
X_train, X_test = train_test_split(dataframe, test_size=test_size)

dataframe1 = X_train.reset_index(drop=True)
dataframe2 = X_test.reset_index(drop=True)

dataframe_json1 = dataframe1.to_json(orient='split').encode()
dataframe_json2 = dataframe2.to_json(orient='split').encode()

compressed_data1 = bz2.compress(dataframe_json1)
compressed_data2 = bz2.compress(dataframe_json2)

dataframe_id1 = str(uuid.uuid4())
dataframe_id2 = str(uuid.uuid4())

variables.put(dataframe_id1, compressed_data1)
variables.put(dataframe_id2, compressed_data2)

print("Train set:")
print("dataframe id1 (out): ", dataframe_id1)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json1), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data1), " bytes")
print(dataframe1.head())

print("Test set:")
print("dataframe id2 (out): ", dataframe_id2)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json2), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data2), " bytes")
print(dataframe2.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id_train", dataframe_id1)
resultMetadata.put("task.dataframe_id_test", dataframe_id2)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
              </code>
            </script>
          </scriptExecutable>
          <controlFlow block="none"></controlFlow>
        </task>
        <task name="Train_Model1" >
          <description>
            <![CDATA[ Train a model using a classification or regression algorithm. ]]>
          </description>
          <variables>
            <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
            <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
            <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
            <variable name="LABEL_COLUMN" value="class" inherited="false" />
          </variables>
          <genericInformation>
            <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
            <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_train_model"/>
          </genericInformation>
          <depends>
            <task ref="Split_Data"/>
            <task ref="Logistic_Regression"/>
          </depends>
          <forkEnvironment javaHome="/usr" >
            <envScript>
              <script>
                <code language="python">
                  <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                </code>
              </script>
            </envScript>
          </forkEnvironment>
          <scriptExecutable>
            <script>
              <code language="cpython">
                <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid, json
import random, pickle
import pandas as pd

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_train': None,
  'task.algorithm_json': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_train'] is not None:
  dataframe_id = input_variables['task.dataframe_id_train']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()
dataframe = pd.read_json(dataframe_json, orient='split')

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

if alg.is_supervised and is_labeled_data:
  model = None
  columns = [LABEL_COLUMN]
  dataframe_train = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  #-------------------------------------------------------------
  # Classification algorithms
  #
  if alg.name == 'SupportVectorMachines':
    from sklearn.svm import SVC
    model = SVC(
      C=alg.C, 
      kernel=alg.kernel
    )
   
  if alg.name == 'GaussianNaiveBayes':
    from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()
  
  if alg.name == 'LogisticRegression':
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(
      penalty=alg.penalty, 
      solver=alg.solver, 
      max_iter=alg.max_iter, 
      n_jobs=alg.n_jobs
    )

  #-------------------------------------------------------------
  # Regression algorithms
  if alg.name == 'LinearRegression':
    from sklearn.linear_model import LinearRegression
    model = LinearRegression(n_jobs=alg.n_jobs)

  if alg.name == 'SupportVectorRegression':
    from sklearn.svm import SVR
    model = SVR(
      C=alg.C, 
      kernel=alg.kernel, 
      epsilon=alg.epsilon
    )
  
  if alg.name == 'BayesianRidgeRegression':
    from sklearn.linear_model import BayesianRidge
    model = BayesianRidge(
      alpha_1=alg.alpha_1, 
      alpha_2=alg.alpha_2, 
      lambda_1=alg.lambda_1, 
      lambda_2=alg.lambda_2, 
      n_iter=alg.n_iter
    )
  #-------------------------------------------------------------

  if model is not None:
    model.fit(dataframe_train.values, dataframe_label.values.ravel())
    model_bin = pickle.dumps(model)
    model_compressed = bz2.compress(model_bin)
    model_id = str(uuid.uuid4())
    variables.put(model_id, model_compressed)
    print("model id: ", model_id)
    print('model size (original):   ', sys.getsizeof(model_bin), " bytes")
    print('model size (compressed): ', sys.getsizeof(model_compressed), " bytes")
    resultMetadata.put("task.model_id", model_id)
  else:
    print("Algorithm not found!")
else:
  print("The algorithm must be supervised and the dataframe must be labelled!")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.dataframe_id", dataframe_id)
resultMetadata.put("task.algorithm_json", algorithm_json)
resultMetadata.put("task.label_column", LABEL_COLUMN)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                </code>
              </script>
            </scriptExecutable>
            <controlFlow block="none"></controlFlow>
          </task>
          <task name="Train_Model2" >
            <description>
              <![CDATA[ Train a model using a classification or regression algorithm. ]]>
            </description>
            <variables>
              <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
              <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
              <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
              <variable name="LABEL_COLUMN" value="class" inherited="false" />
            </variables>
            <genericInformation>
              <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
              <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_train_model"/>
            </genericInformation>
            <depends>
              <task ref="Split_Data"/>
              <task ref="Gaussian_Naive_Bayes"/>
            </depends>
            <forkEnvironment javaHome="/usr" >
              <envScript>
                <script>
                  <code language="python">
                    <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                  </code>
                </script>
              </envScript>
            </forkEnvironment>
            <scriptExecutable>
              <script>
                <code language="cpython">
                  <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid, json
import random, pickle
import pandas as pd

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_train': None,
  'task.algorithm_json': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_train'] is not None:
  dataframe_id = input_variables['task.dataframe_id_train']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()
dataframe = pd.read_json(dataframe_json, orient='split')

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

if alg.is_supervised and is_labeled_data:
  model = None
  columns = [LABEL_COLUMN]
  dataframe_train = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  #-------------------------------------------------------------
  # Classification algorithms
  #
  if alg.name == 'SupportVectorMachines':
    from sklearn.svm import SVC
    model = SVC(
      C=alg.C, 
      kernel=alg.kernel
    )
   
  if alg.name == 'GaussianNaiveBayes':
    from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()
  
  if alg.name == 'LogisticRegression':
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(
      penalty=alg.penalty, 
      solver=alg.solver, 
      max_iter=alg.max_iter, 
      n_jobs=alg.n_jobs
    )

  #-------------------------------------------------------------
  # Regression algorithms
  if alg.name == 'LinearRegression':
    from sklearn.linear_model import LinearRegression
    model = LinearRegression(n_jobs=alg.n_jobs)

  if alg.name == 'SupportVectorRegression':
    from sklearn.svm import SVR
    model = SVR(
      C=alg.C, 
      kernel=alg.kernel, 
      epsilon=alg.epsilon
    )
  
  if alg.name == 'BayesianRidgeRegression':
    from sklearn.linear_model import BayesianRidge
    model = BayesianRidge(
      alpha_1=alg.alpha_1, 
      alpha_2=alg.alpha_2, 
      lambda_1=alg.lambda_1, 
      lambda_2=alg.lambda_2, 
      n_iter=alg.n_iter
    )
  #-------------------------------------------------------------

  if model is not None:
    model.fit(dataframe_train.values, dataframe_label.values.ravel())
    model_bin = pickle.dumps(model)
    model_compressed = bz2.compress(model_bin)
    model_id = str(uuid.uuid4())
    variables.put(model_id, model_compressed)
    print("model id: ", model_id)
    print('model size (original):   ', sys.getsizeof(model_bin), " bytes")
    print('model size (compressed): ', sys.getsizeof(model_compressed), " bytes")
    resultMetadata.put("task.model_id", model_id)
  else:
    print("Algorithm not found!")
else:
  print("The algorithm must be supervised and the dataframe must be labelled!")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.dataframe_id", dataframe_id)
resultMetadata.put("task.algorithm_json", algorithm_json)
resultMetadata.put("task.label_column", LABEL_COLUMN)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                  </code>
                </script>
              </scriptExecutable>
              <controlFlow block="none"></controlFlow>
            </task>
            <task name="Train_Model3" >
              <description>
                <![CDATA[ Train a model using a classification or regression algorithm. ]]>
              </description>
              <variables>
                <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                <variable name="LABEL_COLUMN" value="class" inherited="false" />
              </variables>
              <genericInformation>
                <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
                <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_train_model"/>
              </genericInformation>
              <depends>
                <task ref="Split_Data"/>
                <task ref="Support_Vector_Machines"/>
              </depends>
              <forkEnvironment javaHome="/usr" >
                <envScript>
                  <script>
                    <code language="python">
                      <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                    </code>
                  </script>
                </envScript>
              </forkEnvironment>
              <scriptExecutable>
                <script>
                  <code language="cpython">
                    <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid, json
import random, pickle
import pandas as pd

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_train': None,
  'task.algorithm_json': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_train'] is not None:
  dataframe_id = input_variables['task.dataframe_id_train']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()
dataframe = pd.read_json(dataframe_json, orient='split')

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

if alg.is_supervised and is_labeled_data:
  model = None
  columns = [LABEL_COLUMN]
  dataframe_train = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  #-------------------------------------------------------------
  # Classification algorithms
  #
  if alg.name == 'SupportVectorMachines':
    from sklearn.svm import SVC
    model = SVC(
      C=alg.C, 
      kernel=alg.kernel
    )
   
  if alg.name == 'GaussianNaiveBayes':
    from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()
  
  if alg.name == 'LogisticRegression':
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(
      penalty=alg.penalty, 
      solver=alg.solver, 
      max_iter=alg.max_iter, 
      n_jobs=alg.n_jobs
    )

  #-------------------------------------------------------------
  # Regression algorithms
  if alg.name == 'LinearRegression':
    from sklearn.linear_model import LinearRegression
    model = LinearRegression(n_jobs=alg.n_jobs)

  if alg.name == 'SupportVectorRegression':
    from sklearn.svm import SVR
    model = SVR(
      C=alg.C, 
      kernel=alg.kernel, 
      epsilon=alg.epsilon
    )
  
  if alg.name == 'BayesianRidgeRegression':
    from sklearn.linear_model import BayesianRidge
    model = BayesianRidge(
      alpha_1=alg.alpha_1, 
      alpha_2=alg.alpha_2, 
      lambda_1=alg.lambda_1, 
      lambda_2=alg.lambda_2, 
      n_iter=alg.n_iter
    )
  #-------------------------------------------------------------

  if model is not None:
    model.fit(dataframe_train.values, dataframe_label.values.ravel())
    model_bin = pickle.dumps(model)
    model_compressed = bz2.compress(model_bin)
    model_id = str(uuid.uuid4())
    variables.put(model_id, model_compressed)
    print("model id: ", model_id)
    print('model size (original):   ', sys.getsizeof(model_bin), " bytes")
    print('model size (compressed): ', sys.getsizeof(model_compressed), " bytes")
    resultMetadata.put("task.model_id", model_id)
  else:
    print("Algorithm not found!")
else:
  print("The algorithm must be supervised and the dataframe must be labelled!")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.dataframe_id", dataframe_id)
resultMetadata.put("task.algorithm_json", algorithm_json)
resultMetadata.put("task.label_column", LABEL_COLUMN)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                    </code>
                  </script>
                </scriptExecutable>
                <controlFlow block="none"></controlFlow>
              </task>
              <task name="Predict_Model1" >
                <description>
                  <![CDATA[ Generate predictions using a trained model. ]]>
                </description>
                <variables>
                  <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                  <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                  <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                  <variable name="LABEL_COLUMN" value="" inherited="false" />
                </variables>
                <genericInformation>
                  <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/predict.png"/>
                  <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_predict_model"/>
                </genericInformation>
                <depends>
                  <task ref="Train_Model1"/>
                  <task ref="Split_Data"/>
                </depends>
                <forkEnvironment javaHome="/usr" >
                  <envScript>
                    <script>
                      <code language="python">
                        <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                      </code>
                    </script>
                  </envScript>
                </forkEnvironment>
                <scriptExecutable>
                  <script>
                    <code language="cpython">
                      <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2, uuid, json
import random, pickle, sklearn
import numpy as np
import pandas as pd

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_test': None,
  'task.algorithm_json': None,
  'task.label_column': None,
  'task.model_id': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_test'] is not None:
  dataframe_id = input_variables['task.dataframe_id_test']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True
else:
  LABEL_COLUMN = input_variables['task.label_column']
  if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
    is_labeled_data = True

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None
print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

dataframe_predictions = None
if alg.is_supervised and is_labeled_data:
  columns = [LABEL_COLUMN]
  dataframe_test = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  loaded_model = pickle.loads(model_bin)
  score = loaded_model.score(dataframe_test.values, dataframe_label.values.ravel())
  predictions = list(loaded_model.predict(dataframe_test.values))

  dataframe_predictions = pd.DataFrame(predictions)
  dataframe = dataframe.assign(predictions=dataframe_predictions)
  
  print("MODEL SCORE: %.2f" % score)

  #-------------------------------------------------------------
  # CLASSIFICATION SCORE
  #
  if alg.type == 'classification':
    dataframe['accuracy'] = np.where((dataframe[LABEL_COLUMN] == dataframe['predictions']), 1, 0)
    accuracy_score_result = accuracy_score(dataframe_label.values.ravel(), predictions)
    precision_score_result = precision_score(dataframe_label.values.ravel(), predictions, average='micro')
    confusion_matrix_result = confusion_matrix(dataframe_label.values.ravel(), predictions)
    print("********************** CLASSIFICATION SCORE **********************")
    print("ACCURACY SCORE: %.2f" % accuracy_score_result)
    print("PRECISION SCORE: %.2f" % precision_score_result)
    print("CONFUSION MATRIX:\n%s" % confusion_matrix_result)
    print("*******************************************************************")

  #-------------------------------------------------------------
  # REGRESSION SCORE
  #
  if alg.type == 'regression':
    dataframe['absolute_error'] = dataframe[LABEL_COLUMN] - dataframe['predictions']
    mean_squared_error_result = mean_squared_error(dataframe_label.values.ravel(), predictions)
    mean_absolute_error_result = mean_absolute_error(dataframe_label.values.ravel(), predictions)
    r2_score_result = r2_score(dataframe_label.values.ravel(), predictions) 
    print("********************** REGRESSION SCORES **********************")
    print("MEAN SQUARED ERROR: %.2f" % mean_squared_error_result)
    print("MEAN ABSOLUTE ERROR: %.2f" % mean_absolute_error_result)
    print("R2 SCORE: %.2f" % r2_score_result)
    print("***************************************************************")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                      </code>
                    </script>
                  </scriptExecutable>
                  <controlFlow block="none"></controlFlow>
                </task>
                <task name="Predict_Model2" >
                  <description>
                    <![CDATA[ Generate predictions using a trained model. ]]>
                  </description>
                  <variables>
                    <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                    <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                    <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                    <variable name="LABEL_COLUMN" value="" inherited="false" />
                  </variables>
                  <genericInformation>
                    <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/predict.png"/>
                    <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_predict_model"/>
                  </genericInformation>
                  <depends>
                    <task ref="Train_Model2"/>
                    <task ref="Split_Data"/>
                  </depends>
                  <forkEnvironment javaHome="/usr" >
                    <envScript>
                      <script>
                        <code language="python">
                          <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                        </code>
                      </script>
                    </envScript>
                  </forkEnvironment>
                  <scriptExecutable>
                    <script>
                      <code language="cpython">
                        <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2, uuid, json
import random, pickle, sklearn
import numpy as np
import pandas as pd

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_test': None,
  'task.algorithm_json': None,
  'task.label_column': None,
  'task.model_id': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_test'] is not None:
  dataframe_id = input_variables['task.dataframe_id_test']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True
else:
  LABEL_COLUMN = input_variables['task.label_column']
  if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
    is_labeled_data = True

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None
print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

dataframe_predictions = None
if alg.is_supervised and is_labeled_data:
  columns = [LABEL_COLUMN]
  dataframe_test = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  loaded_model = pickle.loads(model_bin)
  score = loaded_model.score(dataframe_test.values, dataframe_label.values.ravel())
  predictions = list(loaded_model.predict(dataframe_test.values))

  dataframe_predictions = pd.DataFrame(predictions)
  dataframe = dataframe.assign(predictions=dataframe_predictions)
  
  print("MODEL SCORE: %.2f" % score)

  #-------------------------------------------------------------
  # CLASSIFICATION SCORE
  #
  if alg.type == 'classification':
    dataframe['accuracy'] = np.where((dataframe[LABEL_COLUMN] == dataframe['predictions']), 1, 0)
    accuracy_score_result = accuracy_score(dataframe_label.values.ravel(), predictions)
    precision_score_result = precision_score(dataframe_label.values.ravel(), predictions, average='micro')
    confusion_matrix_result = confusion_matrix(dataframe_label.values.ravel(), predictions)
    print("********************** CLASSIFICATION SCORE **********************")
    print("ACCURACY SCORE: %.2f" % accuracy_score_result)
    print("PRECISION SCORE: %.2f" % precision_score_result)
    print("CONFUSION MATRIX:\n%s" % confusion_matrix_result)
    print("*******************************************************************")

  #-------------------------------------------------------------
  # REGRESSION SCORE
  #
  if alg.type == 'regression':
    dataframe['absolute_error'] = dataframe[LABEL_COLUMN] - dataframe['predictions']
    mean_squared_error_result = mean_squared_error(dataframe_label.values.ravel(), predictions)
    mean_absolute_error_result = mean_absolute_error(dataframe_label.values.ravel(), predictions)
    r2_score_result = r2_score(dataframe_label.values.ravel(), predictions) 
    print("********************** REGRESSION SCORES **********************")
    print("MEAN SQUARED ERROR: %.2f" % mean_squared_error_result)
    print("MEAN ABSOLUTE ERROR: %.2f" % mean_absolute_error_result)
    print("R2 SCORE: %.2f" % r2_score_result)
    print("***************************************************************")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                        </code>
                      </script>
                    </scriptExecutable>
                    <controlFlow block="none"></controlFlow>
                  </task>
                  <task name="Predict_Model3" >
                    <description>
                      <![CDATA[ Generate predictions using a trained model. ]]>
                    </description>
                    <variables>
                      <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                      <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                      <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                      <variable name="LABEL_COLUMN" value="" inherited="false" />
                    </variables>
                    <genericInformation>
                      <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/predict.png"/>
                      <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_predict_model"/>
                    </genericInformation>
                    <depends>
                      <task ref="Train_Model3"/>
                      <task ref="Split_Data"/>
                    </depends>
                    <forkEnvironment javaHome="/usr" >
                      <envScript>
                        <script>
                          <code language="python">
                            <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                          </code>
                        </script>
                      </envScript>
                    </forkEnvironment>
                    <scriptExecutable>
                      <script>
                        <code language="cpython">
                          <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2, uuid, json
import random, pickle, sklearn
import numpy as np
import pandas as pd

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_test': None,
  'task.algorithm_json': None,
  'task.label_column': None,
  'task.model_id': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_test'] is not None:
  dataframe_id = input_variables['task.dataframe_id_test']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True
else:
  LABEL_COLUMN = input_variables['task.label_column']
  if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
    is_labeled_data = True

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None
print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

dataframe_predictions = None
if alg.is_supervised and is_labeled_data:
  columns = [LABEL_COLUMN]
  dataframe_test = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  loaded_model = pickle.loads(model_bin)
  score = loaded_model.score(dataframe_test.values, dataframe_label.values.ravel())
  predictions = list(loaded_model.predict(dataframe_test.values))

  dataframe_predictions = pd.DataFrame(predictions)
  dataframe = dataframe.assign(predictions=dataframe_predictions)
  
  print("MODEL SCORE: %.2f" % score)

  #-------------------------------------------------------------
  # CLASSIFICATION SCORE
  #
  if alg.type == 'classification':
    dataframe['accuracy'] = np.where((dataframe[LABEL_COLUMN] == dataframe['predictions']), 1, 0)
    accuracy_score_result = accuracy_score(dataframe_label.values.ravel(), predictions)
    precision_score_result = precision_score(dataframe_label.values.ravel(), predictions, average='micro')
    confusion_matrix_result = confusion_matrix(dataframe_label.values.ravel(), predictions)
    print("********************** CLASSIFICATION SCORE **********************")
    print("ACCURACY SCORE: %.2f" % accuracy_score_result)
    print("PRECISION SCORE: %.2f" % precision_score_result)
    print("CONFUSION MATRIX:\n%s" % confusion_matrix_result)
    print("*******************************************************************")

  #-------------------------------------------------------------
  # REGRESSION SCORE
  #
  if alg.type == 'regression':
    dataframe['absolute_error'] = dataframe[LABEL_COLUMN] - dataframe['predictions']
    mean_squared_error_result = mean_squared_error(dataframe_label.values.ravel(), predictions)
    mean_absolute_error_result = mean_absolute_error(dataframe_label.values.ravel(), predictions)
    r2_score_result = r2_score(dataframe_label.values.ravel(), predictions) 
    print("********************** REGRESSION SCORES **********************")
    print("MEAN SQUARED ERROR: %.2f" % mean_squared_error_result)
    print("MEAN ABSOLUTE ERROR: %.2f" % mean_absolute_error_result)
    print("R2 SCORE: %.2f" % r2_score_result)
    print("***************************************************************")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                          </code>
                        </script>
                      </scriptExecutable>
                      <controlFlow block="none"></controlFlow>
                    </task>
                    <task name="Logistic_Regression" >
                      <description>
                        <![CDATA[ Logistic Regression is a regression model where the Dependent Variable (DV) is categorical. ]]>
                      </description>
                      <variables>
                        <variable name="PENALTY" value="l2" inherited="false" />
                        <variable name="SOLVER" value="liblinear" inherited="false" />
                        <variable name="MAX_ITERATIONS" value="100" inherited="false" />
                        <variable name="N_JOBS" value="1" inherited="false" />
                        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                      </variables>
                      <genericInformation>
                        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/ml_classification.png"/>
                        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_logistic_regression"/>
                      </genericInformation>
                      <forkEnvironment javaHome="/usr" >
                        <envScript>
                          <script>
                            <code language="python">
                              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                            </code>
                          </script>
                        </envScript>
                      </forkEnvironment>
                      <scriptExecutable>
                        <script>
                          <code language="cpython">
                            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import json

algorithm = {
  'name': 'LogisticRegression',
  'is_supervised': True,
  'type': 'classification',
  'n_jobs': int(variables.get("N_JOBS")),
  'max_iter': int(variables.get("MAX_ITERATIONS")),
  'solver': variables.get("SOLVER"),
  'penalty': variables.get("PENALTY")
}

algorithm_json = json.dumps(algorithm)
resultMetadata.put("task.algorithm_json", algorithm_json)

print("END " + __file__)
]]>
                          </code>
                        </script>
                      </scriptExecutable>
                      <controlFlow block="none"></controlFlow>
                    </task>
                    <task name="Gaussian_Naive_Bayes" >
                      <description>
                        <![CDATA[ Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features. ]]>
                      </description>
                      <variables>
                        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                      </variables>
                      <genericInformation>
                        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/ml_classification.png"/>
                        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_gaussian_naive_bayes"/>
                      </genericInformation>
                      <forkEnvironment javaHome="/usr" >
                        <envScript>
                          <script>
                            <code language="python">
                              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                            </code>
                          </script>
                        </envScript>
                      </forkEnvironment>
                      <scriptExecutable>
                        <script>
                          <code language="cpython">
                            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import json

algorithm = {
  'name': 'GaussianNaiveBayes',
  'is_supervised': True,
  'type': 'classification',
}

algorithm_json = json.dumps(algorithm)
resultMetadata.put("task.algorithm_json", algorithm_json)

print("END " + __file__)
]]>
                          </code>
                        </script>
                      </scriptExecutable>
                      <controlFlow block="none"></controlFlow>
                    </task>
                    <task name="Support_Vector_Machines" >
                      <description>
                        <![CDATA[ Support vector machines are supervised learning models with associated learning algorithms that analyze data used for classification. ]]>
                      </description>
                      <variables>
                        <variable name="C" value="1.0" inherited="false" />
                        <variable name="KERNEL" value="rbf" inherited="false" />
                        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                      </variables>
                      <genericInformation>
                        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/ml_classification.png"/>
                        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_support_vector_machines"/>
                      </genericInformation>
                      <forkEnvironment javaHome="/usr" >
                        <envScript>
                          <script>
                            <code language="python">
                              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                            </code>
                          </script>
                        </envScript>
                      </forkEnvironment>
                      <scriptExecutable>
                        <script>
                          <code language="cpython">
                            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import json

algorithm = {
  'name': 'SupportVectorMachines',
  'is_supervised': True,
  'type': 'classification',
  'C': float(variables.get("C")),
  'kernel': variables.get("KERNEL")
}

algorithm_json = json.dumps(algorithm)
resultMetadata.put("task.algorithm_json", algorithm_json)

print("END " + __file__)
]]>
                          </code>
                        </script>
                      </scriptExecutable>
                      <controlFlow block="none"></controlFlow>
                    </task>
                    <task name="Preview_Results1" >
                      <description>
                        <![CDATA[ Export the results. ]]>
                      </description>
                      <variables>
                        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                        <variable name="OUTPUT_TYPE" value="HTML" inherited="false" model="PA:LIST(CSV,JSON,HTML)"/>
                        <variable name="LIMIT_OUTPUT_VIEW" value="1000" inherited="false" model="PA:Integer"/>
                      </variables>
                      <genericInformation>
                        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png"/>
                        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_export_results"/>
                      </genericInformation>
                      <depends>
                        <task ref="Predict_Model1"/>
                      </depends>
                      <forkEnvironment javaHome="/usr" >
                        <envScript>
                          <script>
                            <code language="python">
                              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                            </code>
                          </script>
                        </envScript>
                      </forkEnvironment>
                      <scriptExecutable>
                        <script>
                          <code language="cpython">
                            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import pandas as pd
import numpy as np
import bz2

OUTPUT_TYPE = variables.get("OUTPUT_TYPE")
assert OUTPUT_TYPE is not None and OUTPUT_TYPE is not ""

input_variables = {'task.dataframe_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = input_variables['task.dataframe_id']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')
print(dataframe.head())

OUTPUT_TYPE = OUTPUT_TYPE.upper()
if OUTPUT_TYPE == "S3":
  import s3fs, uuid

  UserAccessKeyID=str(variables.get('UserAccessKeyID'))
  UserSecretAccessKey=str(variables.get('UserSecretAccessKey'))
  UserBucketPath=variables.get('UserBucketPath')

  dataframe_id = str(uuid.uuid4())
  print("dataframe id (out): ", dataframe_id)
  bytes_to_write = dataframe.to_csv(index=False).encode()

  fs = s3fs.S3FileSystem(
      key=UserAccessKeyID, 
      secret=UserSecretAccessKey,
      s3_additional_kwargs={'ACL': 'public-read'}
  )

  bucket_path=str(UserBucketPath) if UserBucketPath is not None else 's3://activeeon-public/results/'
  s3file_path = bucket_path+dataframe_id+'.csv'
  with fs.open(s3file_path, 'wb') as f:
    f.write(bytes_to_write)

  dataframe_url = fs.url(s3file_path).split('?')[0]
  dataframe_info = fs.info(s3file_path)
  print("The dataframe was uploaded successfully to the following url:")
  print(dataframe_url)
  print("File info:")
  print(dataframe_info)

if OUTPUT_TYPE == "CSV":
  #result = dataframe.to_csv(encoding='utf-8', index=False)
  result = dataframe.to_csv(index=False)
  resultMetadata.put("file.extension", ".csv")
  resultMetadata.put("file.name", "dataframe.csv")
  resultMetadata.put("content.type", "text/csv")

if OUTPUT_TYPE == "JSON":
  result = dataframe.to_json(orient='split', encoding='utf-8')
  resultMetadata.put("file.extension", ".json")
  resultMetadata.put("file.name", "dataframe.json")
  resultMetadata.put("content.type", "application/json")

if OUTPUT_TYPE == "HTML":
  LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
  LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
  if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
  
  #***************# HTML PREVIEW STYLING #***************#
  styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
  ]
  #******************************************************#

  with pd.option_context('display.max_colwidth', -1):
    result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")

print("END " + __file__)
]]>
                            </code>
                          </script>
                        </scriptExecutable>
                        <controlFlow block="none"></controlFlow>
                      </task>
                      <task name="Preview_Results2" >
                        <description>
                          <![CDATA[ Export the results. ]]>
                        </description>
                        <variables>
                          <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                          <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                          <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                          <variable name="OUTPUT_TYPE" value="HTML" inherited="false" model="PA:LIST(CSV,JSON,HTML)"/>
                          <variable name="LIMIT_OUTPUT_VIEW" value="1000" inherited="false" model="PA:Integer"/>
                        </variables>
                        <genericInformation>
                          <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png"/>
                          <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_export_results"/>
                        </genericInformation>
                        <depends>
                          <task ref="Predict_Model2"/>
                        </depends>
                        <forkEnvironment javaHome="/usr" >
                          <envScript>
                            <script>
                              <code language="python">
                                <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                              </code>
                            </script>
                          </envScript>
                        </forkEnvironment>
                        <scriptExecutable>
                          <script>
                            <code language="cpython">
                              <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import pandas as pd
import numpy as np
import bz2

OUTPUT_TYPE = variables.get("OUTPUT_TYPE")
assert OUTPUT_TYPE is not None and OUTPUT_TYPE is not ""

input_variables = {'task.dataframe_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = input_variables['task.dataframe_id']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')
print(dataframe.head())

OUTPUT_TYPE = OUTPUT_TYPE.upper()
if OUTPUT_TYPE == "S3":
  import s3fs, uuid

  UserAccessKeyID=str(variables.get('UserAccessKeyID'))
  UserSecretAccessKey=str(variables.get('UserSecretAccessKey'))
  UserBucketPath=variables.get('UserBucketPath')

  dataframe_id = str(uuid.uuid4())
  print("dataframe id (out): ", dataframe_id)
  bytes_to_write = dataframe.to_csv(index=False).encode()

  fs = s3fs.S3FileSystem(
      key=UserAccessKeyID, 
      secret=UserSecretAccessKey,
      s3_additional_kwargs={'ACL': 'public-read'}
  )

  bucket_path=str(UserBucketPath) if UserBucketPath is not None else 's3://activeeon-public/results/'
  s3file_path = bucket_path+dataframe_id+'.csv'
  with fs.open(s3file_path, 'wb') as f:
    f.write(bytes_to_write)

  dataframe_url = fs.url(s3file_path).split('?')[0]
  dataframe_info = fs.info(s3file_path)
  print("The dataframe was uploaded successfully to the following url:")
  print(dataframe_url)
  print("File info:")
  print(dataframe_info)

if OUTPUT_TYPE == "CSV":
  #result = dataframe.to_csv(encoding='utf-8', index=False)
  result = dataframe.to_csv(index=False)
  resultMetadata.put("file.extension", ".csv")
  resultMetadata.put("file.name", "dataframe.csv")
  resultMetadata.put("content.type", "text/csv")

if OUTPUT_TYPE == "JSON":
  result = dataframe.to_json(orient='split', encoding='utf-8')
  resultMetadata.put("file.extension", ".json")
  resultMetadata.put("file.name", "dataframe.json")
  resultMetadata.put("content.type", "application/json")

if OUTPUT_TYPE == "HTML":
  LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
  LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
  if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
  
  #***************# HTML PREVIEW STYLING #***************#
  styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
  ]
  #******************************************************#

  with pd.option_context('display.max_colwidth', -1):
    result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")

print("END " + __file__)
]]>
                              </code>
                            </script>
                          </scriptExecutable>
                          <controlFlow block="none"></controlFlow>
                        </task>
                        <task name="Preview_Results3" >
                          <description>
                            <![CDATA[ Export the results. ]]>
                          </description>
                          <variables>
                            <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                            <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                            <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                            <variable name="OUTPUT_TYPE" value="HTML" inherited="false" model="PA:LIST(CSV,JSON,HTML)"/>
                            <variable name="LIMIT_OUTPUT_VIEW" value="1000" inherited="false" model="PA:Integer"/>
                          </variables>
                          <genericInformation>
                            <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png"/>
                            <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_export_results"/>
                          </genericInformation>
                          <depends>
                            <task ref="Predict_Model3"/>
                          </depends>
                          <forkEnvironment javaHome="/usr" >
                            <envScript>
                              <script>
                                <code language="python">
                                  <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                                </code>
                              </script>
                            </envScript>
                          </forkEnvironment>
                          <scriptExecutable>
                            <script>
                              <code language="cpython">
                                <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import pandas as pd
import numpy as np
import bz2

OUTPUT_TYPE = variables.get("OUTPUT_TYPE")
assert OUTPUT_TYPE is not None and OUTPUT_TYPE is not ""

input_variables = {'task.dataframe_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = input_variables['task.dataframe_id']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')
print(dataframe.head())

OUTPUT_TYPE = OUTPUT_TYPE.upper()
if OUTPUT_TYPE == "S3":
  import s3fs, uuid

  UserAccessKeyID=str(variables.get('UserAccessKeyID'))
  UserSecretAccessKey=str(variables.get('UserSecretAccessKey'))
  UserBucketPath=variables.get('UserBucketPath')

  dataframe_id = str(uuid.uuid4())
  print("dataframe id (out): ", dataframe_id)
  bytes_to_write = dataframe.to_csv(index=False).encode()

  fs = s3fs.S3FileSystem(
      key=UserAccessKeyID, 
      secret=UserSecretAccessKey,
      s3_additional_kwargs={'ACL': 'public-read'}
  )

  bucket_path=str(UserBucketPath) if UserBucketPath is not None else 's3://activeeon-public/results/'
  s3file_path = bucket_path+dataframe_id+'.csv'
  with fs.open(s3file_path, 'wb') as f:
    f.write(bytes_to_write)

  dataframe_url = fs.url(s3file_path).split('?')[0]
  dataframe_info = fs.info(s3file_path)
  print("The dataframe was uploaded successfully to the following url:")
  print(dataframe_url)
  print("File info:")
  print(dataframe_info)

if OUTPUT_TYPE == "CSV":
  #result = dataframe.to_csv(encoding='utf-8', index=False)
  result = dataframe.to_csv(index=False)
  resultMetadata.put("file.extension", ".csv")
  resultMetadata.put("file.name", "dataframe.csv")
  resultMetadata.put("content.type", "text/csv")

if OUTPUT_TYPE == "JSON":
  result = dataframe.to_json(orient='split', encoding='utf-8')
  resultMetadata.put("file.extension", ".json")
  resultMetadata.put("file.name", "dataframe.json")
  resultMetadata.put("content.type", "application/json")

if OUTPUT_TYPE == "HTML":
  LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
  LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
  if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
  
  #***************# HTML PREVIEW STYLING #***************#
  styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
  ]
  #******************************************************#

  with pd.option_context('display.max_colwidth', -1):
    result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")

print("END " + __file__)
]]>
                                </code>
                              </script>
                            </scriptExecutable>
                            <controlFlow block="none"></controlFlow>
                          </task>
                          <task name="Download_Model1" >
                            <description>
                              <![CDATA[ Download a trained model. ]]>
                            </description>
                            <variables>
                              <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                              <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                              <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                            </variables>
                            <genericInformation>
                              <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png"/>
                              <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_download_model"/>
                            </genericInformation>
                            <depends>
                              <task ref="Train_Model1"/>
                            </depends>
                            <forkEnvironment javaHome="/usr" >
                              <envScript>
                                <script>
                                  <code language="python">
                                    <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                                  </code>
                                </script>
                              </envScript>
                            </forkEnvironment>
                            <scriptExecutable>
                              <script>
                                <code language="cpython">
                                  <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2

input_variables = {'task.model_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None

print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

assert model_bin is not None
result = model_bin

#resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.model_bin", model_bin)

resultMetadata.put("file.extension", ".model")
resultMetadata.put("file.name", "myModel.model")
resultMetadata.put("content.type", "application/octet-stream")

print("END " + __file__)
]]>
                                </code>
                              </script>
                            </scriptExecutable>
                            <controlFlow block="none"></controlFlow>
                          </task>
                          <task name="Download_Model2" >
                            <description>
                              <![CDATA[ Download a trained model. ]]>
                            </description>
                            <variables>
                              <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                              <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                              <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                            </variables>
                            <genericInformation>
                              <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png"/>
                              <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_download_model"/>
                            </genericInformation>
                            <depends>
                              <task ref="Train_Model2"/>
                            </depends>
                            <forkEnvironment javaHome="/usr" >
                              <envScript>
                                <script>
                                  <code language="python">
                                    <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                                  </code>
                                </script>
                              </envScript>
                            </forkEnvironment>
                            <scriptExecutable>
                              <script>
                                <code language="cpython">
                                  <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2

input_variables = {'task.model_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None

print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

assert model_bin is not None
result = model_bin

#resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.model_bin", model_bin)

resultMetadata.put("file.extension", ".model")
resultMetadata.put("file.name", "myModel.model")
resultMetadata.put("content.type", "application/octet-stream")

print("END " + __file__)
]]>
                                </code>
                              </script>
                            </scriptExecutable>
                            <controlFlow block="none"></controlFlow>
                          </task>
                          <task name="Download_Model3" >
                            <description>
                              <![CDATA[ Download a trained model. ]]>
                            </description>
                            <variables>
                              <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                              <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                              <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                            </variables>
                            <genericInformation>
                              <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png"/>
                              <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_download_model"/>
                            </genericInformation>
                            <depends>
                              <task ref="Train_Model3"/>
                            </depends>
                            <forkEnvironment javaHome="/usr" >
                              <envScript>
                                <script>
                                  <code language="python">
                                    <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                                  </code>
                                </script>
                              </envScript>
                            </forkEnvironment>
                            <scriptExecutable>
                              <script>
                                <code language="cpython">
                                  <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2

input_variables = {'task.model_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None

print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

assert model_bin is not None
result = model_bin

#resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.model_bin", model_bin)

resultMetadata.put("file.extension", ".model")
resultMetadata.put("file.name", "myModel.model")
resultMetadata.put("content.type", "application/octet-stream")

print("END " + __file__)
]]>
                                </code>
                              </script>
                            </scriptExecutable>
                            <controlFlow block="none"></controlFlow>
                          </task>
                        </taskFlow>
                        <metadata>
                          <visualization>
                            <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:1122px;
            height:646px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-78px;left:-126.13751220703125px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2781" style="top: 83px; left: 466.9px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_Data</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2784" style="top: 211px; left: 466.9px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png" width="20px">&nbsp;<span class="name">Split_Data</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2787" style="top: 339px; left: 136.15px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/train.png" width="20px">&nbsp;<span class="name">Train_Model1</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2790" style="top: 339px; left: 556.4px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/train.png" width="20px">&nbsp;<span class="name">Train_Model2</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2793" style="top: 339px; left: 892.4px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/train.png" width="20px">&nbsp;<span class="name">Train_Model3</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2796" style="top: 467px; left: 173.15px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/predict.png" width="20px">&nbsp;<span class="name">Predict_Model1</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2799" style="top: 467px; left: 471.65px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/predict.png" width="20px">&nbsp;<span class="name">Predict_Model2</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2802" style="top: 467px; left: 770.15px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/predict.png" width="20px">&nbsp;<span class="name">Predict_Model3</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2805" style="top: 211px; left: 131.15px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/ml_classification.png" width="20px">&nbsp;<span class="name">Logistic_Regression</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2808" style="top: 211px; left: 625.9px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/ml_classification.png" width="20px">&nbsp;<span class="name">Gaussian_Naive_Bayes</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2811" style="top: 211px; left: 897.4px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/ml_classification.png" width="20px">&nbsp;<span class="name">Support_Vector_Machines</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2814" style="top: 595px; left: 159.55px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png" width="20px">&nbsp;<span class="name">Preview_Results1</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2817" style="top: 595px; left: 458.05px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png" width="20px">&nbsp;<span class="name">Preview_Results2</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2820" style="top: 595px; left: 756.55px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png" width="20px">&nbsp;<span class="name">Preview_Results3</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2823" style="top: 467px; left: 308.55px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png" width="20px">&nbsp;<span class="name">Download_Model1</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2826" style="top: 467px; left: 607.55px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png" width="20px">&nbsp;<span class="name">Download_Model2</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2829" style="top: 467px; left: 905.55px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png" width="20px">&nbsp;<span class="name">Download_Model3</span></a></div><svg style="position:absolute;left:501.98171321138256px;top:122.5px" width="15.518286788617468" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 -10 50 0 0 " transform="translate(15.018286788617468,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-4.427999999999998,66.303232 L-1.2615185838583702,45.35154005301801 L-7.026331880366543,52.546463795240896 L-15.018286788617468,47.94987193338456 L-4.427999999999998,66.303232" class="" stroke="#666" fill="#666" transform="translate(15.018286788617468,0.5)"></path></svg><svg style="position:absolute;left:175.5px;top:250.5px" width="352" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 341 50 331 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M58.63653125000001,58.2374375 L79.55533363794702,61.61437496670312 L72.41872399022732,55.77752626761262 L77.09542240555963,47.8321822264758 L58.63653125000001,58.2374375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M58.63653125000001,58.2374375 L79.55533363794702,61.61437496670312 L72.41872399022732,55.77752626761262 L77.09542240555963,47.8321822264758 L58.63653125000001,58.2374375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:175.5px;top:250.5px" width="28.5" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 17.5 50 7.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-2.1923999999999997,66.303232 L7.334892955184595,47.37624890849568 L-0.382160168186493,52.42075989481225 L-6.5475791500031475,45.56600907668218 L-2.1923999999999997,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-2.1923999999999997,66.303232 L7.334892955184595,47.37624890849568 L-0.382160168186493,52.42075989481225 L-6.5475791500031475,45.56600907668218 L-2.1923999999999997,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:506.5px;top:250.5px" width="110" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 89 88 C 99 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M80.38784375,62.2538125 L68.29767524802567,44.8518635978262 L69.05011953404043,54.04065174406419 L60.084514492089866,56.18958781378577 L80.38784375,62.2538125" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M80.38784375,62.2538125 L68.29767524802567,44.8518635978262 L69.05011953404043,54.04065174406419 L60.084514492089866,56.18958781378577 L80.38784375,62.2538125" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:595.5px;top:250.5px" width="112" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 101 50 91 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M8.870343749999998,62.2538125 L29.23366776080275,56.39420199834852 L20.29014084100874,54.155156166990906 L21.135011427793653,44.974404907339775 L8.870343749999998,62.2538125" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M8.870343749999998,62.2538125 L29.23366776080275,56.39420199834852 L20.29014084100874,54.155156166990906 L21.135011427793653,44.974404907339775 L8.870343749999998,62.2538125" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:506.5px;top:250.5px" width="447" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 426 88 C 436 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M347.16902400000004,57.860352000000006 L328.3106746578451,48.19791648460098 L333.2998558567651,55.950855989352924 L326.401178647198,62.067084627835925 L347.16902400000004,57.860352000000006" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M347.16902400000004,57.860352000000006 L328.3106746578451,48.19791648460098 L333.2998558567651,55.950855989352924 L326.401178647198,62.067084627835925 L347.16902400000004,57.860352000000006" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:932.5px;top:250.5px" width="52" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 41 50 31 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-0.059283250000002174,65.8307285 L14.515003073892293,50.44924033567709 L5.672151784713131,53.05768452282437 L1.7419590967166538,44.71780530096396 L-0.059283250000002174,65.8307285" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-0.059283250000002174,65.8307285 L14.515003073892293,50.44924033567709 L5.672151784713131,53.05768452282437 L1.7419590967166538,44.71780530096396 L-0.059283250000002174,65.8307285" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:175.5px;top:378.5px" width="60" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 39 88 C 49 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M38.17384200000001,65.364084 L34.414900976112335,44.510538441056454 L31.278182865334045,53.18008280587261 L22.230899781984935,51.406197575722416 L38.17384200000001,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M38.17384200000001,65.364084 L34.414900976112335,44.510538441056454 L31.278182865334045,53.18008280587261 L22.230899781984935,51.406197575722416 L38.17384200000001,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:214.5px;top:250.5px" width="313" height="217" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 216 C -10 166 302 50 292 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M51.41056250000001,162.5214375 L72.05683943068766,157.75370754735428 L63.24512821321441,155.04192853352296 L64.57733046421063,145.9191418341399 L51.41056250000001,162.5214375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M51.41056250000001,162.5214375 L72.05683943068766,157.75370754735428 L63.24512821321441,155.04192853352296 L64.57733046421063,145.9191418341399 L51.41056250000001,162.5214375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:513.5px;top:378.5px" width="103" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 92 50 82 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M7.2772479999999975,62.682047999999995 L27.290050274464395,55.71873376587322 L18.237559451905582,53.9716190279443 L18.5796213024087,44.758422313967635 L7.2772479999999975,62.682047999999995" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M7.2772479999999975,62.682047999999995 L27.290050274464395,55.71873376587322 L18.237559451905582,53.9716190279443 L18.5796213024087,44.758422313967635 L7.2772479999999975,62.682047999999995" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:506.5px;top:250.5px" width="28" height="217" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 7 216 C 17 166 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M8.65924675,167.0637915 L14.38572379899711,146.66262828298443 L7.777508617375644,153.09158559450762 L0.41351789350473034,147.5443664156088 L8.65924675,167.0637915" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M8.65924675,167.0637915 L14.38572379899711,146.66262828298443 L7.777508617375644,153.09158559450762 L0.41351789350473034,147.5443664156088 L8.65924675,167.0637915" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:811.5px;top:378.5px" width="142" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 131 50 121 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M14.717951999999999,60.999424000000005 L35.69695033324354,58.01921781019287 L27.15015540023851,54.562008477051535 L29.259534810295072,45.587014409954364 L14.717951999999999,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M14.717951999999999,60.999424000000005 L35.69695033324354,58.01921781019287 L27.15015540023851,54.562008477051535 L29.259534810295072,45.587014409954364 L14.717951999999999,60.999424000000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:506.5px;top:250.5px" width="326" height="217" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 305 216 C 315 166 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M251.18078125,162.5214375 L237.69885139801104,146.17403503153272 L239.20531176121003,155.26967009314941 L230.44708399116044,158.14950452032272 L251.18078125,162.5214375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M251.18078125,162.5214375 L237.69885139801104,146.17403503153272 L239.20531176121003,155.26967009314941 L230.44708399116044,158.14950452032272 L251.18078125,162.5214375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:205.5px;top:506.5px" width="30" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 19 50 9 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-2.0640960000000006,66.303232 L7.827876985611403,47.56426536755374 L0.014598222698128271,52.45841237934327 L-6.016942635045322,45.485571144855605 L-2.0640960000000006,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-2.0640960000000006,66.303232 L7.827876985611403,47.56426536755374 L0.014598222698128271,52.45841237934327 L-6.016942635045322,45.485571144855605 L-2.0640960000000006,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:504.5px;top:506.5px" width="30" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 19 50 9 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-2.0640960000000006,66.303232 L7.827876985611403,47.56426536755374 L0.014598222698128271,52.45841237934327 L-6.016942635045322,45.485571144855605 L-2.0640960000000006,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-2.0640960000000006,66.303232 L7.827876985611403,47.56426536755374 L0.014598222698128271,52.45841237934327 L-6.016942635045322,45.485571144855605 L-2.0640960000000006,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:803.5px;top:506.5px" width="29" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 18 50 8 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-2.149632,66.303232 L7.49984351657956,47.438247975227235 L-0.24966605297428535,52.43275510120006 L-6.370633382220376,45.538282028201515 L-2.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-2.149632,66.303232 L7.49984351657956,47.438247975227235 L-0.24966605297428535,52.43275510120006 L-6.370633382220376,45.538282028201515 L-2.149632,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:175.5px;top:378.5px" width="203" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 182 88 C 192 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M155.324603,59.788559500000005 L138.59264620162125,46.78695876404492 L142.05265472456648,55.33262088123317 L134.13670758285443,60.05890703947842 L155.324603,59.788559500000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M155.324603,59.788559500000005 L138.59264620162125,46.78695876404492 L142.05265472456648,55.33262088123317 L134.13670758285443,60.05890703947842 L155.324603,59.788559500000005" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:595.5px;top:378.5px" width="81" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 60 88 C 70 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M56.3539725,63.998374500000004 L48.25154501145557,44.41903158985923 L47.027791426533994,53.55699783861456 L37.810168350070136,53.74521266332523 L56.3539725,63.998374500000004" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M56.3539725,63.998374500000004 L48.25154501145557,44.41903158985923 L47.027791426533994,53.55699783861456 L37.810168350070136,53.74521266332523 L56.3539725,63.998374500000004" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:932.5px;top:378.5px" width="43" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 22 88 C 32 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M22.952128,66.303232 L23.499292531227972,45.120677598423065 L18.669980421802435,52.97419557126529 L10.17025610249327,49.40282517662063 L22.952128,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M22.952128,66.303232 L23.499292531227972,45.120677598423065 L18.669980421802435,52.97419557126529 L10.17025610249327,49.40282517662063 L22.952128,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 507px; top: 113px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 507px; top: 241px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 507px; top: 201px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 176px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 176px; top: 329px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 596px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 596px; top: 329px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 933px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 933px; top: 329px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 215px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 215px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 514px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 514px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 812px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 812px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 183.5px; top: 241px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 687px; top: 241px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 964px; top: 241px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 206px; top: 625px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 206px; top: 585px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 505px; top: 625px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 505px; top: 585px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 804px; top: 625px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 804px; top: 585px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 358px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 358px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 656px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 656px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 955px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 955px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
                          </visualization>
                        </metadata>
                      </job>