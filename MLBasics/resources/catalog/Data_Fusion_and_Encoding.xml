<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"  name="Data_Fusion_and_Encoding" projectName="4. Data Analytics" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2" >
  <variables>
    <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ Fuse different data structures ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="machine-learning-workflows"/>
    <info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_import_data"/>
    <info name="group" value="public-objects"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data_analytics.png"/>
  </genericInformation>
  <taskFlow>
    <task name="Import_LCL" >
      <description>
        <![CDATA[ Load data from external sources. ]]>
      </description>
      <variables>
        <variable name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/MAC000002-3.csv" inherited="false" />
        <variable name="FILE_DELIMITER" value="," inherited="false" />
        <variable name="IS_LABELED_DATA" value="False" inherited="false" model="PA:Boolean"/>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="RENAME_COLUMNS" value="LCLid, stdorToU, DateTime, KWH_hh, Acorn, Acorn_grouped" inherited="false" />
        <variable name="ENCODE_COLUMNS" value="LCLid, stdorToU, Acorn, Acorn_grouped" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_import_data"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
RENAME_COLUMNS = variables.get("RENAME_COLUMNS")
FILTER_COLUMNS = variables.get("FILTER_COLUMNS")
ENCODE_COLUMNS = variables.get("ENCODE_COLUMNS")

assert FILE_URL is not None
assert FILE_DELIMITER is not None

dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)

if RENAME_COLUMNS is not None:
  RENAME_COLUMNS = [x.strip() for x in RENAME_COLUMNS.split(',')]
  dataframe.columns = RENAME_COLUMNS

if FILTER_COLUMNS is not None:
  FILTER_COLUMNS = [x.strip() for x in FILTER_COLUMNS.split(',')]
  dataframe = dataframe.filter(items=FILTER_COLUMNS)

if ENCODE_COLUMNS is not None:
  ENCODE_COLUMNS = [x.strip() for x in ENCODE_COLUMNS.split(',')]
  map_struct = {}
  for col in ENCODE_COLUMNS:
    unique_vector = dataframe[col].unique()
    LE = LabelEncoder()
    LE.fit(unique_vector)
    enc_values = LE.transform(unique_vector)
    enc_map = dict(zip(unique_vector, enc_values))
    dataframe[col] = dataframe[col].map(enc_map)
    map_struct[col] = enc_map
  print(map_struct)

# Format columns
dataframe['KWH_hh'] = dataframe['KWH_hh'].replace('Null', 0)
dataframe['KWH_hh'] = dataframe.KWH_hh.astype(float)
#dataframe['DateTime'] = dataframe['DateTime'].astype('datetime64[ns]')

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
variables.put("COLUMNS_NAME_LCL__JSON", COLUMNS_NAME_JSON)

DATAFRAME_JSON = dataframe.to_json(orient='split')
variables.put("DATAFRAME_LCL_JSON", DATAFRAME_JSON)

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
            </code>
          </script>
        </scriptExecutable>
        <controlFlow block="none"></controlFlow>
      </task>
      <task name="Import_Holidays" >
        <description>
          <![CDATA[ Load data from external sources. ]]>
        </description>
        <variables>
          <variable name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/holidays.csv" inherited="false" />
          <variable name="FILE_DELIMITER" value="," inherited="false" />
          <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
          <variable name="RENAME_COLUMNS" value="Date, Description" inherited="false" />
          <variable name="FILTER_COLUMNS" value="Date" inherited="false" />
        </variables>
        <genericInformation>
          <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
          <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_import_data"/>
        </genericInformation>
        <forkEnvironment javaHome="/usr" >
          <envScript>
            <script>
              <code language="python">
                <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
              </code>
            </script>
          </envScript>
        </forkEnvironment>
        <scriptExecutable>
          <script>
            <code language="cpython">
              <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
RENAME_COLUMNS = variables.get("RENAME_COLUMNS")
FILTER_COLUMNS = variables.get("FILTER_COLUMNS")
ENCODE_COLUMNS = variables.get("ENCODE_COLUMNS")

assert FILE_URL is not None
assert FILE_DELIMITER is not None

dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)

if RENAME_COLUMNS is not None:
  RENAME_COLUMNS = [x.strip() for x in RENAME_COLUMNS.split(',')]
  dataframe.columns = RENAME_COLUMNS

if FILTER_COLUMNS is not None:
  FILTER_COLUMNS = [x.strip() for x in FILTER_COLUMNS.split(',')]
  dataframe = dataframe.filter(items=FILTER_COLUMNS)

if ENCODE_COLUMNS is not None:
  ENCODE_COLUMNS = [x.strip() for x in ENCODE_COLUMNS.split(',')]
  map_struct = {}
  for col in ENCODE_COLUMNS:
    unique_vector = dataframe[col].unique()
    LE = LabelEncoder()
    LE.fit(unique_vector)
    enc_values = LE.transform(unique_vector)
    enc_map = dict(zip(unique_vector, enc_values))
    dataframe[col] = dataframe[col].map(enc_map)
    map_struct[col] = enc_map
  print(map_struct)

# Format columns
dataframe['Date'] = dataframe['Date'].astype('datetime64[ns]')
dataframe.set_index('Date', inplace=True)

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATAFRAME_JSON = dataframe.to_json(orient='split')

variables.put("COLUMNS_NAME_HOLIDAY_JSON", COLUMNS_NAME_JSON)
variables.put("DATAFRAME_HOLIDAY_JSON", DATAFRAME_JSON)

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
              </code>
            </script>
          </scriptExecutable>
          <controlFlow block="none"></controlFlow>
        </task>
        <task name="Import_Tariffs" >
          <description>
            <![CDATA[ Load data from external sources. ]]>
          </description>
          <variables>
            <variable name="FILE_URL" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/lcl/tariffs.csv" inherited="false" />
            <variable name="FILE_DELIMITER" value="," inherited="false" />
            <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
            <variable name="RENAME_COLUMNS" value="DateTime, Tariff" inherited="false" />
            <variable name="ENCODE_COLUMNS" value="Tariff" inherited="false" />
          </variables>
          <genericInformation>
            <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png"/>
            <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_import_data"/>
          </genericInformation>
          <forkEnvironment javaHome="/usr" >
            <envScript>
              <script>
                <code language="python">
                  <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                </code>
              </script>
            </envScript>
          </forkEnvironment>
          <scriptExecutable>
            <script>
              <code language="cpython">
                <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

FILE_URL = variables.get("FILE_URL")
FILE_DELIMITER = variables.get("FILE_DELIMITER")
RENAME_COLUMNS = variables.get("RENAME_COLUMNS")
FILTER_COLUMNS = variables.get("FILTER_COLUMNS")
ENCODE_COLUMNS = variables.get("ENCODE_COLUMNS")

assert FILE_URL is not None
assert FILE_DELIMITER is not None

dataframe = pd.read_csv(FILE_URL, FILE_DELIMITER)

if RENAME_COLUMNS is not None:
  RENAME_COLUMNS = [x.strip() for x in RENAME_COLUMNS.split(',')]
  dataframe.columns = RENAME_COLUMNS

if FILTER_COLUMNS is not None:
  FILTER_COLUMNS = [x.strip() for x in FILTER_COLUMNS.split(',')]
  dataframe = dataframe.filter(items=FILTER_COLUMNS)

if ENCODE_COLUMNS is not None:
  ENCODE_COLUMNS = [x.strip() for x in ENCODE_COLUMNS.split(',')]
  map_struct = {}
  for col in ENCODE_COLUMNS:
    unique_vector = dataframe[col].unique()
    LE = LabelEncoder()
    LE.fit(unique_vector)
    enc_values = LE.transform(unique_vector)
    enc_map = dict(zip(unique_vector, enc_values))
    dataframe[col] = dataframe[col].map(enc_map)
    map_struct[col] = enc_map
  print(map_struct)

# Format columns
dataframe['DateTime'] = pd.to_datetime(dataframe['DateTime'], format='%m/%d/%y %H:%M')
dataframe['DateTime'] = dataframe['DateTime'].astype('datetime64[ns]')
dataframe.set_index('DateTime', inplace=True)

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
variables.put("COLUMNS_NAME_TARIFFS_JSON", COLUMNS_NAME_JSON)

DATAFRAME_JSON = dataframe.to_json(orient='split')
variables.put("DATAFRAME_TARIFFS_JSON", DATAFRAME_JSON)

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                </code>
              </script>
            </scriptExecutable>
            <controlFlow block="none"></controlFlow>
          </task>
          <task name="Data_Fusion" >
            <description>
              <![CDATA[ Performs data fusion. ]]>
            </description>
            <variables>
              <variable name="OUTPUT_FORMAT" value="HTML" inherited="false" />
              <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
              <variable name="IS_LABELED_DATA" value="False" inherited="false" model="PA:Boolean"/>
            </variables>
            <genericInformation>
              <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/filled_filter.png"/>
              <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_filter_data"/>
            </genericInformation>
            <depends>
              <task ref="Import_LCL"/>
              <task ref="Import_Holidays"/>
              <task ref="Import_Tariffs"/>
            </depends>
            <forkEnvironment javaHome="/usr" >
              <envScript>
                <script>
                  <code language="python">
                    <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                  </code>
                </script>
              </envScript>
            </forkEnvironment>
            <scriptExecutable>
              <script>
                <code language="cpython">
                  <![CDATA[
print("BEGIN " + __file__)

import pandas as pd
import numpy as np

DATAFRAME_LCL_JSON     = variables.get("DATAFRAME_LCL_JSON")
DATAFRAME_HOLIDAY_JSON = variables.get("DATAFRAME_HOLIDAY_JSON")
DATAFRAME_TARIFFS_JSON = variables.get("DATAFRAME_TARIFFS_JSON")
IS_LABELED_DATA        = variables.get("IS_LABELED_DATA")
OUTPUT_FORMAT          = variables.get("OUTPUT_FORMAT")

assert DATAFRAME_LCL_JSON is not None
assert DATAFRAME_HOLIDAY_JSON is not None
assert DATAFRAME_TARIFFS_JSON is not None
assert OUTPUT_FORMAT is not None

dataframe = pd.read_json(DATAFRAME_LCL_JSON, orient='split')
dataframe_holiday = pd.read_json(DATAFRAME_HOLIDAY_JSON, orient='split')
dataframe_tariffs = pd.read_json(DATAFRAME_TARIFFS_JSON, orient='split')

# Fuse holidays
dataframe['Holiday'] = 0
for holiday_date in dataframe_holiday.index:
    dataframe.loc[dataframe['DateTime'].dt.strftime('%d/%m/%y') == holiday_date.strftime('%d/%m/%y'), 'Holiday'] = 1

# Fuse tariffs
dataframe['Tariff'] = np.nan
for tariff_datetime in dataframe_tariffs.index:
    tariff_value = dataframe_tariffs.loc[tariff_datetime, 'Tariff']
    dataframe.loc[dataframe['DateTime'] == tariff_datetime, 'Tariff'] = tariff_value

# Remove NaN rows (Tariff == NaN)
dataframe.dropna(inplace=True)
dataframe['Tariff'] = dataframe['Tariff'].astype(int)
dataframe.reset_index(drop=True)

print(dataframe.dtypes)
print(dataframe.head(3))
print(dataframe.shape)

columns_name = dataframe.columns
columns_number = len(columns_name)

if IS_LABELED_DATA == 'True':
  data  = dataframe.values[:,0:columns_number-1]
  label = dataframe.values[:,columns_number-1]
  
  data_df = pd.DataFrame(data=data, columns=columns_name[0:columns_number-1])
  label_df = pd.DataFrame(data=label, columns=[columns_name[columns_number-1]])
  
  LABEL_TRAIN_DF_JSON = label_df.to_json(orient='split')
  LABEL_TEST_DF_JSON = label_df.to_json(orient='split')
  
  variables.put("LABEL_TRAIN_DF_JSON", LABEL_TRAIN_DF_JSON)
  variables.put("LABEL_TEST_DF_JSON", LABEL_TEST_DF_JSON)

else:
  data = dataframe.values
  data_df = pd.DataFrame(data=data, columns=columns_name)

DATAFRAME_JSON = dataframe.to_json(orient='split')
COLUMNS_NAME_JSON = pd.Series(columns_name).to_json()
DATA_TRAIN_DF_JSON = data_df.to_json(orient='split')
DATA_TEST_DF_JSON = data_df.to_json(orient='split')

variables.put("DATAFRAME_JSON", DATAFRAME_JSON)
variables.put("COLUMNS_NAME_JSON", COLUMNS_NAME_JSON)
variables.put("DATA_TRAIN_DF_JSON", DATA_TRAIN_DF_JSON)
variables.put("DATA_TEST_DF_JSON", DATA_TEST_DF_JSON)

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                  </code>
                </script>
              </scriptExecutable>
              <controlFlow block="none"></controlFlow>
            </task>
          </taskFlow>
          <metadata>
            <visualization>
              <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:1139px;
            height:566px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-269.9875030517578px;left:-356px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2006" style="top: 275px; left: 361px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_LCL</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2009" style="top: 275px; left: 502.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_Holidays</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2012" style="top: 275px; left: 644px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/import_data.png" width="20px">&nbsp;<span class="name">Import_Tariffs</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2015" style="top: 403px; left: 502.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/filled_filter.png" width="20px">&nbsp;<span class="name">Data_Fusion</span></a></div><svg style="position:absolute;left:400.5px;top:314.5px" width="162" height="89" pointer-events="none" position="absolute" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 141 88 C 151 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" d="M122.58666975,60.59109050000001 L107.11113887921682,46.11670124630653 L109.77678380193485,54.942478104237374 L101.4625264834542,58.92658719437168 L122.58666975,60.59109050000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" d="M122.58666975,60.59109050000001 L107.11113887921682,46.11670124630653 L109.77678380193485,54.942478104237374 L101.4625264834542,58.92658719437168 L122.58666975,60.59109050000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:541.5px;top:314.5px" width="24.5" height="89" pointer-events="none" position="absolute" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 13.5 50 3.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" d="M-2.531265625,66.78168750000002 L5.922688671570663,47.35153935976458 L-1.5001906020674536,52.819707543808825 L-8.03929128462053,46.32046433683204 L-2.531265625,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" d="M-2.531265625,66.78168750000002 L5.922688671570663,47.35153935976458 L-1.5001906020674536,52.819707543808825 L-8.03929128462053,46.32046433683204 L-2.531265625,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:541.5px;top:314.5px" width="163" height="89" pointer-events="none" position="absolute" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 152 50 142 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" d="M18.563992999999996,60.59109050000001 L39.69226134488013,58.979793895790735 L31.388064423950837,54.97475787867072 L34.07592872355084,46.155722471839894 L18.563992999999996,60.59109050000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" d="M18.563992999999996,60.59109050000001 L39.69226134488013,58.979793895790735 L31.388064423950837,54.97475787867072 L34.07592872355084,46.155722471839894 L18.563992999999996,60.59109050000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 401px; top: 305px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 545.5px; top: 305px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 684px; top: 305px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 542px; top: 433px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 542px; top: 393px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
              xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
            </visualization>
          </metadata>
        </job>