<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"  name="Breast_Cancer_Detection_Using_AutoSklearn_Classifier" projectName="2. Basic AutoML" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2" >
  <variables>
    <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ Detect Breast Cancer using AutoSklearn Classifier ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="machine-learning"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/AutoML.png"/>
    <info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_load_boston_dataset"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Load_Breast_Cancer_Dataset" >
      <description>
        <![CDATA[ Load and return the breast_cancer dataset. ]]>
      </description>
      <variables>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
        <variable name="LIMIT_OUTPUT_VIEW" value="-1" inherited="false" model="PA:Integer"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/load_dataset.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_load_boston_dataset"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid
import pandas as pd
import numpy as np

from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()
dataframe_load = pd.DataFrame(cancer.data)
dataframe_load.columns = cancer.feature_names 
data_label = cancer.target
dataframe = dataframe_load.assign(LABEL=data_label)

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id: ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
variables.put("PREVIOUS_PA_TASK_NAME", variables.get("PA_TASK_NAME"))
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
            89
        </positionTop>
        <positionLeft>
            457.5
        </positionLeft>
      </metadata>
    </task>
    <task name="Split_Data" >
      <description>
        <![CDATA[ Separate data into training and testing sets. ]]>
      </description>
      <variables>
        <variable name="TRAIN_SIZE" value="0.7" inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_split_data"/>
      </genericInformation>
      <depends>
        <task ref="Load_Breast_Cancer_Dataset"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split

TRAIN_SIZE = variables.get("TRAIN_SIZE")
assert TRAIN_SIZE is not None and TRAIN_SIZE is not ""
TRAIN_SIZE = float(TRAIN_SIZE)
test_size = 1 - TRAIN_SIZE

input_variables = {'task.dataframe_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = input_variables['task.dataframe_id']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

# Split dataframe into train/test sets
X_train, X_test = train_test_split(dataframe, test_size=test_size)

dataframe1 = X_train.reset_index(drop=True)
dataframe2 = X_test.reset_index(drop=True)

dataframe_json1 = dataframe1.to_json(orient='split').encode()
dataframe_json2 = dataframe2.to_json(orient='split').encode()

compressed_data1 = bz2.compress(dataframe_json1)
compressed_data2 = bz2.compress(dataframe_json2)

dataframe_id1 = str(uuid.uuid4())
dataframe_id2 = str(uuid.uuid4())

variables.put(dataframe_id1, compressed_data1)
variables.put(dataframe_id2, compressed_data2)

print("Train set:")
print("dataframe id1 (out): ", dataframe_id1)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json1), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data1), " bytes")
print(dataframe1.head())

print("Test set:")
print("dataframe id2 (out): ", dataframe_id2)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json2), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data2), " bytes")
print(dataframe2.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id_train", dataframe_id1)
resultMetadata.put("task.dataframe_id_test", dataframe_id2)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            217
        </positionTop>
        <positionLeft>
            457.5
        </positionLeft>
      </metadata>
    </task>
    <task name="Train_Model" >
      <description>
        <![CDATA[ Train a classification/clustering/anomaly detection model ]]>
      </description>
      <variables>
        <variable name="LABEL_COLUMN" value="LABEL" inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" />
        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
        <variable name="TASK_ENABLED" value="True" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_train_model"/>
      </genericInformation>
      <depends>
        <task ref="Split_Data"/>
        <task ref="AutoSklearn_Classifier"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid, json
import random, pickle
import pandas as pd

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_train': None,
  'task.algorithm_json': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_train'] is not None:
  dataframe_id = input_variables['task.dataframe_id_train']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()
dataframe = pd.read_json(dataframe_json, orient='split')

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)

#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)
try:
    if alg.sampling:
        print(alg.sampling + "exists")
except:
    alg.sampling=False
model = None
if alg.is_supervised:
  #-------------------------------------------------------------
  # Classification algorithms
  #
  if alg.name == 'TPOT_Classifier':
    from tpot import TPOTClassifier
    model = TPOTClassifier(
        generations=alg.generations,
        cv=alg.cv,
        scoring=alg.scoring,
        verbosity=alg.verbosity
    )
  if alg.name == 'AutoSklearn_Classifier':
    from autosklearn import classification
    if alg.sampling.lower()=='true':
    	model = classification.AutoSklearnClassifier(
        	time_left_for_this_task=alg.task_time,
        	per_run_time_limit=alg.run_time,
        	resampling_strategy= "".join(alg.sampling_strategy),
        	resampling_strategy_arguments={'folds':int(alg.folds)}
        	#feat_type = {Numerical,Numerical,Numerical,Numerical,Categorical}
    	)
    else:
        model = classification.AutoSklearnClassifier(
        	time_left_for_this_task=alg.task_time,
        	per_run_time_limit=alg.run_time
    	)
  if alg.name == 'SupportVectorMachines':
    from sklearn.svm import SVC
    model = SVC(
      C=alg.C, 
      kernel=alg.kernel
    )
   
  if alg.name == 'GaussianNaiveBayes':
    from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()
  
  if alg.name == 'LogisticRegression':
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(
      penalty=alg.penalty, 
      solver=alg.solver, 
      max_iter=alg.max_iter, 
      n_jobs=alg.n_jobs
    )

  #-------------------------------------------------------------
  # Regression algorithms
    
  if alg.name == 'TPOT_Regressor':
    from tpot import TPOTRegressor
    model = TPOTRegressor(
        generations=alg.generations,
        cv=alg.cv,
        scoring=alg.scoring,
        verbosity=alg.verbosity
    )
  if alg.name == 'AutoSklearn_Regressor':
    from autosklearn import regression
    print("alg.sampling",alg.sampling_strategy)
    if alg.sampling.lower()=='true':
    	model = regression.AutoSklearnRegressor(
        	time_left_for_this_task=alg.task_time,
        	per_run_time_limit=alg.run_time,
        	resampling_strategy= "".join(alg.sampling_strategy),
        	resampling_strategy_arguments={'folds':int(alg.folds)}
        	#feat_type = {Numerical,Numerical,Numerical,Numerical,Categorical}
    	)
    else:
        model = regression.AutoSklearnRegressor(
        	time_left_for_this_task=alg.task_time,
        	per_run_time_limit=alg.run_time
    	)
  if alg.name == 'LinearRegression':
    from sklearn.linear_model import LinearRegression
    model = LinearRegression(
      n_jobs=alg.n_jobs
    )

  if alg.name == 'SupportVectorRegression':
    from sklearn.svm import SVR
    model = SVR(
      C=alg.C, 
      kernel=alg.kernel, 
      epsilon=alg.epsilon
    )
  
  if alg.name == 'BayesianRidgeRegression':
    from sklearn.linear_model import BayesianRidge
    model = BayesianRidge(
      alpha_1=alg.alpha_1, 
      alpha_2=alg.alpha_2, 
      lambda_1=alg.lambda_1, 
      lambda_2=alg.lambda_2, 
      n_iter=alg.n_iter
    )
else:
  #-------------------------------------------------------------
  # Anomaly detection algorithms
  if alg.name == 'OneClassSVM':
    from sklearn import svm
    model = svm.OneClassSVM(
      nu=alg.nu, 
      kernel=alg.kernel, 
      gamma=alg.gamma
    ) 
  
  if alg.name == 'IsolationForest':
    from sklearn.ensemble import IsolationForest
    model = IsolationForest(
      n_estimators=alg.n_estimators, 
      n_jobs=alg.n_jobs
    )
  
  #-------------------------------------------------------------
  # Clustering algorithms
  if alg.name == 'MeanShift':
    from sklearn.cluster import MeanShift
    model = MeanShift(
      cluster_all=alg.cluster_all, 
      n_jobs=alg.n_jobs
    ) 
    
  if alg.name == 'KMeans':
    from sklearn.cluster import KMeans
    model = KMeans(
      n_clusters=alg.n_clusters, 
      max_iter=alg.max_iterations, 
      n_jobs=alg.n_jobs
    )

#-------------------------------------------------------------
if model is not None:
  if is_labeled_data:
    columns = [LABEL_COLUMN]
    dataframe_train = dataframe.drop(columns, axis=1, inplace=False)
    dataframe_label = dataframe.filter(columns, axis=1)
  else:
    dataframe_train = dataframe

  if alg.is_supervised:
    model.fit(dataframe_train.values, dataframe_label.values.ravel())
    if alg.sampling:
        model.refit(dataframe_train.values.copy(), dataframe_label.values.ravel().copy())
  else:
    model.fit(dataframe_train.values)
  if alg.name == 'TPOT_Regressor' or alg.name =='TPOT_Classifier':
    model = model.fitted_pipeline_
  model_bin = pickle.dumps(model)
  model_compressed = bz2.compress(model_bin)
  model_id = str(uuid.uuid4())
  variables.put(model_id, model_compressed)

  print("model id: ", model_id)
  print('model size (original):   ', sys.getsizeof(model_bin), " bytes")
  print('model size (compressed): ', sys.getsizeof(model_compressed), " bytes")   
  resultMetadata.put("task.model_id", model_id)
else:
  print("Algorithm not found!")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.dataframe_id", dataframe_id)
resultMetadata.put("task.algorithm_json", algorithm_json)
resultMetadata.put("task.label_column", LABEL_COLUMN)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            348
        </positionTop>
        <positionLeft>
            688
        </positionLeft>
      </metadata>
    </task>
    <task name="AutoSklearn_Classifier" >
      <description>
        <![CDATA[ AutoSklearn_Classifier frees a machine learning user from algorithm selection and hyperparameter tuning. It leverages recent advantages in Bayesian optimization, meta-learning and ensemble construction. ]]>
      </description>
      <variables>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
        <variable name="TASK_TIME" value="30" inherited="false" model="PA:Integer"/>
        <variable name="RUN_TIME" value="27" inherited="false" model="PA:Integer"/>
        <variable name="SAMPLING" value="True" inherited="false" model="PA:Boolean"/>
        <variable name="FOLDS" value="5" inherited="false" model="PA:Integer"/>
        <variable name="RESAMPLING_STRATEGY" value="cv" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/AutoML.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_autosklearn_classifier"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import json

algorithm = {
  'name': 'AutoSklearn_Classifier',
  'is_supervised': True,
  'type': 'classification',
  'task_time': int(variables.get("TASK_TIME")),
  'run_time': int(variables.get("RUN_TIME")),
  'sampling': variables.get("SAMPLING"),
  'sampling_strategy': variables.get('RESAMPLING_STRATEGY'),
  'folds': variables.get('FOLDS')
}

algorithm_json = json.dumps(algorithm)
resultMetadata.put("task.algorithm_json", algorithm_json)

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            217
        </positionTop>
        <positionLeft>
            663
        </positionLeft>
      </metadata>
    </task>
    <task name="Predict_Model" >
      <description>
        <![CDATA[ Generate predictions using a trained model. ]]>
      </description>
      <variables>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
        <variable name="LABEL_COLUMN" value="LABEL" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/predict.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_predict_model"/>
      </genericInformation>
      <depends>
        <task ref="Train_Model"/>
        <task ref="Split_Data"/>
        <task ref="Start_Visdom_Service"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2, uuid, json
import random, pickle, sklearn
import numpy as np
import pandas as pd

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mutual_info_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score
from sklearn.metrics.cluster import adjusted_mutual_info_score
from sklearn.metrics.cluster import completeness_score
from sklearn.metrics.cluster import homogeneity_score
from sklearn.metrics.cluster import v_measure_score

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_test': None,
  'task.algorithm_json': None,
  'task.label_column': None,
  'task.model_id': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_test'] is not None:
  dataframe_id = input_variables['task.dataframe_id_test']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True
else:
  LABEL_COLUMN = input_variables['task.label_column']
  if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
    is_labeled_data = True

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None
print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

loaded_model = pickle.loads(model_bin)
dataframe_predictions = None

if is_labeled_data:
  columns = [LABEL_COLUMN]
  dataframe_test = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)
  predictions = list(loaded_model.predict(dataframe_test.values))
  dataframe_predictions = pd.DataFrame(predictions)
  dataframe = dataframe.assign(predictions=dataframe_predictions)

  if alg.type == 'anomaly':
    pred_map = {-1: 1, 1: 0}
    dataframe["predictions"].replace(pred_map, inplace=True)
    predictions = dataframe["predictions"].tolist()
  
  if alg.type != 'clustering' and alg.type != 'anomaly':
    score = loaded_model.score(dataframe_test.values, dataframe_label.values.ravel())
    print("MODEL SCORE: %.2f" % score)

  #-------------------------------------------------------------
  # CLASSIFICATION AND ANOMALY DETECTION SCORE
  #
  if alg.type == 'classification' or alg.type == 'anomaly':
    dataframe['accuracy'] = np.where((dataframe[LABEL_COLUMN] == dataframe['predictions']), 1, 0)
    accuracy_score_result = accuracy_score(dataframe_label.values.ravel(), predictions)
    precision_score_result = precision_score(dataframe_label.values.ravel(), predictions, average='micro')
    confusion_matrix_result = confusion_matrix(dataframe_label.values.ravel(), predictions)
    print("********************** CLASSIFICATION SCORE **********************")
    print("ACCURACY SCORE: %.2f" % accuracy_score_result)
    print("PRECISION SCORE: %.2f" % precision_score_result)
    print("CONFUSION MATRIX:\n%s" % confusion_matrix_result)
    print("*******************************************************************")

  #-------------------------------------------------------------
  # REGRESSION SCORE
  #
  if alg.type == 'regression':
    dataframe['absolute_error'] = dataframe[LABEL_COLUMN] - dataframe['predictions']
    mean_squared_error_result = mean_squared_error(dataframe_label.values.ravel(), predictions)
    mean_absolute_error_result = mean_absolute_error(dataframe_label.values.ravel(), predictions)
    r2_score_result = r2_score(dataframe_label.values.ravel(), predictions) 
    print("********************** REGRESSION SCORES **********************")
    print("MEAN SQUARED ERROR: %.2f" % mean_squared_error_result)
    print("MEAN ABSOLUTE ERROR: %.2f" % mean_absolute_error_result)
    print("R2 SCORE: %.2f" % r2_score_result)
    print("***************************************************************")
  
  #-------------------------------------------------------------
  # CLUSTERING SCORE
  #
  if alg.type == 'clustering':
    adjusted_mutual_info_score_result = adjusted_mutual_info_score(dataframe_label.values.ravel(), predictions)
    completeness_score_result = completeness_score(dataframe_label.values.ravel(), predictions)
    homogeneity_score_result = homogeneity_score(dataframe_label.values.ravel(), predictions)
    mutual_info_score_result = mutual_info_score(dataframe_label.values.ravel(), predictions)
    v_measure_score_result = v_measure_score(dataframe_label.values.ravel(), predictions)
    print("********************** CLUSTERING SCORES **********************")
    print("ADJUSTED MUTUAL INFORMATION: %.2f" % adjusted_mutual_info_score_result)
    print("COMPLETENESS SCORE: %.2f" % completeness_score_result)
    print("HOMOGENEITY METRIC: %.2f" % homogeneity_score_result)
    print("MUTUAL INFORMATION: %.2f" % mutual_info_score_result)
    print("V-MEASURE CLUSTER MEASURE: %.2f" % v_measure_score_result)
    print("***************************************************************")
    #-------------------------------------------------------------
else:
  predictions = list(loaded_model.predict(dataframe.values))
  dataframe_predictions = pd.DataFrame(predictions)
  dataframe = dataframe.assign(predictions=dataframe_predictions)

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)
resultMetadata.put("task.algorithm_json", algorithm_json)
resultMetadata.put("task.label_column", LABEL_COLUMN)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            473
        </positionTop>
        <positionLeft>
            461.75
        </positionLeft>
      </metadata>
    </task>
    <task name="Start_Visdom_Service" 
    
    onTaskError="cancelJob" >
      <description>
        <![CDATA[ Start the Visdom server as a service. ]]>
      </description>
      <variables>
        <variable name="SERVICE_ID" value="Visdom" inherited="false" />
        <variable name="INSTANCE_NAME" value="visdom-server" inherited="true" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/cloud-automation-scripts/resources/Service_Start/raw" language="groovy"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <post>
        <script>
          <code language="groovy">
            <![CDATA[
variables.put("ENDPOINT_VISDOM",variables.get("ENDPOINT_" + variables.get("INSTANCE_NAME")))
]]>
          </code>
        </script>
      </post>
      <metadata>
        <positionTop>
            339
        </positionTop>
        <positionLeft>
            340.5
        </positionLeft>
      </metadata>
    </task>
    <task name="Visdom_Visualize_Results" >
      <description>
        <![CDATA[ Plot the different results obtained by a predictive model using Visdom ]]>
      </description>
      <variables>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
        <variable name="TASK_ENABLED" value="True" inherited="false" />
        <variable name="TARGET_CLASS" value="1" inherited="false" />
        <variable name="VISDOM_ENDPOINT" value="$ENDPOINT_VISDOM" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_visdom_visualize_results"/>
      </genericInformation>
      <depends>
        <task ref="Predict_Model"/>
      </depends>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters
  containerName = variables.get("DOCKER_IMAGE")
  dockerRunCommand =  'docker run '
  dockerParameters = '--rm '
  # Prepare ProActive home volume
  paHomeHost = variables.get("PA_SCHEDULER_HOME")
  paHomeContainer = variables.get("PA_SCHEDULER_HOME")
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' '
  # Prepare working directory (For Dataspaces and serialized task file)
  workspaceHost = localspace
  workspaceContainer = localspace
  workspaceVolume = '-v '+localspace +':'+localspace+' '
  # Prepare container working directory
  containerWorkingDirectory = '-w '+workspaceContainer+' '
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid, json
import pandas as pd
import numpy as np

from visdom import Visdom
from sklearn.metrics import *

input_variables = {
  'task.dataframe_id': None,
  'task.dataframe_id_test': None,
  'task.algorithm_json': None,
  'task.label_column': None,
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_test'] is not None:
  dataframe_id = input_variables['task.dataframe_id_test']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True
else:
  LABEL_COLUMN = input_variables['task.label_column']
  if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
    is_labeled_data = True

TARGET_CLASS = variables.get("TARGET_CLASS")
assert TARGET_CLASS is not None, 'The variable TARGET_CLASS is mandatory'
TARGET_CLASS = str(TARGET_CLASS)

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

visdom_endpoint = variables.get("VISDOM_ENDPOINT") if variables.get("VISDOM_ENDPOINT") else results[0].__str__()
print("VISDOM_ENDPOINT = ",visdom_endpoint)
if visdom_endpoint is not None:
  visdom_endpoint = visdom_endpoint.replace("http://", "")
(VISDOM_HOST, VISDOM_PORT) = visdom_endpoint.split(":")
print("Connecting to %s:%s" % (VISDOM_HOST, VISDOM_PORT))
vis = Visdom(server="http://"+VISDOM_HOST,port=int(VISDOM_PORT))
assert vis.check_connection()

columns = []
if alg.type == 'classification' and is_labeled_data:
  columns = [LABEL_COLUMN, "predictions","accuracy"]
elif alg.type == 'regression' and is_labeled_data:
  columns = [LABEL_COLUMN, "predictions","absolute_error"]
elif alg.type == 'clustering' and is_labeled_data:
  columns = [LABEL_COLUMN, "predictions"]
else:
  columns = ["predictions"]

dataframe_idx_values = dataframe.index.values
dataframe_features = dataframe.drop(columns, axis=1, inplace=False)

dataframe_features_values = dataframe_features.values
dataframe_features_values_columns = list(dataframe_features.columns.values)

nb_rows = dataframe_features_values.shape[0]
nb_columns = dataframe_features_values.shape[1]

dataframe_predictions = dataframe["predictions"]
dataframe_predictions_values = dataframe_predictions.values.ravel()
dataframe_predictions_values_str = [str(dataframe_predictions[x]) for x in range(nb_rows)]

if alg.type == 'classification':
  df_classes = dataframe[LABEL_COLUMN].unique()
else:
  df_classes = dataframe_predictions.unique()

classes = [str(df_classes[x]) for x in range(0,len(df_classes))]
classes.sort()
classes_stats = [0]*len(classes)

if is_labeled_data:
  dataframe_labels = dataframe[LABEL_COLUMN]
  dataframe_labels_values = dataframe_labels.values.ravel()

if is_labeled_data and alg.type == 'regression':
  dataframe_predictions_values_float = [float(dataframe_predictions_values[x]) for x in range(nb_rows)]
  model_mse = mean_squared_error(dataframe_labels_values, dataframe_predictions_values_float)
  model_mae = mean_absolute_error(dataframe_labels_values, dataframe_predictions_values_float)
  model_r2s = r2_score(dataframe_labels_values, dataframe_predictions_values_float)

if is_labeled_data and (alg.type == 'classification' or alg.type == 'clustering'):
  dataframe_classes = dataframe_labels.unique()
  classes = [str(dataframe_classes[x]) for x in range(0, len(dataframe_classes))]
  classes.sort()
  classes_stats = [0]*len(classes)
  model_cm = confusion_matrix(dataframe_labels_values, dataframe_predictions_values)
  model_as = accuracy_score(dataframe_labels_values, dataframe_predictions_values)
  model_ps = precision_score(dataframe_labels_values, dataframe_predictions_values, average='micro')
  model_fpr = None
  model_tpr = None
  if len(classes) == 2:
    model_fpr, model_tpr, _ = roc_curve(dataframe_labels_values, dataframe_predictions_values)

#-------------------------------------------------------------
# VISDOM PLOTS
#-------------------------------------------------------------

list_detected_samples_text = vis.text("List of detected samples in class " + TARGET_CLASS, opts=dict(title='List of indexes'))

target_class_line = vis.line(
  Y=np.array([0]),
  X=np.array([0]),
  opts=dict(
    xlabel='Index',
    ylabel='Targeted Class',
    title="Detected samples in class " + TARGET_CLASS
    )
  )

features_line = vis.line(
  X=np.column_stack([0]*nb_columns),
  Y=np.column_stack(dataframe_features_values[0][:]),
  opts=dict(
    legend=dataframe_features_values_columns,
    xlabel='Index',
    ylabel='Feature Value',
    title='Values of extracted features for each sample'
    )
  )
if alg.type == 'classification' or alg.type == 'clustering':
  statistic_pie = vis.pie(X=classes_stats, opts=dict(legend=classes, title='Classification results'))

#-------------------------------------------------------------
count = 0
for x in range(nb_rows):
  vis.line(
    X=np.column_stack([count]*nb_columns),
    Y=np.column_stack(dataframe_features_values[x][:]),
    win=features_line,
    update='append'
  )
  if alg.type == 'regression':
    match = (int(float(dataframe_predictions_values[x])) == int(float(TARGET_CLASS)))
    if match:
      message = "%s\n"%(dataframe_idx_values[x])
      vis.text(message, win=list_detected_samples_text, append=True)
      vis.line(Y=np.array([1]), X=np.array([count]), win=target_class_line, update='append')
    else:
      vis.line(Y=np.array([0]), X=np.array([count]), win=target_class_line, update='append')
    count += 1

  if alg.type == 'classification' or alg.type == 'clustering':
    for i in range(len(classes)):
      if dataframe_predictions_values_str[x] == classes[i]:
        classes_stats[i] += 1
        vis.pie(X=classes_stats, win=statistic_pie, opts=dict(legend=classes, title='Classification results'))
        match = (str(classes[i]) == str(TARGET_CLASS))
        if match:
          message = "%s\n"%(dataframe_idx_values[x])
          vis.text(message, win=list_detected_samples_text, append=True)
          vis.line(Y=np.array([1]), X=np.array([count]), win=target_class_line, update='append')
        else:
          vis.line(Y=np.array([0]), X=np.array([count]), win=target_class_line, update='append')
        count += 1

#-------------------------------------------------------------

score_text = vis.text("Model scoring")
if is_labeled_data and (alg.type == 'classification' or alg.type == 'clustering'):
  if model_fpr is not None and model_tpr is not None:
    vis.line(X=model_fpr, Y=model_tpr, opts=dict(xlabel='False Positive Rate', ylabel='True Positive Rate', title='ROC Curve'))
  vis.bar(X=model_cm, opts=dict(stacked=True, legend=classes, rownames=classes, title='Predictive model performance'))
  vis.text("Classification scores", win=score_text, append=True)
  vis.text("Accuracy score:", win=score_text, append=True)
  vis.text(str(model_as), win=score_text, append=True)
  vis.text("Precision score:", win=score_text, append=True)
  vis.text(str(model_ps), win=score_text, append=True)
  vis.text("Confusion matrix:", win=score_text, append=True)
  vis.text(str(model_cm), win=score_text, append=True)

if is_labeled_data and alg.type == 'regression':
  vis.text("Regression scores", win=score_text, append=True)
  vis.text("Mean squared error:", win=score_text, append=True)
  vis.text(str(model_mse), win=score_text, append=True)
  vis.text("Mean absolute error:", win=score_text, append=True)
  vis.text(str(model_mae), win=score_text, append=True)
  vis.text("Coefficient of determination:", win=score_text, append=True)
  vis.text(str(model_r2s), win=score_text, append=True)

print("END " + __file__)
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            601
        </positionTop>
        <positionLeft>
            461.75
        </positionLeft>
      </metadata>
    </task>
    <task name="Visdom_Service_Actions" 
    
    onTaskError="cancelJob" >
      <description>
        <![CDATA[ This task manages the life-cycle of Visdom PCA service. It allows to trigger three possible actions: Pause_Visdom, Resume_Visdom and Finish_Visdom.
It requires the following variables:
INSTANCE_ID: if used alone or;
INSTANCE_NAME: if used within the same workflow as a Visdom_Service_Start task. In this case there is no need for an INSTANCE_ID.
ACTION: the action to execute on the Visdom service among the aforementioned actions. ]]>
      </description>
      <variables>
        <variable name="INSTANCE_NAME" value="visdom-server" inherited="false" />
        <variable name="ACTION" value="Finish_Visdom" inherited="false" model="PA:LIST(Pause_Visdom, Resume_Visdom, Finish_Visdom)"/>
        <variable name="INSTANCE_ID" value="" inherited="false" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html"/>
      </genericInformation>
      <depends>
        <task ref="WebValidation"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/cloud-automation-scripts/resources/Service_Action/raw" language="groovy"></file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <metadata>
        <positionTop>
            857
        </positionTop>
        <positionLeft>
            461.75
        </positionLeft>
      </metadata>
    </task>
    <task name="WebValidation" 
    
    onTaskError="pauseJob" >
      <description>
        <![CDATA[ Task to pause the job and send a validation message to the notification service ]]>
      </description>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/web_validation.png"/>
      </genericInformation>
      <depends>
        <task ref="Visdom_Visualize_Results"/>
      </depends>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/notification-tools/resources/Web_Validation_Script/raw" language="groovy">
            <arguments>
              <argument value="Put your web validation message here"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <metadata>
        <positionTop>
            729
        </positionTop>
        <positionLeft>
            461.75
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2864px;
            height:3372px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-84px;left:-335.5px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_476" style="top: 89px; left: 457.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/load_dataset.png" width="20px">&nbsp;<span class="name">Load_Breast_Cancer_Dataset</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_479" style="top: 217px; left: 457.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png" width="20px">&nbsp;<span class="name">Split_Data</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_482" style="top: 348px; left: 688px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/train.png" width="20px">&nbsp;<span class="name">Train_Model</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_485" style="top: 217px; left: 663px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/AutoML.png" width="20px">&nbsp;<span class="name">AutoSklearn_Classifier</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_488" style="top: 473px; left: 461.75px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/predict.png" width="20px">&nbsp;<span class="name">Predict_Model</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_491" style="top: 339px; left: 340.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png" width="20px">&nbsp;<span class="name">Start_Visdom_Service</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_494" style="top: 601px; left: 461.75px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png" width="20px">&nbsp;<span class="name">Visdom_Visualize_Results</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_497" style="top: 857px; left: 461.75px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/visdom.png" width="20px">&nbsp;<span class="name">Visdom_Service_Actions</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_500" style="top: 729px; left: 461.75px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/web_validation.png" width="20px">&nbsp;<span class="name">WebValidation</span></a></div><svg style="position:absolute;left:497.5px;top:128.5px" width="55.5" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 44.5 50 34.5 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M0.400538999999998,65.364084 L15.665323030920174,50.66760930402735 L6.712086903011867,52.867509946765 L3.1687489776851647,44.35606140101548 L0.400538999999998,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M0.400538999999998,65.364084 L15.665323030920174,50.66760930402735 L6.712086903011867,52.867509946765 L3.1687489776851647,44.35606140101548 L0.400538999999998,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:497.5px;top:256.5px" width="251" height="92" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 230 91 C 240 41 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M192.85150499999997,61.48388925 L175.40864339116223,49.45282201159868 L179.3480621495815,57.78834718076554 L171.71310132192775,62.95626486201717 L192.85150499999997,61.48388925" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M192.85150499999997,61.48388925 L175.40864339116223,49.45282201159868 L179.3480621495815,57.78834718076554 L171.71310132192775,62.95626486201717 L192.85150499999997,61.48388925" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:720.5px;top:256.5px" width="28" height="92" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 7 91 C 17 41 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M9.235168,69.046624 L13.820511207957226,48.359076352556606 L7.579302585252942,55.14489354195109 L-0.08121925009167619,50.01494176730366 L9.235168,69.046624" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M9.235168,69.046624 L13.820511207957226,48.359076352556606 L7.579302585252942,55.14489354195109 L-0.08121925009167619,50.01494176730366 L9.235168,69.046624" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:501.5px;top:387.5px" width="247" height="86" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 85 C -10 35 236 50 226 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M36.45467200000001,56.52462374999999 L57.55971943770696,58.41591237211432 L50.02874676063509,53.09759961925774 L54.13269530696472,44.841837611479235 L36.45467200000001,56.52462374999999" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M36.45467200000001,56.52462374999999 L57.55971943770696,58.41591237211432 L50.02874676063509,53.09759961925774 L54.13269530696472,44.841837611479235 L36.45467200000001,56.52462374999999" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:497.5px;top:256.5px" width="25" height="217" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 4 216 C 14 166 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M6.1449835,167.0637915 L12.190539108680236,146.75489548415624 L5.482363813758968,153.07948117909373 L-1.7937712122260425,147.41751517039728 L6.1449835,167.0637915" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M6.1449835,167.0637915 L12.190539108680236,146.75489548415624 L5.482363813758968,153.07948117909373 L-1.7937712122260425,147.41751517039728 L6.1449835,167.0637915" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:397px;top:378.5px" width="125.5" height="95" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 104.5 94 C 114.5 44 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M93.327773,67.024496 L80.58107236936331,50.09754639196588 L81.68430476355097,59.25084515713327 L72.8074215264966,61.7410146284149 L93.327773,67.024496" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M93.327773,67.024496 L80.58107236936331,50.09754639196588 L81.68430476355097,59.25084515713327 L72.8074215264966,61.7410146284149 L93.327773,67.024496" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:501.5px;top:512.5px" width="47" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 26 88 C 36 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M26.509342000000004,65.8307285 L25.911972524203918,44.649530476531474 L21.51374988524985,52.752347123734594 L12.833591147938504,49.64512259128163 L26.509342000000004,65.8307285" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M26.509342000000004,65.8307285 L25.911972524203918,44.649530476531474 L21.51374988524985,52.752347123734594 L12.833591147938504,49.64512259128163 L26.509342000000004,65.8307285" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:501.5px;top:768.5px" width="43.5" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 22.5 88 C 32.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M23.40936,66.303232 L23.83038624209553,45.1177950938735 L19.047922429813696,52.999929315276646 L10.52708355737218,49.47923266405979 L23.40936,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M23.40936,66.303232 L23.83038624209553,45.1177950938735 L19.047922429813696,52.999929315276646 L10.52708355737218,49.47923266405979 L23.40936,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:501.5px;top:640.5px" width="47" height="89" pointer-events="none" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 36 50 26 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-0.5093420000000015,65.8307285 L13.166408852061494,49.64512259128163 L4.486250114750149,52.75234712373459 L0.08802747579607573,44.649530476531474 L-0.5093420000000015,65.8307285" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" d="M-0.5093420000000015,65.8307285 L13.166408852061494,49.64512259128163 L4.486250114750149,52.75234712373459 L0.08802747579607573,44.649530476531474 L-0.5093420000000015,65.8307285" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 532.5px; top: 119px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 498px; top: 247px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 498px; top: 207px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 728px; top: 378px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 728px; top: 338px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 721px; top: 247px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 502px; top: 503px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 502px; top: 463px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 397.5px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 528px; top: 631px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 528px; top: 591px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 524.5px; top: 887px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 524.5px; top: 847px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 502px; top: 759px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 502px; top: 719px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
      xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
    </visualization>
  </metadata>
</job>