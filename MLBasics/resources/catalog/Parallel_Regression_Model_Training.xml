<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11" xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"  name="Parallel_Regression_Model_Training" projectName="1. Basic Machine Learning" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2" >
  <variables>
    <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ Train three different regression models. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="machine-learning-workflows"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/machine_learning.png"/>
    <info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_load_boston_dataset"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Load_Boston_Dataset" >
      <description>
        <![CDATA[ Load and return the boston house-prices dataset regression. ]]>
      </description>
      <variables>
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
        <variable name="LIMIT_OUTPUT_VIEW" value="-1" inherited="false" model="PA:Integer"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/load_dataset.png"/>
        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_load_boston_dataset"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid
import pandas as pd
import numpy as np

from sklearn.datasets import load_boston
boston = load_boston()
dataframe_load = pd.DataFrame(boston.data)
dataframe_load.columns = boston.feature_names 
data_label = boston.target
dataframe = dataframe_load.assign(LABEL=data_label)

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id: ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
            </code>
          </script>
        </scriptExecutable>
        <controlFlow block="none"></controlFlow>
        <post>
          <script>
            <code language="groovy">
              <![CDATA[
variables.put("PREVIOUS_PA_TASK_NAME", variables.get("PA_TASK_NAME"))
]]>
            </code>
          </script>
        </post>
      </task>
      <task name="Split_Data" >
        <description>
          <![CDATA[ Separate data into training and testing sets. ]]>
        </description>
        <variables>
          <variable name="TRAIN_SIZE" value="0.7" inherited="false" />
          <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
          <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
          <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
        </variables>
        <genericInformation>
          <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png"/>
          <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_split_data"/>
        </genericInformation>
        <depends>
          <task ref="Load_Boston_Dataset"/>
        </depends>
        <forkEnvironment javaHome="/usr" >
          <envScript>
            <script>
              <code language="python">
                <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
              </code>
            </script>
          </envScript>
        </forkEnvironment>
        <scriptExecutable>
          <script>
            <code language="cpython">
              <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split

TRAIN_SIZE = variables.get("TRAIN_SIZE")
assert TRAIN_SIZE is not None and TRAIN_SIZE is not ""
TRAIN_SIZE = float(TRAIN_SIZE)
test_size = 1 - TRAIN_SIZE

input_variables = {'task.dataframe_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = input_variables['task.dataframe_id']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

# Split dataframe into train/test sets
X_train, X_test = train_test_split(dataframe, test_size=test_size)

dataframe1 = X_train.reset_index(drop=True)
dataframe2 = X_test.reset_index(drop=True)

dataframe_json1 = dataframe1.to_json(orient='split').encode()
dataframe_json2 = dataframe2.to_json(orient='split').encode()

compressed_data1 = bz2.compress(dataframe_json1)
compressed_data2 = bz2.compress(dataframe_json2)

dataframe_id1 = str(uuid.uuid4())
dataframe_id2 = str(uuid.uuid4())

variables.put(dataframe_id1, compressed_data1)
variables.put(dataframe_id2, compressed_data2)

print("Train set:")
print("dataframe id1 (out): ", dataframe_id1)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json1), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data1), " bytes")
print(dataframe1.head())

print("Test set:")
print("dataframe id2 (out): ", dataframe_id2)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json2), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data2), " bytes")
print(dataframe2.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id_train", dataframe_id1)
resultMetadata.put("task.dataframe_id_test", dataframe_id2)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
              </code>
            </script>
          </scriptExecutable>
          <controlFlow block="none"></controlFlow>
        </task>
        <task name="Train_Model1" >
          <description>
            <![CDATA[ Train a model using a classification or regression algorithm. ]]>
          </description>
          <variables>
            <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
            <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
            <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
            <variable name="LABEL_COLUMN" value="LABEL" inherited="false" />
          </variables>
          <genericInformation>
            <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
            <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_train_model"/>
          </genericInformation>
          <depends>
            <task ref="Split_Data"/>
            <task ref="Linear_Regression"/>
          </depends>
          <forkEnvironment javaHome="/usr" >
            <envScript>
              <script>
                <code language="python">
                  <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                </code>
              </script>
            </envScript>
          </forkEnvironment>
          <scriptExecutable>
            <script>
              <code language="cpython">
                <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid, json
import random, pickle
import pandas as pd

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_train': None,
  'task.algorithm_json': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_train'] is not None:
  dataframe_id = input_variables['task.dataframe_id_train']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()
dataframe = pd.read_json(dataframe_json, orient='split')

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

if alg.is_supervised and is_labeled_data:
  model = None
  columns = [LABEL_COLUMN]
  dataframe_train = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  #-------------------------------------------------------------
  # Classification algorithms
  #
  if alg.name == 'SupportVectorMachines':
    from sklearn.svm import SVC
    model = SVC(
      C=alg.C, 
      kernel=alg.kernel
    )
   
  if alg.name == 'GaussianNaiveBayes':
    from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()
  
  if alg.name == 'LogisticRegression':
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(
      penalty=alg.penalty, 
      solver=alg.solver, 
      max_iter=alg.max_iter, 
      n_jobs=alg.n_jobs
    )

  #-------------------------------------------------------------
  # Regression algorithms
  if alg.name == 'LinearRegression':
    from sklearn.linear_model import LinearRegression
    model = LinearRegression(n_jobs=alg.n_jobs)

  if alg.name == 'SupportVectorRegression':
    from sklearn.svm import SVR
    model = SVR(
      C=alg.C, 
      kernel=alg.kernel, 
      epsilon=alg.epsilon
    )
  
  if alg.name == 'BayesianRidgeRegression':
    from sklearn.linear_model import BayesianRidge
    model = BayesianRidge(
      alpha_1=alg.alpha_1, 
      alpha_2=alg.alpha_2, 
      lambda_1=alg.lambda_1, 
      lambda_2=alg.lambda_2, 
      n_iter=alg.n_iter
    )
  #-------------------------------------------------------------

  if model is not None:
    model.fit(dataframe_train.values, dataframe_label.values.ravel())
    model_bin = pickle.dumps(model)
    model_compressed = bz2.compress(model_bin)
    model_id = str(uuid.uuid4())
    variables.put(model_id, model_compressed)
    print("model id: ", model_id)
    print('model size (original):   ', sys.getsizeof(model_bin), " bytes")
    print('model size (compressed): ', sys.getsizeof(model_compressed), " bytes")
    resultMetadata.put("task.model_id", model_id)
  else:
    print("Algorithm not found!")
else:
  print("The algorithm must be supervised and the dataframe must be labelled!")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.dataframe_id", dataframe_id)
resultMetadata.put("task.algorithm_json", algorithm_json)
resultMetadata.put("task.label_column", LABEL_COLUMN)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                </code>
              </script>
            </scriptExecutable>
            <controlFlow block="none"></controlFlow>
          </task>
          <task name="Train_Model2" >
            <description>
              <![CDATA[ Train a model using a classification or regression algorithm. ]]>
            </description>
            <variables>
              <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
              <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
              <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
              <variable name="LABEL_COLUMN" value="LABEL" inherited="false" />
            </variables>
            <genericInformation>
              <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
              <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_train_model"/>
            </genericInformation>
            <depends>
              <task ref="Split_Data"/>
              <task ref="Bayesian_Ridge_Regression"/>
            </depends>
            <forkEnvironment javaHome="/usr" >
              <envScript>
                <script>
                  <code language="python">
                    <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                  </code>
                </script>
              </envScript>
            </forkEnvironment>
            <scriptExecutable>
              <script>
                <code language="cpython">
                  <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid, json
import random, pickle
import pandas as pd

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_train': None,
  'task.algorithm_json': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_train'] is not None:
  dataframe_id = input_variables['task.dataframe_id_train']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()
dataframe = pd.read_json(dataframe_json, orient='split')

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

if alg.is_supervised and is_labeled_data:
  model = None
  columns = [LABEL_COLUMN]
  dataframe_train = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  #-------------------------------------------------------------
  # Classification algorithms
  #
  if alg.name == 'SupportVectorMachines':
    from sklearn.svm import SVC
    model = SVC(
      C=alg.C, 
      kernel=alg.kernel
    )
   
  if alg.name == 'GaussianNaiveBayes':
    from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()
  
  if alg.name == 'LogisticRegression':
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(
      penalty=alg.penalty, 
      solver=alg.solver, 
      max_iter=alg.max_iter, 
      n_jobs=alg.n_jobs
    )

  #-------------------------------------------------------------
  # Regression algorithms
  if alg.name == 'LinearRegression':
    from sklearn.linear_model import LinearRegression
    model = LinearRegression(n_jobs=alg.n_jobs)

  if alg.name == 'SupportVectorRegression':
    from sklearn.svm import SVR
    model = SVR(
      C=alg.C, 
      kernel=alg.kernel, 
      epsilon=alg.epsilon
    )
  
  if alg.name == 'BayesianRidgeRegression':
    from sklearn.linear_model import BayesianRidge
    model = BayesianRidge(
      alpha_1=alg.alpha_1, 
      alpha_2=alg.alpha_2, 
      lambda_1=alg.lambda_1, 
      lambda_2=alg.lambda_2, 
      n_iter=alg.n_iter
    )
  #-------------------------------------------------------------

  if model is not None:
    model.fit(dataframe_train.values, dataframe_label.values.ravel())
    model_bin = pickle.dumps(model)
    model_compressed = bz2.compress(model_bin)
    model_id = str(uuid.uuid4())
    variables.put(model_id, model_compressed)
    print("model id: ", model_id)
    print('model size (original):   ', sys.getsizeof(model_bin), " bytes")
    print('model size (compressed): ', sys.getsizeof(model_compressed), " bytes")
    resultMetadata.put("task.model_id", model_id)
  else:
    print("Algorithm not found!")
else:
  print("The algorithm must be supervised and the dataframe must be labelled!")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.dataframe_id", dataframe_id)
resultMetadata.put("task.algorithm_json", algorithm_json)
resultMetadata.put("task.label_column", LABEL_COLUMN)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                  </code>
                </script>
              </scriptExecutable>
              <controlFlow block="none"></controlFlow>
            </task>
            <task name="Train_Model3" >
              <description>
                <![CDATA[ Train a model using a classification or regression algorithm. ]]>
              </description>
              <variables>
                <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                <variable name="LABEL_COLUMN" value="LABEL" inherited="false" />
              </variables>
              <genericInformation>
                <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/train.png"/>
                <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_train_model"/>
              </genericInformation>
              <depends>
                <task ref="Split_Data"/>
                <task ref="Support_Vector_Regression"/>
              </depends>
              <forkEnvironment javaHome="/usr" >
                <envScript>
                  <script>
                    <code language="python">
                      <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                    </code>
                  </script>
                </envScript>
              </forkEnvironment>
              <scriptExecutable>
                <script>
                  <code language="cpython">
                    <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import sys, bz2, uuid, json
import random, pickle
import pandas as pd

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_train': None,
  'task.algorithm_json': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_train'] is not None:
  dataframe_id = input_variables['task.dataframe_id_train']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()
dataframe = pd.read_json(dataframe_json, orient='split')

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

if alg.is_supervised and is_labeled_data:
  model = None
  columns = [LABEL_COLUMN]
  dataframe_train = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  #-------------------------------------------------------------
  # Classification algorithms
  #
  if alg.name == 'SupportVectorMachines':
    from sklearn.svm import SVC
    model = SVC(
      C=alg.C, 
      kernel=alg.kernel
    )
   
  if alg.name == 'GaussianNaiveBayes':
    from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()
  
  if alg.name == 'LogisticRegression':
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(
      penalty=alg.penalty, 
      solver=alg.solver, 
      max_iter=alg.max_iter, 
      n_jobs=alg.n_jobs
    )

  #-------------------------------------------------------------
  # Regression algorithms
  if alg.name == 'LinearRegression':
    from sklearn.linear_model import LinearRegression
    model = LinearRegression(n_jobs=alg.n_jobs)

  if alg.name == 'SupportVectorRegression':
    from sklearn.svm import SVR
    model = SVR(
      C=alg.C, 
      kernel=alg.kernel, 
      epsilon=alg.epsilon
    )
  
  if alg.name == 'BayesianRidgeRegression':
    from sklearn.linear_model import BayesianRidge
    model = BayesianRidge(
      alpha_1=alg.alpha_1, 
      alpha_2=alg.alpha_2, 
      lambda_1=alg.lambda_1, 
      lambda_2=alg.lambda_2, 
      n_iter=alg.n_iter
    )
  #-------------------------------------------------------------

  if model is not None:
    model.fit(dataframe_train.values, dataframe_label.values.ravel())
    model_bin = pickle.dumps(model)
    model_compressed = bz2.compress(model_bin)
    model_id = str(uuid.uuid4())
    variables.put(model_id, model_compressed)
    print("model id: ", model_id)
    print('model size (original):   ', sys.getsizeof(model_bin), " bytes")
    print('model size (compressed): ', sys.getsizeof(model_compressed), " bytes")
    resultMetadata.put("task.model_id", model_id)
  else:
    print("Algorithm not found!")
else:
  print("The algorithm must be supervised and the dataframe must be labelled!")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.dataframe_id", dataframe_id)
resultMetadata.put("task.algorithm_json", algorithm_json)
resultMetadata.put("task.label_column", LABEL_COLUMN)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                    </code>
                  </script>
                </scriptExecutable>
                <controlFlow block="none"></controlFlow>
              </task>
              <task name="Linear_Regression" >
                <description>
                  <![CDATA[ Linear regression is a linear approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. ]]>
                </description>
                <variables>
                  <variable name="N_JOBS" value="1" inherited="false" />
                  <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                  <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                  <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                </variables>
                <genericInformation>
                  <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/ml_regresssion.png"/>
                  <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_linear_regression"/>
                </genericInformation>
                <forkEnvironment javaHome="/usr" >
                  <envScript>
                    <script>
                      <code language="python">
                        <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                      </code>
                    </script>
                  </envScript>
                </forkEnvironment>
                <scriptExecutable>
                  <script>
                    <code language="cpython">
                      <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import json

algorithm = {
  'name': 'LinearRegression',
  'is_supervised': True,
  'type': 'regression',
  'n_jobs': int(variables.get("N_JOBS"))
}

algorithm_json = json.dumps(algorithm)
resultMetadata.put("task.algorithm_json", algorithm_json)

print("END " + __file__)
]]>
                    </code>
                  </script>
                </scriptExecutable>
                <controlFlow block="none"></controlFlow>
              </task>
              <task name="Bayesian_Ridge_Regression" >
                <description>
                  <![CDATA[ Bayesian linear regression is an approach to linear regression in which the statistical analysis is undertaken within the context of Bayesian inference. ]]>
                </description>
                <variables>
                  <variable name="N_ITERATIONS" value="300" inherited="false" />
                  <variable name="ALPHA_1" value="1.e-6" inherited="false" />
                  <variable name="ALPHA_2" value="1.e-6" inherited="false" />
                  <variable name="LAMBDA_1" value="1.e-6" inherited="false" />
                  <variable name="LAMBDA_2" value="1.e-6" inherited="false" />
                  <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                  <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                  <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                </variables>
                <genericInformation>
                  <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/ml_regresssion.png"/>
                  <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_bayesian_ridge_regression"/>
                </genericInformation>
                <forkEnvironment javaHome="/usr" >
                  <envScript>
                    <script>
                      <code language="python">
                        <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = 'activeeon/dlm3' 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                      </code>
                    </script>
                  </envScript>
                </forkEnvironment>
                <scriptExecutable>
                  <script>
                    <code language="cpython">
                      <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import json

algorithm = {
  'name': 'BayesianRidgeRegression',
  'is_supervised': True,
  'type': 'regression',
  'alpha_1': float(variables.get("ALPHA_1")),
  'alpha_2': float(variables.get("ALPHA_2")),
  'lambda_1': float(variables.get("LAMBDA_1")),
  'lambda_2': float(variables.get("LAMBDA_2")),
  'n_iter': int(variables.get("N_ITERATIONS"))
}

algorithm_json = json.dumps(algorithm)
resultMetadata.put("task.algorithm_json", algorithm_json)

print("END " + __file__)
]]>
                    </code>
                  </script>
                </scriptExecutable>
                <controlFlow block="none"></controlFlow>
              </task>
              <task name="Support_Vector_Regression" >
                <description>
                  <![CDATA[ Support vector regression are supervised learning models with associated learning algorithms that analyze data used for regression. ]]>
                </description>
                <variables>
                  <variable name="C" value="1.0" inherited="false" />
                  <variable name="KERNEL" value="rbf" inherited="false" />
                  <variable name="EPSILON" value="0.1" inherited="false" />
                  <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                  <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                  <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                </variables>
                <genericInformation>
                  <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/ml_regresssion.png"/>
                  <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_support_vector_regression"/>
                </genericInformation>
                <forkEnvironment javaHome="/usr" >
                  <envScript>
                    <script>
                      <code language="python">
                        <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                      </code>
                    </script>
                  </envScript>
                </forkEnvironment>
                <scriptExecutable>
                  <script>
                    <code language="cpython">
                      <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import json

algorithm = {
  'name': 'SupportVectorRegression',
  'is_supervised': True,
  'type': 'regression',
  'C': float(variables.get("C")),
  'kernel': variables.get("KERNEL"),
  'epsilon': float(variables.get("EPSILON"))
}

algorithm_json = json.dumps(algorithm)
resultMetadata.put("task.algorithm_json", algorithm_json)

print("END " + __file__)
]]>
                    </code>
                  </script>
                </scriptExecutable>
                <controlFlow block="none"></controlFlow>
              </task>
              <task name="Predict_Model" >
                <description>
                  <![CDATA[ Generate predictions using a trained model. ]]>
                </description>
                <variables>
                  <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                  <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                  <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                  <variable name="LABEL_COLUMN" value="" inherited="false" />
                </variables>
                <genericInformation>
                  <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/predict.png"/>
                  <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_predict_model"/>
                </genericInformation>
                <depends>
                  <task ref="Train_Model1"/>
                  <task ref="Split_Data"/>
                </depends>
                <forkEnvironment javaHome="/usr" >
                  <envScript>
                    <script>
                      <code language="python">
                        <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                      </code>
                    </script>
                  </envScript>
                </forkEnvironment>
                <scriptExecutable>
                  <script>
                    <code language="cpython">
                      <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2, uuid, json
import random, pickle, sklearn
import numpy as np
import pandas as pd

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_test': None,
  'task.algorithm_json': None,
  'task.label_column': None,
  'task.model_id': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_test'] is not None:
  dataframe_id = input_variables['task.dataframe_id_test']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True
else:
  LABEL_COLUMN = input_variables['task.label_column']
  if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
    is_labeled_data = True

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None
print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

dataframe_predictions = None
if alg.is_supervised and is_labeled_data:
  columns = [LABEL_COLUMN]
  dataframe_test = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  loaded_model = pickle.loads(model_bin)
  score = loaded_model.score(dataframe_test.values, dataframe_label.values.ravel())
  predictions = list(loaded_model.predict(dataframe_test.values))

  dataframe_predictions = pd.DataFrame(predictions)
  dataframe = dataframe.assign(predictions=dataframe_predictions)
  
  print("MODEL SCORE: %.2f" % score)

  #-------------------------------------------------------------
  # CLASSIFICATION SCORE
  #
  if alg.type == 'classification':
    dataframe['accuracy'] = np.where((dataframe[LABEL_COLUMN] == dataframe['predictions']), 1, 0)
    accuracy_score_result = accuracy_score(dataframe_label.values.ravel(), predictions)
    precision_score_result = precision_score(dataframe_label.values.ravel(), predictions, average='micro')
    confusion_matrix_result = confusion_matrix(dataframe_label.values.ravel(), predictions)
    print("********************** CLASSIFICATION SCORE **********************")
    print("ACCURACY SCORE: %.2f" % accuracy_score_result)
    print("PRECISION SCORE: %.2f" % precision_score_result)
    print("CONFUSION MATRIX:\n%s" % confusion_matrix_result)
    print("*******************************************************************")

  #-------------------------------------------------------------
  # REGRESSION SCORE
  #
  if alg.type == 'regression':
    dataframe['absolute_error'] = dataframe[LABEL_COLUMN] - dataframe['predictions']
    mean_squared_error_result = mean_squared_error(dataframe_label.values.ravel(), predictions)
    mean_absolute_error_result = mean_absolute_error(dataframe_label.values.ravel(), predictions)
    r2_score_result = r2_score(dataframe_label.values.ravel(), predictions) 
    print("********************** REGRESSION SCORES **********************")
    print("MEAN SQUARED ERROR: %.2f" % mean_squared_error_result)
    print("MEAN ABSOLUTE ERROR: %.2f" % mean_absolute_error_result)
    print("R2 SCORE: %.2f" % r2_score_result)
    print("***************************************************************")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                      </code>
                    </script>
                  </scriptExecutable>
                  <controlFlow block="none"></controlFlow>
                </task>
                <task name="Predict_Model2" >
                  <description>
                    <![CDATA[ Generate predictions using a trained model. ]]>
                  </description>
                  <variables>
                    <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                    <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                    <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                    <variable name="LABEL_COLUMN" value="" inherited="false" />
                  </variables>
                  <genericInformation>
                    <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/predict.png"/>
                    <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_predict_model"/>
                  </genericInformation>
                  <depends>
                    <task ref="Train_Model2"/>
                    <task ref="Split_Data"/>
                  </depends>
                  <forkEnvironment javaHome="/usr" >
                    <envScript>
                      <script>
                        <code language="python">
                          <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                        </code>
                      </script>
                    </envScript>
                  </forkEnvironment>
                  <scriptExecutable>
                    <script>
                      <code language="cpython">
                        <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2, uuid, json
import random, pickle, sklearn
import numpy as np
import pandas as pd

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_test': None,
  'task.algorithm_json': None,
  'task.label_column': None,
  'task.model_id': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_test'] is not None:
  dataframe_id = input_variables['task.dataframe_id_test']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True
else:
  LABEL_COLUMN = input_variables['task.label_column']
  if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
    is_labeled_data = True

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None
print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

dataframe_predictions = None
if alg.is_supervised and is_labeled_data:
  columns = [LABEL_COLUMN]
  dataframe_test = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  loaded_model = pickle.loads(model_bin)
  score = loaded_model.score(dataframe_test.values, dataframe_label.values.ravel())
  predictions = list(loaded_model.predict(dataframe_test.values))

  dataframe_predictions = pd.DataFrame(predictions)
  dataframe = dataframe.assign(predictions=dataframe_predictions)
  
  print("MODEL SCORE: %.2f" % score)

  #-------------------------------------------------------------
  # CLASSIFICATION SCORE
  #
  if alg.type == 'classification':
    dataframe['accuracy'] = np.where((dataframe[LABEL_COLUMN] == dataframe['predictions']), 1, 0)
    accuracy_score_result = accuracy_score(dataframe_label.values.ravel(), predictions)
    precision_score_result = precision_score(dataframe_label.values.ravel(), predictions, average='micro')
    confusion_matrix_result = confusion_matrix(dataframe_label.values.ravel(), predictions)
    print("********************** CLASSIFICATION SCORE **********************")
    print("ACCURACY SCORE: %.2f" % accuracy_score_result)
    print("PRECISION SCORE: %.2f" % precision_score_result)
    print("CONFUSION MATRIX:\n%s" % confusion_matrix_result)
    print("*******************************************************************")

  #-------------------------------------------------------------
  # REGRESSION SCORE
  #
  if alg.type == 'regression':
    dataframe['absolute_error'] = dataframe[LABEL_COLUMN] - dataframe['predictions']
    mean_squared_error_result = mean_squared_error(dataframe_label.values.ravel(), predictions)
    mean_absolute_error_result = mean_absolute_error(dataframe_label.values.ravel(), predictions)
    r2_score_result = r2_score(dataframe_label.values.ravel(), predictions) 
    print("********************** REGRESSION SCORES **********************")
    print("MEAN SQUARED ERROR: %.2f" % mean_squared_error_result)
    print("MEAN ABSOLUTE ERROR: %.2f" % mean_absolute_error_result)
    print("R2 SCORE: %.2f" % r2_score_result)
    print("***************************************************************")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                        </code>
                      </script>
                    </scriptExecutable>
                    <controlFlow block="none"></controlFlow>
                  </task>
                  <task name="Predict_Model3" >
                    <description>
                      <![CDATA[ Generate predictions using a trained model. ]]>
                    </description>
                    <variables>
                      <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                      <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                      <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                      <variable name="LABEL_COLUMN" value="" inherited="false" />
                    </variables>
                    <genericInformation>
                      <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/predict.png"/>
                      <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_predict_model"/>
                    </genericInformation>
                    <depends>
                      <task ref="Train_Model3"/>
                      <task ref="Split_Data"/>
                    </depends>
                    <forkEnvironment javaHome="/usr" >
                      <envScript>
                        <script>
                          <code language="python">
                            <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                          </code>
                        </script>
                      </envScript>
                    </forkEnvironment>
                    <scriptExecutable>
                      <script>
                        <code language="cpython">
                          <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2, uuid, json
import random, pickle, sklearn
import numpy as np
import pandas as pd

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score

input_variables = {
  'task.dataframe_id': None, 
  'task.dataframe_id_test': None,
  'task.algorithm_json': None,
  'task.label_column': None,
  'task.model_id': None
}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = None
if input_variables['task.dataframe_id'] is not None:
  dataframe_id = input_variables['task.dataframe_id']
if input_variables['task.dataframe_id_test'] is not None:
  dataframe_id = input_variables['task.dataframe_id_test']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')

is_labeled_data = False
LABEL_COLUMN = variables.get("LABEL_COLUMN")
if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
  is_labeled_data = True
else:
  LABEL_COLUMN = input_variables['task.label_column']
  if LABEL_COLUMN is not None and LABEL_COLUMN is not "":
    is_labeled_data = True

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None
print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

algorithm_json = input_variables['task.algorithm_json']
assert algorithm_json is not None
algorithm = json.loads(algorithm_json)
#-------------------------------------------------------------
class obj(object):
  def __init__(self, d):
    for a, b in d.items():
      if isinstance(b, (list, tuple)):
        setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])
      else:
        setattr(self, a, obj(b) if isinstance(b, dict) else b)
#-------------------------------------------------------------
alg = obj(algorithm)

dataframe_predictions = None
if alg.is_supervised and is_labeled_data:
  columns = [LABEL_COLUMN]
  dataframe_test = dataframe.drop(columns, axis=1, inplace=False)
  dataframe_label = dataframe.filter(columns, axis=1)

  loaded_model = pickle.loads(model_bin)
  score = loaded_model.score(dataframe_test.values, dataframe_label.values.ravel())
  predictions = list(loaded_model.predict(dataframe_test.values))

  dataframe_predictions = pd.DataFrame(predictions)
  dataframe = dataframe.assign(predictions=dataframe_predictions)
  
  print("MODEL SCORE: %.2f" % score)

  #-------------------------------------------------------------
  # CLASSIFICATION SCORE
  #
  if alg.type == 'classification':
    dataframe['accuracy'] = np.where((dataframe[LABEL_COLUMN] == dataframe['predictions']), 1, 0)
    accuracy_score_result = accuracy_score(dataframe_label.values.ravel(), predictions)
    precision_score_result = precision_score(dataframe_label.values.ravel(), predictions, average='micro')
    confusion_matrix_result = confusion_matrix(dataframe_label.values.ravel(), predictions)
    print("********************** CLASSIFICATION SCORE **********************")
    print("ACCURACY SCORE: %.2f" % accuracy_score_result)
    print("PRECISION SCORE: %.2f" % precision_score_result)
    print("CONFUSION MATRIX:\n%s" % confusion_matrix_result)
    print("*******************************************************************")

  #-------------------------------------------------------------
  # REGRESSION SCORE
  #
  if alg.type == 'regression':
    dataframe['absolute_error'] = dataframe[LABEL_COLUMN] - dataframe['predictions']
    mean_squared_error_result = mean_squared_error(dataframe_label.values.ravel(), predictions)
    mean_absolute_error_result = mean_absolute_error(dataframe_label.values.ravel(), predictions)
    r2_score_result = r2_score(dataframe_label.values.ravel(), predictions) 
    print("********************** REGRESSION SCORES **********************")
    print("MEAN SQUARED ERROR: %.2f" % mean_squared_error_result)
    print("MEAN ABSOLUTE ERROR: %.2f" % mean_absolute_error_result)
    print("R2 SCORE: %.2f" % r2_score_result)
    print("***************************************************************")

dataframe_json = dataframe.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id (out): ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")
print(dataframe.head())

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)

LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()

#============================== Preview results ===============================
#***************# HTML PREVIEW STYLING #***************#
styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
]
#******************************************************#

with pd.option_context('display.max_colwidth', -1):
  result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
  resultMetadata.put("file.extension", ".html")
  resultMetadata.put("file.name", "output.html")
  resultMetadata.put("content.type", "text/html")
#==============================================================================

print("END " + __file__)
]]>
                          </code>
                        </script>
                      </scriptExecutable>
                      <controlFlow block="none"></controlFlow>
                    </task>
                    <task name="Preview_Results1" >
                      <description>
                        <![CDATA[ Export the results. ]]>
                      </description>
                      <variables>
                        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                        <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                        <variable name="OUTPUT_TYPE" value="HTML" inherited="false" model="PA:LIST(CSV,JSON,HTML)"/>
                        <variable name="LIMIT_OUTPUT_VIEW" value="1000" inherited="false" model="PA:Integer"/>
                      </variables>
                      <genericInformation>
                        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png"/>
                        <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_export_results"/>
                      </genericInformation>
                      <depends>
                        <task ref="Predict_Model"/>
                      </depends>
                      <forkEnvironment javaHome="/usr" >
                        <envScript>
                          <script>
                            <code language="python">
                              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                            </code>
                          </script>
                        </envScript>
                      </forkEnvironment>
                      <scriptExecutable>
                        <script>
                          <code language="cpython">
                            <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import pandas as pd
import numpy as np
import bz2

OUTPUT_TYPE = variables.get("OUTPUT_TYPE")
assert OUTPUT_TYPE is not None and OUTPUT_TYPE is not ""

input_variables = {'task.dataframe_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = input_variables['task.dataframe_id']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')
print(dataframe.head())

OUTPUT_TYPE = OUTPUT_TYPE.upper()
if OUTPUT_TYPE == "S3":
  import s3fs, uuid

  UserAccessKeyID=str(variables.get('UserAccessKeyID'))
  UserSecretAccessKey=str(variables.get('UserSecretAccessKey'))
  UserBucketPath=variables.get('UserBucketPath')

  dataframe_id = str(uuid.uuid4())
  print("dataframe id (out): ", dataframe_id)
  bytes_to_write = dataframe.to_csv(index=False).encode()

  fs = s3fs.S3FileSystem(
      key=UserAccessKeyID, 
      secret=UserSecretAccessKey,
      s3_additional_kwargs={'ACL': 'public-read'}
  )

  bucket_path=str(UserBucketPath) if UserBucketPath is not None else 's3://activeeon-public/results/'
  s3file_path = bucket_path+dataframe_id+'.csv'
  with fs.open(s3file_path, 'wb') as f:
    f.write(bytes_to_write)

  dataframe_url = fs.url(s3file_path).split('?')[0]
  dataframe_info = fs.info(s3file_path)
  print("The dataframe was uploaded successfully to the following url:")
  print(dataframe_url)
  print("File info:")
  print(dataframe_info)

if OUTPUT_TYPE == "CSV":
  #result = dataframe.to_csv(encoding='utf-8', index=False)
  result = dataframe.to_csv(index=False)
  resultMetadata.put("file.extension", ".csv")
  resultMetadata.put("file.name", "dataframe.csv")
  resultMetadata.put("content.type", "text/csv")

if OUTPUT_TYPE == "JSON":
  result = dataframe.to_json(orient='split', encoding='utf-8')
  resultMetadata.put("file.extension", ".json")
  resultMetadata.put("file.name", "dataframe.json")
  resultMetadata.put("content.type", "application/json")

if OUTPUT_TYPE == "HTML":
  LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
  LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
  if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
  
  #***************# HTML PREVIEW STYLING #***************#
  styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
  ]
  #******************************************************#

  with pd.option_context('display.max_colwidth', -1):
    result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")

print("END " + __file__)
]]>
                            </code>
                          </script>
                        </scriptExecutable>
                        <controlFlow block="none"></controlFlow>
                      </task>
                      <task name="Preview_Results2" >
                        <description>
                          <![CDATA[ Export the results. ]]>
                        </description>
                        <variables>
                          <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                          <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                          <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                          <variable name="OUTPUT_TYPE" value="HTML" inherited="false" model="PA:LIST(CSV,JSON,HTML)"/>
                          <variable name="LIMIT_OUTPUT_VIEW" value="1000" inherited="false" model="PA:Integer"/>
                        </variables>
                        <genericInformation>
                          <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png"/>
                          <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_export_results"/>
                        </genericInformation>
                        <depends>
                          <task ref="Predict_Model2"/>
                        </depends>
                        <forkEnvironment javaHome="/usr" >
                          <envScript>
                            <script>
                              <code language="python">
                                <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                              </code>
                            </script>
                          </envScript>
                        </forkEnvironment>
                        <scriptExecutable>
                          <script>
                            <code language="cpython">
                              <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import pandas as pd
import numpy as np
import bz2

OUTPUT_TYPE = variables.get("OUTPUT_TYPE")
assert OUTPUT_TYPE is not None and OUTPUT_TYPE is not ""

input_variables = {'task.dataframe_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = input_variables['task.dataframe_id']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')
print(dataframe.head())

OUTPUT_TYPE = OUTPUT_TYPE.upper()
if OUTPUT_TYPE == "S3":
  import s3fs, uuid

  UserAccessKeyID=str(variables.get('UserAccessKeyID'))
  UserSecretAccessKey=str(variables.get('UserSecretAccessKey'))
  UserBucketPath=variables.get('UserBucketPath')

  dataframe_id = str(uuid.uuid4())
  print("dataframe id (out): ", dataframe_id)
  bytes_to_write = dataframe.to_csv(index=False).encode()

  fs = s3fs.S3FileSystem(
      key=UserAccessKeyID, 
      secret=UserSecretAccessKey,
      s3_additional_kwargs={'ACL': 'public-read'}
  )

  bucket_path=str(UserBucketPath) if UserBucketPath is not None else 's3://activeeon-public/results/'
  s3file_path = bucket_path+dataframe_id+'.csv'
  with fs.open(s3file_path, 'wb') as f:
    f.write(bytes_to_write)

  dataframe_url = fs.url(s3file_path).split('?')[0]
  dataframe_info = fs.info(s3file_path)
  print("The dataframe was uploaded successfully to the following url:")
  print(dataframe_url)
  print("File info:")
  print(dataframe_info)

if OUTPUT_TYPE == "CSV":
  #result = dataframe.to_csv(encoding='utf-8', index=False)
  result = dataframe.to_csv(index=False)
  resultMetadata.put("file.extension", ".csv")
  resultMetadata.put("file.name", "dataframe.csv")
  resultMetadata.put("content.type", "text/csv")

if OUTPUT_TYPE == "JSON":
  result = dataframe.to_json(orient='split', encoding='utf-8')
  resultMetadata.put("file.extension", ".json")
  resultMetadata.put("file.name", "dataframe.json")
  resultMetadata.put("content.type", "application/json")

if OUTPUT_TYPE == "HTML":
  LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
  LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
  if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
  
  #***************# HTML PREVIEW STYLING #***************#
  styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
  ]
  #******************************************************#

  with pd.option_context('display.max_colwidth', -1):
    result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")

print("END " + __file__)
]]>
                              </code>
                            </script>
                          </scriptExecutable>
                          <controlFlow block="none"></controlFlow>
                        </task>
                        <task name="Preview_Results3" >
                          <description>
                            <![CDATA[ Export the results. ]]>
                          </description>
                          <variables>
                            <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                            <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                            <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                            <variable name="OUTPUT_TYPE" value="HTML" inherited="false" model="PA:LIST(CSV,JSON,HTML)"/>
                            <variable name="LIMIT_OUTPUT_VIEW" value="1000" inherited="false" model="PA:Integer"/>
                          </variables>
                          <genericInformation>
                            <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png"/>
                            <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_export_results"/>
                          </genericInformation>
                          <depends>
                            <task ref="Predict_Model3"/>
                          </depends>
                          <forkEnvironment javaHome="/usr" >
                            <envScript>
                              <script>
                                <code language="python">
                                  <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                                </code>
                              </script>
                            </envScript>
                          </forkEnvironment>
                          <scriptExecutable>
                            <script>
                              <code language="cpython">
                                <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import pandas as pd
import numpy as np
import bz2

OUTPUT_TYPE = variables.get("OUTPUT_TYPE")
assert OUTPUT_TYPE is not None and OUTPUT_TYPE is not ""

input_variables = {'task.dataframe_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = input_variables['task.dataframe_id']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe = pd.read_json(dataframe_json, orient='split')
print(dataframe.head())

OUTPUT_TYPE = OUTPUT_TYPE.upper()
if OUTPUT_TYPE == "S3":
  import s3fs, uuid

  UserAccessKeyID=str(variables.get('UserAccessKeyID'))
  UserSecretAccessKey=str(variables.get('UserSecretAccessKey'))
  UserBucketPath=variables.get('UserBucketPath')

  dataframe_id = str(uuid.uuid4())
  print("dataframe id (out): ", dataframe_id)
  bytes_to_write = dataframe.to_csv(index=False).encode()

  fs = s3fs.S3FileSystem(
      key=UserAccessKeyID, 
      secret=UserSecretAccessKey,
      s3_additional_kwargs={'ACL': 'public-read'}
  )

  bucket_path=str(UserBucketPath) if UserBucketPath is not None else 's3://activeeon-public/results/'
  s3file_path = bucket_path+dataframe_id+'.csv'
  with fs.open(s3file_path, 'wb') as f:
    f.write(bytes_to_write)

  dataframe_url = fs.url(s3file_path).split('?')[0]
  dataframe_info = fs.info(s3file_path)
  print("The dataframe was uploaded successfully to the following url:")
  print(dataframe_url)
  print("File info:")
  print(dataframe_info)

if OUTPUT_TYPE == "CSV":
  #result = dataframe.to_csv(encoding='utf-8', index=False)
  result = dataframe.to_csv(index=False)
  resultMetadata.put("file.extension", ".csv")
  resultMetadata.put("file.name", "dataframe.csv")
  resultMetadata.put("content.type", "text/csv")

if OUTPUT_TYPE == "JSON":
  result = dataframe.to_json(orient='split', encoding='utf-8')
  resultMetadata.put("file.extension", ".json")
  resultMetadata.put("file.name", "dataframe.json")
  resultMetadata.put("content.type", "application/json")

if OUTPUT_TYPE == "HTML":
  LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")
  LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
  if LIMIT_OUTPUT_VIEW > 0:
    print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
    dataframe = dataframe.head(LIMIT_OUTPUT_VIEW).copy()
  
  #***************# HTML PREVIEW STYLING #***************#
  styles = [
    dict(selector="th", props=[("font-weight", "bold"),
                               ("text-align", "center"),
                               ("font-size", "15px"),
                               ("background", "#0B6FA4"),
                               ("color", "#FFFFFF")]),
                               ("padding", "3px 7px"),
    dict(selector="td", props=[("text-align", "right"),
                               ("padding", "3px 3px"),
                               ("border", "1px solid #999999"),
                               ("font-size", "13px"),
                               ("border-bottom", "1px solid #0B6FA4")]),
    dict(selector="table", props=[("border", "1px solid #999999"),
                               ("text-align", "center"),
                               ("width", "100%"),
                               ("border-collapse", "collapse")])
  ]
  #******************************************************#

  with pd.option_context('display.max_colwidth', -1):
    result = dataframe.style.set_table_styles(styles).render().encode('utf-8')
    resultMetadata.put("file.extension", ".html")
    resultMetadata.put("file.name", "output.html")
    resultMetadata.put("content.type", "text/html")

print("END " + __file__)
]]>
                                </code>
                              </script>
                            </scriptExecutable>
                            <controlFlow block="none"></controlFlow>
                          </task>
                          <task name="Download_Model" >
                            <description>
                              <![CDATA[ Download a trained model. ]]>
                            </description>
                            <variables>
                              <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                              <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                              <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                            </variables>
                            <genericInformation>
                              <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png"/>
                              <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_download_model"/>
                            </genericInformation>
                            <depends>
                              <task ref="Train_Model1"/>
                            </depends>
                            <forkEnvironment javaHome="/usr" >
                              <envScript>
                                <script>
                                  <code language="python">
                                    <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                                  </code>
                                </script>
                              </envScript>
                            </forkEnvironment>
                            <scriptExecutable>
                              <script>
                                <code language="cpython">
                                  <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2

input_variables = {'task.model_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None

print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

assert model_bin is not None
result = model_bin

#resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.model_bin", model_bin)

resultMetadata.put("file.extension", ".model")
resultMetadata.put("file.name", "myModel.model")
resultMetadata.put("content.type", "application/octet-stream")

print("END " + __file__)
]]>
                                </code>
                              </script>
                            </scriptExecutable>
                            <controlFlow block="none"></controlFlow>
                          </task>
                          <task name="Download_Model2" >
                            <description>
                              <![CDATA[ Download a trained model. ]]>
                            </description>
                            <variables>
                              <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                              <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                              <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                            </variables>
                            <genericInformation>
                              <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png"/>
                              <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_download_model"/>
                            </genericInformation>
                            <depends>
                              <task ref="Train_Model2"/>
                            </depends>
                            <forkEnvironment javaHome="/usr" >
                              <envScript>
                                <script>
                                  <code language="python">
                                    <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                                  </code>
                                </script>
                              </envScript>
                            </forkEnvironment>
                            <scriptExecutable>
                              <script>
                                <code language="cpython">
                                  <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2

input_variables = {'task.model_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None

print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

assert model_bin is not None
result = model_bin

#resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.model_bin", model_bin)

resultMetadata.put("file.extension", ".model")
resultMetadata.put("file.name", "myModel.model")
resultMetadata.put("content.type", "application/octet-stream")

print("END " + __file__)
]]>
                                </code>
                              </script>
                            </scriptExecutable>
                            <controlFlow block="none"></controlFlow>
                          </task>
                          <task name="Download_Model3" >
                            <description>
                              <![CDATA[ Download a trained model. ]]>
                            </description>
                            <variables>
                              <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
                              <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
                              <variable name="TASK_ENABLED" value="True" inherited="false" model="PA:Boolean"/>
                            </variables>
                            <genericInformation>
                              <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png"/>
                              <info name="task.documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_download_model"/>
                            </genericInformation>
                            <depends>
                              <task ref="Train_Model3"/>
                            </depends>
                            <forkEnvironment javaHome="/usr" >
                              <envScript>
                                <script>
                                  <code language="python">
                                    <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
                                  </code>
                                </script>
                              </envScript>
                            </forkEnvironment>
                            <scriptExecutable>
                              <script>
                                <code language="cpython">
                                  <![CDATA[
__file__ = variables.get("PA_TASK_NAME")

if str(variables.get("TASK_ENABLED")).lower() != 'true':
  print("Task " + __file__ + " disabled")
  quit()

print("BEGIN " + __file__)

import os, sys, bz2

input_variables = {'task.model_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

model_id = input_variables['task.model_id']
model_compressed = variables.get(model_id)
model_bin = bz2.decompress(model_compressed)
assert model_bin is not None

print("model id (in): ", model_id)
print("model size: ", sys.getsizeof(model_compressed), " bytes")
print("model size (decompressed): ", sys.getsizeof(model_bin), " bytes")

assert model_bin is not None
result = model_bin

#resultMetadata.put("task.name", __file__)
#resultMetadata.put("task.model_bin", model_bin)

resultMetadata.put("file.extension", ".model")
resultMetadata.put("file.name", "myModel.model")
resultMetadata.put("content.type", "application/octet-stream")

print("END " + __file__)
]]>
                                </code>
                              </script>
                            </scriptExecutable>
                            <controlFlow block="none"></controlFlow>
                          </task>
                        </taskFlow>
                        <metadata>
                          <visualization>
                            <![CDATA[ <html><head><link rel="stylesheet" href="/studio/styles/studio-standalone.css"><style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:1122px;
            height:646px;
            }
        </style></head><body><div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-78px;left:-131.5875244140625px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2973" style="top: 83px; left: 458.1px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/load_dataset.png" width="20px">&nbsp;<span class="name">Load_Boston_Dataset</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2976" style="top: 211px; left: 458.1px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/data-processing.png" width="20px">&nbsp;<span class="name">Split_Data</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2979" style="top: 339px; left: 141.6px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/train.png" width="20px">&nbsp;<span class="name">Train_Model1</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2982" style="top: 339px; left: 554.1px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/train.png" width="20px">&nbsp;<span class="name">Train_Model2</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2985" style="top: 339px; left: 890.35px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/train.png" width="20px">&nbsp;<span class="name">Train_Model3</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2988" style="top: 211px; left: 136.6px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/ml_regresssion.png" width="20px">&nbsp;<span class="name">Linear_Regression</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2991" style="top: 211px; left: 628.1px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/ml_regresssion.png" width="20px">&nbsp;<span class="name">Bayesian_Ridge_Regression</span></a></div><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_2994" style="top: 211px; left: 895.35px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/ml_regresssion.png" width="20px">&nbsp;<span class="name">Support_Vector_Regression</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_2997" style="top: 467px; left: 157px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/predict.png" width="20px">&nbsp;<span class="name">Predict_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_3000" style="top: 467px; left: 447px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/predict.png" width="20px">&nbsp;<span class="name">Predict_Model2</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_3003" style="top: 467px; left: 745.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/predict.png" width="20px">&nbsp;<span class="name">Predict_Model3</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_3006" style="top: 595px; left: 157px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png" width="20px">&nbsp;<span class="name">Preview_Results1</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_3009" style="top: 595px; left: 447px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png" width="20px">&nbsp;<span class="name">Preview_Results2</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_3012" style="top: 595px; left: 745.5px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/export_data.png" width="20px">&nbsp;<span class="name">Preview_Results3</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_3015" style="top: 467px; left: 301px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png" width="20px">&nbsp;<span class="name">Download_Model</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_3018" style="top: 467px; left: 596px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png" width="20px">&nbsp;<span class="name">Download_Model2</span></a></div><div class="task ui-draggable _jsPlumb_endpoint_anchor_" id="jsPlumb_1_3021" style="top: 467px; left: 895px;"><a class="task-name"><img src="/automation-dashboard/styles/patterns/img/wf-icons/download_model.png" width="20px">&nbsp;<span class="name">Download_Model3</span></a></div><svg style="position:absolute;left:497.5px;top:122.5px" width="38" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 27 50 17 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-1.3798080000000006,66.303232 L10.352421397765497,48.6579835359458 L2.0852028728218883,52.7388042696744 L-3.212006332560102,45.19297266312391 L-1.3798080000000006,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-1.3798080000000006,66.303232 L10.352421397765497,48.6579835359458 L2.0852028728218883,52.7388042696744 L-3.212006332560102,45.19297266312391 L-1.3798080000000006,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:181.5px;top:250.5px" width="337" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 326 50 316 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M55.8573125,58.2374375 L76.80264179354393,61.44573623687141 L69.61924006883228,55.666571966718685 L74.23177626026262,47.68380866803912 L55.8573125,58.2374375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M55.8573125,58.2374375 L76.80264179354393,61.44573623687141 L69.61924006883228,55.666571966718685 L74.23177626026262,47.68380866803912 L55.8573125,58.2374375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:181.5px;top:250.5px" width="25" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 14 50 4 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-2.4906875000000004,66.78168750000002 L6.088432834392776,47.40647926142854 L-1.3695665952116438,52.82664941632405 L-7.866605249283188,46.28535835664018 L-2.4906875000000004,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-2.4906875000000004,66.78168750000002 L6.088432834392776,47.40647926142854 L-1.3695665952116438,52.82664941632405 L-7.866605249283188,46.28535835664018 L-2.4906875000000004,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:497.5px;top:250.5px" width="117" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 96 88 C 106 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M86.48418750000002,62.2538125 L73.809011182591,45.27323814803553 L74.87361811165471,54.43110973954573 L65.98630842213673,56.88380753638084 L86.48418750000002,62.2538125" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M86.48418750000002,62.2538125 L73.809011182591,45.27323814803553 L74.87361811165471,54.43110973954573 L65.98630842213673,56.88380753638084 L86.48418750000002,62.2538125" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:593.5px;top:250.5px" width="127" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 116 50 106 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M11.373775999999998,61.830692 L32.1119500181267,57.480043957018964 L23.35668294178916,54.591220940287066 L24.87247895841376,45.4971370152298 L11.373775999999998,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M11.373775999999998,61.830692 L32.1119500181267,57.480043957018964 L23.35668294178916,54.591220940287066 L24.87247895841376,45.4971370152298 L11.373775999999998,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:497.5px;top:250.5px" width="453" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 432 88 C 442 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M352.021248,57.860352000000006 L333.1450302351593,48.23287035139046 L338.14856609416677,55.976553513014956 L331.2612317481743,62.10555225722369 L352.021248,57.860352000000006" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M352.021248,57.860352000000006 L333.1450302351593,48.23287035139046 L338.14856609416677,55.976553513014956 L331.2612317481743,62.10555225722369 L352.021248,57.860352000000006" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:929.5px;top:250.5px" width="56" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 45 50 35 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M0.44782999999999823,65.364084 L15.791408772376329,50.74989259383995 L6.826474317286607,52.90162450463765 L3.3289492770139786,44.37124827655334 L0.44782999999999823,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M0.44782999999999823,65.364084 L15.791408772376329,50.74989259383995 L6.826474317286607,52.90162450463765 L3.3289492770139786,44.37124827655334 L0.44782999999999823,65.364084" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:181.5px;top:378.5px" width="36" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 15 88 C 25 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M16.55088,66.303232 L18.90737940053047,45.245052815291274 L13.424194637075896,52.656846447727325 L5.260993848257804,48.37173817821538 L16.55088,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M16.55088,66.303232 L18.90737940053047,45.245052815291274 L13.424194637075896,52.656846447727325 L5.260993848257804,48.37173817821538 L16.55088,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:196.5px;top:250.5px" width="322" height="217" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 216 C -10 166 311 50 301 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M53.07809375000001,162.5214375 L73.78626221148227,158.0301393612798 L65.01159030149323,155.20080500987325 L66.46562972135553,146.0966428097866 L53.07809375000001,162.5214375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M53.07809375000001,162.5214375 L73.78626221148227,158.0301393612798 L65.01159030149323,155.20080500987325 L66.46562972135553,146.0966428097866 L53.07809375000001,162.5214375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:488.5px;top:378.5px" width="126" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 115 50 105 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M11.23941,61.830692 L31.959836339316745,57.396288734965474 L23.192968697183307,54.54286417046167 L24.672008509778422,45.44273003778216 L11.23941,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M11.23941,61.830692 L31.959836339316745,57.396288734965474 L23.192968697183307,54.54286417046167 L24.672008509778422,45.44273003778216 L11.23941,61.830692" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:488.5px;top:250.5px" width="30" height="217" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 216 C -10 166 19 50 9 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-1.3354222499999997,167.0637915 L7.113510048445452,147.63145908682105 L-0.3079557309060377,153.10154552909185 L-6.848735922462701,146.60399256772712 L-1.3354222499999997,167.0637915" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M-1.3354222499999997,167.0637915 L7.113510048445452,147.63145908682105 L-0.3079557309060377,153.10154552909185 L-6.848735922462701,146.60399256772712 L-1.3354222499999997,167.0637915" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:787.5px;top:378.5px" width="163" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 0 88 C -10 38 152 50 142 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M18.563992999999996,60.59109050000001 L39.69226134488013,58.979793895790735 L31.388064423950837,54.97475787867072 L34.07592872355084,46.155722471839894 L18.563992999999996,60.59109050000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M18.563992999999996,60.59109050000001 L39.69226134488013,58.979793895790735 L31.388064423950837,54.97475787867072 L34.07592872355084,46.155722471839894 L18.563992999999996,60.59109050000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:497.5px;top:250.5px" width="311" height="217" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 290 216 C 300 166 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M238.95999999999998,162.5214375 L225.84392762047693,145.87906250917874 L227.14830063392662,155.00586978455078 L218.32835990502772,157.6907618752521 L238.95999999999998,162.5214375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M238.95999999999998,162.5214375 L225.84392762047693,145.87906250917874 L227.14830063392662,155.00586978455078 L218.32835990502772,157.6907618752521 L238.95999999999998,162.5214375" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:196.5px;top:506.5px" width="28" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 7 88 C 17 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M9.235168,66.303232 L13.724569009562899,45.59465217000355 L7.514881717901915,52.40932631773681 L-0.1693366727002843,47.314938452101636 L9.235168,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M9.235168,66.303232 L13.724569009562899,45.59465217000355 L7.514881717901915,52.40932631773681 L-0.1693366727002843,47.314938452101636 L9.235168,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:488.5px;top:506.5px" width="26.5" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 5.5 88 C 15.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M7.868953124999999,66.78168750000002 L12.848095417762192,46.18537370290451 L6.478576933147113,52.85089950918167 L-1.0826925730561543,47.575749894757394 L7.868953124999999,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M7.868953124999999,66.78168750000002 L12.848095417762192,46.18537370290451 L6.478576933147113,52.85089950918167 L-1.0826925730561543,47.575749894757394 L7.868953124999999,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:787.5px;top:506.5px" width="26.5" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 5.5 88 C 15.5 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M7.868953124999999,66.78168750000002 L12.848095417762192,46.18537370290451 L6.478576933147113,52.85089950918167 L-1.0826925730561543,47.575749894757394 L7.868953124999999,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M7.868953124999999,66.78168750000002 L12.848095417762192,46.18537370290451 L6.478576933147113,52.85089950918167 L-1.0826925730561543,47.575749894757394 L7.868953124999999,66.78168750000002" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:181.5px;top:378.5px" width="186" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 165 88 C 175 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M142.03125,60.1875 L125.74937877703124,46.626501899614404 L128.91788305953443,55.28447975889303 L120.84635853592428,59.73986884007997 L142.03125,60.1875" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M142.03125,60.1875 L125.74937877703124,46.626501899614404 L128.91788305953443,55.28447975889303 L120.84635853592428,59.73986884007997 L142.03125,60.1875" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:593.5px;top:378.5px" width="72" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 51 88 C 61 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M48.576,64.44800000000001 L42.12796115021043,44.26328313323161 L40.14937832765171,53.26801577858403 L30.947976928794457,52.6899048055799 L48.576,64.44800000000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M48.576,64.44800000000001 L42.12796115021043,44.26328313323161 L40.14937832765171,53.26801577858403 L30.947976928794457,52.6899048055799 L48.576,64.44800000000001" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><svg style="position:absolute;left:929.5px;top:378.5px" width="35" height="89" pointer-events="none" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" class="_jsPlumb_connector "><path d="M 14 88 C 24 38 -10 50 0 0 " transform="translate(10.5,0.5)" pointer-events="visibleStroke" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="none" stroke="#666" style=""></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M15.636416,66.303232 L18.256834191833065,45.2762634001302 L12.681124621216075,52.61870596266551 L4.57230815449858,48.23155477891412 L15.636416,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path><path pointer-events="all" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" d="M15.636416,66.303232 L18.256834191833065,45.2762634001302 L12.681124621216075,52.61870596266551 L4.57230815449858,48.23155477891412 L15.636416,66.303232" class="" stroke="#666" fill="#666" transform="translate(10.5,0.5)"></path></svg><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 515px; top: 113px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 498px; top: 241px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 498px; top: 201px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 182px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 182px; top: 329px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 594px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 594px; top: 329px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 930px; top: 369px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 930px; top: 329px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 186px; top: 241px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 700px; top: 241px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 965px; top: 241px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 197px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 197px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 489px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 489px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 788px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 788px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 204px; top: 625px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 204px; top: 585px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 494.5px; top: 625px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 494.5px; top: 585px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 793.5px; top: 625px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 793.5px; top: 585px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 347px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 347px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 645px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 645px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 944px; top: 497px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div><div class="_jsPlumb_endpoint target-endpoint dependency-target-endpoint _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable _jsPlumb_endpoint_connected" style="position: absolute; height: 20px; width: 20px; left: 944px; top: 457px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1"
                            xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div></body></html>
 ]]>
                          </visualization>
                        </metadata>
                      </job>