<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.14" xsi:schemaLocation="urn:proactive:jobdescriptor:3.14 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.14/schedulerjob.xsd"  name="MaaS_ML_Service_Start" tags="Services,Azure,Model deployment,Model Management" projectName="1. MaaS_ML" priority="normal" onTaskError="continueJobExecution"  maxNumberOfExecution="2"  >
  <variables>
    <variable name="CONTAINER_PLATFORM" value="docker" model="PA:LIST(docker,singularity)" description="The container platform to be used for executing the workflow tasks." group="Container Parameters" advanced="true" hidden="false"/>
    <variable name="MODEL_SERVICE_INSTANCE_NAME" value="maas-ml-${PA_JOB_ID}"  description="The service instance name." group="MaaS_ML Service Configuration" advanced="true" hidden="false"/>
    <variable name="MODEL_SERVICE_PROXYFIED" value="True" model="PA:Boolean" description="True if a proxy is needed to protect the access to this model-service endpoint." group="MaaS_ML Service Configuration" advanced="false" hidden="false"/>
    <variable name="MODEL_SERVICE_ENTRYPOINT" value="ml_service"  description="This entry script starts the service and defines the different functions to deploy the model, scores the prediction requests based on the deployed model, and returns the results." group="MaaS_ML Service Configuration" advanced="true" hidden="false"/>
    <variable name="MODEL_SERVICE_YAML_FILE" value="ml_service-api"  description="A YAML file that describes the OpenAPI Specification ver. 2 (known as Swagger Spec) of the service. This file should be stored in the catalog under the model_as_service_resources bucket." group="MaaS_ML Service Configuration" advanced="true" hidden="false"/>
    <variable name="MODEL_SERVICE_USER_NAME" value="user"  description="A valid username having the needed privileges to execute this action." group="MaaS_ML Service Configuration" advanced="false" hidden="false"/>
    <variable name="MODEL_SERVICE_NODE_NAME" value=""  description="The name of the node where the service will be deployed. If empty, the service will be deployed on an available node selected randomly." group="Resource Management" advanced="false" hidden="false"/>
    <variable name="USE_NVIDIA_RAPIDS" value="False" model="PA:Boolean" description="If True, the service will be configured to use the GPU and the Nvidia Rapids library." group="MaaS_ML Service Configuration" advanced="false" hidden="false"/>
  </variables>
  <description>
    <![CDATA[ Start a server to deploy, update and call ML models. ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="ai-model-as-a-service"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/model_as_service.png"/>
    <info name="Documentation" value="PAIO/PAIOUserGuide.html#_start_a_generic_service_instance"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="MaaS_ML_Service_Start" 
    
    onTaskError="cancelJob" 
    
    
    fork="true">
      <description>
        <![CDATA[ Start a model server to deploy ML models. ]]>
      </description>
      <variables>
        <variable inherited="false" name="SERVICE_ACTIVATION_WORKFLOW" value="service-automation/MaaS_ML" model="PA:CATALOG_OBJECT(Workflow/psa)" group="Service Parameters" description="The service activation workflow. Please keep the default value for this variable." advanced="false" hidden="false"/>
        <variable name="INSTANCE_NAME" value="$MODEL_SERVICE_INSTANCE_NAME" inherited="false"  description="The name of the service that will be deployed." group="Service Parameters" advanced="false" hidden="false"/>
        <variable name="ENGINE" value="$CONTAINER_PLATFORM" inherited="false"  description="The container platform that will be used (no container, docker, singularity, or podman)." group="Service Parameters" advanced="false" hidden="false"/>
        <variable name="PROXYFIED" value="$MODEL_SERVICE_PROXYFIED" inherited="false"  description="True if a proxy is needed to protect the access to this model-service endpoint. It takes by default the value of MODEL_SERVICE_PROXYFIED workflow variable." group="Service Parameters" advanced="false" hidden="false"/>
        <variable name="PYTHON_ENTRYPOINT" value="$MODEL_SERVICE_ENTRYPOINT" inherited="false"  description="This entry script starts the service and defines the different functions to deploy the model, scores the prediction requests based on the deployed model, and returns the results. This script is specific to your model. It takes by default the value of MODEL_SERVICE_ENTRYPOINT workflow variable." group="MaaS_ML Service Configuration" advanced="false" hidden="false"/>
        <variable name="YAML_FILE" value="$MODEL_SERVICE_YAML_FILE" inherited="false"  description="A YAML file that describes the OpenAPI Specification ver. 2 (known as Swagger Spec) of the service. This file should be stored in the catalog under the model_as_service_resources bucket.   It takes by default the value of MODEL_SERVICE_YAML_FILE workflow variable." group="MaaS_ML Service Configuration" advanced="false" hidden="false"/>
        <variable name="USER_NAME" value="$MODEL_SERVICE_USER_NAME" inherited="false"  description="A valid username having the needed privileges to execute this action. It takes by default the value of MODEL_SERVICE_USER_NAME workflow variable." group="MaaS_ML Service Configuration" advanced="false" hidden="false"/>
        <variable name="NODE_NAME" value="$MODEL_SERVICE_NODE_NAME" inherited="false"  description="The name of the node where the service will be deployed. If empty, the service will be deployed on an available node selected randomly. It takes by default the value of MODEL_SERVICE_NODE_NAME workflow variable." group="Resource Management" advanced="false" hidden="false"/>
        <variable name="GPU_ENABLED" value="$USE_NVIDIA_RAPIDS" inherited="false"  description="If True, the service will be configured to use the GPU and the Nvidia Rapids library." group="Resource Management" advanced="false" hidden="false"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/model_as_service.png"/>
        <info name="task.documentation" value="PAIO/PAIOUserGuide.html#_start_a_generic_service_instance"/>
      </genericInformation>
      <scriptExecutable>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/service-automation/resources/Service_Start/raw" language="groovy">
            <arguments>
              <argument value="true"/>
              <argument value="NATIVE_SCHEDULER"/>
              <argument value="NATIVE_SCHEDULER_PARAMS"/>
              <argument value="ENGINE"/>
              <argument value="PROXYFIED"/>
              <argument value="PYTHON_ENTRYPOINT"/>
              <argument value="YAML_FILE"/>
              <argument value="NODE_NAME"/>
              <argument value="GPU_ENABLED"/>
              <argument value="DRIFT_ENABLED"/>
              <argument value="DRIFT_NOTIFICATION"/>
            </arguments>
          </file>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
      <post>
        <script>
          <file url="${PA_CATALOG_REST_URL}/buckets/ai-model-as-a-service/resources/MaaS_Start_Post_Script/raw" language="cpython"></file>
        </script>
      </post>
      <metadata>
        <positionTop>
            111.8125
        </positionTop>
        <positionLeft>
            204.6875
        </positionLeft>
      </metadata>
    </task>
  </taskFlow>
  <metadata>
    <visualization>
      <![CDATA[ <html>
    <head>
    <link rel="stylesheet" href="/studio/styles/studio-standalone.css">
        <style>
        #workflow-designer {
            left:0 !important;
            top:0 !important;
            width:2146px;
            height:2284px;
            }
        </style>
    </head>
    <body>
    <div id="workflow-visualization-view"><div id="workflow-visualization" style="position:relative;top:-106.8125px;left:-199.6875px"><div class="task _jsPlumb_endpoint_anchor_ ui-draggable" id="jsPlumb_1_1273" style="top: 111.812px; left: 204.688px;"><a class="task-name" data-toggle="tooltip" data-placement="right" title="Start a model server to deploy ML models."><img src="/automation-dashboard/styles/patterns/img/wf-icons/model_as_service.png" width="20px">&nbsp;<span class="name">MaaS_ML_Service_Start</span></a></div><div class="_jsPlumb_endpoint source-endpoint dependency-source-endpoint connected _jsPlumb_endpoint_anchor_ ui-draggable ui-droppable" style="position: absolute; height: 20px; width: 20px; left: 268px; top: 142px;"><svg style="position:absolute;left:0px;top:0px" width="20" height="20" pointer-events="all" position="absolute" version="1.1" xmlns="http://www.w3.org/1999/xhtml"><circle cx="10" cy="10" r="10" version="1.1" xmlns="http://www.w3.org/1999/xhtml" fill="#666" stroke="none" style=""></circle></svg></div></div></div>
    </body>
</html>
 ]]>
    </visualization>
  </metadata>
</job>