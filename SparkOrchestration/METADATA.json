{
	"metadata": {
		"slug": "sparkorchestration",
		"name": "Spark Orchestration",
		"short_description": "Orchestrate Spark jobs from ProActive",
		"author": "ActiveEon's Team",
		"tags": ["Building blocks", "Spark", "Orchestration", "Big Data", "Analytics"],
		"version": "1.0"
	},
	"catalog" : {
		"bucket" : "big-data",
		"objects" : [
			{
				"name" : "Spark_Pi",
				"metadata" : {
					"kind": "Workflow/standard",
					"commitMessage": "First commit",
					"contentType": "application/xml"
				},
				"file" : "resources/catalog/Spark_Pi.xml",
				"studio_template" : {
					"name" : "Spark_Pi",
					"offsets_json_string": "{\"offsets\":{\"Spark_Pi\":{\"top\":620.5,\"left\":986}},\"project\":\"Basic Big Data\",\"detailedView\":true}"
				}
			},
			{
				"name" : "Spark_Write_Read_HDFS",
				"metadata" : {
					"kind": "Workflow/standard",
					"commitMessage": "First commit",
					"contentType": "application/xml"
				},
				"file" : "resources/catalog/Spark_Write_Read_HDFS.xml",
				"studio_template" : {
					"name" : "Spark_Write_Read_HDFS",
					"offsets_json_string": "{\"offsets\":{\"Spark_Write_Read_HDFS\":{\"top\":620.5,\"left\":986}},\"project\":\"Basic Big Data\",\"detailedView\":true}"
				}
			}
		]
	}
}
